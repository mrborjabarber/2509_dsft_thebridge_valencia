{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JpS8k_tshonl"
   },
   "source": [
    "## Web scrapping de IMDB"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descarga la información correspondiente y guarda en un csv el top de las 250 películas mediante webscrapping. Encapsúlalo en un script.\n",
    "\n",
    "Obtén:\n",
    "* Título\n",
    "* Año\n",
    "* Duración\n",
    "* Posición\n",
    "* Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si la petición te devuelve un 403, puedes probar con:\n",
    "# pip install fake-useragent\n",
    "# from fake_useragent import UserAgent\n",
    "# ua = UserAgent()\n",
    "# headers = {'User-Agent': ua.random}\n",
    "# response = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.imdb.com/chart/top/\"\n",
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fake_useragent import UserAgent\n",
    "ua = UserAgent()\n",
    "headers = {'User-Agent': ua.random}\n",
    "response = requests.get(url, headers=headers)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(response.content, 'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in soup.find_all('h3')[1:-1]:\n",
    "    print(x.get_text().split(\". \")[0])\n",
    "    print(x.get_text().split(\". \")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in soup.find_all('span', class_='sc-f30335b4-7 jhjEEd cli-title-metadata-item'):\n",
    "    text = x.get_text()\n",
    "    # print(text)\n",
    "    if \"h\" in text or \"m\" in text:\n",
    "        print(\"Duración:\", text)\n",
    "    if len(text) == 4:\n",
    "        print(\"Año:\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in soup.find_all('span', class_='ipc-rating-star--rating'):\n",
    "    print(x.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in soup.find_all('span', class_='ipc-rating-star--rating'):\n",
    "    print(x.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_top25 = {\n",
    "            \"Titulo\": [x.get_text().split(\". \")[1] for x in soup.find_all('h3')[1:-1]],\n",
    "            \"Ranking\": [x.get_text().split(\". \")[0] for x in soup.find_all('h3')[1:-1]],\n",
    "            \"Año\": [x.get_text() for x in soup.find_all('span', class_='sc-f30335b4-7 jhjEEd cli-title-metadata-item') if len(x.get_text()) == 4],\n",
    "            \"Duración\": [x.get_text() for x in soup.find_all('span', class_='sc-f30335b4-7 jhjEEd cli-title-metadata-item') if \"h\" in x.get_text() or \"m\" in x.get_text()],\n",
    "            \"Rating\": [x.get_text() for x in soup.find_all('span', class_='ipc-rating-star--rating')]\n",
    "            }\n",
    "pd.DataFrame(my_top25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_top25 = {\n",
    "            \"Ranking\": [],\n",
    "            \"Titulo\": [],\n",
    "            \"Año\": [],\n",
    "            \"Duración\": [],\n",
    "            \"Rating\": []\n",
    "            }\n",
    "\n",
    "for p in soup.find_all(\"div\", class_=\"sc-f30335b4-0 eefKuM cli-children\"):\n",
    "    my_top25['Ranking'].append(p.find('div').find('a').find('h3').get_text().split(\". \")[0])\n",
    "    my_top25['Titulo'].append(p.find('div').find('a').find('h3').get_text().split(\". \")[1])\n",
    "    my_top25['Año'].append(p.find(\"div\", class_='sc-f30335b4-6 kGhnhC cli-title-metadata').find('span').get_text())\n",
    "    my_top25['Duración'].append(p.find(\"div\", class_='sc-f30335b4-6 kGhnhC cli-title-metadata').find_all('span')[1].get_text())\n",
    "    my_top25['Rating'].append(p.find(\"span\", class_=\"sc-f30335b4-1 kSqvWq\").get_text()[:3])\n",
    "    \n",
    "\n",
    "df_25 = pd.DataFrame(my_top25)\n",
    "df_25.to_csv(\"./data/top25.csv\")\n",
    "df_25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"milla verde\" in soup.find(\"script\", id=\"__NEXT_DATA__\").get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.loads(soup.find(\"script\", id=\"__NEXT_DATA__\").get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in {\"1\": \"Hola\", \"2\": \"Mundo\"}:\n",
    "#     print(x)\n",
    "\n",
    "json.loads(soup.find(\"script\", type=\"application/ld+json\").get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in json.loads(soup.find(\"script\", type=\"application/ld+json\").get_text())['itemListElement']:\n",
    "    # print(x['item'].get('alternateName', x['item'].get('name')))\n",
    "    # print(x['item']['aggregateRating']['ratingValue'])\n",
    "    print(x['item']['duration'][2:])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in json.loads(soup.find(\"script\", id=\"__NEXT_DATA__\").get_text())['props']['pageProps']['pageData']['chartTitles']['edges']:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.loads(soup.find(\"script\", id=\"__NEXT_DATA__\").get_text())['props']['pageProps']['pageData']['chartTitles']['edges'][0]['node']['releaseYear']['year'])\n",
    "print(json.loads(soup.find(\"script\", id=\"__NEXT_DATA__\").get_text())['props']['pageProps']['pageData']['chartTitles']['edges'][0]['currentRank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_top250 = {\n",
    "            \"Ranking\": [],\n",
    "            \"Titulo\": [],\n",
    "            \"Año\": [],\n",
    "            \"Duración\": [],\n",
    "            \"Rating\": []\n",
    "            }\n",
    "\n",
    "for x in json.loads(soup.find(\"script\", type=\"application/ld+json\").get_text())['itemListElement']:\n",
    "    my_top250['Titulo'].append(x['item'].get('alternateName', x['item'].get('name')))\n",
    "    my_top250['Duración'].append(x['item']['duration'][2:])    \n",
    "    my_top250['Rating'].append(x['item']['aggregateRating']['ratingValue'])\n",
    "    \n",
    "for p in json.loads(soup.find(\"script\", id=\"__NEXT_DATA__\").get_text())['props']['pageProps']['pageData']['chartTitles']['edges']:\n",
    "    my_top250['Año'].append(p['node']['releaseYear']['year'])    \n",
    "    my_top250['Ranking'].append(p['currentRank'])\n",
    "    \n",
    "my_top250 = pd.DataFrame(my_top250)\n",
    "my_top250.to_csv(\"./data/top250.csv\")\n",
    "my_top250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\"data\":[{\"BootcampDS2503\": {\"profesores\":[{\"rol\":\"LI\",\n",
    "#                                         \"name\":\"Miguel\"},\n",
    "#                                        {\"rol\":\"TA\",\n",
    "#                                         \"name\":\"Hugo\"}],\n",
    "#                          \"alumnos\": []}}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_paths(data, target_value, current_path=\"\"):\n",
    "    \"\"\"Encuentra las rutas de las claves que contienen un valor específico en un JSON anidado.\"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            new_path = f\"{current_path}.{key}\" if current_path else key\n",
    "            if value == target_value:\n",
    "                print(f\"Valor encontrado en: {new_path}\")\n",
    "            find_paths(value, target_value, new_path)\n",
    "    \n",
    "    elif isinstance(data, list):\n",
    "        for index, item in enumerate(data):\n",
    "            new_path = f\"{current_path}[{index}]\"\n",
    "            find_paths(item, target_value, new_path)\n",
    "\n",
    "# JSON de ejemplo\n",
    "json_data = {\n",
    "    \"usuario\": {\n",
    "        \"nombre\": \"Carlos\",\n",
    "        \"edad\": 30,\n",
    "        \"direccion\": {\n",
    "            \"ciudad\": \"Madrid\",\n",
    "            \"codigo_postal\": \"28001\"\n",
    "        }\n",
    "    },\n",
    "    \"pedidos\": [\n",
    "        {\"id\": 101, \"producto\": \"Laptop\", \"precio\": 1200},\n",
    "        {\"id\": 102, \"producto\": \"Teléfono\", \"precio\": 800}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Búsqueda del valor \"Madrid\"\n",
    "find_paths(json_data, \"Madrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = json.loads(soup.find(\"script\", id=\"__NEXT_DATA__\").get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_paths(json_data, \"La milla verde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data['props']['pageProps']['pageData']['chartTitles']['edges'][25]['node']['titleText']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/json_ejemplo.json', 'w') as file:\n",
    "    json.dump(json_data, file)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "1-DataAccess.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
