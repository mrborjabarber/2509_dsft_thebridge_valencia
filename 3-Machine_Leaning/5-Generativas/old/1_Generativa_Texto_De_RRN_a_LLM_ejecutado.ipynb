{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZ8-spwGrtMI"
      },
      "source": [
        "<img src=\"https://github.com/Jaimegrp/Practicando/blob/main/Texto/img/cabecera.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43dkXdozrtMK"
      },
      "source": [
        "## Una (muy) breve (pero densa) introducción a la IA Generativa en Textos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4Tab-WKrtMK"
      },
      "source": [
        "*NOTA: Este notebook adapta y amplía parte del capítulo dedicado a NLP en el excelente libro [Hands on Machine Learning for Python](https://learning.oreilly.com/library/view/hands-on-machine-learning/9781492032632/ch16.html#nlp_chapter)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-TYG-VJrtML"
      },
      "source": [
        "La generación de textos y más que eso el tratamiento de lenguaje natural ha dado un salto \"cuántico\" en los últimos años dentro del campo de la IA. Vamos a ver de una forma poco ortodoxa la evolución partiendo de las arquitecturas más complejas sobre redes recurrentes hasta terminar en los instruct LLM (la base de la IA multimodal generativa actual). Será un viaje denso y breve, pero espero que despierte el interés en ti para ampliar más con el material extra que se proporciona en la plataforma y en algunos enlaces de este notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTwE2Qu4rtMM"
      },
      "source": [
        "*Antes de empezar, este notebook \"no\" se recomienda si no se ejecuta en un entorno con GPU disponible. Si no es el caso -> Colab:*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUIn-3_qrtMM"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/Jaimegrp/DS_Online_Oct23/blob/main/05_Deep_Learning/Sprint_21/02_NLP_y_Texto/Generativa_Texto_De_RRN_a_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOQNKhDtrtMN",
        "outputId": "6af1eaa6-d7f5-4a10-e310-769f29be896d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Note: using Google CoLab\n",
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XXGCfC43rtMN"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "assert sys.version_info >= (3, 7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gCHANlswrtMO"
      },
      "outputs": [],
      "source": [
        "from packaging import version\n",
        "import sklearn\n",
        "\n",
        "assert version.parse(sklearn.__version__) >= version.parse(\"1.0.1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Rg025n4NrtMO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "assert version.parse(tf.__version__) >= version.parse(\"2.8.0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6pZ5hfvkrtMP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from collections import Counter\n",
        "from IPython.display import clear_output\n",
        "from pathlib import Path\n",
        "from random import random, randint,sample\n",
        "from time import time, sleep\n",
        "\n",
        "\n",
        "plt.rc('font', size=14)\n",
        "plt.rc('axes', labelsize=14, titlesize=14)\n",
        "plt.rc('legend', fontsize=14)\n",
        "plt.rc('xtick', labelsize=10)\n",
        "plt.rc('ytick', labelsize=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oqYnbmiRrtMP"
      },
      "outputs": [],
      "source": [
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"No GPU was detected. Neural nets can be very slow without a GPU.\")\n",
        "    if \"google.colab\" in sys.modules:\n",
        "        print(\"Go to Runtime > Change runtime and select a GPU hardware \"\n",
        "              \"accelerator.\")\n",
        "    if \"kaggle_secrets\" in sys.modules:\n",
        "        print(\"Go to Settings > Accelerator and select GPU.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDnv_Sx0rtMP"
      },
      "source": [
        "## Usando RNNs: Una estructura Encoder-Decoder para traducir de inglés a español"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBcIBBUArtMP"
      },
      "source": [
        "El primer gran avance por encima de la vectorización y las técnicas iniciales de resumen (summarization), traducción (translation), preguntas y respuestas (Q&A), es el empleo de redes recurrentes en el tratamiento de textos. Veamos un ejemplo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiDAs2-VrtMP"
      },
      "source": [
        "El objetivo del siguiente ejemplo es doble:  \n",
        "1. Mostrar como las redes recurrentes pueden configurarse para tratar un problema de traducción donde a una secuencia de entrada de longitud variable le corresponderá una secuencia de longitud variable y además no necesariamente coincidente, en dicha longitud, con la de entrada. Este problema se aplica a la traducción de inglés a español pero es un esquema que se puede emplear en cualquier tipo de cambio de representación entre secuencias (yes, para pasar de una secuencia a una imagen y viceversa).  \n",
        "\n",
        "2. Introducir de forma progresiva el concepto de Atention (atención) para mejorar el modelo anterior y sobre este la arquitectura conocida como Transformers, que nos permitirá hablar de GPT, BERT y los LLN (Large Language Models, no Master of Laws, ojo) en general."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ81WAyHrtMQ"
      },
      "source": [
        "### El dataset de entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh3YfbK_rtMQ"
      },
      "source": [
        "Utilizaremos un datset que empareja palabras y frases en inglés con sus traducciones al español de Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EhfQe-d36cTe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kry1EyVWrtMQ",
        "outputId": "b16f0eeb-b075-401b-a316-65b0139a6728"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "\u001b[1m2638744/2638744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "url = \"https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\"\n",
        "path = tf.keras.utils.get_file(\"spa-eng.zip\", origin=url, cache_dir=\".\",\n",
        "                               extract=True)\n",
        "text = (Path(path).with_name(\"spa-eng_extracted\") / \"spa-eng\" / \"spa.txt\").read_text(encoding = \"utf-8\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls datasets/spa-eng_extracted/spa-eng"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "locaqR4FBtB6",
        "outputId": "a95f2565-b495-48af-ff76-e2e5e4f53acc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_about.txt  spa.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emipPlQartMQ"
      },
      "source": [
        "Observamos su contenido (siempre hay que mirar la mercancía antes de ponerse a cocinar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PsOOYjNrtMQ",
        "outputId": "077b978c-9021-45d1-c920-bd0630d79e86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go.\tVe.\n",
            "Go.\tVete.\n",
            "Go.\tVaya.\n",
            "Go.\tVáyase.\n",
            "Hi.\tHola.\n",
            "Run!\t¡Corre!\n",
            "Run.\tCorred.\n",
            "Who?\t¿Quién?\n",
            "Fire!\t¡Fueg\n"
          ]
        }
      ],
      "source": [
        "print(text[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "P8CXept6nklu",
        "outputId": "4e0aa9e9-1649-4995-ae18-e362efc633bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'or correo electrónico las URL\\'s de esas páginas web y ver el contenido en tu computadora cuando llegas a casa.\\nA mistake young people often make is to start learning too many languages at the same time, as they underestimate the difficulties and overestimate their own ability to learn them.\\tUn error que cometen a menudo los jóvenes es el de comenzar a aprender demasiadas lenguas al mismo tiempo, porque subestiman sus dificultades y sobrestiman sus propias capacidades para aprenderlas.\\nNo matter how much you try to convince people that chocolate is vanilla, it\\'ll still be chocolate, even though you may manage to convince yourself and a few others that it\\'s vanilla.\\tNo importa cuánto insistas en convencer a la gente de que el chocolate es vainilla, seguirá siendo chocolate, aunque puede que te convenzas a ti mismo y a algunos otros de que es vainilla.\\nIn 1969, Roger Miller recorded a song called \"You Don\\'t Want My Love.\" Today, this song is better known as \"In the Summer Time.\" It\\'s the first song he wrote and sang that became popular.\\tEn 1969, Roger Miller grabó una canción llamada \"Tú no quieres mi amor\". Hoy, esta canción es más conocida como \"En el verano\". Es la primera canción que escribió y cantó que se convirtió popular.\\nA child who is a native speaker usually knows many things about his or her language that a non-native speaker who has been studying for years still does not know and perhaps will never know.\\tUn niño que es hablante nativo normalmente sabe muchas cosas acerca de su lengua que un hablante no nativo que lo haya estado estudiando durante muchos años no sabe todavía y que quizá no sabrá nunca.\\nThere are four main causes of alcohol-related death. Injury from car accidents or violence is one. Diseases like cirrhosis of the liver, cancer, heart and blood system diseases are the others.\\tHay cuatro causas principales de muertes relacionadas con el alcohol. Lesión por un accidente automovilístico o violencia es una. Enfermedades como cirrosis del hígado, cáncer, enfermedades del corazón y del sistema circulatorio son las otras.\\nThere are mothers and fathers who will lie awake after the children fall asleep and wonder how they\\'ll make the mortgage, or pay their doctor\\'s bills, or save enough for their child\\'s college education.\\tHay madres y padres que se quedan despiertos después de que sus hijos se hayan dormido y se preguntan cómo conseguir pagar la hipoteca o las facturas del médico, o cómo ahorrar el suficiente dinero para la educación universitaria de sus hijos.\\nA carbon footprint is the amount of carbon dioxide pollution that we produce as a result of our activities. Some people try to reduce their carbon footprint because they are concerned about climate change.\\tUna huella de carbono es la cantidad de contaminación de dióxido de carbono que producimos como producto de nuestras actividades. Algunas personas intentan reducir su huella de carbono porque están preocupados acerca del cambio climático.\\nSince there are usually multiple websites on any given topic, I usually just click the back button when I arrive on any webpage that has pop-up advertising. I just go to the next page found by Google and hope for something less irritating.\\tComo suele haber varias páginas web sobre cualquier tema, normalmente sólo le doy al botón de retroceso cuando entro en una página web que tiene anuncios en ventanas emergentes. Simplemente voy a la siguiente página encontrada por Google y espero encontrar algo menos irritante.\\nIf you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo.\\tSi quieres sonar como un hablante nativo, debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un músico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "text[-4000:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34GsOC45rtMQ"
      },
      "source": [
        "Lo transformamos para que sea una relación de secuencia a secuencia (dada una secuencia tenemos su target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "o8hoHlQwrtMR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "text = text.replace(\"¡\", \"\").replace(\"¿\", \"\")\n",
        "pairs = [line.split(\"\\t\") for line in text.splitlines()]\n",
        "np.random.shuffle(pairs)\n",
        "sentences_en, sentences_es = zip(*pairs)  # separa las parejas en dos listas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "hr6GoqdzuVq9",
        "outputId": "5511c55a-420a-48e0-ec75-2bb8476897ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tenemos 118964 sentencias para entrenar\n",
            "Distribuciones del corpus en inglés\n",
            "count    118964.000000\n",
            "mean          6.310363\n",
            "std           2.611586\n",
            "min           1.000000\n",
            "25%           4.000000\n",
            "50%           6.000000\n",
            "75%           8.000000\n",
            "max          47.000000\n",
            "dtype: float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAGdCAYAAADwjmIIAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAL45JREFUeJzt3Xt4lPWd//9XEpIJASYclIQsp+yFBVJOkkiYeliEkJGmXqLRRctqFhFXmriGuVbaeGE42WJxOdZgahVwL6Ui3QuqgJDZIKGW4RTIloOwuqUXbnESK4dgkMmQme8f/eX+OQ0kmWgOfPJ8XFcuuO/P+77nM/c7N768576TiGAwGBQAAIBhItt7AgAAAK2BkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMFKX9p5AewoEAjp79qx69OihiIiI9p4OAABohmAwqEuXLikpKUmRkde/XtOpQ87Zs2c1YMCA9p4GAABogU8//VT9+/e/7ninDjk9evSQ9NeDZLfbm6z3+/0qKSlRZmamoqOjW3t6uA760DHQh46BPnQM9KFtVVdXa8CAAdZ/x6+nU4ec+o+o7HZ7s0NOXFyc7HY738TtiD50DPShY6APHQN9aB9N3WrCjccAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMFLYIefPf/6z/umf/kl9+vRR165dNXLkSB06dMgaDwaDKiwsVL9+/dS1a1dlZGTo448/DtnHuXPnNH36dNntdvXs2VMzZ87Ul19+GVLzhz/8QXfeeadiY2M1YMAALV26tMFcNm3apGHDhik2NlYjR47U9u3bw307AADAUGGFnPPnz+v2229XdHS03n//fZ04cULLli1Tr169rJqlS5dq9erVKi4u1v79+9WtWzc5nU5duXLFqpk+fbqOHz8ut9utrVu3as+ePXryySet8erqamVmZmrQoEEqLy/XSy+9pAULFujVV1+1avbu3atHHnlEM2fO1JEjRzR16lRNnTpVx44d+ybHAwAAmCIYhh//+MfBO+6447rjgUAgmJiYGHzppZesdRcuXAjabLbgr3/962AwGAyeOHEiKCl48OBBq+b9998PRkREBP/85z8Hg8FgcM2aNcFevXoFfT5fyGsPHTrUWv7Hf/zHYFZWVsjrp6enB//lX/6l2e/n4sWLQUnBixcvNqu+trY2uGXLlmBtbW2zXwPfPvrQMdCHjoE+dAz0oW0197/fXcIJRO+++66cTqceeughlZWV6e/+7u/0ox/9SLNmzZIknT59Wl6vVxkZGdY28fHxSk9Pl8fj0cMPPyyPx6OePXsqLS3NqsnIyFBkZKT279+v+++/Xx6PR3fddZdiYmKsGqfTqZ///Oc6f/68evXqJY/HI5fLFTI/p9OpLVu2XHf+Pp9PPp/PWq6urpYk+f1++f3+Jt9/fU1zam9EIxbsbO8pNIstMqjFaVLqoh0qL7ynvafTaZl+Ptwo6EPHQB/aVnOPc1gh549//KNeeeUVuVwuPffcczp48KD+9V//VTExMcrJyZHX65UkJSQkhGyXkJBgjXm9XvXt2zd0El26qHfv3iE1ycnJDfZRP9arVy95vd5GX+dalixZooULFzZYX1JSori4uOYcAkmS2+1udu2NZOm49p5BeBanBbgPqwMw9Xy40dCHjoE+tI3Lly83qy6skBMIBJSWlqaf/exnkqRbb71Vx44dU3FxsXJycsKfZRsrKCgIufpTXV2tAQMGKDMzU3a7vcnt/X6/3G63Jk+erOjo6Nacaru4sa7kBPT8oUiu5LQj08+HGwV96BjoQ9uq/ySmKWGFnH79+iklJSVk3fDhw/Wf//mfkqTExERJUmVlpfr162fVVFZWasyYMVZNVVVVyD6uXr2qc+fOWdsnJiaqsrIypKZ+uama+vFrsdlsstlsDdZHR0eH9U0Zbv2NwlcX0d5TCIsvEGFkH240pp4PNxr60DHQh7bR3GMc1tNVt99+u06dOhWy7n/+5380aNAgSVJycrISExNVWlpqjVdXV2v//v1yOBySJIfDoQsXLqi8vNyq2bVrlwKBgNLT062aPXv2hHzm5na7NXToUOtJLofDEfI69TX1rwMAADq3sELOnDlztG/fPv3sZz/TJ598og0bNujVV19Vbm6uJCkiIkL5+fl64YUX9O677+ro0aN67LHHlJSUpKlTp0r665Wfe+65R7NmzdKBAwf0+9//Xnl5eXr44YeVlJQkSfrhD3+omJgYzZw5U8ePH9fGjRu1atWqkI+annnmGe3YsUPLli3TyZMntWDBAh06dEh5eXnf0qEBAAA3srA+rrrtttu0efNmFRQUaNGiRUpOTtbKlSs1ffp0q2bu3LmqqanRk08+qQsXLuiOO+7Qjh07FBsba9W89dZbysvL06RJkxQZGans7GytXr3aGo+Pj1dJSYlyc3OVmpqqm266SYWFhSE/S+d73/ueNmzYoHnz5um5557TLbfcoi1btmjEiBHf5HgAAABDhBVyJOkHP/iBfvCDH1x3PCIiQosWLdKiRYuuW9O7d29t2LCh0dcZNWqUfve73zVa89BDD+mhhx5qfMIAAKBT4ndXAQAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGKlLe0/AVIN/sq29pwAAQKcW1pWcBQsWKCIiIuRr2LBh1viVK1eUm5urPn36qHv37srOzlZlZWXIPs6cOaOsrCzFxcWpb9++evbZZ3X16tWQmt27d2vs2LGy2WwaMmSI1q9f32AuRUVFGjx4sGJjY5Wenq4DBw6E81YAAIDhwv646rvf/a4+++wz6+vDDz+0xubMmaP33ntPmzZtUllZmc6ePasHHnjAGq+rq1NWVpZqa2u1d+9evfHGG1q/fr0KCwutmtOnTysrK0t33323KioqlJ+fryeeeEI7d+60ajZu3CiXy6X58+fr8OHDGj16tJxOp6qqqlp6HAAAgGHCDjldunRRYmKi9XXTTTdJki5evKjXX39dy5cv18SJE5Wamqp169Zp79692rdvnySppKREJ06c0JtvvqkxY8ZoypQpWrx4sYqKilRbWytJKi4uVnJyspYtW6bhw4crLy9PDz74oFasWGHNYfny5Zo1a5ZmzJihlJQUFRcXKy4uTmvXrv02jgkAADBA2CHn448/VlJSkv7+7/9e06dP15kzZyRJ5eXl8vv9ysjIsGqHDRumgQMHyuPxSJI8Ho9GjhyphIQEq8bpdKq6ulrHjx+3ar6+j/qa+n3U1taqvLw8pCYyMlIZGRlWDQAAQFg3Hqenp2v9+vUaOnSoPvvsMy1cuFB33nmnjh07Jq/Xq5iYGPXs2TNkm4SEBHm9XkmS1+sNCTj14/VjjdVUV1frq6++0vnz51VXV3fNmpMnTzY6f5/PJ5/PZy1XV1dLkvx+v/x+f5Pvv76mObW2qGCTNWgZW2TQ+rM5vUDrCOd8QOuhDx0DfWhbzT3OYYWcKVOmWH8fNWqU0tPTNWjQIL3zzjvq2rVreDNsB0uWLNHChQsbrC8pKVFcXFyz9+N2u5usWTourKmhBRanBbR9+/b2nkan15zzAa2PPnQM9KFtXL58uVl13+gR8p49e+o73/mOPvnkE02ePFm1tbW6cOFCyNWcyspKJSYmSpISExMbPAVV//TV12v+9omsyspK2e12de3aVVFRUYqKirpmTf0+rqegoEAul8tarq6u1oABA5SZmSm73d7k+/X7/XK73Zo8ebKio6MbrR2xYGej42g5W2RQi9MCev5QpMoL72nv6XRa4ZwPaD30oWOgD22r/pOYpnyjkPPll1/qf//3f/Xoo48qNTVV0dHRKi0tVXZ2tiTp1KlTOnPmjBwOhyTJ4XDopz/9qaqqqtS3b19Jf029drtdKSkpVs3f/t+52+229hETE6PU1FSVlpZq6tSpkqRAIKDS0lLl5eU1Ol+bzSabzdZgfXR0dFjflM2p99VFNHt/aBlfIIJ/TDqAcM8ftA760DHQh7bR3GMc1o3H//Zv/6aysjL96U9/0t69e3X//fcrKipKjzzyiOLj4zVz5ky5XC598MEHKi8v14wZM+RwODR+/HhJUmZmplJSUvToo4/qv//7v7Vz507NmzdPubm5Vvh46qmn9Mc//lFz587VyZMntWbNGr3zzjuaM2eONQ+Xy6Vf/epXeuONN/TRRx9p9uzZqqmp0YwZM8J5OwAAwGBhXcn5v//7Pz3yyCP64osvdPPNN+uOO+7Qvn37dPPNN0uSVqxYocjISGVnZ8vn88npdGrNmjXW9lFRUdq6datmz54th8Ohbt26KScnR4sWLbJqkpOTtW3bNs2ZM0erVq1S//799dprr8npdFo106ZN0+eff67CwkJ5vV6NGTNGO3bsaHAzMgAA6LzCCjlvv/12o+OxsbEqKipSUVHRdWsGDRrU5M2iEyZM0JEjRxqtycvLa/LjKQAA0HnxCzoBAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjfaOQ8+KLLyoiIkL5+fnWuitXrig3N1d9+vRR9+7dlZ2drcrKypDtzpw5o6ysLMXFxalv37569tlndfXq1ZCa3bt3a+zYsbLZbBoyZIjWr1/f4PWLioo0ePBgxcbGKj09XQcOHPgmbwcAABikxSHn4MGD+uUvf6lRo0aFrJ8zZ47ee+89bdq0SWVlZTp79qweeOABa7yurk5ZWVmqra3V3r179cYbb2j9+vUqLCy0ak6fPq2srCzdfffdqqioUH5+vp544gnt3LnTqtm4caNcLpfmz5+vw4cPa/To0XI6naqqqmrpWwIAAAZpUcj58ssvNX36dP3qV79Sr169rPUXL17U66+/ruXLl2vixIlKTU3VunXrtHfvXu3bt0+SVFJSohMnTujNN9/UmDFjNGXKFC1evFhFRUWqra2VJBUXFys5OVnLli3T8OHDlZeXpwcffFArVqywXmv58uWaNWuWZsyYoZSUFBUXFysuLk5r1679JscDAAAYoktLNsrNzVVWVpYyMjL0wgsvWOvLy8vl9/uVkZFhrRs2bJgGDhwoj8ej8ePHy+PxaOTIkUpISLBqnE6nZs+erePHj+vWW2+Vx+MJ2Ud9Tf3HYrW1tSovL1dBQYE1HhkZqYyMDHk8nuvO2+fzyefzWcvV1dWSJL/fL7/f3+T7rq9pTq0tKthkDVrGFhm0/mxOL9A6wjkf0HroQ8dAH9pWc49z2CHn7bff1uHDh3Xw4MEGY16vVzExMerZs2fI+oSEBHm9Xqvm6wGnfrx+rLGa6upqffXVVzp//rzq6uquWXPy5Mnrzn3JkiVauHBhg/UlJSWKi4u77nZ/y+12N1mzdFyzd4cWWpwW0Pbt29t7Gp1ec84HtD760DHQh7Zx+fLlZtWFFXI+/fRTPfPMM3K73YqNjW3RxNpTQUGBXC6XtVxdXa0BAwYoMzNTdru9ye39fr/cbrcmT56s6OjoRmtHLNjZ6DhazhYZ1OK0gJ4/FKnywnvaezqdVjjnA1oPfegY6EPbqv8kpilhhZzy8nJVVVVp7Nix1rq6ujrt2bNHL7/8snbu3Kna2lpduHAh5GpOZWWlEhMTJUmJiYkNnoKqf/rq6zV/+0RWZWWl7Ha7unbtqqioKEVFRV2zpn4f12Kz2WSz2Rqsj46ODuubsjn1vrqIZu8PLeMLRPCPSQcQ7vmD1kEfOgb60Daae4zDuvF40qRJOnr0qCoqKqyvtLQ0TZ8+3fp7dHS0SktLrW1OnTqlM2fOyOFwSJIcDoeOHj0a8hSU2+2W3W5XSkqKVfP1fdTX1O8jJiZGqampITWBQEClpaVWDQAA6NzCupLTo0cPjRgxImRdt27d1KdPH2v9zJkz5XK51Lt3b9ntdj399NNyOBwaP368JCkzM1MpKSl69NFHtXTpUnm9Xs2bN0+5ubnWVZannnpKL7/8subOnavHH39cu3bt0jvvvKNt27ZZr+tyuZSTk6O0tDSNGzdOK1euVE1NjWbMmPGNDggAADBDi56uasyKFSsUGRmp7Oxs+Xw+OZ1OrVmzxhqPiorS1q1bNXv2bDkcDnXr1k05OTlatGiRVZOcnKxt27Zpzpw5WrVqlfr376/XXntNTqfTqpk2bZo+//xzFRYWyuv1asyYMdqxY0eDm5EBAEDn9I1Dzu7du0OWY2NjVVRUpKKioutuM2jQoCafipkwYYKOHDnSaE1eXp7y8vKaPVcAANB58LurAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAI4UVcl555RWNGjVKdrtddrtdDodD77//vjV+5coV5ebmqk+fPurevbuys7NVWVkZso8zZ84oKytLcXFx6tu3r5599lldvXo1pGb37t0aO3asbDabhgwZovXr1zeYS1FRkQYPHqzY2Filp6frwIED4bwVAABguLBCTv/+/fXiiy+qvLxchw4d0sSJE3Xffffp+PHjkqQ5c+bovffe06ZNm1RWVqazZ8/qgQcesLavq6tTVlaWamtrtXfvXr3xxhtav369CgsLrZrTp08rKytLd999tyoqKpSfn68nnnhCO3futGo2btwol8ul+fPn6/Dhwxo9erScTqeqqqq+6fEAAACGCCvk3Hvvvfr+97+vW265Rd/5znf005/+VN27d9e+fft08eJFvf7661q+fLkmTpyo1NRUrVu3Tnv37tW+ffskSSUlJTpx4oTefPNNjRkzRlOmTNHixYtVVFSk2tpaSVJxcbGSk5O1bNkyDR8+XHl5eXrwwQe1YsUKax7Lly/XrFmzNGPGDKWkpKi4uFhxcXFau3btt3hoAADAjaxLSzesq6vTpk2bVFNTI4fDofLycvn9fmVkZFg1w4YN08CBA+XxeDR+/Hh5PB6NHDlSCQkJVo3T6dTs2bN1/Phx3XrrrfJ4PCH7qK/Jz8+XJNXW1qq8vFwFBQXWeGRkpDIyMuTxeBqds8/nk8/ns5arq6slSX6/X36/v8n3XF/TnFpbVLDJGrSMLTJo/dmcXqB1hHM+oPXQh46BPrSt5h7nsEPO0aNH5XA4dOXKFXXv3l2bN29WSkqKKioqFBMTo549e4bUJyQkyOv1SpK8Xm9IwKkfrx9rrKa6ulpfffWVzp8/r7q6umvWnDx5stG5L1myRAsXLmywvqSkRHFxcU2/+f+P2+1usmbpuGbvDi20OC2g7du3t/c0Or3mnA9offShY6APbePy5cvNqgs75AwdOlQVFRW6ePGifvOb3ygnJ0dlZWVhT7A9FBQUyOVyWcvV1dUaMGCAMjMzZbfbm9ze7/fL7XZr8uTJio6ObrR2xIKdjY6j5WyRQS1OC+j5Q5EqL7ynvafTaYVzPqD10IeOgT60rfpPYpoSdsiJiYnRkCFDJEmpqak6ePCgVq1apWnTpqm2tlYXLlwIuZpTWVmpxMRESVJiYmKDp6Dqn776es3fPpFVWVkpu92url27KioqSlFRUdesqd/H9dhsNtlstgbro6Ojw/qmbE69ry6i2ftDy/gCEfxj0gGEe/6gddCHjoE+tI3mHuNv/HNyAoGAfD6fUlNTFR0drdLSUmvs1KlTOnPmjBwOhyTJ4XDo6NGjIU9Bud1u2e12paSkWDVf30d9Tf0+YmJilJqaGlITCARUWlpq1QAAAIR1JaegoEBTpkzRwIEDdenSJW3YsEG7d+/Wzp07FR8fr5kzZ8rlcql3796y2+16+umn5XA4NH78eElSZmamUlJS9Oijj2rp0qXyer2aN2+ecnNzrSssTz31lF5++WXNnTtXjz/+uHbt2qV33nlH27Zts+bhcrmUk5OjtLQ0jRs3TitXrlRNTY1mzJjxLR4aAABwIwsr5FRVVemxxx7TZ599pvj4eI0aNUo7d+7U5MmTJUkrVqxQZGSksrOz5fP55HQ6tWbNGmv7qKgobd26VbNnz5bD4VC3bt2Uk5OjRYsWWTXJycnatm2b5syZo1WrVql///567bXX5HQ6rZpp06bp888/V2Fhobxer8aMGaMdO3Y0uBkZAAB0XmGFnNdff73R8djYWBUVFamoqOi6NYMGDWryiZgJEyboyJEjjdbk5eUpLy+v0RoAANB58burAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARgor5CxZskS33XabevToob59+2rq1Kk6depUSM2VK1eUm5urPn36qHv37srOzlZlZWVIzZkzZ5SVlaW4uDj17dtXzz77rK5evRpSs3v3bo0dO1Y2m01DhgzR+vXrG8ynqKhIgwcPVmxsrNLT03XgwIFw3g4AADBYWCGnrKxMubm52rdvn9xut/x+vzIzM1VTU2PVzJkzR++99542bdqksrIynT17Vg888IA1XldXp6ysLNXW1mrv3r164403tH79ehUWFlo1p0+fVlZWlu6++25VVFQoPz9fTzzxhHbu3GnVbNy4US6XS/Pnz9fhw4c1evRoOZ1OVVVVfZPjAQAADNElnOIdO3aELK9fv159+/ZVeXm57rrrLl28eFGvv/66NmzYoIkTJ0qS1q1bp+HDh2vfvn0aP368SkpKdOLECf3Xf/2XEhISNGbMGC1evFg//vGPtWDBAsXExKi4uFjJyclatmyZJGn48OH68MMPtWLFCjmdTknS8uXLNWvWLM2YMUOSVFxcrG3btmnt2rX6yU9+8o0PDAAAuLGFFXL+1sWLFyVJvXv3liSVl5fL7/crIyPDqhk2bJgGDhwoj8ej8ePHy+PxaOTIkUpISLBqnE6nZs+erePHj+vWW2+Vx+MJ2Ud9TX5+viSptrZW5eXlKigosMYjIyOVkZEhj8dz3fn6fD75fD5rubq6WpLk9/vl9/ubfL/1Nc2ptUUFm6xBy9gig9afzekFWkc45wNaD33oGOhD22rucW5xyAkEAsrPz9ftt9+uESNGSJK8Xq9iYmLUs2fPkNqEhAR5vV6r5usBp368fqyxmurqan311Vc6f/686urqrllz8uTJ6855yZIlWrhwYYP1JSUliouLa8a7/iu3291kzdJxzd4dWmhxWkDbt29v72l0es05H9D66EPHQB/axuXLl5tV1+KQk5ubq2PHjunDDz9s6S7aXEFBgVwul7VcXV2tAQMGKDMzU3a7vcnt/X6/3G63Jk+erOjo6EZrRyzY2eg4Ws4WGdTitICePxSp8sJ72ns6nVY45wNaD33oGOhD26r/JKYpLQo5eXl52rp1q/bs2aP+/ftb6xMTE1VbW6sLFy6EXM2prKxUYmKiVfO3T0HVP3319Zq/fSKrsrJSdrtdXbt2VVRUlKKioq5ZU7+Pa7HZbLLZbA3WR0dHh/VN2Zx6X11Es/eHlvEFIvjHpAMI9/xB66APHQN9aBvNPcZhPV0VDAaVl5enzZs3a9euXUpOTg4ZT01NVXR0tEpLS611p06d0pkzZ+RwOCRJDodDR48eDXkKyu12y263KyUlxar5+j7qa+r3ERMTo9TU1JCaQCCg0tJSqwYAAHRuYV3Jyc3N1YYNG/Tb3/5WPXr0sO6hiY+PV9euXRUfH6+ZM2fK5XKpd+/estvtevrpp+VwODR+/HhJUmZmplJSUvToo49q6dKl8nq9mjdvnnJzc62rLE899ZRefvllzZ07V48//rh27dqld955R9u2bbPm4nK5lJOTo7S0NI0bN04rV65UTU2N9bQVAADo3MIKOa+88ookacKECSHr161bp3/+53+WJK1YsUKRkZHKzs6Wz+eT0+nUmjVrrNqoqCht3bpVs2fPlsPhULdu3ZSTk6NFixZZNcnJydq2bZvmzJmjVatWqX///nrttdesx8cladq0afr8889VWFgor9erMWPGaMeOHQ1uRgYAAJ1TWCEnGGz6sejY2FgVFRWpqKjoujWDBg1q8qmYCRMm6MiRI43W5OXlKS8vr8k5AQCAzoffXQUAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABgp7JCzZ88e3XvvvUpKSlJERIS2bNkSMh4MBlVYWKh+/fqpa9euysjI0McffxxSc+7cOU2fPl12u109e/bUzJkz9eWXX4bU/OEPf9Cdd96p2NhYDRgwQEuXLm0wl02bNmnYsGGKjY3VyJEjtX379nDfDgAAMFTYIaempkajR49WUVHRNceXLl2q1atXq7i4WPv371e3bt3kdDp15coVq2b69Ok6fvy43G63tm7dqj179ujJJ5+0xqurq5WZmalBgwapvLxcL730khYsWKBXX33Vqtm7d68eeeQRzZw5U0eOHNHUqVM1depUHTt2LNy3BAAADNQl3A2mTJmiKVOmXHMsGAxq5cqVmjdvnu677z5J0n/8x38oISFBW7Zs0cMPP6yPPvpIO3bs0MGDB5WWliZJ+sUvfqHvf//7+vd//3clJSXprbfeUm1trdauXauYmBh997vfVUVFhZYvX26FoVWrVumee+7Rs88+K0lavHix3G63Xn75ZRUXF7foYAAAAHOEHXIac/r0aXm9XmVkZFjr4uPjlZ6eLo/Ho4cfflgej0c9e/a0Ao4kZWRkKDIyUvv379f9998vj8eju+66SzExMVaN0+nUz3/+c50/f169evWSx+ORy+UKeX2n09ng47Ov8/l88vl81nJ1dbUkye/3y+/3N/n+6muaU2uLCjZZg5axRQatP5vTC7SOcM4HtB760DHQh7bV3OP8rYYcr9crSUpISAhZn5CQYI15vV717ds3dBJduqh3794hNcnJyQ32UT/Wq1cveb3eRl/nWpYsWaKFCxc2WF9SUqK4uLjmvEVJktvtbrJm6bhm7w4ttDgtwH1YHUBzzge0PvrQMdCHtnH58uVm1X2rIaejKygoCLn6U11drQEDBigzM1N2u73J7f1+v9xutyZPnqzo6OhGa0cs2PmN54trs0UGtTgtoOcPRaq88J72nk6nFc75gNZDHzoG+tC26j+Jacq3GnISExMlSZWVlerXr5+1vrKyUmPGjLFqqqqqQra7evWqzp07Z22fmJioysrKkJr65aZq6sevxWazyWazNVgfHR0d1jdlc+p9dRHN3h9axheI4B+TDiDc8wetgz50DPShbTT3GH+rPycnOTlZiYmJKi0ttdZVV1dr//79cjgckiSHw6ELFy6ovLzcqtm1a5cCgYDS09Otmj179oR85uZ2uzV06FD16tXLqvn669TX1L8OAADo3MIOOV9++aUqKipUUVEh6a83G1dUVOjMmTOKiIhQfn6+XnjhBb377rs6evSoHnvsMSUlJWnq1KmSpOHDh+uee+7RrFmzdODAAf3+979XXl6eHn74YSUlJUmSfvjDHyomJkYzZ87U8ePHtXHjRq1atSrko6ZnnnlGO3bs0LJly3Ty5EktWLBAhw4dUl5e3jc/KgAA4IYX9sdVhw4d0t13320t1wePnJwcrV+/XnPnzlVNTY2efPJJXbhwQXfccYd27Nih2NhYa5u33npLeXl5mjRpkiIjI5Wdna3Vq1db4/Hx8SopKVFubq5SU1N10003qbCwMORn6Xzve9/Thg0bNG/ePD333HO65ZZbtGXLFo0YMaJFBwIAAJgl7JAzYcIEBYPXfzw6IiJCixYt0qJFi65b07t3b23YsKHR1xk1apR+97vfNVrz0EMP6aGHHmp8wgAAoFPid1cBAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYKSwf0En0JEM/sm29p5C2P70YlZ7TwEAOgWu5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAI3Vp7wkAnc3gn2xr7ym0yJ9ezGrvKQBAWG74KzlFRUUaPHiwYmNjlZ6ergMHDrT3lAAAQAdwQ4ecjRs3yuVyaf78+Tp8+LBGjx4tp9Opqqqq9p4aAABoZzd0yFm+fLlmzZqlGTNmKCUlRcXFxYqLi9PatWvbe2oAAKCd3bD35NTW1qq8vFwFBQXWusjISGVkZMjj8VxzG5/PJ5/PZy1fvHhRknTu3Dn5/f4mX9Pv9+vy5cv64osvFB0d3Whtl6s1zXkbaIEugaAuXw6oiz9SdYGI9p5Op/HFF1+ELIdzPqD10IeOgT60rUuXLkmSgsFgo3U3bMj5y1/+orq6OiUkJISsT0hI0MmTJ6+5zZIlS7Rw4cIG65OTk1tljmg9P2zvCXRCNy1r7xkAQKhLly4pPj7+uuM3bMhpiYKCArlcLms5EAjo3Llz6tOnjyIimr4iUF1drQEDBujTTz+V3W5vzamiEfShY6APHQN96BjoQ9sKBoO6dOmSkpKSGq27YUPOTTfdpKioKFVWVoasr6ysVGJi4jW3sdlsstlsIet69uwZ9mvb7Xa+iTsA+tAx0IeOgT50DPSh7TR2BafeDXvjcUxMjFJTU1VaWmqtCwQCKi0tlcPhaMeZAQCAjuCGvZIjSS6XSzk5OUpLS9O4ceO0cuVK1dTUaMaMGe09NQAA0M5u6JAzbdo0ff755yosLJTX69WYMWO0Y8eOBjcjf1tsNpvmz5/f4CMvtC360DHQh46BPnQM9KFjigg29fwVAADADeiGvScHAACgMYQcAABgJEIOAAAwEiEHAAAYiZAThqKiIg0ePFixsbFKT0/XgQMH2ntKRtuzZ4/uvfdeJSUlKSIiQlu2bAkZDwaDKiwsVL9+/dS1a1dlZGTo448/bp/JGmzJkiW67bbb1KNHD/Xt21dTp07VqVOnQmquXLmi3Nxc9enTR927d1d2dnaDH9SJb+aVV17RqFGjrB8253A49P7771vj9KDtvfjii4qIiFB+fr61jj50LIScZtq4caNcLpfmz5+vw4cPa/To0XI6naqqqmrvqRmrpqZGo0ePVlFR0TXHly5dqtWrV6u4uFj79+9Xt27d5HQ6deXKlTaeqdnKysqUm5urffv2ye12y+/3KzMzUzU1//8voZ0zZ47ee+89bdq0SWVlZTp79qweeOCBdpy1efr3768XX3xR5eXlOnTokCZOnKj77rtPx48fl0QP2trBgwf1y1/+UqNGjQpZTx86mCCaZdy4ccHc3Fxrua6uLpiUlBRcsmRJO86q85AU3Lx5s7UcCASCiYmJwZdeeslad+HChaDNZgv++te/bocZdh5VVVVBScGysrJgMPjX4x4dHR3ctGmTVfPRRx8FJQU9Hk97TbNT6NWrV/C1116jB23s0qVLwVtuuSXodruD//AP/xB85plngsEg50JHxJWcZqitrVV5ebkyMjKsdZGRkcrIyJDH42nHmXVep0+fltfrDelJfHy80tPT6Ukru3jxoiSpd+/ekqTy8nL5/f6QXgwbNkwDBw6kF62krq5Ob7/9tmpqauRwOOhBG8vNzVVWVlbI8ZY4FzqiG/onHreVv/zlL6qrq2vwk5QTEhJ08uTJdppV5+b1eiXpmj2pH8O3LxAIKD8/X7fffrtGjBgh6a+9iImJafDLbunFt+/o0aNyOBy6cuWKunfvrs2bNyslJUUVFRX0oI28/fbbOnz4sA4ePNhgjHOh4yHkAGi23NxcHTt2TB9++GF7T6VTGjp0qCoqKnTx4kX95je/UU5OjsrKytp7Wp3Gp59+qmeeeUZut1uxsbHtPR00Ax9XNcNNN92kqKioBnfIV1ZWKjExsZ1m1bnVH3d60nby8vK0detWffDBB+rfv7+1PjExUbW1tbpw4UJIPb349sXExGjIkCFKTU3VkiVLNHr0aK1atYoetJHy8nJVVVVp7Nix6tKli7p06aKysjKtXr1aXbp0UUJCAn3oYAg5zRATE6PU1FSVlpZa6wKBgEpLS+VwONpxZp1XcnKyEhMTQ3pSXV2t/fv305NvWTAYVF5enjZv3qxdu3YpOTk5ZDw1NVXR0dEhvTh16pTOnDlDL1pZIBCQz+ejB21k0qRJOnr0qCoqKqyvtLQ0TZ8+3fo7fehY+LiqmVwul3JycpSWlqZx48Zp5cqVqqmp0YwZM9p7asb68ssv9cknn1jLp0+fVkVFhXr37q2BAwcqPz9fL7zwgm655RYlJyfr+eefV1JSkqZOndp+kzZQbm6uNmzYoN/+9rfq0aOHdW9BfHy8unbtqvj4eM2cOVMul0u9e/eW3W7X008/LYfDofHjx7fz7M1RUFCgKVOmaODAgbp06ZI2bNig3bt3a+fOnfSgjfTo0cO6F61et27d1KdPH2s9fehg2vvxrhvJL37xi+DAgQODMTExwXHjxgX37dvX3lMy2gcffBCU1OArJycnGAz+9THy559/PpiQkBC02WzBSZMmBU+dOtW+kzbQtXogKbhu3Tqr5quvvgr+6Ec/Cvbq1SsYFxcXvP/++4OfffZZ+03aQI8//nhw0KBBwZiYmODNN98cnDRpUrCkpMQapwft4+uPkAeD9KGjiQgGg8F2ylcAAACthntyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADDS/wPwzptoFhYdtwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(f\"Tenemos {len(sentences_en)} sentencias para entrenar\")\n",
        "print(\"Distribuciones del corpus en inglés\")\n",
        "series_en = pd.Series([len(sentencia.split()) for sentencia in sentences_en])\n",
        "series_en.hist();\n",
        "print(series_en.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "id": "pPbLpRYru4F3",
        "outputId": "2b4744ff-217a-4219-a15f-edbcb5426b3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribuciones del corpus en español\n",
            "count    118964.000000\n",
            "mean          6.083866\n",
            "std           2.764452\n",
            "min           1.000000\n",
            "25%           4.000000\n",
            "50%           6.000000\n",
            "75%           7.000000\n",
            "max          49.000000\n",
            "dtype: float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAGdCAYAAADwjmIIAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAK5dJREFUeJzt3X1wVGWa/vErCUmHAE14kQSWt2yhQkTCEIbQO+MsYkgPk58lGqfQsZxsRCzZxDL0ro5sYXhbKwyuIGo0s6MQtxyXl6nSWcEh6Q0S1iEIBLICCqWzzMYt6MRRoTFAp0mf3x9TOWMbQroDSQ8P309VKpznuc/pp++cxMs+fZI4y7IsAQAAGCY+1gsAAADoDYQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICR+sV6AbEUCoV08uRJDRo0SHFxcbFeDgAAiIBlWTp79qxGjRql+PiuX6+5rkPOyZMnNWbMmFgvAwAA9MBnn32m0aNHdzl/XYecQYMGSfpTk5xOZ0T7BINB1dTUKC8vT4mJib25PHwDfY8N+h4b9D026Hvf62nP/X6/xowZY/93vCvXdcjpuETldDqjCjkpKSlyOp18E/Qh+h4b9D026Hts0Pe+d6U97+6tJrzxGAAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBI/WK9AFONf2p7rJcQtT+szo/1EgAAuGp4JQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgpH6xXgD+cox/anusl9AlR4KlNTOkycurFWiPs8f/sDo/hqsCAPwl45UcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAI0UVcpYvX664uLiwj4kTJ9rzFy5cUHFxsYYNG6aBAweqoKBAzc3NYcdoampSfn6+UlJSNGLECD3xxBO6ePFiWM2uXbs0bdo0ORwOTZgwQVVVVZ3WUlFRofHjxys5OVk5OTnat29fNE8FAAAYLupXcm655RadOnXK/nj//fftucWLF+udd97R1q1bVVdXp5MnT+qee+6x59vb25Wfn6+2tjbt2bNHr7/+uqqqqlRWVmbXnDhxQvn5+br99tvV2Nio0tJSPfzww6qurrZrNm/eLI/Ho2XLlungwYPKysqS2+1WS0tLT/sAAAAME3XI6devn9LT0+2P4cOHS5LOnDmj1157TWvXrtXs2bOVnZ2tjRs3as+ePdq7d68kqaamRh999JHeeOMNTZ06VXPnztWqVatUUVGhtrY2SVJlZaUyMjL03HPPadKkSSopKdG9996rdevW2WtYu3atFi5cqKKiImVmZqqyslIpKSnasGHD1egJAAAwQL9od/jkk080atQoJScny+Vyqby8XGPHjlVDQ4OCwaByc3Pt2okTJ2rs2LGqr6/XzJkzVV9fr1tvvVVpaWl2jdvt1qJFi3T06FF95zvfUX19fdgxOmpKS0slSW1tbWpoaNCSJUvs+fj4eOXm5qq+vv6yaw8EAgoEAva23++XJAWDQQWDwYief0ddd/WOBCui4yEyjngr7HOHSL9u6JlIz3dcXfQ9Nuh73+tpzyOtjyrk5OTkqKqqSjfffLNOnTqlFStW6LbbbtORI0fk8/mUlJSk1NTUsH3S0tLk8/kkST6fLyzgdMx3zF2uxu/36/z58/rqq6/U3t5+yZpjx45ddv3l5eVasWJFp/GamhqlpKR034Bv8Hq9l51fMyOqwyFCq6aHwrbffffdGK3k+tLd+Y7eQd9jg773vWh7fu7cuYjqogo5c+fOtf89ZcoU5eTkaNy4cdqyZYv69+8f1QJjYcmSJfJ4PPa23+/XmDFjlJeXJ6fTGdExgsGgvF6v5syZo8TExC7rJi+v7nIO0XPEW1o1PaSnD8QrEIqzx48sd8dwVeaL9HzH1UXfY4O+972e9rzjSkx3or5c9U2pqam66aab9Omnn2rOnDlqa2vT6dOnw17NaW5uVnp6uiQpPT29011QHXdffbPm23dkNTc3y+l0qn///kpISFBCQsIlazqO0RWHwyGHw9FpPDExMeoTurt9Au1xXc6h5wKhuLDe8oOob/TkewRXjr7HBn3ve9H2PNLaK/o9OV9//bV+//vfa+TIkcrOzlZiYqJqa2vt+ePHj6upqUkul0uS5HK5dPjw4bC7oLxer5xOpzIzM+2abx6jo6bjGElJScrOzg6rCYVCqq2ttWsAAACiCjn/+I//qLq6Ov3hD3/Qnj17dPfddyshIUH333+/Bg8erAULFsjj8ei9995TQ0ODioqK5HK5NHPmTElSXl6eMjMz9eCDD+q///u/VV1draVLl6q4uNh+heXRRx/V//zP/+jJJ5/UsWPH9PLLL2vLli1avHixvQ6Px6Nf/vKXev311/Xxxx9r0aJFam1tVVFR0VVsDQAAuJZFdbnq//7v/3T//ffriy++0A033KDvf//72rt3r2644QZJ0rp16xQfH6+CggIFAgG53W69/PLL9v4JCQnatm2bFi1aJJfLpQEDBqiwsFArV660azIyMrR9+3YtXrxY69ev1+jRo/Xqq6/K7f7zey/mz5+vzz//XGVlZfL5fJo6dap27NjR6c3IAADg+hVVyNm0adNl55OTk1VRUaGKiooua8aNG9ftHTGzZs3SoUOHLltTUlKikpKSy9YAAIDrF3+7CgAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjHRFIWf16tWKi4tTaWmpPXbhwgUVFxdr2LBhGjhwoAoKCtTc3By2X1NTk/Lz85WSkqIRI0boiSee0MWLF8Nqdu3apWnTpsnhcGjChAmqqqrq9PgVFRUaP368kpOTlZOTo3379l3J0wEAAAbpccjZv3+/fvGLX2jKlClh44sXL9Y777yjrVu3qq6uTidPntQ999xjz7e3tys/P19tbW3as2ePXn/9dVVVVamsrMyuOXHihPLz83X77bersbFRpaWlevjhh1VdXW3XbN68WR6PR8uWLdPBgweVlZUlt9utlpaWnj4lAABgkB6FnK+//loPPPCAfvnLX2rIkCH2+JkzZ/Taa69p7dq1mj17trKzs7Vx40bt2bNHe/fulSTV1NToo48+0htvvKGpU6dq7ty5WrVqlSoqKtTW1iZJqqysVEZGhp577jlNmjRJJSUluvfee7Vu3Tr7sdauXauFCxeqqKhImZmZqqysVEpKijZs2HAl/QAAAIboUcgpLi5Wfn6+cnNzw8YbGhoUDAbDxidOnKixY8eqvr5eklRfX69bb71VaWlpdo3b7Zbf79fRo0ftmm8f2+1228doa2tTQ0NDWE18fLxyc3PtGgAAcH3rF+0OmzZt0sGDB7V///5Ocz6fT0lJSUpNTQ0bT0tLk8/ns2u+GXA65jvmLlfj9/t1/vx5ffXVV2pvb79kzbFjx7pceyAQUCAQsLf9fr8kKRgMKhgMXu5p2zrquqt3JFgRHQ+RccRbYZ87RPp1Q89Eer7j6qLvsUHf+15Pex5pfVQh57PPPtPjjz8ur9er5OTkqBb0l6C8vFwrVqzoNF5TU6OUlJSojuX1ei87v2ZGVIdDhFZND4Vtv/vuuzFayfWlu/MdvYO+xwZ973vR9vzcuXMR1UUVchoaGtTS0qJp06bZY+3t7dq9e7deeuklVVdXq62tTadPnw57Nae5uVnp6emSpPT09E53QXXcffXNmm/fkdXc3Cyn06n+/fsrISFBCQkJl6zpOMalLFmyRB6Px972+/0aM2aM8vLy5HQ6I+pBMBiU1+vVnDlzlJiY2GXd5OXVXc4heo54S6umh/T0gXgFQnH2+JHl7hiuynyRnu+4uuh7bND3vtfTnndcielOVCHnjjvu0OHDh8PGioqKNHHiRP3sZz/TmDFjlJiYqNraWhUUFEiSjh8/rqamJrlcLkmSy+XSM888o5aWFo0YMULSnxKc0+lUZmamXfPt/0P3er32MZKSkpSdna3a2lrNmzdPkhQKhVRbW6uSkpIu1+9wOORwODqNJyYmRn1Cd7dPoD2uyzn0XCAUF9ZbfhD1jZ58j+DK0ffYoO99L9qeR1obVcgZNGiQJk+eHDY2YMAADRs2zB5fsGCBPB6Phg4dKqfTqccee0wul0szZ86UJOXl5SkzM1MPPvig1qxZI5/Pp6VLl6q4uNgOII8++qheeuklPfnkk3rooYe0c+dObdmyRdu3b7cf1+PxqLCwUNOnT9eMGTP0/PPPq7W1VUVFRdE8JQAAYKio33jcnXXr1ik+Pl4FBQUKBAJyu916+eWX7fmEhARt27ZNixYtksvl0oABA1RYWKiVK1faNRkZGdq+fbsWL16s9evXa/To0Xr11Vfldv/50sT8+fP1+eefq6ysTD6fT1OnTtWOHTs6vRkZAABcn6445OzatStsOzk5WRUVFaqoqOhyn3HjxnX7htFZs2bp0KFDl60pKSm57OUpAABw/eJvVwEAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEhRhZxXXnlFU6ZMkdPplNPplMvl0m9/+1t7/sKFCyouLtawYcM0cOBAFRQUqLm5OewYTU1Nys/PV0pKikaMGKEnnnhCFy9eDKvZtWuXpk2bJofDoQkTJqiqqqrTWioqKjR+/HglJycrJydH+/bti+apAAAAw0UVckaPHq3Vq1eroaFBBw4c0OzZs3XXXXfp6NGjkqTFixfrnXfe0datW1VXV6eTJ0/qnnvusfdvb29Xfn6+2tratGfPHr3++uuqqqpSWVmZXXPixAnl5+fr9ttvV2Njo0pLS/Xwww+rurrartm8ebM8Ho+WLVumgwcPKisrS263Wy0tLVfaDwAAYIioQs6dd96pH/3oR7rxxht100036ZlnntHAgQO1d+9enTlzRq+99prWrl2r2bNnKzs7Wxs3btSePXu0d+9eSVJNTY0++ugjvfHGG5o6darmzp2rVatWqaKiQm1tbZKkyspKZWRk6LnnntOkSZNUUlKie++9V+vWrbPXsXbtWi1cuFBFRUXKzMxUZWWlUlJStGHDhqvYGgAAcC3r8Xty2tvbtWnTJrW2tsrlcqmhoUHBYFC5ubl2zcSJEzV27FjV19dLkurr63XrrbcqLS3NrnG73fL7/farQfX19WHH6KjpOEZbW5saGhrCauLj45Wbm2vXAAAA9It2h8OHD8vlcunChQsaOHCg3nrrLWVmZqqxsVFJSUlKTU0Nq09LS5PP55Mk+Xy+sIDTMd8xd7kav9+v8+fP66uvvlJ7e/sla44dO3bZtQcCAQUCAXvb7/dLkoLBoILBYETPv6Ouu3pHghXR8RAZR7wV9rlDpF839Eyk5zuuLvoeG/S97/W055HWRx1ybr75ZjU2NurMmTP69a9/rcLCQtXV1UV7mJgoLy/XihUrOo3X1NQoJSUlqmN5vd7Lzq+ZEdXhEKFV00Nh2++++26MVnJ96e58R++g77FB3/tetD0/d+5cRHVRh5ykpCRNmDBBkpSdna39+/dr/fr1mj9/vtra2nT69OmwV3Oam5uVnp4uSUpPT+90F1TH3VffrPn2HVnNzc1yOp3q37+/EhISlJCQcMmajmN0ZcmSJfJ4PPa23+/XmDFjlJeXJ6fTGdHzDwaD8nq9mjNnjhITE7usm7y8uss5RM8Rb2nV9JCePhCvQCjOHj+y3B3DVZkv0vMdVxd9jw363vd62vOOKzHdiTrkfFsoFFIgEFB2drYSExNVW1urgoICSdLx48fV1NQkl8slSXK5XHrmmWfU0tKiESNGSPpTenM6ncrMzLRrvv1/516v1z5GUlKSsrOzVVtbq3nz5tlrqK2tVUlJyWXX6nA45HA4Oo0nJiZGfUJ3t0+gPa7LOfRcIBQX1lt+EPWNnnyP4MrR99ig730v2p5HWhtVyFmyZInmzp2rsWPH6uzZs3rzzTe1a9cuVVdXa/DgwVqwYIE8Ho+GDh0qp9Opxx57TC6XSzNnzpQk5eXlKTMzUw8++KDWrFkjn8+npUuXqri42A4fjz76qF566SU9+eSTeuihh7Rz505t2bJF27dvt9fh8XhUWFio6dOna8aMGXr++efV2tqqoqKiaJ4OAAAwWFQhp6WlRT/96U916tQpDR48WFOmTFF1dbXmzJkjSVq3bp3i4+NVUFCgQCAgt9utl19+2d4/ISFB27Zt06JFi+RyuTRgwAAVFhZq5cqVdk1GRoa2b9+uxYsXa/369Ro9erReffVVud1/viwxf/58ff755yorK5PP59PUqVO1Y8eOTm9GBgAA16+oQs5rr7122fnk5GRVVFSooqKiy5px48Z1+2bRWbNm6dChQ5etKSkp6fbyFAAAuH7xt6sAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGCkqEJOeXm5vvvd72rQoEEaMWKE5s2bp+PHj4fVXLhwQcXFxRo2bJgGDhyogoICNTc3h9U0NTUpPz9fKSkpGjFihJ544gldvHgxrGbXrl2aNm2aHA6HJkyYoKqqqk7rqaio0Pjx45WcnKycnBzt27cvmqcDAAAMFlXIqaurU3Fxsfbu3Suv16tgMKi8vDy1trbaNYsXL9Y777yjrVu3qq6uTidPntQ999xjz7e3tys/P19tbW3as2ePXn/9dVVVVamsrMyuOXHihPLz83X77bersbFRpaWlevjhh1VdXW3XbN68WR6PR8uWLdPBgweVlZUlt9utlpaWK+kHAAAwRL9oinfs2BG2XVVVpREjRqihoUE/+MEPdObMGb322mt68803NXv2bEnSxo0bNWnSJO3du1czZ85UTU2NPvroI/3nf/6n0tLSNHXqVK1atUo/+9nPtHz5ciUlJamyslIZGRl67rnnJEmTJk3S+++/r3Xr1sntdkuS1q5dq4ULF6qoqEiSVFlZqe3bt2vDhg166qmnrrgxAADg2hZVyPm2M2fOSJKGDh0qSWpoaFAwGFRubq5dM3HiRI0dO1b19fWaOXOm6uvrdeuttyotLc2ucbvdWrRokY4eParvfOc7qq+vDztGR01paakkqa2tTQ0NDVqyZIk9Hx8fr9zcXNXX13e53kAgoEAgYG/7/X5JUjAYVDAYjOg5d9R1V+9IsCI6HiLjiLfCPneI9OuGnon0fMfVRd9jg773vZ72PNL6HoecUCik0tJSfe9739PkyZMlST6fT0lJSUpNTQ2rTUtLk8/ns2u+GXA65jvmLlfj9/t1/vx5ffXVV2pvb79kzbFjx7pcc3l5uVasWNFpvKamRikpKRE86z/zer2XnV8zI6rDIUKrpofCtt99990YreT60t35jt5B32ODvve9aHt+7ty5iOp6HHKKi4t15MgRvf/++z09RJ9bsmSJPB6Pve33+zVmzBjl5eXJ6XRGdIxgMCiv16s5c+YoMTGxy7rJy6u7nEP0HPGWVk0P6ekD8QqE4uzxI8vdMVyV+SI933F10ffYoO99r6c977gS050ehZySkhJt27ZNu3fv1ujRo+3x9PR0tbW16fTp02Gv5jQ3Nys9Pd2u+fZdUB13X32z5tt3ZDU3N8vpdKp///5KSEhQQkLCJWs6jnEpDodDDoej03hiYmLUJ3R3+wTa47qcQ88FQnFhveUHUd/oyfcIrhx9jw363vei7XmktVHdXWVZlkpKSvTWW29p586dysjICJvPzs5WYmKiamtr7bHjx4+rqalJLpdLkuRyuXT48OGwu6C8Xq+cTqcyMzPtmm8eo6Om4xhJSUnKzs4OqwmFQqqtrbVrAADA9S2qV3KKi4v15ptv6je/+Y0GDRpkv4dm8ODB6t+/vwYPHqwFCxbI4/Fo6NChcjqdeuyxx+RyuTRz5kxJUl5enjIzM/Xggw9qzZo18vl8Wrp0qYqLi+1XWR599FG99NJLevLJJ/XQQw9p586d2rJli7Zv326vxePxqLCwUNOnT9eMGTP0/PPPq7W11b7bCgAAXN+iCjmvvPKKJGnWrFlh4xs3btTf/d3fSZLWrVun+Ph4FRQUKBAIyO126+WXX7ZrExIStG3bNi1atEgul0sDBgxQYWGhVq5caddkZGRo+/btWrx4sdavX6/Ro0fr1VdftW8fl6T58+fr888/V1lZmXw+n6ZOnaodO3Z0ejMyAAC4PkUVciyr+9uik5OTVVFRoYqKii5rxo0b1+1dMbNmzdKhQ4cuW1NSUqKSkpJu1wQAAK4//O0qAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYKeqQs3v3bt15550aNWqU4uLi9Pbbb4fNW5alsrIyjRw5Uv3791dubq4++eSTsJovv/xSDzzwgJxOp1JTU7VgwQJ9/fXXYTUffvihbrvtNiUnJ2vMmDFas2ZNp7Vs3bpVEydOVHJysm699Va9++670T4dAABgqKhDTmtrq7KyslRRUXHJ+TVr1uiFF15QZWWlPvjgAw0YMEBut1sXLlywax544AEdPXpUXq9X27Zt0+7du/XII4/Y836/X3l5eRo3bpwaGhr07LPPavny5frXf/1Xu2bPnj26//77tWDBAh06dEjz5s3TvHnzdOTIkWifEgAAMFC/aHeYO3eu5s6de8k5y7L0/PPPa+nSpbrrrrskSf/2b/+mtLQ0vf3227rvvvv08ccfa8eOHdq/f7+mT58uSXrxxRf1ox/9SP/yL/+iUaNG6Ve/+pXa2tq0YcMGJSUl6ZZbblFjY6PWrl1rh6H169frhz/8oZ544glJ0qpVq+T1evXSSy+psrKyR80AAADmiDrkXM6JEyfk8/mUm5trjw0ePFg5OTmqr6/Xfffdp/r6eqWmptoBR5Jyc3MVHx+vDz74QHfffbfq6+v1gx/8QElJSXaN2+3Wz3/+c3311VcaMmSI6uvr5fF4wh7f7XZ3unz2TYFAQIFAwN72+/2SpGAwqGAwGNFz7Kjrrt6RYEV0PETGEW+Ffe4Q6dcNPRPp+Y6ri77HBn3vez3teaT1VzXk+Hw+SVJaWlrYeFpamj3n8/k0YsSI8EX066ehQ4eG1WRkZHQ6RsfckCFD5PP5Lvs4l1JeXq4VK1Z0Gq+pqVFKSkokT9Hm9XovO79mRlSHQ4RWTQ+FbfM+rL7R3fmO3kHfY4O+971oe37u3LmI6q5qyPlLt2TJkrBXf/x+v8aMGaO8vDw5nc6IjhEMBuX1ejVnzhwlJiZ2WTd5efUVrxd/5oi3tGp6SE8fiFcgFGePH1nujuGqzBfp+Y6ri77HBn3vez3teceVmO5c1ZCTnp4uSWpubtbIkSPt8ebmZk2dOtWuaWlpCdvv4sWL+vLLL+3909PT1dzcHFbTsd1dTcf8pTgcDjkcjk7jiYmJUZ/Q3e0TaI/rcg49FwjFhfWWH0R9oyffI7hy9D026Hvfi7bnkdZe1d+Tk5GRofT0dNXW1tpjfr9fH3zwgVwulyTJ5XLp9OnTamhosGt27typUCiknJwcu2b37t1h19y8Xq9uvvlmDRkyxK755uN01HQ8DgAAuL5FHXK+/vprNTY2qrGxUdKf3mzc2NiopqYmxcXFqbS0VP/8z/+s//iP/9Dhw4f105/+VKNGjdK8efMkSZMmTdIPf/hDLVy4UPv27dPvfvc7lZSU6L777tOoUaMkST/5yU+UlJSkBQsW6OjRo9q8ebPWr18fdqnp8ccf144dO/Tcc8/p2LFjWr58uQ4cOKCSkpIr7woAALjmRX256sCBA7r99tvt7Y7gUVhYqKqqKj355JNqbW3VI488otOnT+v73/++duzYoeTkZHufX/3qVyopKdEdd9yh+Ph4FRQU6IUXXrDnBw8erJqaGhUXFys7O1vDhw9XWVlZ2O/S+Zu/+Ru9+eabWrp0qf7pn/5JN954o95++21Nnjy5R40AAABmiTrkzJo1S5bV9e3RcXFxWrlypVauXNllzdChQ/Xmm29e9nGmTJmi//qv/7pszY9//GP9+Mc/vvyCAQDAdYm/XQUAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkaL+A53AX5LxT22P9RKi9ofV+bFeAgBcF3glBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBI/WK9gCtVUVGhZ599Vj6fT1lZWXrxxRc1Y8aMWC8L6NL4p7bHegkRcyRYWjNDmry8Wsef+X+xXg4AROWafiVn8+bN8ng8WrZsmQ4ePKisrCy53W61tLTEemkAACDGrumQs3btWi1cuFBFRUXKzMxUZWWlUlJStGHDhlgvDQAAxNg1e7mqra1NDQ0NWrJkiT0WHx+v3Nxc1dfXX3KfQCCgQCBgb585c0aS9OWXXyoYDEb0uMFgUOfOndMXX3yhxMTELuv6XWyN6HiITL+QpXPnQuoXjFd7KC7Wy7lufLPvX3zxRayXc92I9OcMri763vd62vOzZ89KkizLumzdNRty/vjHP6q9vV1paWlh42lpaTp27Ngl9ykvL9eKFSs6jWdkZPTKGnF1/STWC7hOdfR9+LMxXQYAdHL27FkNHjy4y/lrNuT0xJIlS+TxeOztUCikL7/8UsOGDVNcXGSvDvj9fo0ZM0afffaZnE5nby0V30LfY4O+xwZ9jw363vd62nPLsnT27FmNGjXqsnXXbMgZPny4EhIS1NzcHDbe3Nys9PT0S+7jcDjkcDjCxlJTU3v0+E6nk2+CGKDvsUHfY4O+xwZ973s96fnlXsHpcM2+8TgpKUnZ2dmqra21x0KhkGpra+VyuWK4MgAA8Jfgmn0lR5I8Ho8KCws1ffp0zZgxQ88//7xaW1tVVFQU66UBAIAYu6ZDzvz58/X555+rrKxMPp9PU6dO1Y4dOzq9GflqcjgcWrZsWafLXuhd9D026Hts0PfYoO99r7d7Hmd1d/8VAADANeiafU8OAADA5RByAACAkQg5AADASIQcAABgJEJOFCoqKjR+/HglJycrJydH+/bti/WSjLJ7927deeedGjVqlOLi4vT222+HzVuWpbKyMo0cOVL9+/dXbm6uPvnkk9gs1iDl5eX67ne/q0GDBmnEiBGaN2+ejh8/HlZz4cIFFRcXa9iwYRo4cKAKCgo6/SJOROeVV17RlClT7F+C5nK59Nvf/taep+e9b/Xq1YqLi1Npaak9Rt97x/LlyxUXFxf2MXHiRHu+t/pOyInQ5s2b5fF4tGzZMh08eFBZWVlyu91qaWmJ9dKM0draqqysLFVUVFxyfs2aNXrhhRdUWVmpDz74QAMGDJDb7daFCxf6eKVmqaurU3Fxsfbu3Suv16tgMKi8vDy1tv75j8wuXrxY77zzjrZu3aq6ujqdPHlS99xzTwxXfe0bPXq0Vq9erYaGBh04cECzZ8/WXXfdpaNHj0qi571t//79+sUvfqEpU6aEjdP33nPLLbfo1KlT9sf7779vz/Va3y1EZMaMGVZxcbG93d7ebo0aNcoqLy+P4arMJcl666237O1QKGSlp6dbzz77rD12+vRpy+FwWP/+7/8egxWaq6WlxZJk1dXVWZb1pz4nJiZaW7dutWs+/vhjS5JVX18fq2UaaciQIdarr75Kz3vZ2bNnrRtvvNHyer3W3/7t31qPP/64ZVmc671p2bJlVlZW1iXnerPvvJITgba2NjU0NCg3N9cei4+PV25ururr62O4suvHiRMn5PP5wr4GgwcPVk5ODl+Dq+zMmTOSpKFDh0qSGhoaFAwGw3o/ceJEjR07lt5fJe3t7dq0aZNaW1vlcrnoeS8rLi5Wfn5+WH8lzvXe9sknn2jUqFH667/+az3wwANqamqS1Lt9v6Z/43Ff+eMf/6j29vZOv0k5LS1Nx44di9Gqri8+n0+SLvk16JjDlQuFQiotLdX3vvc9TZ48WdKfep+UlNTpj9nS+yt3+PBhuVwuXbhwQQMHDtRbb72lzMxMNTY20vNesmnTJh08eFD79+/vNMe53ntycnJUVVWlm2++WadOndKKFSt022236ciRI73ad0IOAFtxcbGOHDkSdq0cvefmm29WY2Ojzpw5o1//+tcqLCxUXV1drJdlrM8++0yPP/64vF6vkpOTY72c68rcuXPtf0+ZMkU5OTkaN26ctmzZov79+/fa43K5KgLDhw9XQkJCp3d6Nzc3Kz09PUarur509JmvQe8pKSnRtm3b9N5772n06NH2eHp6utra2nT69Omwenp/5ZKSkjRhwgRlZ2ervLxcWVlZWr9+PT3vJQ0NDWppadG0adPUr18/9evXT3V1dXrhhRfUr18/paWl0fc+kpqaqptuukmffvppr57vhJwIJCUlKTs7W7W1tfZYKBRSbW2tXC5XDFd2/cjIyFB6enrY18Dv9+uDDz7ga3CFLMtSSUmJ3nrrLe3cuVMZGRlh89nZ2UpMTAzr/fHjx9XU1ETvr7JQKKRAIEDPe8kdd9yhw4cPq7Gx0f6YPn26HnjgAfvf9L1vfP311/r973+vkSNH9u75fkVvW76ObNq0yXI4HFZVVZX10UcfWY888oiVmppq+Xy+WC/NGGfPnrUOHTpkHTp0yJJkrV271jp06JD1v//7v5ZlWdbq1aut1NRU6ze/+Y314YcfWnfddZeVkZFhnT9/PsYrv7YtWrTIGjx4sLVr1y7r1KlT9se5c+fsmkcffdQaO3astXPnTuvAgQOWy+WyXC5XDFd97Xvqqaesuro668SJE9aHH35oPfXUU1ZcXJxVU1NjWRY97yvfvLvKsuh7b/mHf/gHa9euXdaJEyes3/3ud1Zubq41fPhwq6WlxbKs3us7IScKL774ojV27FgrKSnJmjFjhrV3795YL8ko7733niWp00dhYaFlWX+6jfzpp5+20tLSLIfDYd1xxx3W8ePHY7toA1yq55KsjRs32jXnz5+3/v7v/94aMmSIlZKSYt19993WqVOnYrdoAzz00EPWuHHjrKSkJOuGG26w7rjjDjvgWBY97yvfDjn0vXfMnz/fGjlypJWUlGT91V/9lTV//nzr008/ted7q+9xlmVZV/ZaEAAAwF8e3pMDAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJH+P+5gB1gh6uDXAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(\"Distribuciones del corpus en español\")\n",
        "series_es = pd.Series([len(sentencia.split()) for sentencia in sentences_es])\n",
        "series_es.hist();\n",
        "print(series_es.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wiqv5UaVrtMR",
        "outputId": "37870c50-ff72-4ce9-9229-34d0dd5328c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Who is he talking to?(5), '=>', Con quién habla?(3)\n",
            "China is rich in natural resources.(6), '=>', China es rica en recursos naturales.(6)\n",
            "We'll stay here until the next contest.(7), '=>', Nos quedaremos aquí hasta el próximo concurso.(7)\n"
          ]
        }
      ],
      "source": [
        "origen = randint(0,len(sentences_es)-3)\n",
        "for i in range(origen, origen+3):\n",
        "    print(f\"{sentences_en[i]}({len(sentences_en[i].split())}), '=>', {sentences_es[i]}({len(sentences_es[i].split())})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INrVVj9_rtMR"
      },
      "source": [
        "### ENCODER-DECODER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_pkKlb_rtMR"
      },
      "source": [
        "Antes de introducir encoder-decoder teníamos este tipo de arquitectura:\n",
        "\n",
        "![imagen](./data/foto2.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlxxYM2x5sAQ"
      },
      "source": [
        "Encoder-decoder, ¡tamanño de entrada y de salida distinto!\n",
        "\n",
        "![imagen](./data/foto3.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaIbmHaG5sAQ"
      },
      "source": [
        "![imagen](./data/foto4.png)\n",
        "\n",
        "Cuando return_sequences está a False, la salida es el último estado oculto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFvst-dH5sAR"
      },
      "source": [
        "![imagen](./data/foto5.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nY8qFvTZ5sAR"
      },
      "source": [
        "![imagen](./data/foto6.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8K6q_NP-rtMR"
      },
      "source": [
        "Y, ¿por qué esta arquitectura? Porque antes de que se propusiese no había forma de entrenar modelos que admitiesen secuencias de longitud variable con target otra secuencia de longitud variable (y por tanto pudiendo ser esa longitud diferente a la primera)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGjjpK26rtMR"
      },
      "source": [
        "El encoder ahora se encarga de convertir cualquier secuencia que haya a la entrada en un vector de longitud fija y el decoder convertira este vector en una secuencia de salida de longitud variable.  \n",
        "\n",
        "De hecho al encoder le vamos a dar de comer secuencias de longitud fija pero lo suficientemente larga como para que entren todas, y aplicaremos el truco del padding para completar y el de la máscara para que no le afecte a las secuencias cortas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__amabJsrtMS"
      },
      "source": [
        "Entre el encoder y el ecoder se puede pasar el vector repetido o la salida del estado de memoria (otra implementación diferente, como se muestra a continuación)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLiJdIRZrtMS"
      },
      "source": [
        "<img src=\"https://github.com/Jaimegrp/Practicando/blob/main/Texto/img/encoder_decoder_to_train.jpg?raw=1\" alt=\"Diagram of encoder_decoder\" width=\"600\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYk-xYBOrtMS"
      },
      "source": [
        "Mejor si lo desenrrollamos:\n",
        "\n",
        "<img src=\"img/encoder_decoder_unrolled.jpg\" alt=\"Diagram of encoder_decoder\" width=\"600\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpCMaENGrtMS"
      },
      "source": [
        "Veamos como funcionaría (en entrenamiento) [*nota: h y c son los hidden_state de la recurrente del encoder, $h_d$ y $c_d$ son los hidden_state de la recurrente del decoder*]:\n",
        "1. Al enconder le damos la secuencia [I, like, soccer], y no le va a pasar nada todavía al encoder...\n",
        "2. Hace el embedding, supongamos que de 2 dimensiones, [ (0.212,-3.32), (1.34, 0.344), (6.665,-4.443)]\n",
        "3. Procesa la secuencia uno a uno y va transmitiendose el hidden_state ( y la cell_state, es una LSTM) en cada elemento de la secuencia:\n",
        "    Procesa: e0: [(0.212,-3.32),(0,0,...0),(0,0.....)]\n",
        "    Procesa: e1: [(1.34,0.344), h([(0.212,-3.32),(0,0,...0),(0,0.....)]),c((0.212,-3.32),(0,0,...0),(0,0.....))] (recordad que las LSTM tienen dos estados ocultos h y c el primero en teoría para la memoria a corto y el segundo para la memoria a largo)\n",
        "    Procesa: e2 [(6.665, -4.443), h(e1), c(1)]\n",
        "4. Ahora sí devuelve [salida(e2),h(e2),c(2)] y esto es parte de lo que entra en el Decoder\n",
        "5. El decoder a la vez ha hecho el embedding de su entrada [emb(\"\\<sos\\>\"),emb(\"Me\"),emb(\"gusta\"),emb(\"el\"),emb(\"fútbol\")]\n",
        "5. Lo primero que procesa el decoder es d1: [h(e2),c(e2),emb(\"\\<sos\\>\")] y la capa de salida predice (en el caso de la figura) \"me\"  \n",
        "6. Luego procesa d2: [emb(\"Me\"),$h_d$(d1),$c_d$(d1)] y la capa de salida predice (en este caso): \"encanta\"\n",
        "7. procesa d3: [emb(\"gusta\"),$h_d$(d2),$c_d$(d2)] y la capa de salida predice: \"el\" (Importante, le entra el embedding de la palabra que tendría que haber predicho antes (\"gusta\") no la que realmente predijo \"encanta\", esto es *Teaching Forcing*)\n",
        "8. procesa d4: [emb(\"el\"),$h_d$(d3),$c_d$(d3)] y la capa de salida predice: \"fútbol\"\n",
        "9. procesa d5: [emb(\"fútbol\"),$h_d$(d4),$c_d$(4)] y la capa de salida predice: \"\\<eos\\>\" (end of sequence) (podría haber hecho la predicción de otra palabra y hubiera acabado igual pero se contabilizaría como un error para el optimizador, etc, etc)\n",
        "10. Se acaba la secuencia de entrada para el decoder\n",
        "\n",
        "A destacar:\n",
        "- El encoder sólo le pasara los hidden_state (h y c) del final de la secuencia de entrada al decoder o un vector repetido.\n",
        "- El decoder trabaja sobre el target completo desplazado una vez (esto nos sirve para construir el vec2seq), sino, habría que usar TimeDistributed (porque no predecimos solo una palabra).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8ADOrEjrtMS"
      },
      "source": [
        "### Construcción del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-mpvJODrtMS"
      },
      "source": [
        "Ok, ahora que todo ha quedado clarito como la teoría de la relatividad, vamos a construir el modelo.  \n",
        "Primero las capas de embeddings: como ya hemos visto primero nuestros vectorizadores para convertir cada sentencia en secuencia de índices y después la capa de embedding para que aprenda cual es la mejor reprensentación de cada índice/palabra en el contexto del problema que estamos resolviendo. (De hecho, ***inciso: ¿qué es lo que realmente está haciendo el encoder...***, *se te ocurre qué podríamos hacer con el encoder una vez entrenado todo el modelo...*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "luUMMVZ0rtMS"
      },
      "outputs": [],
      "source": [
        "vocab_size = 1000 # Número de tokens de nuestro vocabulario, en este caso vamos a hacer que token = (conjunto caracteres separados por espacios)\n",
        "max_length = 50 # Las secuencias de entrada están fijadas a 50, podríamos haberlas fijado a...\n",
        "text_vec_layer_en = tf.keras.layers.TextVectorization(\n",
        "    vocab_size, output_sequence_length=max_length) # Como no decimos nada split=\"whitespace\", o sea la tokenizacion mencionada\n",
        "text_vec_layer_es = tf.keras.layers.TextVectorization(\n",
        "    vocab_size, output_sequence_length=max_length)\n",
        "text_vec_layer_en.adapt(sentences_en)\n",
        "text_vec_layer_es.adapt([f\"startofseq {s} endofseq\" for s in sentences_es]) # Importante le añadimos el comienzo de secuencia y el final para que sepa dónde empieza y para que aprenda cuándo se acaba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxiguIiTrtMT",
        "outputId": "5823e1f5-5a52-4bd8-9163-8d06d20175b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " np.str_('the'),\n",
              " np.str_('i'),\n",
              " np.str_('to'),\n",
              " np.str_('you'),\n",
              " np.str_('tom'),\n",
              " np.str_('a'),\n",
              " np.str_('is'),\n",
              " np.str_('he')]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "text_vec_layer_en.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRDoz0NOrtMT",
        "outputId": "f4d03ce7-b93e-4210-f2b2-dedf3d18280d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " np.str_('startofseq'),\n",
              " np.str_('endofseq'),\n",
              " np.str_('de'),\n",
              " np.str_('que'),\n",
              " np.str_('a'),\n",
              " np.str_('no'),\n",
              " np.str_('tom'),\n",
              " np.str_('la')]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "text_vec_layer_es.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKXkImlH5Sdd"
      },
      "source": [
        "Veamos cómo codifica algunas de las setencias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BH1Nz_po5iV4",
        "outputId": "58e657dd-7494-43ed-96e4-5c20ef4a0237"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It is thirty meters in length.(6), '=>', Tiene treinta metros de largo.(5)\n",
            "Vectorizacion sin embedding de la entrada al encoder\n",
            "tf.Tensor(\n",
            "[ 13   8 752   1  10   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0], shape=(50,), dtype=int64)\n",
            "Vectorizacion sin embedding de la entrada al decoder\n",
            "tf.Tensor(\n",
            "[  2  40 676   1   4 552   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0], shape=(50,), dtype=int64)\n",
            "Vectorizacion del target\n",
            "tf.Tensor(\n",
            "[ 40 676   1   4 552   3   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0], shape=(50,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "origen = randint(0,len(sentences_es)-3)\n",
        "for i in range(origen, origen+1):\n",
        "    print(f\"{sentences_en[i]}({len(sentences_en[i].split())}), '=>', {sentences_es[i]}({len(sentences_es[i].split())})\")\n",
        "    print(\"Vectorizacion sin embedding de la entrada al encoder\",text_vec_layer_en(sentences_en[i]), sep = \"\\n\")\n",
        "    print(\"Vectorizacion sin embedding de la entrada al decoder\", text_vec_layer_es(f\"startofseq {sentences_es[i]}\"), sep = \"\\n\")\n",
        "    print(\"Vectorizacion del target\", text_vec_layer_es(f\"{sentences_es[i]} endofseq\"), sep = \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGVInDEhrtMT"
      },
      "source": [
        "Construímos los datasets de entrenamiento y validación, teniendo encuenta que encoder y decoder reciben entradas ligeramente diferentes y que el targert debe contener el endofseq (que es un token que debe predecir el modelo, es decir debe predecir cuando acaba la frase)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "6-vrcZDyrtMT"
      },
      "outputs": [],
      "source": [
        "X_train = tf.constant(sentences_en[:100_000])\n",
        "X_valid = tf.constant(sentences_en[100_000:])\n",
        "X_train_dec = tf.constant([f\"startofseq {s}\" for s in sentences_es[:100_000]])\n",
        "X_valid_dec = tf.constant([f\"startofseq {s}\" for s in sentences_es[100_000:]])\n",
        "Y_train = text_vec_layer_es([f\"{s} endofseq\" for s in sentences_es[:100_000]])\n",
        "Y_valid = text_vec_layer_es([f\"{s} endofseq\" for s in sentences_es[100_000:]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "PM7qi61-eh9z"
      },
      "outputs": [],
      "source": [
        "from keras.layers import RepeatVector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "aZt8_NX7bOuH",
        "outputId": "4c8d1a31-a120-44de-dca0-a2fb9e4b8370"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ text_vectorization  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mTextVectorization\u001b[0m) │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m128,000\u001b[0m │ text_vectorizati… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ text_vectorizati… │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │  \u001b[38;5;34m1,312,768\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                     │                   │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ repeat_vector       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mRepeatVector\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m2,099,200\u001b[0m │ repeat_vector[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m1000\u001b[0m)  │    \u001b[38;5;34m513,000\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ text_vectorization  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>) │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">128,000</span> │ text_vectorizati… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ text_vectorizati… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,312,768</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                     │                   │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ repeat_vector       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">513,000</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,052,968\u001b[0m (15.46 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,052,968</span> (15.46 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,052,968\u001b[0m (15.46 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,052,968</span> (15.46 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "embed_size = 128\n",
        "\n",
        "# Layer 1 & 2 of Encoder\n",
        "encoder_inputs     = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
        "encoder_input_ids  = text_vec_layer_en(encoder_inputs)\n",
        "encoder_embeddings = tf.keras.layers.Embedding(vocab_size, embed_size,mask_zero=True)(encoder_input_ids)\n",
        "encoder = tf.keras.layers.LSTM(512)(encoder_embeddings)\n",
        "r_vec = RepeatVector(n=max_length)(encoder) # con el repeatVector\n",
        "\n",
        "# Layer 1 & 2 of Decoder\n",
        "decoder_inputs     = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
        "decoder_input_ids  = text_vec_layer_es(decoder_inputs)\n",
        "decoder_embeddings = tf.keras.layers.Embedding(vocab_size, embed_size,mask_zero=True)(decoder_input_ids)\n",
        "decoder_outputs    = tf.keras.layers.LSTM(512, return_sequences=True, dropout=0.2)(r_vec)\n",
        "\n",
        "# Layer 3 of Decoder\n",
        "Y_proba = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")(decoder_outputs)\n",
        "\n",
        "model = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs],outputs=[Y_proba])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6XplSzgrtMT"
      },
      "source": [
        "Y ahora sí, comenzamos con la definición (funcional del modelo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-W99DourtMW"
      },
      "source": [
        "**Warning**: the following cell will take a while to run (possibly a couple hours if you are not using a GPU)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Escoged en Google Colab una GPU gratuita !!!! (o tardará muuuuucho en entrenarse, pero muuuuucho)"
      ],
      "metadata": {
        "id": "j6NkCLj0F3T4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "v8ZLhJoz0myR"
      },
      "outputs": [],
      "source": [
        "checkpoint_filepath = './tmp/ckpt/checkpoint.model.keras'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "5TiytMJJMNU7"
      },
      "outputs": [],
      "source": [
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZT7TWtjrtMW",
        "outputId": "e1fb1d5b-dc91-498d-af44-ba55ef3c8a92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 24ms/step - accuracy: 0.8797 - loss: 0.7136 - val_accuracy: 0.8961 - val_loss: 0.5142\n",
            "Epoch 2/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 25ms/step - accuracy: 0.8984 - loss: 0.4839 - val_accuracy: 0.9064 - val_loss: 0.4129\n",
            "Epoch 3/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 24ms/step - accuracy: 0.9082 - loss: 0.3934 - val_accuracy: 0.9117 - val_loss: 0.3691\n",
            "Epoch 4/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 24ms/step - accuracy: 0.9144 - loss: 0.3454 - val_accuracy: 0.9146 - val_loss: 0.3484\n",
            "Epoch 5/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 24ms/step - accuracy: 0.9185 - loss: 0.3171 - val_accuracy: 0.9157 - val_loss: 0.3374\n",
            "Epoch 6/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 24ms/step - accuracy: 0.9214 - loss: 0.2980 - val_accuracy: 0.9175 - val_loss: 0.3326\n",
            "Epoch 7/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 24ms/step - accuracy: 0.9246 - loss: 0.2807 - val_accuracy: 0.9178 - val_loss: 0.3272\n",
            "Epoch 8/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 24ms/step - accuracy: 0.9270 - loss: 0.2670 - val_accuracy: 0.9186 - val_loss: 0.3266\n",
            "Epoch 9/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 24ms/step - accuracy: 0.9296 - loss: 0.2536 - val_accuracy: 0.9180 - val_loss: 0.3278\n",
            "Epoch 10/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 24ms/step - accuracy: 0.9319 - loss: 0.2435 - val_accuracy: 0.9177 - val_loss: 0.3310\n",
            "Epoch 11/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 26ms/step - accuracy: 0.9343 - loss: 0.2324 - val_accuracy: 0.9186 - val_loss: 0.3332\n",
            "Epoch 12/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 24ms/step - accuracy: 0.9359 - loss: 0.2247 - val_accuracy: 0.9183 - val_loss: 0.3375\n",
            "Epoch 13/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 26ms/step - accuracy: 0.9379 - loss: 0.2163 - val_accuracy: 0.9178 - val_loss: 0.3414\n",
            "Epoch 14/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 26ms/step - accuracy: 0.9393 - loss: 0.2095 - val_accuracy: 0.9182 - val_loss: 0.3449\n",
            "Epoch 15/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 26ms/step - accuracy: 0.9407 - loss: 0.2036 - val_accuracy: 0.9178 - val_loss: 0.3492\n",
            "Epoch 16/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 24ms/step - accuracy: 0.9422 - loss: 0.1966 - val_accuracy: 0.9175 - val_loss: 0.3538\n",
            "Epoch 17/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 26ms/step - accuracy: 0.9436 - loss: 0.1910 - val_accuracy: 0.9170 - val_loss: 0.3575\n",
            "Epoch 18/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 25ms/step - accuracy: 0.9451 - loss: 0.1854 - val_accuracy: 0.9169 - val_loss: 0.3616\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78b553809090>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "model.fit((X_train, X_train_dec), Y_train, epochs=100,\n",
        "          validation_data=((X_valid, X_valid_dec), Y_valid), callbacks=[model_checkpoint_callback, early_stopping_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPtEaBMqrtMW"
      },
      "source": [
        "Una vez entrenado el modelo, la traducción la hacemos palabra por palabra (si no, habría que usar una capa TimeDistributed).  \n",
        "\n",
        "El decoder espera que le pasemos una secuencia guía (el teacher, aquí no hacemos teacher forcing), que es la función que hacía la secuencia target desplazada uno en el entrenamiento.  \n",
        "\n",
        "Lo que vamos a hacer es ir prediciendo palabra a palabra introduciendo como guía la última predicción hasta llegar a que el modelo devuelva el carácter de fin de secuencia y en ese momento devolvemos la \"traducción\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "adTniqXUrtMW"
      },
      "outputs": [],
      "source": [
        "def translate(sentence_en):\n",
        "    translation = \"\"\n",
        "    for word_idx in range(max_length):\n",
        "        X = np.array([sentence_en])  # encoder input\n",
        "        X_dec = np.array([\"startofseq \" + translation])  # decoder input\n",
        "        y_probs = model.predict((X.astype(object), X_dec.astype(object)))\n",
        "        y_proba = y_probs[0, word_idx]  # last token's probas\n",
        "        predicted_word_id = np.argmax(y_proba)\n",
        "        predicted_proba = round(float(y_proba[predicted_word_id]),3)\n",
        "        predicted_word = text_vec_layer_es.get_vocabulary()[predicted_word_id]\n",
        "        if predicted_word == \"endofseq\":\n",
        "            break\n",
        "        translation += \" \" + predicted_word\n",
        "        print(f\"{translation}({predicted_proba})\")\n",
        "    return translation.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnh_m6khrtMW"
      },
      "source": [
        "Probemos con algo sencillo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "-ranB-ZwsQmG"
      },
      "outputs": [],
      "source": [
        "frase = \"I like snow\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "CKivIVBkrtMW",
        "outputId": "e491c7d2-ca3a-4557-a8b5-bf09de35c7c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step\n",
            " me(0.998)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            " me gusta(0.963)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            " me gusta la(0.73)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            " me gusta la la(0.477)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'me gusta la la'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "translate(frase)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "3acbdajllVUC"
      },
      "outputs": [],
      "source": [
        "frase= \"I like eating cake.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "9VAwaBcAvx7T",
        "outputId": "18714146-b3dc-4593-f379-4210ef421866"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            " me(0.997)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            " me gusta(0.911)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            " me gusta comer(0.978)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            " me gusta comer [UNK](0.909)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'me gusta comer [UNK]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "translate(frase)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "TE1JWcXylkU2"
      },
      "outputs": [],
      "source": [
        "frase= \"The flowers are so beautiful\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "UdzzHeA5lqyu",
        "outputId": "769e77e3-d38f-4b33-a098-6d17ddf7dfa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            " mis(0.684)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            " mis flores(0.699)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            " mis flores son(0.491)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            " mis flores son demasiado(0.731)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            " mis flores son demasiado [UNK](0.741)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mis flores son demasiado [UNK]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "translate(frase)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sbpR3btrrtMX",
        "outputId": "bf789f78-4234-470d-ad98-8e0948b7bd73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            " me(0.998)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            " me gusta(0.617)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            " me gusta [UNK](0.381)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            " me gusta [UNK] y(0.311)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            " me gusta [UNK] y y(0.34)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            " me gusta [UNK] y y pero(0.348)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            " me gusta [UNK] y y pero [UNK](0.36)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK](0.298)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a(0.468)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la(0.591)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa(0.507)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa (0.734)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa  (0.97)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa   (0.998)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa    (0.998)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa     (1.0)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa      (1.0)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa       (1.0)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa        (1.0)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa         (1.0)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa          (1.0)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa           (1.0)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa            (1.0)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa             (1.0)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa              (1.0)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa               (1.0)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa                (1.0)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa                 (1.0)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa                  (1.0)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa                   (1.0)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa                    (1.0)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa                     (1.0)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa                      (1.0)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa                       (1.0)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa                        (1.0)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa                         (1.0)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa                          (1.0)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa                           (1.0)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa                            (1.0)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa                             (1.0)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa                              (1.0)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa                               (1.0)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa                                (1.0)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa                                 (1.0)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa                                  (1.0)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa                                   (1.0)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa                                    (1.0)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa                                     (1.0)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa                                      (1.0)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            " me gusta [UNK] y y pero [UNK] [UNK] a la playa                                       (1.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'me gusta [UNK] y y pero [UNK] [UNK] a la playa'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "translate(\"I like soccer and also going to the beach\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLEFb-nymBSN",
        "outputId": "429f18f0-0d80-4fe6-e1ad-06a84a2068a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " np.str_('the'),\n",
              " np.str_('i'),\n",
              " np.str_('to'),\n",
              " np.str_('you'),\n",
              " np.str_('tom'),\n",
              " np.str_('a'),\n",
              " np.str_('is'),\n",
              " np.str_('he'),\n",
              " np.str_('in'),\n",
              " np.str_('of'),\n",
              " np.str_('that'),\n",
              " np.str_('it'),\n",
              " np.str_('was'),\n",
              " np.str_('do'),\n",
              " np.str_('have'),\n",
              " np.str_('this'),\n",
              " np.str_('me'),\n",
              " np.str_('my'),\n",
              " np.str_('for'),\n",
              " np.str_('she'),\n",
              " np.str_('dont'),\n",
              " np.str_('are'),\n",
              " np.str_('what'),\n",
              " np.str_('his'),\n",
              " np.str_('mary'),\n",
              " np.str_('we'),\n",
              " np.str_('your'),\n",
              " np.str_('on'),\n",
              " np.str_('be'),\n",
              " np.str_('with'),\n",
              " np.str_('want'),\n",
              " np.str_('not'),\n",
              " np.str_('im'),\n",
              " np.str_('and'),\n",
              " np.str_('like'),\n",
              " np.str_('at'),\n",
              " np.str_('know'),\n",
              " np.str_('him'),\n",
              " np.str_('can'),\n",
              " np.str_('go'),\n",
              " np.str_('her'),\n",
              " np.str_('has'),\n",
              " np.str_('will'),\n",
              " np.str_('its'),\n",
              " np.str_('there'),\n",
              " np.str_('they'),\n",
              " np.str_('time'),\n",
              " np.str_('how'),\n",
              " np.str_('did'),\n",
              " np.str_('as'),\n",
              " np.str_('were'),\n",
              " np.str_('very'),\n",
              " np.str_('had'),\n",
              " np.str_('all'),\n",
              " np.str_('about'),\n",
              " np.str_('here'),\n",
              " np.str_('up'),\n",
              " np.str_('didnt'),\n",
              " np.str_('think'),\n",
              " np.str_('get'),\n",
              " np.str_('out'),\n",
              " np.str_('when'),\n",
              " np.str_('from'),\n",
              " np.str_('cant'),\n",
              " np.str_('if'),\n",
              " np.str_('an'),\n",
              " np.str_('no'),\n",
              " np.str_('one'),\n",
              " np.str_('doesnt'),\n",
              " np.str_('going'),\n",
              " np.str_('by'),\n",
              " np.str_('would'),\n",
              " np.str_('why'),\n",
              " np.str_('come'),\n",
              " np.str_('see'),\n",
              " np.str_('good'),\n",
              " np.str_('ill'),\n",
              " np.str_('please'),\n",
              " np.str_('youre'),\n",
              " np.str_('just'),\n",
              " np.str_('who'),\n",
              " np.str_('been'),\n",
              " np.str_('need'),\n",
              " np.str_('so'),\n",
              " np.str_('more'),\n",
              " np.str_('help'),\n",
              " np.str_('tell'),\n",
              " np.str_('but'),\n",
              " np.str_('now'),\n",
              " np.str_('where'),\n",
              " np.str_('than'),\n",
              " np.str_('never'),\n",
              " np.str_('am'),\n",
              " np.str_('got'),\n",
              " np.str_('too'),\n",
              " np.str_('some'),\n",
              " np.str_('us'),\n",
              " np.str_('something'),\n",
              " np.str_('last'),\n",
              " np.str_('take'),\n",
              " np.str_('much'),\n",
              " np.str_('should'),\n",
              " np.str_('day'),\n",
              " np.str_('ive'),\n",
              " np.str_('car'),\n",
              " np.str_('could'),\n",
              " np.str_('money'),\n",
              " np.str_('home'),\n",
              " np.str_('people'),\n",
              " np.str_('work'),\n",
              " np.str_('well'),\n",
              " np.str_('back'),\n",
              " np.str_('really'),\n",
              " np.str_('our'),\n",
              " np.str_('went'),\n",
              " np.str_('many'),\n",
              " np.str_('said'),\n",
              " np.str_('told'),\n",
              " np.str_('house'),\n",
              " np.str_('book'),\n",
              " np.str_('any'),\n",
              " np.str_('lot'),\n",
              " np.str_('anything'),\n",
              " np.str_('hes'),\n",
              " np.str_('does'),\n",
              " np.str_('isnt'),\n",
              " np.str_('say'),\n",
              " np.str_('thought'),\n",
              " np.str_('only'),\n",
              " np.str_('make'),\n",
              " np.str_('eat'),\n",
              " np.str_('french'),\n",
              " np.str_('school'),\n",
              " np.str_('room'),\n",
              " np.str_('new'),\n",
              " np.str_('two'),\n",
              " np.str_('thats'),\n",
              " np.str_('always'),\n",
              " np.str_('made'),\n",
              " np.str_('today'),\n",
              " np.str_('toms'),\n",
              " np.str_('must'),\n",
              " np.str_('give'),\n",
              " np.str_('speak'),\n",
              " np.str_('right'),\n",
              " np.str_('long'),\n",
              " np.str_('every'),\n",
              " np.str_('love'),\n",
              " np.str_('man'),\n",
              " np.str_('old'),\n",
              " np.str_('three'),\n",
              " np.str_('father'),\n",
              " np.str_('wanted'),\n",
              " np.str_('still'),\n",
              " np.str_('lets'),\n",
              " np.str_('off'),\n",
              " np.str_('night'),\n",
              " np.str_('let'),\n",
              " np.str_('look'),\n",
              " np.str_('before'),\n",
              " np.str_('asked'),\n",
              " np.str_('tomorrow'),\n",
              " np.str_('talk'),\n",
              " np.str_('boston'),\n",
              " np.str_('id'),\n",
              " np.str_('left'),\n",
              " np.str_('way'),\n",
              " np.str_('little'),\n",
              " np.str_('dog'),\n",
              " np.str_('leave'),\n",
              " np.str_('put'),\n",
              " np.str_('nothing'),\n",
              " np.str_('or'),\n",
              " np.str_('saw'),\n",
              " np.str_('again'),\n",
              " np.str_('job'),\n",
              " np.str_('over'),\n",
              " np.str_('after'),\n",
              " np.str_('years'),\n",
              " np.str_('yesterday'),\n",
              " np.str_('whats'),\n",
              " np.str_('into'),\n",
              " np.str_('may'),\n",
              " np.str_('live'),\n",
              " np.str_('better'),\n",
              " np.str_('down'),\n",
              " np.str_('english'),\n",
              " np.str_('them'),\n",
              " np.str_('wont'),\n",
              " np.str_('buy'),\n",
              " np.str_('came'),\n",
              " np.str_('stay'),\n",
              " np.str_('everything'),\n",
              " np.str_('happy'),\n",
              " np.str_('read'),\n",
              " np.str_('first'),\n",
              " np.str_('find'),\n",
              " np.str_('play'),\n",
              " np.str_('next'),\n",
              " np.str_('wants'),\n",
              " np.str_('mother'),\n",
              " np.str_('theres'),\n",
              " np.str_('couldnt'),\n",
              " np.str_('took'),\n",
              " np.str_('life'),\n",
              " np.str_('understand'),\n",
              " np.str_('other'),\n",
              " np.str_('friends'),\n",
              " np.str_('children'),\n",
              " np.str_('these'),\n",
              " np.str_('ask'),\n",
              " np.str_('bought'),\n",
              " np.str_('stop'),\n",
              " np.str_('morning'),\n",
              " np.str_('used'),\n",
              " np.str_('doing'),\n",
              " np.str_('keep'),\n",
              " np.str_('door'),\n",
              " np.str_('problem'),\n",
              " np.str_('call'),\n",
              " np.str_('believe'),\n",
              " np.str_('feel'),\n",
              " np.str_('their'),\n",
              " np.str_('lost'),\n",
              " np.str_('ever'),\n",
              " np.str_('away'),\n",
              " np.str_('late'),\n",
              " np.str_('gave'),\n",
              " np.str_('soon'),\n",
              " np.str_('sure'),\n",
              " np.str_('happened'),\n",
              " np.str_('name'),\n",
              " np.str_('friend'),\n",
              " np.str_('remember'),\n",
              " np.str_('already'),\n",
              " np.str_('enough'),\n",
              " np.str_('alone'),\n",
              " np.str_('hard'),\n",
              " np.str_('year'),\n",
              " np.str_('married'),\n",
              " np.str_('heard'),\n",
              " np.str_('without'),\n",
              " np.str_('wrong'),\n",
              " np.str_('week'),\n",
              " np.str_('best'),\n",
              " np.str_('water'),\n",
              " np.str_('busy'),\n",
              " np.str_('boy'),\n",
              " np.str_('teacher'),\n",
              " np.str_('wasnt'),\n",
              " np.str_('even'),\n",
              " np.str_('bad'),\n",
              " np.str_('beautiful'),\n",
              " np.str_('things'),\n",
              " np.str_('because'),\n",
              " np.str_('try'),\n",
              " np.str_('often'),\n",
              " np.str_('knows'),\n",
              " np.str_('bed'),\n",
              " np.str_('looking'),\n",
              " np.str_('hear'),\n",
              " np.str_('found'),\n",
              " np.str_('marys'),\n",
              " np.str_('likes'),\n",
              " np.str_('wait'),\n",
              " np.str_('same'),\n",
              " np.str_('done'),\n",
              " np.str_('party'),\n",
              " np.str_('seen'),\n",
              " np.str_('looks'),\n",
              " np.str_('able'),\n",
              " np.str_('thing'),\n",
              " np.str_('cold'),\n",
              " np.str_('theyre'),\n",
              " np.str_('big'),\n",
              " np.str_('knew'),\n",
              " np.str_('food'),\n",
              " np.str_('train'),\n",
              " np.str_('person'),\n",
              " np.str_('idea'),\n",
              " np.str_('john'),\n",
              " np.str_('tired'),\n",
              " np.str_('coffee'),\n",
              " np.str_('answer'),\n",
              " np.str_('use'),\n",
              " np.str_('being'),\n",
              " np.str_('brother'),\n",
              " np.str_('true'),\n",
              " np.str_('hope'),\n",
              " np.str_('while'),\n",
              " np.str_('everyone'),\n",
              " np.str_('around'),\n",
              " np.str_('watch'),\n",
              " np.str_('learn'),\n",
              " np.str_('letter'),\n",
              " np.str_('drink'),\n",
              " np.str_('books'),\n",
              " np.str_('shes'),\n",
              " np.str_('yet'),\n",
              " np.str_('open'),\n",
              " np.str_('days'),\n",
              " np.str_('wish'),\n",
              " np.str_('met'),\n",
              " np.str_('japan'),\n",
              " np.str_('girl'),\n",
              " np.str_('which'),\n",
              " np.str_('almost'),\n",
              " np.str_('youll'),\n",
              " np.str_('died'),\n",
              " np.str_('someone'),\n",
              " np.str_('mind'),\n",
              " np.str_('sleep'),\n",
              " np.str_('bus'),\n",
              " np.str_('pay'),\n",
              " np.str_('study'),\n",
              " np.str_('kind'),\n",
              " np.str_('few'),\n",
              " np.str_('world'),\n",
              " np.str_('those'),\n",
              " np.str_('young'),\n",
              " np.str_('parents'),\n",
              " np.str_('turn'),\n",
              " np.str_('truth'),\n",
              " np.str_('each'),\n",
              " np.str_('talking'),\n",
              " np.str_('another'),\n",
              " np.str_('seems'),\n",
              " np.str_('place'),\n",
              " np.str_('walk'),\n",
              " np.str_('lunch'),\n",
              " np.str_('looked'),\n",
              " np.str_('getting'),\n",
              " np.str_('family'),\n",
              " np.str_('once'),\n",
              " np.str_('happen'),\n",
              " np.str_('care'),\n",
              " np.str_('anyone'),\n",
              " np.str_('most'),\n",
              " np.str_('doctor'),\n",
              " np.str_('tried'),\n",
              " np.str_('afraid'),\n",
              " np.str_('early'),\n",
              " np.str_('both'),\n",
              " np.str_('own'),\n",
              " np.str_('ten'),\n",
              " np.str_('sister'),\n",
              " np.str_('until'),\n",
              " np.str_('monday'),\n",
              " np.str_('havent'),\n",
              " np.str_('together'),\n",
              " np.str_('difficult'),\n",
              " np.str_('ago'),\n",
              " np.str_('mine'),\n",
              " np.str_('rain'),\n",
              " np.str_('write'),\n",
              " np.str_('great'),\n",
              " np.str_('plan'),\n",
              " np.str_('angry'),\n",
              " np.str_('show'),\n",
              " np.str_('dinner'),\n",
              " np.str_('coming'),\n",
              " np.str_('tv'),\n",
              " np.str_('else'),\n",
              " np.str_('cat'),\n",
              " np.str_('hours'),\n",
              " np.str_('favorite'),\n",
              " np.str_('youve'),\n",
              " np.str_('since'),\n",
              " np.str_('yourself'),\n",
              " np.str_('wouldnt'),\n",
              " np.str_('himself'),\n",
              " np.str_('child'),\n",
              " np.str_('country'),\n",
              " np.str_('wife'),\n",
              " np.str_('playing'),\n",
              " np.str_('arent'),\n",
              " np.str_('meeting'),\n",
              " np.str_('says'),\n",
              " np.str_('five'),\n",
              " np.str_('question'),\n",
              " np.str_('might'),\n",
              " np.str_('sorry'),\n",
              " np.str_('reading'),\n",
              " np.str_('table'),\n",
              " np.str_('such'),\n",
              " np.str_('phone'),\n",
              " np.str_('matter'),\n",
              " np.str_('police'),\n",
              " np.str_('lives'),\n",
              " np.str_('nobody'),\n",
              " np.str_('hurt'),\n",
              " np.str_('everybody'),\n",
              " np.str_('meet'),\n",
              " np.str_('eating'),\n",
              " np.str_('accident'),\n",
              " np.str_('easy'),\n",
              " np.str_('ate'),\n",
              " np.str_('waiting'),\n",
              " np.str_('trying'),\n",
              " np.str_('japanese'),\n",
              " np.str_('start'),\n",
              " np.str_('nice'),\n",
              " np.str_('month'),\n",
              " np.str_('swim'),\n",
              " np.str_('students'),\n",
              " np.str_('finished'),\n",
              " np.str_('called'),\n",
              " np.str_('minutes'),\n",
              " np.str_('hand'),\n",
              " np.str_('started'),\n",
              " np.str_('decided'),\n",
              " np.str_('son'),\n",
              " np.str_('office'),\n",
              " np.str_('hate'),\n",
              " np.str_('far'),\n",
              " np.str_('drive'),\n",
              " np.str_('trouble'),\n",
              " np.str_('times'),\n",
              " np.str_('story'),\n",
              " np.str_('small'),\n",
              " np.str_('myself'),\n",
              " np.str_('important'),\n",
              " np.str_('under'),\n",
              " np.str_('tonight'),\n",
              " np.str_('ready'),\n",
              " np.str_('needs'),\n",
              " np.str_('felt'),\n",
              " np.str_('station'),\n",
              " np.str_('having'),\n",
              " np.str_('shoes'),\n",
              " np.str_('fire'),\n",
              " np.str_('window'),\n",
              " np.str_('arrived'),\n",
              " np.str_('ran'),\n",
              " np.str_('sick'),\n",
              " np.str_('woman'),\n",
              " np.str_('usually'),\n",
              " np.str_('shouldnt'),\n",
              " np.str_('music'),\n",
              " np.str_('city'),\n",
              " np.str_('working'),\n",
              " np.str_('pretty'),\n",
              " np.str_('change'),\n",
              " np.str_('goes'),\n",
              " np.str_('anymore'),\n",
              " np.str_('word'),\n",
              " np.str_('homework'),\n",
              " np.str_('gone'),\n",
              " np.str_('fun'),\n",
              " np.str_('fast'),\n",
              " np.str_('park'),\n",
              " np.str_('hot'),\n",
              " np.str_('tennis'),\n",
              " np.str_('broke'),\n",
              " np.str_('town'),\n",
              " np.str_('christmas'),\n",
              " np.str_('picture'),\n",
              " np.str_('mistake'),\n",
              " np.str_('eyes'),\n",
              " np.str_('visit'),\n",
              " np.str_('breakfast'),\n",
              " np.str_('movie'),\n",
              " np.str_('red'),\n",
              " np.str_('game'),\n",
              " np.str_('run'),\n",
              " np.str_('language'),\n",
              " np.str_('baby'),\n",
              " np.str_('afternoon'),\n",
              " np.str_('thank'),\n",
              " np.str_('six'),\n",
              " np.str_('quite'),\n",
              " np.str_('stupid'),\n",
              " np.str_('forget'),\n",
              " np.str_('song'),\n",
              " np.str_('against'),\n",
              " np.str_('advice'),\n",
              " np.str_('rich'),\n",
              " np.str_('interesting'),\n",
              " np.str_('hair'),\n",
              " np.str_('summer'),\n",
              " np.str_('caught'),\n",
              " np.str_('weve'),\n",
              " np.str_('then'),\n",
              " np.str_('spend'),\n",
              " np.str_('lived'),\n",
              " np.str_('cake'),\n",
              " np.str_('listen'),\n",
              " np.str_('fell'),\n",
              " np.str_('studying'),\n",
              " np.str_('smoking'),\n",
              " np.str_('finish'),\n",
              " np.str_('began'),\n",
              " np.str_('turned'),\n",
              " np.str_('comes'),\n",
              " np.str_('along'),\n",
              " np.str_('river'),\n",
              " np.str_('longer'),\n",
              " np.str_('face'),\n",
              " np.str_('makes'),\n",
              " np.str_('class'),\n",
              " np.str_('close'),\n",
              " np.str_('sit'),\n",
              " np.str_('number'),\n",
              " np.str_('war'),\n",
              " np.str_('free'),\n",
              " np.str_('fish'),\n",
              " np.str_('through'),\n",
              " np.str_('milk'),\n",
              " np.str_('whos'),\n",
              " np.str_('loves'),\n",
              " np.str_('hotel'),\n",
              " np.str_('present'),\n",
              " np.str_('older'),\n",
              " np.str_('australia'),\n",
              " np.str_('watching'),\n",
              " np.str_('later'),\n",
              " np.str_('large'),\n",
              " np.str_('kept'),\n",
              " np.str_('cannot'),\n",
              " np.str_('youd'),\n",
              " np.str_('end'),\n",
              " np.str_('weather'),\n",
              " np.str_('bring'),\n",
              " np.str_('thinking'),\n",
              " np.str_('short'),\n",
              " np.str_('mean'),\n",
              " np.str_('living'),\n",
              " np.str_('hour'),\n",
              " np.str_('death'),\n",
              " np.str_('age'),\n",
              " np.str_('killed'),\n",
              " np.str_('america'),\n",
              " np.str_('hands'),\n",
              " np.str_('dream'),\n",
              " np.str_('box'),\n",
              " np.str_('kill'),\n",
              " np.str_('hospital'),\n",
              " np.str_('sometimes'),\n",
              " np.str_('news'),\n",
              " np.str_('full'),\n",
              " np.str_('dark'),\n",
              " np.str_('chance'),\n",
              " np.str_('became'),\n",
              " np.str_('wonder'),\n",
              " np.str_('surprised'),\n",
              " np.str_('seem'),\n",
              " np.str_('questions'),\n",
              " np.str_('street'),\n",
              " np.str_('sat'),\n",
              " np.str_('making'),\n",
              " np.str_('clean'),\n",
              " np.str_('snow'),\n",
              " np.str_('light'),\n",
              " np.str_('hurry'),\n",
              " np.str_('hungry'),\n",
              " np.str_('forgot'),\n",
              " np.str_('camera'),\n",
              " np.str_('tree'),\n",
              " np.str_('men'),\n",
              " np.str_('hasnt'),\n",
              " np.str_('gets'),\n",
              " np.str_('dollars'),\n",
              " np.str_('born'),\n",
              " np.str_('stopped'),\n",
              " np.str_('cut'),\n",
              " np.str_('bit'),\n",
              " np.str_('student'),\n",
              " np.str_('high'),\n",
              " np.str_('computer'),\n",
              " np.str_('white'),\n",
              " np.str_('stand'),\n",
              " np.str_('tokyo'),\n",
              " np.str_('rather'),\n",
              " np.str_('bicycle'),\n",
              " np.str_('works'),\n",
              " np.str_('trust'),\n",
              " np.str_('thinks'),\n",
              " np.str_('spent'),\n",
              " np.str_('glad'),\n",
              " np.str_('wine'),\n",
              " np.str_('miss'),\n",
              " np.str_('careful'),\n",
              " np.str_('taking'),\n",
              " np.str_('near'),\n",
              " np.str_('dogs'),\n",
              " np.str_('die'),\n",
              " np.str_('company'),\n",
              " np.str_('secret'),\n",
              " np.str_('others'),\n",
              " np.str_('birthday'),\n",
              " np.str_('lie'),\n",
              " np.str_('whether'),\n",
              " np.str_('saying'),\n",
              " np.str_('dead'),\n",
              " np.str_('230'),\n",
              " np.str_('store'),\n",
              " np.str_('oclock'),\n",
              " np.str_('moment'),\n",
              " np.str_('daughter'),\n",
              " np.str_('behind'),\n",
              " np.str_('tea'),\n",
              " np.str_('speaks'),\n",
              " np.str_('flowers'),\n",
              " np.str_('clothes'),\n",
              " np.str_('hit'),\n",
              " np.str_('become'),\n",
              " np.str_('sing'),\n",
              " np.str_('plane'),\n",
              " np.str_('speaking'),\n",
              " np.str_('helped'),\n",
              " np.str_('wrote'),\n",
              " np.str_('possible'),\n",
              " np.str_('eaten'),\n",
              " np.str_('between'),\n",
              " np.str_('stayed'),\n",
              " np.str_('expensive'),\n",
              " np.str_('changed'),\n",
              " np.str_('canadian'),\n",
              " np.str_('business'),\n",
              " np.str_('wearing'),\n",
              " np.str_('rest'),\n",
              " np.str_('building'),\n",
              " np.str_('beer'),\n",
              " np.str_('maybe'),\n",
              " np.str_('takes'),\n",
              " np.str_('sunday'),\n",
              " np.str_('outside'),\n",
              " np.str_('key'),\n",
              " np.str_('girlfriend'),\n",
              " np.str_('four'),\n",
              " np.str_('paper'),\n",
              " np.str_('dress'),\n",
              " np.str_('yours'),\n",
              " np.str_('worked'),\n",
              " np.str_('advised'),\n",
              " np.str_('touch'),\n",
              " np.str_('lose'),\n",
              " np.str_('running'),\n",
              " np.str_('reason'),\n",
              " np.str_('order'),\n",
              " np.str_('needed'),\n",
              " np.str_('famous'),\n",
              " np.str_('break'),\n",
              " np.str_('whole'),\n",
              " np.str_('herself'),\n",
              " np.str_('black'),\n",
              " np.str_('asleep'),\n",
              " np.str_('strange'),\n",
              " np.str_('drunk'),\n",
              " np.str_('catch'),\n",
              " np.str_('anybody'),\n",
              " np.str_('women'),\n",
              " np.str_('wheres'),\n",
              " np.str_('quit'),\n",
              " np.str_('piano'),\n",
              " np.str_('part'),\n",
              " np.str_('pain'),\n",
              " np.str_('glasses'),\n",
              " np.str_('different'),\n",
              " np.str_('cup'),\n",
              " np.str_('trip'),\n",
              " np.str_('team'),\n",
              " np.str_('showed'),\n",
              " np.str_('raining'),\n",
              " np.str_('quickly'),\n",
              " np.str_('problems'),\n",
              " np.str_('paid'),\n",
              " np.str_('noise'),\n",
              " np.str_('hold'),\n",
              " np.str_('exactly'),\n",
              " np.str_('during'),\n",
              " np.str_('dangerous'),\n",
              " np.str_('cats'),\n",
              " np.str_('bank'),\n",
              " np.str_('library'),\n",
              " np.str_('least'),\n",
              " np.str_('ice'),\n",
              " np.str_('dictionary'),\n",
              " np.str_('words'),\n",
              " np.str_('uncle'),\n",
              " np.str_('tall'),\n",
              " np.str_('send'),\n",
              " np.str_('proud'),\n",
              " np.str_('loved'),\n",
              " np.str_('crazy'),\n",
              " np.str_('blame'),\n",
              " np.str_('worry'),\n",
              " np.str_('interested'),\n",
              " np.str_('baseball'),\n",
              " np.str_('waited'),\n",
              " np.str_('telephone'),\n",
              " np.str_('played'),\n",
              " np.str_('mistakes'),\n",
              " np.str_('floor'),\n",
              " np.str_('cook'),\n",
              " np.str_('win'),\n",
              " np.str_('strong'),\n",
              " np.str_('weight'),\n",
              " np.str_('real'),\n",
              " np.str_('probably'),\n",
              " np.str_('head'),\n",
              " np.str_('hat'),\n",
              " np.str_('air'),\n",
              " np.str_('swimming'),\n",
              " np.str_('move'),\n",
              " np.str_('lucky'),\n",
              " np.str_('heart'),\n",
              " np.str_('broken'),\n",
              " np.str_('boys'),\n",
              " np.str_('bag'),\n",
              " np.str_('agree'),\n",
              " np.str_('safe'),\n",
              " np.str_('restaurant'),\n",
              " np.str_('poor'),\n",
              " np.str_('movies'),\n",
              " np.str_('known'),\n",
              " np.str_('garden'),\n",
              " np.str_('front'),\n",
              " np.str_('walked'),\n",
              " np.str_('sound'),\n",
              " np.str_('seemed'),\n",
              " np.str_('opened'),\n",
              " np.str_('health'),\n",
              " np.str_('glass'),\n",
              " np.str_('enjoy'),\n",
              " np.str_('several'),\n",
              " np.str_('hide'),\n",
              " np.str_('hell'),\n",
              " np.str_('finally'),\n",
              " np.str_('cry'),\n",
              " np.str_('television'),\n",
              " np.str_('prefer'),\n",
              " np.str_('guitar'),\n",
              " np.str_('evening'),\n",
              " np.str_('concert'),\n",
              " np.str_('wear'),\n",
              " np.str_('united'),\n",
              " np.str_('thanks'),\n",
              " np.str_('talked'),\n",
              " np.str_('shirt'),\n",
              " np.str_('missed'),\n",
              " np.str_('explain'),\n",
              " np.str_('umbrella'),\n",
              " np.str_('choice'),\n",
              " np.str_('brought'),\n",
              " np.str_('sun'),\n",
              " np.str_('seven'),\n",
              " np.str_('sad'),\n",
              " np.str_('learned'),\n",
              " np.str_('whose'),\n",
              " np.str_('thirty'),\n",
              " np.str_('side'),\n",
              " np.str_('rules'),\n",
              " np.str_('return'),\n",
              " np.str_('radio'),\n",
              " np.str_('pass'),\n",
              " np.str_('lying'),\n",
              " np.str_('feeling'),\n",
              " np.str_('either'),\n",
              " np.str_('states'),\n",
              " np.str_('somebody'),\n",
              " np.str_('road'),\n",
              " np.str_('ok'),\n",
              " np.str_('minute'),\n",
              " np.str_('animals'),\n",
              " np.str_('shut'),\n",
              " np.str_('seeing'),\n",
              " np.str_('half'),\n",
              " np.str_('attention'),\n",
              " np.str_('smoke'),\n",
              " np.str_('leaving'),\n",
              " np.str_('crying'),\n",
              " np.str_('cost'),\n",
              " np.str_('visited'),\n",
              " np.str_('twice'),\n",
              " np.str_('meat'),\n",
              " np.str_('lawyer'),\n",
              " np.str_('forward'),\n",
              " np.str_('fishing'),\n",
              " np.str_('driving'),\n",
              " np.str_('drinking'),\n",
              " np.str_('paris'),\n",
              " np.str_('invited'),\n",
              " np.str_('danger'),\n",
              " np.str_('won'),\n",
              " np.str_('wall'),\n",
              " np.str_('solve'),\n",
              " np.str_('situation'),\n",
              " np.str_('seat'),\n",
              " np.str_('promise'),\n",
              " np.str_('guess'),\n",
              " np.str_('fine'),\n",
              " np.str_('arrive'),\n",
              " np.str_('apple'),\n",
              " np.str_('alive'),\n",
              " np.str_('kids'),\n",
              " np.str_('husband'),\n",
              " np.str_('decision'),\n",
              " np.str_('completely'),\n",
              " np.str_('closed'),\n",
              " np.str_('accept'),\n",
              " np.str_('worried'),\n",
              " np.str_('set'),\n",
              " np.str_('mad'),\n",
              " np.str_('less'),\n",
              " np.str_('expect'),\n",
              " np.str_('desk'),\n",
              " np.str_('dance'),\n",
              " np.str_('airport'),\n",
              " np.str_('winter'),\n",
              " np.str_('vacation'),\n",
              " np.str_('traffic'),\n",
              " np.str_('sleeping'),\n",
              " np.str_('sent'),\n",
              " np.str_('point'),\n",
              " np.str_('lake'),\n",
              " np.str_('follow'),\n",
              " np.str_('blue'),\n",
              " np.str_('learning'),\n",
              " np.str_('knife'),\n",
              " np.str_('younger'),\n",
              " np.str_('london'),\n",
              " np.str_('eggs'),\n",
              " np.str_('beach'),\n",
              " np.str_('abroad'),\n",
              " np.str_('writing'),\n",
              " np.str_('weekend'),\n",
              " np.str_('singing'),\n",
              " np.str_('promised'),\n",
              " np.str_('kitchen'),\n",
              " np.str_('girls'),\n",
              " np.str_('spoke'),\n",
              " np.str_('mountain'),\n",
              " np.str_('kiss'),\n",
              " np.str_('apples'),\n",
              " np.str_('shouldve'),\n",
              " np.str_('patient'),\n",
              " np.str_('passed'),\n",
              " np.str_('liked'),\n",
              " np.str_('hiding'),\n",
              " np.str_('travel'),\n",
              " np.str_('though'),\n",
              " np.str_('taken'),\n",
              " np.str_('sitting'),\n",
              " np.str_('shopping'),\n",
              " np.str_('months'),\n",
              " np.str_('impossible'),\n",
              " np.str_('guy'),\n",
              " np.str_('drank'),\n",
              " np.str_('worse'),\n",
              " np.str_('waste'),\n",
              " np.str_('wash'),\n",
              " np.str_('soccer'),\n",
              " np.str_('ship'),\n",
              " np.str_('serious'),\n",
              " np.str_('opinion'),\n",
              " np.str_('medicine'),\n",
              " np.str_('excuse'),\n",
              " np.str_('begin'),\n",
              " np.str_('also'),\n",
              " np.str_('address'),\n",
              " np.str_('written'),\n",
              " np.str_('worth'),\n",
              " np.str_('werent'),\n",
              " np.str_('ticket'),\n",
              " np.str_('second'),\n",
              " np.str_('listening'),\n",
              " np.str_('happens'),\n",
              " np.str_('coat'),\n",
              " np.str_('china'),\n",
              " np.str_('sense'),\n",
              " np.str_('hed'),\n",
              " np.str_('fight'),\n",
              " np.str_('brothers'),\n",
              " np.str_('tie'),\n",
              " np.str_('success'),\n",
              " np.str_('piece'),\n",
              " np.str_('machine'),\n",
              " np.str_('hardly'),\n",
              " np.str_('foreign'),\n",
              " np.str_('teach'),\n",
              " np.str_('languages'),\n",
              " np.str_('itll'),\n",
              " np.str_('expected'),\n",
              " np.str_('clear'),\n",
              " np.str_('walking'),\n",
              " np.str_('terrible'),\n",
              " np.str_('pick'),\n",
              " np.str_('offer'),\n",
              " np.str_('keys'),\n",
              " np.str_('grandfather'),\n",
              " np.str_('case'),\n",
              " np.str_('arm'),\n",
              " np.str_('test'),\n",
              " np.str_('pictures'),\n",
              " np.str_('pen'),\n",
              " np.str_('message'),\n",
              " np.str_('figure'),\n",
              " np.str_('church'),\n",
              " np.str_('bird'),\n",
              " np.str_('american'),\n",
              " np.str_('wake'),\n",
              " np.str_('smart'),\n",
              " np.str_('perfect'),\n",
              " np.str_('sounds'),\n",
              " np.str_('refused'),\n",
              " np.str_('horse'),\n",
              " np.str_('happening'),\n",
              " np.str_('easily'),\n",
              " np.str_('doubt'),\n",
              " np.str_('chair'),\n",
              " np.str_('across'),\n",
              " np.str_('foot'),\n",
              " np.str_('eats'),\n",
              " np.str_('choose'),\n",
              " np.str_('carefully'),\n",
              " np.str_('bread'),\n",
              " np.str_('smile'),\n",
              " np.str_('inside'),\n",
              " np.str_('france'),\n",
              " np.str_('cars'),\n",
              " np.str_('sky'),\n",
              " np.str_('save'),\n",
              " np.str_('plans'),\n",
              " np.str_('past'),\n",
              " np.str_('leaves'),\n",
              " np.str_('future'),\n",
              " np.str_('fault'),\n",
              " np.str_('deal'),\n",
              " np.str_('voice'),\n",
              " np.str_('taxi'),\n",
              " np.str_('surprise'),\n",
              " np.str_('shot'),\n",
              " np.str_('novel'),\n",
              " np.str_('mustve'),\n",
              " np.str_('gun'),\n",
              " np.str_('given'),\n",
              " np.str_('feed'),\n",
              " np.str_('cream'),\n",
              " np.str_('boyfriend'),\n",
              " np.str_('telling'),\n",
              " np.str_('suddenly'),\n",
              " np.str_('shop'),\n",
              " np.str_('lend'),\n",
              " np.str_('law'),\n",
              " np.str_('honest'),\n",
              " np.str_('enemy'),\n",
              " np.str_('cooking'),\n",
              " np.str_('york'),\n",
              " np.str_('somewhere'),\n",
              " np.str_('slowly'),\n",
              " np.str_('quiet'),\n",
              " np.str_('laughed'),\n",
              " np.str_('college'),\n",
              " np.str_('chinese'),\n",
              " np.str_('bath'),\n",
              " np.str_('stolen'),\n",
              " np.str_('standing'),\n",
              " np.str_('difference'),\n",
              " np.str_('boss'),\n",
              " np.str_('actually'),\n",
              " np.str_('sell'),\n",
              " np.str_('heavy'),\n",
              " np.str_('failed'),\n",
              " np.str_('entered'),\n",
              " np.str_('bridge'),\n",
              " np.str_('warm'),\n",
              " np.str_('share'),\n",
              " np.str_('ride'),\n",
              " np.str_('policeman'),\n",
              " np.str_('none'),\n",
              " np.str_('newspaper'),\n",
              " np.str_('necessary'),\n",
              " np.str_('guys'),\n",
              " np.str_('empty'),\n",
              " np.str_('count'),\n",
              " np.str_('sugar'),\n",
              " np.str_('prison'),\n",
              " np.str_('price'),\n",
              " np.str_('moved'),\n",
              " np.str_('mouth'),\n",
              " np.str_('hundred'),\n",
              " np.str_('funny'),\n",
              " np.str_('fat'),\n",
              " np.str_('carry'),\n",
              " np.str_('till'),\n",
              " np.str_('sign'),\n",
              " np.str_('salt'),\n",
              " np.str_('couple'),\n",
              " np.str_('trees'),\n",
              " np.str_('public'),\n",
              " np.str_('nervous'),\n",
              " np.str_('means'),\n",
              " np.str_('fly'),\n",
              " np.str_('eye'),\n",
              " np.str_('aware'),\n",
              " np.str_('weeks'),\n",
              " np.str_('wallet')]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "text_vec_layer_en.get_vocabulary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lWG1UaXmuYo",
        "outputId": "21f4a023-77da-42e4-9c9e-3fc780e1d8ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-bb384b726498>:1: DeprecationWarning: `in1d` is deprecated. Use `np.isin` instead.\n",
            "  np.in1d(\"shop\", text_vec_layer_en.get_vocabulary())\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "np.in1d(\"shop\", text_vec_layer_en.get_vocabulary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_HC751em3is",
        "outputId": "a11d33ca-f579-478e-d37d-8467284ca683"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-3a9bc7e1150b>:1: DeprecationWarning: `in1d` is deprecated. Use `np.isin` instead.\n",
            "  np.in1d(\"beautiful\", text_vec_layer_en.get_vocabulary())\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "np.in1d(\"beautiful\", text_vec_layer_en.get_vocabulary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzoWs5hynA2_",
        "outputId": "9cbeee7c-b71a-47cd-88fc-8d5a6ac6a2b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-7967209a55be>:1: DeprecationWarning: `in1d` is deprecated. Use `np.isin` instead.\n",
            "  np.in1d(\"bonitas\", text_vec_layer_es.get_vocabulary())\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "np.in1d(\"bonitas\", text_vec_layer_es.get_vocabulary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ov8c7UzrtMX"
      },
      "source": [
        "Vamos a ver mejoras que además nos vayan adelantando conceptos para llegar a los LLN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RreDpT8rtMX"
      },
      "source": [
        "## Bidirectional RNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zudtQcm1rtMX"
      },
      "source": [
        "Extra\n",
        "\n",
        "Una red recurrente bidireccional es la que lee la secuencia tanto de izquierda a derecha como de derecha a izquierda y procesa ambas secuencias en conjunto. Ojo: la secuencia de entrada.\n",
        "\n",
        "En general es como tener una capa que mira en un sentido y otra en el otro y concatenar luego sus salidas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSNm3wlTrtMX"
      },
      "source": [
        "<img src=\"img/bidirectionalrnn.jpg\" alt=\"Bidirectional RNN\" width=\"700\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzxTTMFzrtMX"
      },
      "source": [
        "¿Por qué y para qué? Porque, por ejemplo, hay frases que para traducirlas necesitas ver que viene después, como en el caso de los adjetivos en inglés que anteceden al nombre y de los sinónimos en un idioma que no coinciden necesariamente con los sinónimos en otro: the left arm, the left party, they left the restaurant...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "Q8OW1b3uoxS8",
        "outputId": "8a10ddf9-d403-45b6-9812-9a9dc5345e8e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ text_vectorization  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mTextVectorization\u001b[0m) │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m128,000\u001b[0m │ text_vectorizati… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ text_vectorizati… │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m788,480\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ repeat_vector_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mRepeatVector\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m2,099,200\u001b[0m │ repeat_vector_1[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m1000\u001b[0m)  │    \u001b[38;5;34m513,000\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ text_vectorization  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>) │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">128,000</span> │ text_vectorizati… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ text_vectorizati… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">788,480</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ repeat_vector_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ repeat_vector_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">513,000</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,528,680\u001b[0m (13.46 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,528,680</span> (13.46 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,528,680\u001b[0m (13.46 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,528,680</span> (13.46 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "embed_size = 128\n",
        "\n",
        "# Layer 1 & 2 of Encoder\n",
        "encoder_inputs     = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
        "encoder_input_ids  = text_vec_layer_en(encoder_inputs)\n",
        "encoder_embeddings = tf.keras.layers.Embedding(vocab_size, embed_size,mask_zero=True)(encoder_input_ids)\n",
        "encoder = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256))(encoder_embeddings)\n",
        "r_vec = RepeatVector(n=max_length)(encoder) # este sí, con el repeatVector funciona\n",
        "\n",
        "# Layer 1 & 2 of Decoder\n",
        "decoder_inputs     = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
        "decoder_input_ids  = text_vec_layer_es(decoder_inputs)\n",
        "decoder_embeddings = tf.keras.layers.Embedding(vocab_size, embed_size,mask_zero=True)(decoder_input_ids)\n",
        "decoder_outputs    = tf.keras.layers.LSTM(512, return_sequences=True, dropout=0.2)(r_vec)\n",
        "\n",
        "# Layer 3 of Decoder\n",
        "Y_proba = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")(decoder_outputs)\n",
        "\n",
        "model_bidirectional = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs],outputs=[Y_proba])\n",
        "model_bidirectional.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
        "model_bidirectional.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "gkoB5o9Np1bY"
      },
      "outputs": [],
      "source": [
        "checkpoint_filepath_bidirectional = './tmp/ckpt/checkpoint.model_bidirectional.keras'\n",
        "model_checkpoint_callback_bidirectional = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath_bidirectional,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VfGA9aApyNa",
        "outputId": "e7851f0a-faa8-4c7b-dc73-bc20a774962e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 26ms/step - accuracy: 0.8797 - loss: 0.7184 - val_accuracy: 0.8958 - val_loss: 0.5150\n",
            "Epoch 2/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 24ms/step - accuracy: 0.8982 - loss: 0.4789 - val_accuracy: 0.9069 - val_loss: 0.4032\n",
            "Epoch 3/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 26ms/step - accuracy: 0.9082 - loss: 0.3840 - val_accuracy: 0.9115 - val_loss: 0.3611\n",
            "Epoch 4/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 25ms/step - accuracy: 0.9141 - loss: 0.3400 - val_accuracy: 0.9143 - val_loss: 0.3418\n",
            "Epoch 5/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 27ms/step - accuracy: 0.9179 - loss: 0.3150 - val_accuracy: 0.9164 - val_loss: 0.3312\n",
            "Epoch 6/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 25ms/step - accuracy: 0.9211 - loss: 0.2956 - val_accuracy: 0.9168 - val_loss: 0.3259\n",
            "Epoch 7/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 25ms/step - accuracy: 0.9238 - loss: 0.2802 - val_accuracy: 0.9182 - val_loss: 0.3237\n",
            "Epoch 8/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 27ms/step - accuracy: 0.9266 - loss: 0.2659 - val_accuracy: 0.9182 - val_loss: 0.3214\n",
            "Epoch 9/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 25ms/step - accuracy: 0.9291 - loss: 0.2539 - val_accuracy: 0.9187 - val_loss: 0.3236\n",
            "Epoch 10/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 25ms/step - accuracy: 0.9314 - loss: 0.2429 - val_accuracy: 0.9182 - val_loss: 0.3245\n",
            "Epoch 11/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 26ms/step - accuracy: 0.9335 - loss: 0.2332 - val_accuracy: 0.9187 - val_loss: 0.3265\n",
            "Epoch 12/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 26ms/step - accuracy: 0.9350 - loss: 0.2259 - val_accuracy: 0.9184 - val_loss: 0.3306\n",
            "Epoch 13/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 24ms/step - accuracy: 0.9368 - loss: 0.2183 - val_accuracy: 0.9185 - val_loss: 0.3353\n",
            "Epoch 14/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 26ms/step - accuracy: 0.9384 - loss: 0.2113 - val_accuracy: 0.9181 - val_loss: 0.3362\n",
            "Epoch 15/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 26ms/step - accuracy: 0.9396 - loss: 0.2060 - val_accuracy: 0.9178 - val_loss: 0.3411\n",
            "Epoch 16/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 26ms/step - accuracy: 0.9414 - loss: 0.1987 - val_accuracy: 0.9185 - val_loss: 0.3444\n",
            "Epoch 17/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 25ms/step - accuracy: 0.9421 - loss: 0.1953 - val_accuracy: 0.9181 - val_loss: 0.3509\n",
            "Epoch 18/100\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 26ms/step - accuracy: 0.9437 - loss: 0.1891 - val_accuracy: 0.9174 - val_loss: 0.3524\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78b553f47910>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "model_bidirectional.fit((X_train, X_train_dec), Y_train, epochs=100,\n",
        "          validation_data=((X_valid, X_valid_dec), Y_valid), callbacks=[model_checkpoint_callback_bidirectional, early_stopping_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "A94bYNY0xx4i"
      },
      "outputs": [],
      "source": [
        "def translate_bidirectional(sentence_en):\n",
        "    translation = \"\"\n",
        "    for word_idx in range(max_length):\n",
        "        X = np.array([sentence_en])  # encoder input\n",
        "        X_dec = np.array([\"startofseq \" + translation])  # decoder input\n",
        "        y_probs = model_bidirectional.predict((X.astype(object), X_dec.astype(object)))\n",
        "        y_proba = y_probs[0, word_idx]  # last token's probas\n",
        "        predicted_word_id = np.argmax(y_proba)\n",
        "        predicted_proba = round(float(y_proba[predicted_word_id]),3)\n",
        "        predicted_word = text_vec_layer_es.get_vocabulary()[predicted_word_id]\n",
        "        if predicted_word == \"endofseq\":\n",
        "            break\n",
        "        translation += \" \" + predicted_word\n",
        "        print(f\"{translation}({predicted_proba})\")\n",
        "    return translation.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kdGZV5FrtMX"
      },
      "source": [
        "Para crear un capa recurrente bidireccional, se hace lo siguiente (encapsular una recurrente en una más genérica denominada Bidirectional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrN_tlVyrtMY"
      },
      "source": [
        "En el caso del decoder no podemos hacer lo mismo porque en el target mirar al futuro sí es hacer trampa (recordemos que hasta ahora le pasamos la palabra que correspondería a la palabra esperada anterior, o sea no hacemos trampa), y por tanto no serviría para predecir algo que no hubiera visto (de hecho no podríamos construir una entrada para predecir de forma correcta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jle372OvrtMY"
      },
      "source": [
        "Pero, la recurrente bidireccional produce el doble de estados ocultos. Como se trata de una lstm tendremos dos hidden_state y dos cell_state, aunque el decoder sólo espera dos (porque es otra LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "qUG81j9YrtMc",
        "outputId": "dbcaeffc-303b-4c5f-d9bd-7cd8c54e111d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443ms/step\n",
            " quiero(0.903)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            " quiero leer(0.758)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            " quiero leer un(0.996)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            " quiero leer un libro(0.695)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            " quiero leer un libro libro(0.467)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'quiero leer un libro libro'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "translate_bidirectional(\"I want to read an old book.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "XVFvEw4dyuE-",
        "outputId": "7b7d5f49-9207-4b47-c93d-b22d96bbf07e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            " quiero(0.992)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            " quiero [UNK](0.803)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            " quiero [UNK] un(0.913)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            " quiero [UNK] un libro(0.916)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            " quiero [UNK] un libro libro(0.323)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'quiero [UNK] un libro libro'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "translate(\"I want to read an old book.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzKUaOHortMc"
      },
      "source": [
        "## Beam Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDpeeJ1ArtMc"
      },
      "source": [
        "This is a very basic implementation of beam search. I tried to make it readable and understandable, but it's definitely not optimized for speed! The function first uses the model to find the top _k_ words to start the translations (where _k_ is the beam width). For each of the top _k_ translations, it evaluates the conditional probabilities of all possible words it could add to that translation. These extended translations and their probabilities are added to the list of candidates. Once we've gone through all top _k_ translations and all words that could complete them, we keep only the top _k_ candidates with the highest probability, and we iterate over and over until they all finish with an EOS token. The top translation is then returned (after removing its EOS token).\n",
        "\n",
        "* Note: If p(S) is the probability of sentence S, and p(W|S) is the conditional probability of the word W given that the translation starts with S, then the probability of the sentence S' = concat(S, W) is p(S') = p(S) * p(W|S). As we add more words, the probability gets smaller and smaller. To avoid the risk of it getting too small, which could cause floating point precision errors, the function keeps track of log probabilities instead of probabilities: recall that log(a\\*b) = log(a) + log(b), therefore log(p(S')) = log(p(S)) + log(p(W|S))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "QQm-RZ8urtMc"
      },
      "outputs": [],
      "source": [
        "# extra code – a basic implementation of beam search\n",
        "\n",
        "def beam_search(sentence_en, beam_width, verbose=False):\n",
        "    X = np.array([sentence_en])  # encoder input\n",
        "    X_dec = np.array([\"startofseq\"])  # decoder input\n",
        "    y_proba = model.predict((X.astype(object), X_dec.astype(object)))[0, 0]  # first token's probas\n",
        "    top_k = tf.math.top_k(y_proba, k=beam_width)\n",
        "    top_translations = [  # list of best (log_proba, translation)\n",
        "        (np.log(word_proba), text_vec_layer_es.get_vocabulary()[word_id])\n",
        "        for word_proba, word_id in zip(top_k.values, top_k.indices)\n",
        "    ]\n",
        "\n",
        "    # extra code – displays the top first words in verbose mode\n",
        "    if verbose:\n",
        "        print(\"Top first words:\", top_translations)\n",
        "\n",
        "    for idx in range(1, max_length):\n",
        "        candidates = []\n",
        "        for log_proba, translation in top_translations:\n",
        "            if translation.endswith(\"endofseq\"):\n",
        "                candidates.append((log_proba, translation))\n",
        "                continue  # translation is finished, so don't try to extend it\n",
        "            X = np.array([sentence_en])  # encoder input\n",
        "            X_dec = np.array([\"startofseq \" + translation])  # decoder input\n",
        "            y_proba = model.predict((X.astype(object), X_dec.astype(object)))[0, idx]  # last token's proba\n",
        "            for word_id, word_proba in enumerate(y_proba):\n",
        "                word = text_vec_layer_es.get_vocabulary()[word_id]\n",
        "                candidates.append((log_proba + np.log(word_proba),\n",
        "                                   f\"{translation} {word}\"))\n",
        "        top_translations = sorted(candidates, reverse=True)[:beam_width]\n",
        "\n",
        "        # extra code – displays the top translation so far in verbose mode\n",
        "        if verbose:\n",
        "            print(\"Top translations so far:\", top_translations)\n",
        "\n",
        "        if all([tr.endswith(\"endofseq\") for _, tr in top_translations]):\n",
        "            return top_translations[0][1].replace(\"endofseq\", \"\").strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "jndVFH6qrtMd",
        "outputId": "5898c3bb-ea64-4496-dde6-760aa7e1ab41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            " me(0.988)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            " me gustan(0.719)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            " me gustan tanto(0.397)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            " me gustan tanto perros(0.446)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            " me gustan tanto perros y(0.804)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            " me gustan tanto perros y los(0.831)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            " me gustan tanto perros y los [UNK](0.486)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'me gustan tanto perros y los [UNK]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "# extra code – shows how the model making an error\n",
        "sentence_en = \"I love cats and dogs\"\n",
        "translate(sentence_en)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHZA7cMKrtMd"
      },
      "source": [
        "The correct translation is in the top 3 sentences found by beam search, but it's not the first. Since we're using a small vocabulary, the \\[UNK] token is quite frequent, so you may want to penalize it (e.g., divide its probability by 2 in the beam search function): this will discourage beam search from using it too much."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNF-QP37rtMd"
      },
      "source": [
        "## Mecanismos de Atencion (Attention mechanisms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52TxgFCRrtMd"
      },
      "source": [
        "Como mejora a este tipo de arquitecturas, en 2014 (Dzmitry Bahdanau y colegas, et al. que se dice) introdujeron una mejora sustancial a la arquitectura de Encoder-Decoders.\n",
        "\n",
        "La idea detrás del mecanismo es pasarle al decoder más información de la secuencia de entrada y no sólo los estados ocultos producidos por el último elemento (el primero y el úlitmo en el caso de bidireccionales). ¿Qué información? Pues algo así como la palabra que más le aporte en cada momento. Por ejemplo que cuando al decoder le toque producir fútbol en la traducción de I like soccer, reciba \"soccer\" (en concreto la salida del enconder a la palabra \"soccer\").  \n",
        "\n",
        "Supongamos que estamos traduciendo frases como:\n",
        "\n",
        "I like soccer  \n",
        "I like Rain Man  \n",
        "you like The Bridge  \n",
        "we like Marta  \n",
        "  \n",
        "Para los dos primeras el decoder iría traduciendo:\n",
        "(Me) gusta ... y la idea es que las entradas \"soccer\", \"Rain\" + \"Man\", \"The\" + \"Bridge\", \"Marta\" aporten más en ese instante...  \n",
        "\n",
        "Entonces al decoder tendré que pasarle todas las palabras de la frase (en concreto la salida de cada una de estas del encoder) y que exista un mecanismo que le diga en función de lo que lleva cuál de las entradas debe considerar más (aquí nos fijamos en la siguiente, pero para traducir \"Me\" es mejor que se fije en la primera, el pronombre, para traducir \"gusta\", igual)  \n",
        "\n",
        "Lo interesante no es considerar solo una palabra de entrada, sino una combinación pesada de estas (una combinación lineal -> \"The\" + \"Bridge\")\n",
        "\n",
        "Es decir, volviendo a nuestras entradas del decoder:\n",
        "\n",
        "* Antes d1: [h(e2),c(2),emb(\"<start_of_sequence>\")], ahora da1 (la a es de attention): [h(e2),c(e2), (coef1 * e1 + coef2 * e2 + coef3 * e3)] y probablemente todos los coef se aproximarían a cero\n",
        "* Antes d2: [emb(\"Me\"),$h_d$(d1),$c_d$(d1)], ahora da2: [emb(\"Me\"),$h_d$(d1),$c_d$(d1), (coef21 * e1 + coef22 * e2 + coef23 * e3)] y probablemente coef21 >> coef22 y coef23\n",
        "* Antes d3: [emb(\"gusta\"),$h_d$(d2),$c_d$(d2)], ahora da3: [emb(\"gusta\"),$h_d$(d1),$c_d$(d1), (coef31 * e1 + coef32 * e2 + coef33 * e3) ] y coef31 y coef32 serán altos y coef33 bajo o nulo\n",
        "\n",
        "\n",
        "__¿Y cómo le digo en cuál debe fijarse más? Pues como en los embeddings... que lo aprenda :-) (o sea tendré una Attention Layer)__\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSJSezrertMd"
      },
      "source": [
        "Muy bien, y cómo se hace ese \"que lo aprenda\": Dos mecanismos de Atencion (aditiva y multiplicativa), pero el multiplicativo ha superado al aditivo y de hecho la Attention Layer de keras hace Attention multiplicativa y además al final la predicción se hace a partir de la salida de la capa de atención.\n",
        "\n",
        "Gráficamente:\n",
        "\n",
        "<img src=\"https://github.com/Jaimegrp/Practicando/blob/main/Texto/img/encoder_decoder_with_attention.jpg?raw=1\" />\n",
        "\n",
        "\n",
        "Intuitivamente al poner la capa de atención al final está configurando toda la red (toda incluidos los embeddings) para que \"memorice\" la relación estadística entre las posiciones de salida y las de entrada en diferentes situaciones. Y luego ya nosotros a eso le llamamos atención, porque es verdad que cuando llega el momento de \"Me gusta el...\", ha memorizado que las posiciones que deben aportar más es donde haya salidas que generalmente pertenecen a nombres. (pero él ni sabe que son nombres, ni que está traduciendo ni nada,...)\n",
        "\n",
        "\n",
        "El siguiente paso sería aumentar la memoria y olvidarse de las recurrencias (y del problema de traducir) :-)... los Transformers, pero antes... prestémosle Atención al traductor con atención"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5v4cs87rtMe"
      },
      "source": [
        "And finally, let's add the `Attention` layer and the output layer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qx3jPpJOrtMf"
      },
      "source": [
        "## Y sí, la solución es simple y llanamente establecer relacion los elementos de la secuencia entre sí.... ***Attention Is All You Need: The Transformer Architecture***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eghXhvLprtMf"
      },
      "source": [
        "Y en 2017, alguien de una empresa..., publicó un paper en el que se presentaba en sociedad una arquitectura que sólo necesitaba de mecanismos de Atenttion y capas Densas para hacer NMT como el mejor.\n",
        "\n",
        "OJO, esta sección es a título ilustrativo... Pero molón.\n",
        "Si quieres saber más cuando tengas más tiempo, te recomiendo esta referencia [https://kikaben.com/transformers-encoder-decoder/].\n",
        "\n",
        "<img src=\"https://github.com/Jaimegrp/Practicando/blob/main/Texto/img/transformers.webp?raw=1\" />\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snQivuXHrtMf"
      },
      "source": [
        "Antes de asustarse, lo que realmente hace esta arquitectura es ser las superconvolucional con memoria de las secuencias de texto... Vamos por partes:\n",
        "\n",
        "__La parte del encoder__ al incluir el mecanismo de atención (y ese positional encoding) lo que está haciendo es aprender las relaciones posicionales de las palabras del \"lenguaje\" de entrada (sí está memorizando y caracterizando las relaciones entre todas las palabras y sus posiciones de entrada), está haciendo un embedding de la información posicional. Luego concatena la información posicional con la de entrada y aprende a relacionarla lo mejor posible para esa secuencia. En tiempo de inferencia diríamos que para cada secuencia está analizandola sintácticamente, gramaticalmente, etc, etc y luego la devuelve... Pero nunca le hemos pasado información ni sintáctica, ni gramatical, ni nada.\n",
        "\n",
        "__La parte del decoder__ primero hace lo mismo que el encoder pero con el \"lenguaje\" de destino, se aprende y caracteriza todas las relaciones posicionales de las sentencias de ese \"lenguaje\". Combina ese embedding por secuencia con la secuencia de destino y se lo pasa a la siguiente capa de atención que ahora memoriza y caracteriza todas las relaciones posicionales entre las sentencias procesadas y enriquecidas del lenguaje destino y las sentencias procesadas y enriquecidas del lenguaje de origen. Y luego el feedfoward es el que realmente mezcla todo (mezclará toda la información de la secuencia, vease que se va transmitiendo, las posiciones y las posiciones con el lenguaje origen).\n",
        "\n",
        "Para aumentar la memoria y dar más relaciones lo que hacemos es que la capa de atención en realidad son muchas capas de atención en paralelo y acumular modulos de atención (como acumulábamos capas convolucionales en una red convolucional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gl91Sdu4rtMf"
      },
      "source": [
        "A título ilustrativo un __capa multihead de atención__:\n",
        "\n",
        "<img src=\"https://github.com/Jaimegrp/Practicando/blob/main/Texto/img/multihead_attention.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uh_6C3mWrtMf"
      },
      "source": [
        "Las capas linear son capas densas sin función de activación, tienen pesos entrenables -> Memoria (en estos pesos está la memoria de las características posicionales)\n",
        "Y las capas head fuerzan que las linear (tantas como cabezas*3) aprendan un número de relaciones \"poscionales\" que dependen del número de cabezas (si quiero que apredan más relaciones posicionales -> Más cabezas)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zna3md12rtMf"
      },
      "source": [
        "Y para terminar hay N modulos (en el paper de 2017, 6 por Encoder y 6 por Decoder) apilados, ¿por qué? Aquí una idea intuitiva es la misma que en las convolucionales, para que pueda memorizar relaciones posicionales más complicadas (y tener más memoria entrenable)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3ar9UqqrtMf"
      },
      "source": [
        "## Large Language Models (Pretrained Transformers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yt8wIErgrtMf"
      },
      "source": [
        "Y en 2018, llegaron las arquitecturas que apilaban multihead attention layers pero ya olvidándose de decoders y encoders... Una sola columna con muchos módulos... pero con la magia de estar pre-entrenadas para una tarea (generalmente adivina cuál es la siguiente palabra de la sentencia (GPT) o de cada sentencia te voy a ocultar 2 palabras, adivina cuales son (BERT)).\n",
        "\n",
        "En esencia, están memorizando todas las relaciones que existen entre las palabras de un lenguaje... Por eso cada vez se hacen más grandes (para memorizar más) y tienen más parámetros... y necesitan más que les des de comer (si quieres tenerlo todo representado)... (Imagina que le pudieras dar para entrenar a un red convolucional todas las imágenes posibles que existen)\n",
        "\n",
        "<img src=\"https://github.com/Jaimegrp/Practicando/blob/main/Texto/img/gpt2_vs_BERT.jpg?raw=1\" >\n",
        "\n",
        "Luego estos modelos preentrenados se adaptan (fine-tunning), o sea, se hace transfer learning, a otros tipos de problemas (clasificación, sentiment analysis, question and answers, y ahora chats, texto generativo).\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOi7vkFOAClz"
      },
      "source": [
        "## Instruct LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_8qCUXkAE_r"
      },
      "source": [
        "Hoy en día, lo que realmente se ha puesto \"de moda\" no es emplear los LLM como los vistos hasta ahora, sino los fine-tuned y más concretamente los basados en una aproximación denominada \"Instruct LLM\" (partiendo de un paper de OpenAI):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yY38EYRAbDw"
      },
      "source": [
        "<img src=\"https://github.com/Jaimegrp/Practicando/blob/main/Texto/img/rlhf.jpg?raw=1\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrzskW7CrtMg"
      },
      "source": [
        "Han surgido decenas de modelos, propietarios y abiertos, los más destacados (que puedes usar):  \n",
        "[OpenAI, ChatGPT](https://chat.openai.com/)  \n",
        "[Google, Gemini](https://gemini.google.com/?hl=es)  \n",
        "[Mistral, Mistral MoE](https://mistral.ai/)  \n",
        "[Meta, Llama-2](https://ai.meta.com/blog/5-steps-to-getting-started-with-llama-2/)  \n",
        "[Hugging Face, miles y miles de modelos](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)  \n",
        "[Preplexity AI, integra GPT-4 y Claude (no accesible directamente en España](https://www.perplexity.ai/)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}