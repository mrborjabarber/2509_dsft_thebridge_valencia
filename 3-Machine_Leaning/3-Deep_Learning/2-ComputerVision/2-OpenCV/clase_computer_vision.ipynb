{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción a Computer Vision con Python\n",
    "\n",
    "## ¿Qué es Computer Vision?\n",
    "\n",
    "**Computer Vision** (Visión por Computadora) es un campo de la inteligencia artificial que entrena a las computadoras para interpretar y comprender el mundo visual. Utilizando imágenes digitales de cámaras y videos, los algoritmos pueden identificar y clasificar objetos, e incluso reaccionar a lo que \"ven\".\n",
    "\n",
    "### Aplicaciones principales:\n",
    "-  Vehículos autónomos\n",
    "-  Reconocimiento facial en smartphones\n",
    "-  Diagnóstico médico por imágenes\n",
    "-  Control de calidad en manufactura\n",
    "-  Realidad aumentada y videojuegos\n",
    "\n",
    "### Librerías que usaremos:\n",
    "- **OpenCV**: Librería principal para procesamiento de imágenes\n",
    "- **NumPy**: Para operaciones numéricas con arrays\n",
    "- **Matplotlib**: Para visualización de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalación de librerías necesarias\n",
    "# Ejecuta esto si no tienes las librerías instaladas\n",
    "\n",
    "# !pip install opencv-python\n",
    "# !pip install numpy\n",
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================\n# IMPORTACIÓN DE LIBRERÍAS NECESARIAS\n# ============================================\n\n# cv2 (OpenCV): Librería principal para procesamiento de imágenes y computer vision\n# - Proporciona funciones para leer, escribir, manipular imágenes\n# - Incluye algoritmos de detección, segmentación, transformaciones, etc.\nimport cv2\n\n# numpy (np): Librería fundamental para computación científica en Python\n# - Las imágenes se representan como arrays de NumPy (matrices numéricas)\n# - Permite operaciones matemáticas eficientes sobre los píxeles\nimport numpy as np\n\n# matplotlib.pyplot: Librería para visualización y creación de gráficos\n# - plt.imshow() muestra imágenes en el notebook\n# - plt.plot() crea gráficos, plt.subplots() maneja múltiples imágenes\nimport matplotlib.pyplot as plt\n\n# matplotlib.rcParams: Parámetros de configuración de matplotlib\n# - Permite personalizar el tamaño por defecto de las figuras\n# - Controla aspectos visuales de los gráficos\nfrom matplotlib import rcParams\n\n\n# ============================================\n# CONFIGURACIÓN DE VISUALIZACIÓN\n# ============================================\n# Establecer el tamaño por defecto de las figuras en matplotlib\n# (12, 8) significa: 12 pulgadas de ancho x 8 pulgadas de alto\n# Esto hace que las imágenes se vean más grandes y claras en el notebook\nrcParams['figure.figsize'] = 12, 8\n\n\n# ============================================\n# VERIFICACIÓN DE INSTALACIÓN\n# ============================================\n# Imprimir mensaje de confirmación\nprint(\"✓ Librerías importadas correctamente\")\n\n# Mostrar la versión de OpenCV instalada\n# cv2.__version__ obtiene el número de versión como string\n# Útil para verificar compatibilidad y reproducibilidad\nprint(f\"Versión de OpenCV: {cv2.__version__}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Fundamentos: ¿Qué es una imagen digital?\n",
    "\n",
    "Una imagen digital es una matriz (array) de números que representan los valores de intensidad de los píxeles.\n",
    "\n",
    "### Tipos de imágenes:\n",
    "\n",
    "1. **Escala de grises**: Matriz 2D (altura × ancho)\n",
    "   - Cada píxel tiene un valor entre 0 (negro) y 255 (blanco)\n",
    "\n",
    "2. **Color (RGB)**: Matriz 3D (altura × ancho × 3 canales)\n",
    "   - Cada píxel tiene 3 valores: Red, Green, Blue\n",
    "   - Cada canal va de 0 a 255\n",
    "\n",
    "**Nota**: OpenCV usa el formato BGR (Blue, Green, Red) en lugar de RGB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de la imagen: (200, 200)\n",
      "Tipo de datos: uint8\n"
     ]
    }
   ],
   "source": [
    "# Crear una imagen simple desde cero\n",
    "# Creamos una imagen de 200x200 píxeles en escala de grises\n",
    "\n",
    "# ============================================\n",
    "# CREACIÓN DE IMAGEN COMPLETAMENTE NEGRA\n",
    "# ============================================\n",
    "# np.zeros() crea un array lleno de ceros\n",
    "# (200, 200) define las dimensiones: 200 filas x 200 columnas (píxeles)\n",
    "# dtype=np.uint8 especifica el tipo de dato: enteros sin signo de 8 bits (rango 0-255)\n",
    "# En escala de grises: 0 = negro, 255 = blanco\n",
    "imagen_negra = np.zeros((200, 200), dtype=np.uint8)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# CREACIÓN DE IMAGEN COMPLETAMENTE BLANCA\n",
    "# ============================================\n",
    "# np.ones() crea un array lleno de unos\n",
    "# (200, 200) define las dimensiones de la imagen\n",
    "# dtype=np.uint8 usa valores entre 0-255 (estándar para imágenes)\n",
    "# Multiplicamos por 255 para convertir los 1s en 255s (blanco puro)\n",
    "imagen_blanca = np.ones((200, 200), dtype=np.uint8) * 255\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# CREACIÓN DE IMAGEN CON GRADIENTE HORIZONTAL\n",
    "# ============================================\n",
    "# PASO 1: Crear un array unidimensional con valores de 0 a 255\n",
    "# np.linspace(0, 255, 200) genera 200 valores espaciados uniformemente\n",
    "# desde 0 (negro) hasta 255 (blanco)\n",
    "# dtype=np.uint8 asegura que los valores sean enteros en rango 0-255\n",
    "imagen_gradiente = np.linspace(0, 255, 200, dtype=np.uint8)\n",
    "\n",
    "# PASO 2: Replicar el array horizontalmente para crear la imagen 2D\n",
    "# np.tile() repite el array 1D verticalmente 200 veces\n",
    "# (200, 1) significa: repetir 200 veces en el eje vertical, 1 vez en horizontal\n",
    "# Resultado: imagen de 200x200 píxeles con gradiente de izquierda (negro) a derecha (blanco)\n",
    "imagen_gradiente = np.tile(imagen_gradiente, (200, 1))\n",
    "\n",
    "# Visualizar las imágenes\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(imagen_negra, cmap='gray')\n",
    "axes[0].set_title('Imagen Negra')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(imagen_blanca, cmap='gray')\n",
    "axes[1].set_title('Imagen Blanca')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(imagen_gradiente, cmap='gray')\n",
    "axes[2].set_title('Gradiente')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Forma de la imagen: {imagen_negra.shape}\")\n",
    "print(f\"Tipo de datos: {imagen_negra.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================\n# CREAR IMÁGENES RGB DE COLORES\n# ============================================\n# En OpenCV, las imágenes a color usan el formato BGR (Blue, Green, Red)\n# Formato: (altura, ancho, 3) donde 3 representa los 3 canales de color\n\n\n# ============================================\n# CREAR IMAGEN ROJA\n# ============================================\n# PASO 1: Crear un lienzo negro de 200x200 píxeles con 3 canales\n# np.zeros() inicializa todos los píxeles en [0, 0, 0] = negro\n# (200, 200, 3): 200 filas, 200 columnas, 3 canales (B, G, R)\nimagen_roja = np.zeros((200, 200, 3), dtype=np.uint8)\n\n# PASO 2: Activar solo el canal ROJO\n# [:, :, 2] significa: todas las filas, todas las columnas, canal índice 2 (Red)\n# Los índices son: 0=Blue, 1=Green, 2=Red\n# Asignamos 255 (máximo) al canal rojo, resultando en [0, 0, 255] = ROJO PURO\nimagen_roja[:, :, 2] = 255\n\n\n# ============================================\n# CREAR IMAGEN VERDE\n# ============================================\n# PASO 1: Crear lienzo negro\nimagen_verde = np.zeros((200, 200, 3), dtype=np.uint8)\n\n# PASO 2: Activar solo el canal VERDE\n# [:, :, 1] selecciona el canal índice 1 (Green)\n# Resultado: [0, 255, 0] = VERDE PURO\nimagen_verde[:, :, 1] = 255\n\n\n# ============================================\n# CREAR IMAGEN AZUL\n# ============================================\n# PASO 1: Crear lienzo negro\nimagen_azul = np.zeros((200, 200, 3), dtype=np.uint8)\n\n# PASO 2: Activar solo el canal AZUL\n# [:, :, 0] selecciona el canal índice 0 (Blue)\n# Resultado: [255, 0, 0] = AZUL PURO\nimagen_azul[:, :, 0] = 255\n\n\n# ============================================\n# VISUALIZAR LAS TRES IMÁGENES\n# ============================================\n# plt.subplots() crea múltiples subgráficos en una cuadrícula\n# (1, 3): 1 fila, 3 columnas de gráficos\n# figsize=(15, 5): ancho 15 pulgadas, alto 5 pulgadas\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\n# IMPORTANTE: matplotlib espera formato RGB, pero OpenCV usa BGR\n# cv2.cvtColor() convierte entre espacios de color\n# COLOR_BGR2RGB invierte el orden de los canales para visualización correcta\n\n# Mostrar imagen roja\naxes[0].imshow(cv2.cvtColor(imagen_roja, cv2.COLOR_BGR2RGB))\naxes[0].set_title('Canal Rojo')  # Título del gráfico\naxes[0].axis('off')  # Ocultar los ejes x e y\n\n# Mostrar imagen verde\naxes[1].imshow(cv2.cvtColor(imagen_verde, cv2.COLOR_BGR2RGB))\naxes[1].set_title('Canal Verde')\naxes[1].axis('off')\n\n# Mostrar imagen azul\naxes[2].imshow(cv2.cvtColor(imagen_azul, cv2.COLOR_BGR2RGB))\naxes[2].set_title('Canal Azul')\naxes[2].axis('off')\n\n# tight_layout() ajusta automáticamente el espaciado entre subgráficos\nplt.tight_layout()\n# Mostrar todas las figuras\nplt.show()\n\n\n# ============================================\n# INFORMACIÓN DE LA IMAGEN\n# ============================================\n# .shape devuelve las dimensiones del array\n# Para imágenes RGB: (altura, ancho, canales)\nprint(f\"Forma de imagen RGB: {imagen_roja.shape}\")\n# Output esperado: (200, 200, 3)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga y Manipulación de Imágenes\n",
    "\n",
    "Para trabajar con imágenes reales, necesitamos:\n",
    "1. Cargar la imagen desde un archivo\n",
    "2. Convertir entre espacios de color\n",
    "3. Redimensionar y recortar\n",
    "4. Guardar los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================\n# DEFINICIÓN DE FUNCIÓN AUXILIAR PARA VISUALIZACIÓN\n# ============================================\n# Esta función simplifica el proceso de mostrar imágenes de forma consistente\n# Maneja automáticamente la conversión de BGR a RGB cuando es necesario\n\ndef mostrar_imagen(imagen, titulo=\"Imagen\", cmap=None):\n    \"\"\"\n    Función para mostrar imágenes de forma consistente\n    \n    Args:\n        imagen: Array de NumPy con la imagen (puede ser BGR o escala de grises)\n        titulo: Título para la imagen (string)\n        cmap: Mapa de colores\n              - None para imágenes RGB/BGR (a color)\n              - 'gray' para imágenes en escala de grises\n              - Otros: 'hot', 'jet', 'hsv', etc.\n    \"\"\"\n    \n    # ============================================\n    # CREAR FIGURA DE MATPLOTLIB\n    # ============================================\n    # plt.figure() crea una nueva ventana/figura\n    # figsize=(10, 6): ancho 10 pulgadas, alto 6 pulgadas\n    plt.figure(figsize=(10, 6))\n    \n    \n    # ============================================\n    # CONVERSIÓN AUTOMÁTICA BGR -> RGB\n    # ============================================\n    # OpenCV usa BGR, matplotlib usa RGB\n    # len(imagen.shape) == 3: verifica si tiene 3 dimensiones (imagen a color)\n    # cmap is None: verifica que no se especificó escala de grises\n    if len(imagen.shape) == 3 and cmap is None:\n        # cv2.cvtColor() convierte entre espacios de color\n        # COLOR_BGR2RGB invierte el orden: [B,G,R] -> [R,G,B]\n        imagen = cv2.cvtColor(imagen, cv2.COLOR_BGR2RGB)\n    \n    \n    # ============================================\n    # MOSTRAR LA IMAGEN\n    # ============================================\n    # plt.imshow() muestra la imagen como un gráfico\n    # imagen: array de píxeles a mostrar\n    # cmap: mapa de colores (None usa los colores originales)\n    plt.imshow(imagen, cmap=cmap)\n    \n    # plt.title() establece el título sobre la imagen\n    plt.title(titulo)\n    \n    # plt.axis('off') oculta los ejes numéricos (x, y)\n    # Hace que solo se vea la imagen sin coordenadas\n    plt.axis('off')\n    \n    # plt.tight_layout() optimiza el uso del espacio\n    # Ajusta márgenes para que todo quepa bien\n    plt.tight_layout()\n    \n    # plt.show() renderiza y muestra la figura en el notebook\n    plt.show()\n\n\n# ============================================\n# MENSAJE DE CONFIRMACIÓN\n# ============================================\nprint(\"✓ Función auxiliar definida\")\n# La función ahora está lista para usarse en el resto del notebook"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de la imagen: (400, 600, 3)\n",
      "Alto: 400 píxeles\n",
      "Ancho: 600 píxeles\n",
      "Canales: 3\n"
     ]
    }
   ],
   "source": [
    "# Para este ejemplo, vamos a crear una imagen de muestra\n",
    "\n",
    "# ============================================\n",
    "# CREAR LIENZO BASE (IMAGEN EN BLANCO)\n",
    "# ============================================\n",
    "# np.ones() crea un array lleno de unos\n",
    "# (400, 600, 3) define las dimensiones:\n",
    "#   - 400 píxeles de alto\n",
    "#   - 600 píxeles de ancho\n",
    "#   - 3 canales de color (BGR: Blue, Green, Red - formato de OpenCV)\n",
    "# dtype=np.uint8 especifica valores entre 0-255 (estándar para imágenes)\n",
    "# Multiplicamos por 255 para obtener blanco puro en los 3 canales [255, 255, 255]\n",
    "imagen_ejemplo = np.ones((400, 600, 3), dtype=np.uint8) * 255\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# DIBUJAR UN RECTÁNGULO AZUL\n",
    "# ============================================\n",
    "# cv2.rectangle(imagen, punto_inicial, punto_final, color, grosor)\n",
    "# (50, 50): coordenada superior izquierda (x=50, y=50)\n",
    "# (250, 200): coordenada inferior derecha (x=250, y=200)\n",
    "# (255, 0, 0): color en formato BGR (Azul=255, Verde=0, Rojo=0) = AZUL\n",
    "# -1: grosor negativo indica relleno completo (sólido)\n",
    "cv2.rectangle(imagen_ejemplo, (50, 50), (250, 200), (255, 0, 0), -1)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# DIBUJAR UN CÍRCULO VERDE\n",
    "# ============================================\n",
    "# cv2.circle(imagen, centro, radio, color, grosor)\n",
    "# (450, 125): coordenadas del centro del círculo (x=450, y=125)\n",
    "# 80: radio del círculo en píxeles\n",
    "# (0, 255, 0): color en formato BGR (Azul=0, Verde=255, Rojo=0) = VERDE\n",
    "# -1: grosor negativo para rellenar completamente el círculo\n",
    "cv2.circle(imagen_ejemplo, (450, 125), 80, (0, 255, 0), -1)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# DIBUJAR UNA LÍNEA ROJA\n",
    "# ============================================\n",
    "# cv2.line(imagen, punto_inicio, punto_fin, color, grosor)\n",
    "# (50, 300): coordenada inicial de la línea (x=50, y=300)\n",
    "# (550, 350): coordenada final de la línea (x=550, y=350)\n",
    "# (0, 0, 255): color en formato BGR (Azul=0, Verde=0, Rojo=255) = ROJO\n",
    "# 5: grosor de la línea en píxeles\n",
    "cv2.line(imagen_ejemplo, (50, 300), (550, 350), (0, 0, 255), 5)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# AGREGAR TEXTO A LA IMAGEN\n",
    "# ============================================\n",
    "# cv2.putText(imagen, texto, posición, fuente, escala, color, grosor)\n",
    "# 'Computer Vision': texto que se mostrará\n",
    "# (150, 380): posición de la esquina inferior izquierda del texto (x=150, y=380)\n",
    "# cv2.FONT_HERSHEY_SIMPLEX: tipo de fuente (sans-serif normal)\n",
    "# 1: escala de la fuente (tamaño relativo)\n",
    "# (0, 0, 0): color en formato BGR (Azul=0, Verde=0, Rojo=0) = NEGRO\n",
    "# 2: grosor del texto en píxeles\n",
    "cv2.putText(imagen_ejemplo, 'Computer Vision', (150, 380), \n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "\n",
    "mostrar_imagen(imagen_ejemplo, \"Imagen de Ejemplo\")\n",
    "print(f\"Dimensiones de la imagen: {imagen_ejemplo.shape}\")\n",
    "print(f\"Alto: {imagen_ejemplo.shape[0]} píxeles\")\n",
    "print(f\"Ancho: {imagen_ejemplo.shape[1]} píxeles\")\n",
    "print(f\"Canales: {imagen_ejemplo.shape[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================\n# CARGAR UNA IMAGEN REAL DESDE ARCHIVO\n# ============================================\n# Este ejemplo usa una imagen real guardada en el disco\n# Es la forma más común de trabajar con Computer Vision\n\n\n# ============================================\n# LECTURA DE IMAGEN CON cv2.imread()\n# ============================================\n# cv2.imread() lee una imagen desde un archivo\n# './imagen.jpg': ruta relativa al archivo de imagen\n#   - './' significa: en el directorio actual\n#   - Puede ser ruta absoluta: 'C:/Users/nombre/imagen.jpg'\n#   - Formatos soportados: .jpg, .png, .bmp, .tiff, etc.\n# Por defecto, lee la imagen en formato BGR (Blue, Green, Red)\n# Si el archivo no existe, devuelve None\nimagen_ejemplo = cv2.imread('./imagen.jpg')\n\n\n# ============================================\n# VISUALIZAR LA IMAGEN CARGADA\n# ============================================\n# Usamos nuestra función auxiliar definida anteriormente\n# Automáticamente convierte de BGR a RGB para visualización correcta\nmostrar_imagen(imagen_ejemplo, \"Imagen de Ejemplo\")\n\n\n# ============================================\n# INFORMACIÓN DETALLADA DE LA IMAGEN\n# ============================================\n# .shape devuelve una tupla con las dimensiones del array\n# Para imágenes a color: (altura, ancho, canales)\nprint(f\"Dimensiones de la imagen: {imagen_ejemplo.shape}\")\n\n# .shape[0]: número de filas (altura en píxeles)\nprint(f\"Alto: {imagen_ejemplo.shape[0]} píxeles\")\n\n# .shape[1]: número de columnas (ancho en píxeles)\nprint(f\"Ancho: {imagen_ejemplo.shape[1]} píxeles\")\n\n# .shape[2]: número de canales de color\n# 3 canales = imagen a color (BGR)\n# 1 canal = escala de grises\nprint(f\"Canales: {imagen_ejemplo.shape[2]}\")\n\n\n# NOTA IMPORTANTE PARA LA CLASE:\n# -----------------------------------------------------\n# Si la imagen no existe en la ruta especificada:\n# - cv2.imread() devuelve None\n# - Esto causará un error al intentar usar la imagen\n# - Siempre verificar que el archivo exista antes de continuar\n# - Alternativa: usar la imagen sintética de la celda anterior"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conversión de Espacios de Color\n",
    "\n",
    "Los espacios de color son diferentes formas de representar colores:\n",
    "\n",
    "- **BGR/RGB**: Basado en los colores primarios de luz\n",
    "- **Escala de grises**: Solo intensidad, sin información de color\n",
    "- **HSV**: Hue (tono), Saturation (saturación), Value (valor)\n",
    "  - Más intuitivo para segmentación por color\n",
    "  - H: 0-179, S: 0-255, V: 0-255 en OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================\n# CONVERSIÓN A ESCALA DE GRISES\n# ============================================\n# La escala de grises elimina la información de color\n# Cada píxel tiene un solo valor: intensidad de luz (0-255)\n# - 0 = negro (sin luz)\n# - 255 = blanco (máxima luz)\n# - Valores intermedios = tonos de gris\n\n# cv2.cvtColor() convierte entre espacios de color\n# COLOR_BGR2GRAY: de Blue-Green-Red a escala de grises\n# Usa una fórmula ponderada: Gray = 0.299*R + 0.587*G + 0.114*B\nimagen_gris = cv2.cvtColor(imagen_ejemplo, cv2.COLOR_BGR2GRAY)\n\n\n# ============================================\n# CONVERSIÓN A ESPACIO HSV\n# ============================================\n# HSV = Hue (Tono), Saturation (Saturación), Value (Valor/Brillo)\n# Es más intuitivo que RGB para el procesamiento de color:\n# \n# - Hue (H): El color puro (0-179 en OpenCV)\n#   * 0° = Rojo, 60° = Amarillo, 120° = Verde, 180° = Cian\n# - Saturation (S): Intensidad del color (0-255)\n#   * 0 = gris/blanco (sin color), 255 = color puro saturado\n# - Value (V): Brillo del color (0-255)\n#   * 0 = negro, 255 = máximo brillo\n#\n# Ventaja: Facilita la segmentación por color (ej: detectar todos los rojos)\nimagen_hsv = cv2.cvtColor(imagen_ejemplo, cv2.COLOR_BGR2HSV)\n\n\n# ============================================\n# VISUALIZACIÓN DE LAS CONVERSIONES\n# ============================================\n# Crear cuadrícula de 2x2 subgráficos\n# (2, 2): 2 filas, 2 columnas\n# figsize=(14, 10): ancho 14 pulgadas, alto 10 pulgadas\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n\n# ============================================\n# SUBGRÁFICO 1: IMAGEN ORIGINAL (RGB)\n# ============================================\n# axes[0, 0]: fila 0, columna 0 (superior izquierda)\naxes[0, 0].imshow(cv2.cvtColor(imagen_ejemplo, cv2.COLOR_BGR2RGB))\naxes[0, 0].set_title('Original (RGB)')\naxes[0, 0].axis('off')\n\n\n# ============================================\n# SUBGRÁFICO 2: ESCALA DE GRISES\n# ============================================\n# axes[0, 1]: fila 0, columna 1 (superior derecha)\n# cmap='gray': mapa de colores de grises (0=negro, 255=blanco)\naxes[0, 1].imshow(imagen_gris, cmap='gray')\naxes[0, 1].set_title('Escala de Grises')\naxes[0, 1].axis('off')\n\n\n# ============================================\n# SUBGRÁFICO 3: CANAL HUE (TONO) DE HSV\n# ============================================\n# axes[1, 0]: fila 1, columna 0 (inferior izquierda)\n# imagen_hsv[:, :, 0]: todas las filas, todas las columnas, canal 0 (Hue)\n# [:, :, 0] extrae solo el primer canal (el tono)\n# cmap='hsv': mapa de colores que visualiza el espectro de tonos\naxes[1, 0].imshow(imagen_hsv[:, :, 0], cmap='hsv')\naxes[1, 0].set_title('HSV - Canal Hue (Tono)')\naxes[1, 0].axis('off')\n\n\n# ============================================\n# SUBGRÁFICO 4: CANAL VALUE (BRILLO) DE HSV\n# ============================================\n# axes[1, 1]: fila 1, columna 1 (inferior derecha)\n# imagen_hsv[:, :, 2]: canal 2 = Value (brillo)\n# Los canales HSV son: 0=Hue, 1=Saturation, 2=Value\n# cmap='gray': muestra el brillo como escala de grises\naxes[1, 1].imshow(imagen_hsv[:, :, 2], cmap='gray')\naxes[1, 1].set_title('HSV - Canal Value (Brillo)')\naxes[1, 1].axis('off')\n\n\n# ============================================\n# AJUSTAR DISEÑO Y MOSTRAR\n# ============================================\nplt.tight_layout()  # Optimiza el espaciado entre subgráficos\nplt.show()\n\n\n# ============================================\n# INFORMACIÓN DE LAS IMÁGENES CONVERTIDAS\n# ============================================\n# Imagen en grises: 2D (solo altura x ancho, sin canales)\nprint(f\"Forma imagen en grises: {imagen_gris.shape}\")\n# Output esperado: (altura, ancho) - solo 2 dimensiones\n\n# Imagen HSV: 3D (igual que BGR, pero diferentes canales)\nprint(f\"Forma imagen HSV: {imagen_hsv.shape}\")\n# Output esperado: (altura, ancho, 3) - 3 canales H, S, V"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Operaciones Básicas con Imágenes\n",
    "\n",
    "### 4.1 Redimensionar Imágenes\n",
    "\n",
    "Redimensionar es crucial para:\n",
    "- Reducir el costo computacional\n",
    "- Preparar datos para redes neuronales (que requieren tamaños fijos)\n",
    "- Crear thumbnails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================\n# MÉTODO 1: REDIMENSIONAR A TAMAÑO ESPECÍFICO\n# ============================================\n# Especificar las dimensiones exactas deseadas en píxeles\nnuevo_ancho = 300  # Ancho deseado en píxeles\nnuevo_alto = 200   # Alto deseado en píxeles\n\n# cv2.resize(imagen, (ancho, alto))\n# IMPORTANTE: El orden es (ancho, alto), no (alto, ancho)\n# Esto redimensiona la imagen al tamaño exacto especificado\nimagen_redimensionada = cv2.resize(imagen_ejemplo, (nuevo_ancho, nuevo_alto))\n\n\n# ============================================\n# MÉTODO 2: REDIMENSIONAR CON FACTOR DE ESCALA\n# ============================================\n# Usar un factor multiplicador en lugar de dimensiones específicas\nfactor_escala = 0.5  # 0.5 = reducir a 50% del tamaño original\n\n# cv2.resize() con factores de escala:\n# - None: indica que no especificamos dimensiones exactas\n# - fx: factor de escala en el eje X (ancho)\n# - fy: factor de escala en el eje Y (alto)\n# - interpolation: método para calcular los nuevos píxeles\n#   * INTER_LINEAR: interpolación lineal (buena calidad, velocidad media)\nimagen_escalada = cv2.resize(imagen_ejemplo, None, \n                             fx=factor_escala, fy=factor_escala, \n                             interpolation=cv2.INTER_LINEAR)\n\n\n# ============================================\n# MÉTODOS DE INTERPOLACIÓN: COMPARACIÓN\n# ============================================\n# La interpolación determina cómo se calculan los nuevos valores de píxeles\n# al redimensionar. Diferentes métodos = diferentes resultados\n\n# INTER_NEAREST: Vecino más cercano\n# - Más rápido\n# - Menor calidad (imagen pixelada)\n# - Mejor para: imágenes con bordes duros, máscaras binarias\nimagen_nearest = cv2.resize(imagen_ejemplo, (150, 100), \n                           interpolation=cv2.INTER_NEAREST)\n\n# INTER_LINEAR: Interpolación bilineal\n# - Velocidad media\n# - Calidad media-buena\n# - Mejor para: uso general, reducción de tamaño\nimagen_linear = cv2.resize(imagen_ejemplo, (150, 100), \n                          interpolation=cv2.INTER_LINEAR)\n\n# INTER_CUBIC: Interpolación bicúbica\n# - Más lento\n# - Mejor calidad (imagen más suave)\n# - Mejor para: ampliación de imágenes, fotografías\nimagen_cubic = cv2.resize(imagen_ejemplo, (150, 100), \n                         interpolation=cv2.INTER_CUBIC)\n\n\n# ============================================\n# VISUALIZACIÓN DE RESULTADOS\n# ============================================\n# Crear cuadrícula de 2x2 subgráficos para comparar\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n\n# SUBGRÁFICO 1: Imagen original\n# axes[0, 0]: fila 0, columna 0 (superior izquierda)\naxes[0, 0].imshow(cv2.cvtColor(imagen_ejemplo, cv2.COLOR_BGR2RGB))\n# Mostrar dimensiones en el título usando slicing [:2] para obtener (alto, ancho)\naxes[0, 0].set_title(f'Original {imagen_ejemplo.shape[:2]}')\naxes[0, 0].axis('off')\n\n\n# SUBGRÁFICO 2: Imagen redimensionada a tamaño específico\naxes[0, 1].imshow(cv2.cvtColor(imagen_redimensionada, cv2.COLOR_BGR2RGB))\naxes[0, 1].set_title(f'Redimensionada {imagen_redimensionada.shape[:2]}')\naxes[0, 1].axis('off')\n\n\n# SUBGRÁFICO 3: Interpolación NEAREST (vecino más cercano)\naxes[1, 0].imshow(cv2.cvtColor(imagen_nearest, cv2.COLOR_BGR2RGB))\naxes[1, 0].set_title('INTER_NEAREST (más rápido)')\naxes[1, 0].axis('off')\n\n\n# SUBGRÁFICO 4: Interpolación CUBIC (bicúbica)\naxes[1, 1].imshow(cv2.cvtColor(imagen_cubic, cv2.COLOR_BGR2RGB))\naxes[1, 1].set_title('INTER_CUBIC (mejor calidad)')\naxes[1, 1].axis('off')\n\n\n# ============================================\n# AJUSTAR Y MOSTRAR\n# ============================================\nplt.tight_layout()  # Optimiza el espaciado\nplt.show()\n\n\n# NOTAS PARA LA CLASE:\n# ========================================\n# - INTER_NEAREST: Use para máscaras y cuando la velocidad es crítica\n# - INTER_LINEAR: Use para la mayoría de casos (balance velocidad/calidad)\n# - INTER_CUBIC: Use cuando la calidad visual es prioritaria\n# - INTER_AREA: Mejor para reducir tamaño (shrinking)\n# - El orden en resize es (ancho, alto), ¡no (alto, ancho)!"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Filtros y Suavizado de Imágenes\n",
    "\n",
    "Los filtros son operaciones que modifican los valores de los píxeles basándose en sus vecinos.\n",
    "\n",
    "### Tipos de filtros comunes:\n",
    "\n",
    "1. **Blur (Desenfoque)**: Reduce el ruido y suaviza la imagen\n",
    "2. **Gaussian Blur**: Similar al blur pero con pesos gaussianos\n",
    "3. **Median Blur**: Excelente para eliminar ruido \"sal y pimienta\"\n",
    "4. **Bilateral Filter**: Suaviza pero preserva bordes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================\n# APLICAR DIFERENTES FILTROS DE SUAVIZADO\n# ============================================\n# Los filtros suavizan la imagen reduciendo el ruido y los detalles finos\n# Se basan en reemplazar cada píxel con un promedio de sus vecinos\n\n\n# ============================================\n# FILTRO 1: BLUR PROMEDIO (AVERAGE BLUR)\n# ============================================\n# Reemplaza cada píxel con el promedio de sus vecinos\n# kernel_size: tamaño de la ventana de vecindad\n# (15, 15) significa una ventana de 15x15 píxeles\n# DEBE ser un número IMPAR (3, 5, 7, 9, 11, 13, 15, etc.)\nkernel_size = (15, 15)\n\n# cv2.blur(imagen, tamaño_kernel)\n# Calcula el promedio simple (sin pesos) de todos los píxeles en la ventana\n# Cuanto mayor el kernel, más suavizado (pero más pérdida de detalles)\nblur = cv2.blur(imagen_ejemplo, kernel_size)\n\n\n# ============================================\n# FILTRO 2: GAUSSIAN BLUR (DESENFOQUE GAUSSIANO)\n# ============================================\n# Similar al blur promedio, pero usa pesos gaussianos\n# Los píxeles centrales tienen más peso que los periféricos\n# Resultado: suavizado más natural, preserva mejor los bordes que blur promedio\n\n# cv2.GaussianBlur(imagen, tamaño_kernel, sigmaX)\n# - kernel_size: (15, 15) ventana de suavizado\n# - 0: sigmaX (desviación estándar), 0 = se calcula automáticamente\n# Produce un efecto más \"natural\" que el blur promedio\ngaussian = cv2.GaussianBlur(imagen_ejemplo, kernel_size, 0)\n\n\n# ============================================\n# FILTRO 3: MEDIAN BLUR (DESENFOQUE POR MEDIANA)\n# ============================================\n# Reemplaza cada píxel con la MEDIANA (no el promedio) de sus vecinos\n# Excelente para eliminar ruido \"sal y pimienta\" (píxeles blancos/negros aleatorios)\n# Preserva mejor los bordes que blur promedio\n\n# cv2.medianBlur(imagen, tamaño_kernel)\n# - 15: tamaño del kernel (DEBE ser impar y UN SOLO número, no tupla)\n# Ventaja: elimina ruido sin difuminar tanto los bordes\nmedian = cv2.medianBlur(imagen_ejemplo, 15)\n\n\n# ============================================\n# FILTRO 4: BILATERAL FILTER (FILTRO BILATERAL)\n# ============================================\n# El filtro más sofisticado: suaviza PERO preserva bordes nítidos\n# Considera tanto la distancia espacial como la diferencia de color\n# Ideal para fotografías: reduce ruido manteniendo detalles importantes\n\n# cv2.bilateralFilter(imagen, d, sigmaColor, sigmaSpace)\n# - 15: diámetro de la vecindad de cada píxel\n# - 75: sigmaColor (diferencia de color para considerar píxeles similares)\n#   * Mayor valor = colores más diferentes se promedian juntos\n# - 75: sigmaSpace (distancia espacial en coordenadas de píxeles)\n#   * Mayor valor = píxeles más lejanos se influencian mutuamente\n# MÁS LENTO que otros filtros, pero mejor calidad\nbilateral = cv2.bilateralFilter(imagen_ejemplo, 15, 75, 75)\n\n\n# ============================================\n# VISUALIZACIÓN COMPARATIVA\n# ============================================\n# Crear cuadrícula de 2x3 para mostrar todas las variantes\nfig, axes = plt.subplots(2, 3, figsize=(16, 10))\n\n\n# FILA 1, COLUMNA 1: Imagen original\naxes[0, 0].imshow(cv2.cvtColor(imagen_ejemplo, cv2.COLOR_BGR2RGB))\naxes[0, 0].set_title('Original')\naxes[0, 0].axis('off')\n\n# FILA 1, COLUMNA 2: Blur promedio\naxes[0, 1].imshow(cv2.cvtColor(blur, cv2.COLOR_BGR2RGB))\naxes[0, 1].set_title('Blur Promedio')\naxes[0, 1].axis('off')\n\n# FILA 1, COLUMNA 3: Gaussian blur\naxes[0, 2].imshow(cv2.cvtColor(gaussian, cv2.COLOR_BGR2RGB))\naxes[0, 2].set_title('Gaussian Blur')\naxes[0, 2].axis('off')\n\n# FILA 2, COLUMNA 1: Median blur\naxes[1, 0].imshow(cv2.cvtColor(median, cv2.COLOR_BGR2RGB))\naxes[1, 0].set_title('Median Blur')\naxes[1, 0].axis('off')\n\n# FILA 2, COLUMNA 2: Bilateral filter\naxes[1, 1].imshow(cv2.cvtColor(bilateral, cv2.COLOR_BGR2RGB))\naxes[1, 1].set_title('Bilateral Filter')\naxes[1, 1].axis('off')\n\n\n# ============================================\n# VISUALIZACIÓN DE DIFERENCIA\n# ============================================\n# Mostrar qué fue eliminado por el filtro bilateral\n# cv2.absdiff() calcula la diferencia absoluta píxel por píxel\n# Píxeles diferentes = brillantes, píxeles iguales = oscuros\ndiferencia = cv2.absdiff(imagen_ejemplo, bilateral)\n\n# FILA 2, COLUMNA 3: Diferencia (lo que se eliminó)\naxes[1, 2].imshow(cv2.cvtColor(diferencia, cv2.COLOR_BGR2RGB))\naxes[1, 2].set_title('Diferencia (Original - Bilateral)')\naxes[1, 2].axis('off')\n\n\n# ============================================\n# AJUSTAR Y MOSTRAR\n# ============================================\nplt.tight_layout()\nplt.show()\n\n\n# GUÍA DE SELECCIÓN DE FILTROS PARA LA CLASE:\n# ====================================================\n# - Blur Promedio: Suavizado rápido y simple\n# - Gaussian Blur: Suavizado natural, uso general\n# - Median Blur: Eliminar ruido sal y pimienta\n# - Bilateral Filter: Reducir ruido preservando bordes (más lento)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Detección de Bordes\n",
    "\n",
    "La detección de bordes es fundamental en Computer Vision. Los bordes representan cambios abruptos en la intensidad.\n",
    "\n",
    "### Algoritmos principales:\n",
    "\n",
    "1. **Sobel**: Detecta gradientes en dirección X e Y\n",
    "2. **Canny**: El detector de bordes más popular\n",
    "   - Usa múltiples etapas\n",
    "   - Produce bordes delgados y bien definidos\n",
    "3. **Laplacian**: Detecta cambios rápidos en intensidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================\n# PREPARACIÓN: CONVERTIR A ESCALA DE GRISES\n# ============================================\n# La detección de bordes trabaja mejor en escala de grises\n# Los bordes representan cambios bruscos en la intensidad de luz\n# El color no es necesario y puede complicar el análisis\nimagen_gris = cv2.cvtColor(imagen_ejemplo, cv2.COLOR_BGR2GRAY)\n\n\n# ============================================\n# MÉTODO 1: SOBEL - DETECTAR GRADIENTES\n# ============================================\n# Sobel detecta cambios de intensidad (gradientes) en direcciones X e Y\n# Un gradiente grande = un borde\n# Se aplica en dos direcciones separadas y luego se combinan\n\n# Sobel en dirección X (detecta bordes verticales)\n# cv2.Sobel(imagen, profundidad_output, dx, dy, tamaño_kernel)\n# - cv2.CV_64F: profundidad de salida (float de 64 bits para valores negativos)\n# - dx=1, dy=0: derivada de primer orden en X, cero en Y\n# - ksize=5: tamaño del kernel Sobel (3, 5, 7, etc.)\n# Resultado: detecta cambios horizontales (bordes verticales)\nsobel_x = cv2.Sobel(imagen_gris, cv2.CV_64F, 1, 0, ksize=5)\n\n# Sobel en dirección Y (detecta bordes horizontales)\n# dx=0, dy=1: derivada en Y, cero en X\n# Resultado: detecta cambios verticales (bordes horizontales)\nsobel_y = cv2.Sobel(imagen_gris, cv2.CV_64F, 0, 1, ksize=5)\n\n# Combinar gradientes X e Y usando magnitud vectorial\n# cv2.magnitude() calcula: sqrt(sobel_x² + sobel_y²)\n# Esto da la magnitud total del gradiente en cualquier dirección\nsobel_combinado = cv2.magnitude(sobel_x, sobel_y)\n\n\n# ============================================\n# MÉTODO 2: LAPLACIAN - SEGUNDA DERIVADA\n# ============================================\n# Laplacian detecta cambios rápidos en intensidad (segunda derivada)\n# Detecta regiones donde la intensidad cambia abruptamente\n# Más sensible al ruido que Sobel\n\n# cv2.Laplacian(imagen, profundidad_output)\n# - cv2.CV_64F: permite valores negativos (importante para derivadas)\n# Detecta bordes en todas las direcciones simultáneamente\nlaplacian = cv2.Laplacian(imagen_gris, cv2.CV_64F)\n\n\n# ============================================\n# MÉTODO 3: CANNY - DETECTOR DE BORDES ÓPTIMO\n# ============================================\n# Canny es el algoritmo más popular para detección de bordes\n# Proceso multi-etapa:\n# 1. Suavizado Gaussiano (reduce ruido)\n# 2. Cálculo de gradientes\n# 3. Supresión no-máxima (adelgaza bordes)\n# 4. Umbralización por histéresis (usa dos umbrales)\n\n# cv2.Canny(imagen, umbral_bajo, umbral_alto)\n# - 50: threshold1 (umbral bajo)\n#   * Píxeles con gradiente > 50 son \"candidatos débiles\"\n# - 150: threshold2 (umbral alto)\n#   * Píxeles con gradiente > 150 son \"bordes seguros\"\n# - Píxeles entre 50-150: se incluyen solo si están conectados a bordes seguros\n# Proporción recomendada: 1:2 o 1:3 (bajo:alto)\ncanny = cv2.Canny(imagen_gris, 50, 150)\n\n\n# ============================================\n# VISUALIZACIÓN DE RESULTADOS\n# ============================================\n# Crear cuadrícula de 2x3 para comparar todos los métodos\nfig, axes = plt.subplots(2, 3, figsize=(16, 10))\n\n\n# FILA 1, COLUMNA 1: Imagen original en grises\naxes[0, 0].imshow(imagen_gris, cmap='gray')\naxes[0, 0].set_title('Imagen Original (Gris)')\naxes[0, 0].axis('off')\n\n\n# FILA 1, COLUMNA 2: Sobel X (bordes verticales)\n# np.abs() convierte valores negativos a positivos para visualización\naxes[0, 1].imshow(np.abs(sobel_x), cmap='gray')\naxes[0, 1].set_title('Sobel X (Vertical)')\naxes[0, 1].axis('off')\n\n\n# FILA 1, COLUMNA 3: Sobel Y (bordes horizontales)\naxes[0, 2].imshow(np.abs(sobel_y), cmap='gray')\naxes[0, 2].set_title('Sobel Y (Horizontal)')\naxes[0, 2].axis('off')\n\n\n# FILA 2, COLUMNA 1: Sobel combinado (todas las direcciones)\naxes[1, 0].imshow(sobel_combinado, cmap='gray')\naxes[1, 0].set_title('Sobel Combinado')\naxes[1, 0].axis('off')\n\n\n# FILA 2, COLUMNA 2: Laplacian\naxes[1, 1].imshow(np.abs(laplacian), cmap='gray')\naxes[1, 1].set_title('Laplacian')\naxes[1, 1].axis('off')\n\n\n# FILA 2, COLUMNA 3: Canny (el mejor)\naxes[1, 2].imshow(canny, cmap='gray')\naxes[1, 2].set_title('Canny Edge Detection')\naxes[1, 2].axis('off')\n\n\n# ============================================\n# AJUSTAR Y MOSTRAR\n# ============================================\nplt.tight_layout()\nplt.show()\n\n\n# GUÍA DE SELECCIÓN PARA LA CLASE:\n# =========================================\n# - Sobel: Útil cuando necesitas conocer la DIRECCIÓN del borde\n# - Laplacian: Detecta cambios finos, pero sensible al ruido\n# - Canny: MEJOR opción general - bordes limpios y precisos\n# - Ajusta umbrales Canny: valores bajos → más bordes (+ ruido)\n#                          valores altos → menos bordes (solo los fuertes)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Umbralización (Thresholding)\n",
    "\n",
    "La umbralización convierte una imagen en escala de grises a una imagen binaria (blanco y negro).\n",
    "\n",
    "### Tipos de umbralización:\n",
    "\n",
    "1. **Simple**: Usa un valor fijo como umbral\n",
    "2. **Adaptativa**: Calcula el umbral para pequeñas regiones\n",
    "3. **Otsu**: Calcula automáticamente el umbral óptimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================\n# MÉTODO 1: UMBRALIZACIÓN SIMPLE (BINARIA)\n# ============================================\n# Convierte imagen de grises a blanco y negro puro (binaria)\n# Cada píxel se compara con un umbral fijo\n# Si píxel >= umbral → blanco (255)\n# Si píxel < umbral → negro (0)\n\numbral_valor = 127  # Valor de umbral (0-255), 127 = punto medio\n\n# cv2.threshold(imagen, valor_umbral, valor_máximo, tipo)\n# - imagen_gris: imagen de entrada en escala de grises\n# - 127: umbral de comparación\n# - 255: valor asignado a píxeles que pasan el umbral\n# - cv2.THRESH_BINARY: tipo de umbralización binaria\n# Retorna: (valor_umbral_usado, imagen_umbralizada)\n_, thresh_simple = cv2.threshold(imagen_gris, umbral_valor, 255, cv2.THRESH_BINARY)\n\n\n# ============================================\n# MÉTODO 2: UMBRALIZACIÓN INVERSA\n# ============================================\n# Igual que binaria, pero invertida:\n# Si píxel >= umbral → negro (0)\n# Si píxel < umbral → blanco (255)\n\n# THRESH_BINARY_INV: invierte el resultado\n# Útil cuando queremos destacar objetos oscuros sobre fondo claro\n_, thresh_inversa = cv2.threshold(imagen_gris, umbral_valor, 255, cv2.THRESH_BINARY_INV)\n\n\n# ============================================\n# MÉTODO 3: MÉTODO DE OTSU (AUTOMÁTICO)\n# ============================================\n# Otsu calcula automáticamente el MEJOR umbral\n# Usa el histograma de la imagen para encontrar el valor óptimo\n# que maximiza la varianza entre las clases (fondo y objeto)\n\n# cv2.threshold() con THRESH_OTSU:\n# - 0: valor umbral (se ignora, Otsu lo calcula automáticamente)\n# - 255: valor máximo para píxeles que pasan el umbral\n# - THRESH_BINARY + THRESH_OTSU: combina binaria con cálculo automático\n# Ventaja: No necesitas saber qué umbral usar\n_, thresh_otsu = cv2.threshold(imagen_gris, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n\n\n# ============================================\n# MÉTODO 4: UMBRALIZACIÓN ADAPTATIVA\n# ============================================\n# Calcula diferentes umbrales para diferentes regiones de la imagen\n# Ideal para imágenes con iluminación NO UNIFORME\n# En lugar de un umbral global, usa umbrales locales\n\n# cv2.adaptiveThreshold(imagen, valor_máx, método, tipo, tamaño_bloque, constante)\n# - imagen_gris: entrada en escala de grises\n# - 255: valor máximo para píxeles umbralizados\n# - ADAPTIVE_THRESH_GAUSSIAN_C: método de cálculo del umbral local\n#   * Usa promedio ponderado gaussiano de la vecindad\n#   * Alternativa: ADAPTIVE_THRESH_MEAN_C (promedio simple)\n# - THRESH_BINARY: tipo de umbralización\n# - 11: tamaño de la vecindad (área para calcular umbral local)\n#   * Debe ser impar (3, 5, 7, 9, 11, etc.)\n# - 2: constante C que se resta del promedio calculado\n#   * Ajusta finamente el umbral (puede ser negativa)\nthresh_adaptativa = cv2.adaptiveThreshold(imagen_gris, 255, \n                                          cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n                                          cv2.THRESH_BINARY, 11, 2)\n\n\n# ============================================\n# VISUALIZACIÓN DE RESULTADOS\n# ============================================\n# Crear cuadrícula de 2x3 para comparar métodos\nfig, axes = plt.subplots(2, 3, figsize=(16, 10))\n\n\n# FILA 1, COLUMNA 1: Imagen original en grises\naxes[0, 0].imshow(imagen_gris, cmap='gray')\naxes[0, 0].set_title('Original')\naxes[0, 0].axis('off')\n\n\n# FILA 1, COLUMNA 2: Umbralización simple\naxes[0, 1].imshow(thresh_simple, cmap='gray')\naxes[0, 1].set_title(f'Umbral Simple (threshold={umbral_valor})')\naxes[0, 1].axis('off')\n\n\n# FILA 1, COLUMNA 3: Umbralización inversa\naxes[0, 2].imshow(thresh_inversa, cmap='gray')\naxes[0, 2].set_title('Umbral Inverso')\naxes[0, 2].axis('off')\n\n\n# FILA 2, COLUMNA 1: Método de Otsu\naxes[1, 0].imshow(thresh_otsu, cmap='gray')\naxes[1, 0].set_title('Método de Otsu')\naxes[1, 0].axis('off')\n\n\n# FILA 2, COLUMNA 2: Umbralización adaptativa\naxes[1, 1].imshow(thresh_adaptativa, cmap='gray')\naxes[1, 1].set_title('Umbral Adaptativo')\naxes[1, 1].axis('off')\n\n\n# ============================================\n# FILA 2, COLUMNA 3: HISTOGRAMA\n# ============================================\n# Visualizar la distribución de intensidades de píxeles\n# Ayuda a entender por qué ciertos umbrales funcionan mejor\n\n# .ravel() convierte la imagen 2D en un array 1D\n# hist(datos, número_bins, rango)\n# - imagen_gris.ravel(): todos los valores de píxeles en 1D\n# - 256: número de bins (uno por cada valor 0-255)\n# - [0, 256]: rango de valores a considerar\naxes[1, 2].hist(imagen_gris.ravel(), 256, [0, 256])\n\n# Dibujar línea vertical roja mostrando el umbral usado\n# axvline() dibuja una línea vertical en x=umbral_valor\naxes[1, 2].axvline(x=umbral_valor, color='r', linestyle='--', label='Umbral')\n\naxes[1, 2].set_title('Histograma')\naxes[1, 2].set_xlabel('Intensidad del píxel')  # Etiqueta eje X\naxes[1, 2].set_ylabel('Frecuencia')  # Etiqueta eje Y\naxes[1, 2].legend()  # Mostrar leyenda\n\n\n# ============================================\n# AJUSTAR Y MOSTRAR\n# ============================================\nplt.tight_layout()\nplt.show()\n\n\n# GUÍA DE SELECCIÓN PARA LA CLASE:\n# =========================================\n# - Simple: Cuando conoces el umbral ideal (ej: 127)\n# - Inversa: Cuando quieres invertir el resultado\n# - Otsu: MEJOR para imágenes con histograma bimodal (dos picos)\n# - Adaptativa: MEJOR para iluminación irregular (sombras, gradientes)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Operaciones Morfológicas\n",
    "\n",
    "Las operaciones morfológicas procesan imágenes basándose en formas. Se aplican típicamente a imágenes binarias.\n",
    "\n",
    "### Operaciones principales:\n",
    "\n",
    "1. **Erosión**: Reduce el tamaño de los objetos blancos\n",
    "2. **Dilatación**: Aumenta el tamaño de los objetos blancos\n",
    "3. **Apertura**: Erosión seguida de dilatación (elimina ruido pequeño)\n",
    "4. **Cierre**: Dilatación seguida de erosión (rellena huecos pequeños)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================\n# PREPARACIÓN: USAR IMAGEN UMBRALIZADA\n# ============================================\n# Las operaciones morfológicas trabajan mejor con imágenes binarias\n# Usamos la imagen umbralizada con Otsu de la celda anterior\n# thresh_otsu ya está disponible: imagen en blanco y negro puro\n\n\n# ============================================\n# CREAR KERNEL (ELEMENTO ESTRUCTURANTE)\n# ============================================\n# El kernel define la forma y tamaño del \"pincel\" morfológico\n# Es una matriz de unos que se desliza por la imagen\n\n# np.ones((5, 5), np.uint8)\n# - (5, 5): kernel cuadrado de 5x5 píxeles\n# - np.uint8: tipo de datos entero sin signo de 8 bits\n# Tamaños comunes: (3,3), (5,5), (7,7), (9,9)\n# Cuanto mayor el kernel, mayor el efecto\nkernel = np.ones((5, 5), np.uint8)\n\n\n# ============================================\n# OPERACIÓN 1: EROSIÓN\n# ============================================\n# Erosión \"corroe\" o reduce los objetos blancos\n# Elimina píxeles de los bordes de los objetos\n# Útil para: eliminar ruido pequeño, separar objetos conectados\n\n# cv2.erode(imagen, kernel, iterations)\n# - thresh_otsu: imagen binaria de entrada\n# - kernel: elemento estructurante que define el área de erosión\n# - iterations=1: número de veces que se aplica la erosión\n#   * Más iteraciones = más erosión\n# Cada píxel blanco se mantiene SOLO si todos los píxeles bajo el kernel son blancos\nerosion = cv2.erode(thresh_otsu, kernel, iterations=1)\n\n\n# ============================================\n# OPERACIÓN 2: DILATACIÓN\n# ============================================\n# Dilatación \"expande\" o agranda los objetos blancos\n# Añade píxeles a los bordes de los objetos\n# Útil para: rellenar huecos pequeños, conectar objetos cercanos\n\n# cv2.dilate(imagen, kernel, iterations)\n# - iterations=1: número de veces que se aplica la dilatación\n# Un píxel se vuelve blanco si AL MENOS UN píxel bajo el kernel es blanco\ndilatacion = cv2.dilate(thresh_otsu, kernel, iterations=1)\n\n\n# ============================================\n# OPERACIÓN 3: APERTURA (OPENING)\n# ============================================\n# Apertura = Erosión seguida de Dilatación\n# Efecto: elimina ruido pequeño FUERA de los objetos principales\n# Secuencia:\n#   1. Erosión elimina ruido pequeño\n#   2. Dilatación restaura el tamaño de los objetos grandes\n\n# cv2.morphologyEx(imagen, operación, kernel)\n# - cv2.MORPH_OPEN: operación de apertura\n# Equivale a: cv2.dilate(cv2.erode(thresh_otsu, kernel), kernel)\n# Útil para limpiar fondos ruidosos\napertura = cv2.morphologyEx(thresh_otsu, cv2.MORPH_OPEN, kernel)\n\n\n# ============================================\n# OPERACIÓN 4: CIERRE (CLOSING)\n# ============================================\n# Cierre = Dilatación seguida de Erosión\n# Efecto: rellena huecos pequeños DENTRO de los objetos\n# Secuencia:\n#   1. Dilatación rellena huecos\n#   2. Erosión restaura el tamaño original\n\n# cv2.MORPH_CLOSE: operación de cierre\n# Equivale a: cv2.erode(cv2.dilate(thresh_otsu, kernel), kernel)\n# Útil para conectar partes separadas de un mismo objeto\ncierre = cv2.morphologyEx(thresh_otsu, cv2.MORPH_CLOSE, kernel)\n\n\n# ============================================\n# OPERACIÓN 5: GRADIENTE MORFOLÓGICO\n# ============================================\n# Gradiente = Dilatación - Erosión\n# Efecto: extrae el CONTORNO (borde) de los objetos\n# La diferencia entre la imagen dilatada y erosionada da solo los bordes\n\n# cv2.MORPH_GRADIENT: operación de gradiente morfológico\n# Equivale a: cv2.dilate(thresh_otsu) - cv2.erode(thresh_otsu)\n# Útil para detectar solo los bordes de objetos\ngradiente = cv2.morphologyEx(thresh_otsu, cv2.MORPH_GRADIENT, kernel)\n\n\n# ============================================\n# VISUALIZACIÓN DE RESULTADOS\n# ============================================\n# Crear cuadrícula de 2x3 para comparar todas las operaciones\nfig, axes = plt.subplots(2, 3, figsize=(16, 10))\n\n\n# FILA 1, COLUMNA 1: Imagen original umbralizada\naxes[0, 0].imshow(thresh_otsu, cmap='gray')\naxes[0, 0].set_title('Original (Umbralizada)')\naxes[0, 0].axis('off')\n\n\n# FILA 1, COLUMNA 2: Erosión (reduce objetos)\naxes[0, 1].imshow(erosion, cmap='gray')\naxes[0, 1].set_title('Erosión')\naxes[0, 1].axis('off')\n\n\n# FILA 1, COLUMNA 3: Dilatación (expande objetos)\naxes[0, 2].imshow(dilatacion, cmap='gray')\naxes[0, 2].set_title('Dilatación')\naxes[0, 2].axis('off')\n\n\n# FILA 2, COLUMNA 1: Apertura (elimina ruido exterior)\naxes[1, 0].imshow(apertura, cmap='gray')\naxes[1, 0].set_title('Apertura (Opening)')\naxes[1, 0].axis('off')\n\n\n# FILA 2, COLUMNA 2: Cierre (rellena huecos interiores)\naxes[1, 1].imshow(cierre, cmap='gray')\naxes[1, 1].set_title('Cierre (Closing)')\naxes[1, 1].axis('off')\n\n\n# FILA 2, COLUMNA 3: Gradiente (solo bordes)\naxes[1, 2].imshow(gradiente, cmap='gray')\naxes[1, 2].set_title('Gradiente Morfológico')\naxes[1, 2].axis('off')\n\n\n# ============================================\n# AJUSTAR Y MOSTRAR\n# ============================================\nplt.tight_layout()\nplt.show()\n\n\n# GUÍA DE SELECCIÓN PARA LA CLASE:\n# =========================================\n# - Erosión: Eliminar ruido pequeño, adelgazar objetos\n# - Dilatación: Rellenar huecos, engrosar objetos\n# - Apertura: Limpiar ruido FUERA de objetos (erosión + dilatación)\n# - Cierre: Rellenar huecos DENTRO de objetos (dilatación + erosión)\n# - Gradiente: Extraer solo los CONTORNOS de objetos\n# \n# REGLA PRÁCTICA:\n# - Fondo ruidoso → Apertura\n# - Objeto con huecos → Cierre\n# - Solo quiero bordes → Gradiente"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Detección de Contornos\n",
    "\n",
    "Los contornos son curvas que unen todos los puntos continuos (a lo largo del borde) que tienen el mismo color o intensidad.\n",
    "\n",
    "### Aplicaciones:\n",
    "- Detección de formas\n",
    "- Reconocimiento de objetos\n",
    "- Análisis de formas\n",
    "- Conteo de objetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================\n# ENCONTRAR CONTORNOS EN LA IMAGEN\n# ============================================\n# Los contornos son curvas que conectan puntos del mismo color/intensidad\n# Esenciales para detección y análisis de formas\n\n# cv2.findContours(imagen, modo_recuperación, método_aproximación)\n# - thresh_otsu: imagen binaria (blanco y negro)\n# - cv2.RETR_EXTERNAL: modo de recuperación\n#   * Solo recupera contornos externos (ignora jerarquías internas)\n#   * Alternativas: RETR_LIST (todos), RETR_TREE (con jerarquía)\n# - cv2.CHAIN_APPROX_SIMPLE: método de aproximación\n#   * Comprime contornos eliminando puntos redundantes\n#   * Ej: un rectángulo usa solo 4 puntos (esquinas)\n#   * Alternativa: CHAIN_APPROX_NONE (todos los puntos)\n# Retorna: (contornos, jerarquía)\ncontornos, jerarquia = cv2.findContours(thresh_otsu, \n                                        cv2.RETR_EXTERNAL, \n                                        cv2.CHAIN_APPROX_SIMPLE)\n\n# Mostrar cuántos contornos se encontraron\nprint(f\"Número de contornos encontrados: {len(contornos)}\")\n\n\n# ============================================\n# DIBUJAR TODOS LOS CONTORNOS\n# ============================================\n# Crear una copia de la imagen original para no modificarla\n# .copy() crea una copia independiente en memoria\nimagen_contornos = imagen_ejemplo.copy()\n\n# cv2.drawContours(imagen, contornos, índice, color, grosor)\n# - imagen_contornos: imagen donde dibujar\n# - contornos: lista de contornos a dibujar\n# - -1: índice del contorno (-1 = dibujar TODOS)\n# - (0, 255, 0): color BGR (verde)\n# - 3: grosor de la línea en píxeles\ncv2.drawContours(imagen_contornos, contornos, -1, (0, 255, 0), 3)\n\n\n# ============================================\n# ANÁLISIS DETALLADO DE CONTORNOS\n# ============================================\n# Crear otra copia para análisis individual\nimagen_analisis = imagen_ejemplo.copy()\n\n# Iterar sobre cada contorno encontrado\n# enumerate() da índice (i) y valor (contorno) de cada elemento\nfor i, contorno in enumerate(contornos):\n    \n    # --------------------------------------------\n    # CÁLCULO DE ÁREA\n    # --------------------------------------------\n    # cv2.contourArea() calcula el área en píxeles²\n    # Área = número de píxeles dentro del contorno\n    area = cv2.contourArea(contorno)\n    \n    \n    # --------------------------------------------\n    # CÁLCULO DE PERÍMETRO\n    # --------------------------------------------\n    # cv2.arcLength() calcula la longitud del contorno\n    # - contorno: puntos del contorno\n    # - True: indica que el contorno es cerrado\n    perimetro = cv2.arcLength(contorno, True)\n    \n    \n    # --------------------------------------------\n    # RECTÁNGULO DELIMITADOR (BOUNDING BOX)\n    # --------------------------------------------\n    # cv2.boundingRect() encuentra el rectángulo más pequeño\n    # que contiene completamente el contorno\n    # Retorna: (x, y, ancho, alto)\n    # - x, y: coordenadas de la esquina superior izquierda\n    # - w: ancho del rectángulo\n    # - h: alto del rectángulo\n    x, y, w, h = cv2.boundingRect(contorno)\n    \n    \n    # --------------------------------------------\n    # FILTRAR CONTORNOS PEQUEÑOS (RUIDO)\n    # --------------------------------------------\n    # Solo procesar contornos con área mayor a 1000 píxeles\n    # Esto elimina ruido y contornos insignificantes\n    if area > 1000:\n        \n        # Dibujar rectángulo delimitador\n        # cv2.rectangle(imagen, punto1, punto2, color, grosor)\n        # (x, y): esquina superior izquierda\n        # (x+w, y+h): esquina inferior derecha\n        # (255, 0, 0): color azul en BGR\n        # 2: grosor de línea\n        cv2.rectangle(imagen_analisis, (x, y), (x+w, y+h), (255, 0, 0), 2)\n        \n        \n        # --------------------------------------------\n        # CALCULAR EL CENTRO DEL CONTORNO (CENTROIDE)\n        # --------------------------------------------\n        # cv2.moments() calcula momentos estadísticos del contorno\n        # Los momentos describen la forma y posición del contorno\n        M = cv2.moments(contorno)\n        \n        # Verificar que m00 no sea cero (evitar división por cero)\n        # m00 es el área del contorno\n        if M[\"m00\"] != 0:\n            # Calcular coordenadas del centroide:\n            # cx = m10 / m00  (momento en X / área)\n            # cy = m01 / m00  (momento en Y / área)\n            # int() convierte a entero para coordenadas de píxeles\n            cx = int(M[\"m10\"] / M[\"m00\"])\n            cy = int(M[\"m01\"] / M[\"m00\"])\n            \n            \n            # --------------------------------------------\n            # DIBUJAR EL CENTRO\n            # --------------------------------------------\n            # cv2.circle(imagen, centro, radio, color, grosor)\n            # (cx, cy): coordenadas del centro\n            # 5: radio del círculo en píxeles\n            # (0, 0, 255): color rojo en BGR\n            # -1: grosor negativo = círculo relleno\n            cv2.circle(imagen_analisis, (cx, cy), 5, (0, 0, 255), -1)\n            \n            \n            # --------------------------------------------\n            # AÑADIR ETIQUETA CON EL ÁREA\n            # --------------------------------------------\n            # cv2.putText(imagen, texto, posición, fuente, escala, color, grosor)\n            # f'A:{int(area)}': texto formateado mostrando el área\n            # (x, y-10): posición sobre el rectángulo\n            # cv2.FONT_HERSHEY_SIMPLEX: fuente sans-serif estándar\n            # 0.5: escala de la fuente (tamaño)\n            # (255, 255, 0): color cian en BGR\n            # 2: grosor del texto\n            cv2.putText(imagen_analisis, f'A:{int(area)}', (x, y-10),\n                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)\n\n\n# ============================================\n# VISUALIZACIÓN DE RESULTADOS\n# ============================================\n# Crear cuadrícula de 1x3 para mostrar las tres etapas\nfig, axes = plt.subplots(1, 3, figsize=(18, 6))\n\n\n# COLUMNA 1: Imagen umbralizada (entrada)\naxes[0].imshow(thresh_otsu, cmap='gray')\naxes[0].set_title('Imagen Umbralizada')\naxes[0].axis('off')\n\n\n# COLUMNA 2: Todos los contornos dibujados\naxes[1].imshow(cv2.cvtColor(imagen_contornos, cv2.COLOR_BGR2RGB))\naxes[1].set_title(f'Contornos Detectados ({len(contornos)})')\naxes[1].axis('off')\n\n\n# COLUMNA 3: Análisis detallado con mediciones\naxes[2].imshow(cv2.cvtColor(imagen_analisis, cv2.COLOR_BGR2RGB))\naxes[2].set_title('Análisis de Contornos')\naxes[2].axis('off')\n\n\n# ============================================\n# AJUSTAR Y MOSTRAR\n# ============================================\nplt.tight_layout()\nplt.show()\n\n\n# CONCEPTOS CLAVE PARA LA CLASE:\n# =========================================\n# - Contornos: curvas que definen los bordes de objetos\n# - Área: tamaño del objeto en píxeles²\n# - Perímetro: longitud del borde en píxeles\n# - Bounding Box: rectángulo más pequeño que contiene el objeto\n# - Centroide: punto central (centro de masa) del objeto\n# - Momentos: propiedades estadísticas que describen la forma\n#\n# USOS PRÁCTICOS:\n# - Contar objetos: len(contornos)\n# - Clasificar por tamaño: filtrar por área\n# - Tracking: seguir el centroide entre frames\n# - Detección de formas: analizar relación área/perímetro"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Detección de Características: Detección de Esquinas\n",
    "\n",
    "Las esquinas son puntos donde hay cambios significativos en múltiples direcciones.\n",
    "\n",
    "### Algoritmo de Harris Corner Detection:\n",
    "- Detecta puntos de interés en una imagen\n",
    "- Útil para tracking, reconocimiento de objetos, y reconstrucción 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================\n# PREPARACIÓN: CONVERTIR A FLOAT32\n# ============================================\n# El algoritmo de Harris requiere imagen en formato float32\n# np.float32() convierte los valores de uint8 (0-255) a punto flotante\nimagen_gris_float = np.float32(imagen_gris)\n\n\n# ============================================\n# MÉTODO 1: HARRIS CORNER DETECTION\n# ============================================\n# Harris detecta esquinas buscando cambios en intensidad en múltiples direcciones\n# Una esquina tiene variación grande tanto en dirección X como Y\n\n# cv2.cornerHarris(imagen, blockSize, ksize, k)\n# - imagen_gris_float: imagen en escala de grises float32\n# - blockSize=2: tamaño de vecindad considerada para detección de esquinas\n#   * Ventana de 2x2 píxeles para cada punto\n# - ksize=3: tamaño de apertura del operador Sobel\n#   * Usado para calcular derivadas (gradientes)\n#   * Debe ser impar: 3, 5, 7, etc.\n# - k=0.04: parámetro libre del detector Harris (típico: 0.04-0.06)\n#   * Controla la sensibilidad del detector\n#   * k más pequeño = más esquinas detectadas\n# Retorna: imagen con valores de \"respuesta\" de Harris en cada píxel\nharris_corners = cv2.cornerHarris(imagen_gris_float, blockSize=2, ksize=3, k=0.04)\n\n\n# ============================================\n# DILATAR PARA MARCAR LAS ESQUINAS\n# ============================================\n# cv2.dilate() expande las regiones de esquinas detectadas\n# Esto hace que las esquinas sean más visibles\n# None: usa kernel por defecto\nharris_corners = cv2.dilate(harris_corners, None)\n\n\n# ============================================\n# CREAR IMAGEN PARA VISUALIZACIÓN\n# ============================================\n# Hacer una copia de la imagen original para marcar esquinas\nimagen_esquinas = imagen_ejemplo.copy()\n\n# Marcar las esquinas en ROJO\n# harris_corners > 0.01 * harris_corners.max(): umbralización\n#   * Selecciona solo píxeles con respuesta Harris > 1% del máximo\n#   * Esto filtra esquinas débiles, mantiene solo las fuertes\n# [0, 0, 255]: color rojo en formato BGR\n# Asigna rojo a todos los píxeles que son esquinas fuertes\nimagen_esquinas[harris_corners > 0.01 * harris_corners.max()] = [0, 0, 255]\n\n\n# ============================================\n# MÉTODO 2: SHI-TOMASI (GOOD FEATURES TO TRACK)\n# ============================================\n# Shi-Tomasi es una mejora de Harris, más moderna y precisa\n# Optimizado para tracking de puntos entre frames de video\n# También conocido como \"Good Features to Track\"\n\n# cv2.goodFeaturesToTrack(imagen, maxCorners, qualityLevel, minDistance)\n# - imagen_gris: imagen en escala de grises (uint8)\n# - maxCorners=50: número máximo de esquinas a detectar\n#   * Retorna las 50 mejores esquinas ordenadas por calidad\n# - qualityLevel=0.01: calidad mínima de las esquinas (0-1)\n#   * 0.01 = esquinas con calidad > 1% de la mejor esquina\n#   * Valores más altos = menos esquinas pero de mejor calidad\n# - minDistance=10: distancia mínima entre esquinas en píxeles\n#   * Evita agrupar muchas esquinas en la misma región\n#   * Distribuye las esquinas por toda la imagen\n# Retorna: array de coordenadas (x, y) de las esquinas detectadas\nesquinas_shi_tomasi = cv2.goodFeaturesToTrack(imagen_gris, \n                                               maxCorners=50, \n                                               qualityLevel=0.01, \n                                               minDistance=10)\n\n\n# ============================================\n# DIBUJAR ESQUINAS SHI-TOMASI\n# ============================================\n# Crear copia para visualizar Shi-Tomasi\nimagen_shi_tomasi = imagen_ejemplo.copy()\n\n# Verificar que se encontraron esquinas\nif esquinas_shi_tomasi is not None:\n    # Convertir coordenadas de float a enteros\n    # np.int32() convierte para usar en funciones de dibujo\n    esquinas_shi_tomasi = np.int32(esquinas_shi_tomasi)\n    \n    # Iterar sobre cada esquina detectada\n    for esquina in esquinas_shi_tomasi:\n        # .ravel() convierte [[x, y]] en [x, y] (aplana el array)\n        x, y = esquina.ravel()\n        \n        # Dibujar un círculo verde en cada esquina\n        # cv2.circle(imagen, centro, radio, color, grosor)\n        # (x, y): coordenadas de la esquina\n        # 5: radio del círculo en píxeles\n        # (0, 255, 0): color verde en BGR\n        # -1: grosor negativo = círculo relleno (sólido)\n        cv2.circle(imagen_shi_tomasi, (x, y), 5, (0, 255, 0), -1)\n\n\n# ============================================\n# VISUALIZACIÓN DE RESULTADOS\n# ============================================\n# Crear cuadrícula de 1x3 para comparar métodos\nfig, axes = plt.subplots(1, 3, figsize=(18, 6))\n\n\n# COLUMNA 1: Imagen original\naxes[0].imshow(cv2.cvtColor(imagen_ejemplo, cv2.COLOR_BGR2RGB))\naxes[0].set_title('Imagen Original')\naxes[0].axis('off')\n\n\n# COLUMNA 2: Harris Corner Detection (puntos rojos)\naxes[1].imshow(cv2.cvtColor(imagen_esquinas, cv2.COLOR_BGR2RGB))\naxes[1].set_title('Harris Corner Detection')\naxes[1].axis('off')\n\n\n# COLUMNA 3: Shi-Tomasi (círculos verdes)\n# Mostrar número de esquinas detectadas en el título\naxes[2].imshow(cv2.cvtColor(imagen_shi_tomasi, cv2.COLOR_BGR2RGB))\naxes[2].set_title(f'Shi-Tomasi ({len(esquinas_shi_tomasi)} esquinas)')\naxes[2].axis('off')\n\n\n# ============================================\n# AJUSTAR Y MOSTRAR\n# ============================================\nplt.tight_layout()\nplt.show()\n\n\n# CONCEPTOS CLAVE PARA LA CLASE:\n# =========================================\n# - Esquinas: puntos donde hay cambios significativos en múltiples direcciones\n# - Son características importantes para:\n#   * Tracking (seguimiento de objetos entre frames)\n#   * Matching (encontrar correspondencias entre imágenes)\n#   * Reconstrucción 3D\n#   * SLAM (mapeo y localización simultáneos)\n#\n# COMPARACIÓN DE MÉTODOS:\n# - Harris: Clásico, detecta muchas esquinas\n#   * Puede dar muchos falsos positivos\n#   * Bueno para entender el concepto\n# - Shi-Tomasi: Más moderno y preciso\n#   * Mejor para tracking\n#   * Devuelve las N mejores esquinas\n#   * Más usado en aplicaciones prácticas"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Segmentación por Color\n",
    "\n",
    "La segmentación por color permite extraer objetos de un color específico de una imagen.\n",
    "\n",
    "### Proceso:\n",
    "1. Convertir a espacio HSV (más fácil para definir rangos de color)\n",
    "2. Definir rangos de color\n",
    "3. Crear una máscara\n",
    "4. Aplicar la máscara a la imagen original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================\n# CONVERTIR A ESPACIO DE COLOR HSV\n# ============================================\n# HSV es MUY superior a BGR/RGB para segmentación por color\n# Razón: en HSV, el color (Hue) está separado del brillo (Value)\n# Esto hace que sea más robusto ante cambios de iluminación\nimagen_hsv = cv2.cvtColor(imagen_ejemplo, cv2.COLOR_BGR2HSV)\n\n\n# ============================================\n# DEFINIR RANGOS DE COLOR: AZUL\n# ============================================\n# Los rangos HSV definen qué píxeles consideramos \"azules\"\n# En OpenCV, Hue va de 0-179 (no 0-360 como en estándar)\n\n# Límite inferior del azul\n# np.array([H, S, V])\n# - H (Hue) = 100: tono azul en el espectro (azul está ~100-130)\n# - S (Saturation) = 50: saturación mínima (50 = un poco saturado)\n#   * 0 = gris/blanco (sin color), 255 = color puro\n# - V (Value) = 50: brillo mínimo\n#   * 0 = negro, 255 = máximo brillo\nlower_blue = np.array([100, 50, 50])\n\n# Límite superior del azul\n# - H = 130: fin del rango azul\n# - S = 255: máxima saturación permitida\n# - V = 255: máximo brillo permitido\nupper_blue = np.array([130, 255, 255])\n\n# cv2.inRange(imagen_hsv, límite_inferior, límite_superior)\n# Crea máscara binaria: 255 (blanco) donde el color está en el rango, 0 (negro) fuera\n# Retorna: imagen binaria del mismo tamaño\nmascara_azul = cv2.inRange(imagen_hsv, lower_blue, upper_blue)\n\n\n# ============================================\n# DEFINIR RANGOS DE COLOR: VERDE\n# ============================================\n# Verde en el espectro de Hue: aproximadamente 40-80\n\n# Límite inferior del verde\n# H = 40: inicio del verde en el espectro\nlower_green = np.array([40, 50, 50])\n\n# Límite superior del verde\n# H = 80: fin del rango verde (antes de llegar a cian)\nupper_green = np.array([80, 255, 255])\n\n# Crear máscara para píxeles verdes\nmascara_verde = cv2.inRange(imagen_hsv, lower_green, upper_green)\n\n\n# ============================================\n# DEFINIR RANGOS DE COLOR: ROJO (ESPECIAL)\n# ============================================\n# PROBLEMA: El rojo está en AMBOS extremos del espectro de Hue\n# Hue es circular: 0° = rojo, 360° = rojo también\n# En OpenCV: 0-10 es rojo Y 170-179 es rojo\n# SOLUCIÓN: Necesitamos DOS rangos y combinarlos\n\n# Rango 1: Rojo en valores bajos de Hue (0-10)\nlower_red1 = np.array([0, 50, 50])   # Inicio del espectro\nupper_red1 = np.array([10, 255, 255])\nmascara_rojo1 = cv2.inRange(imagen_hsv, lower_red1, upper_red1)\n\n# Rango 2: Rojo en valores altos de Hue (170-179)\nlower_red2 = np.array([170, 50, 50])  # Final del espectro\nupper_red2 = np.array([180, 255, 255])  # 180 es el máximo en OpenCV\nmascara_rojo2 = cv2.inRange(imagen_hsv, lower_red2, upper_red2)\n\n# Combinar ambas máscaras con OR lógico\n# cv2.bitwise_or(): píxel = blanco si es blanco en CUALQUIERA de las máscaras\n# Esto une ambos rangos de rojo en una sola máscara\nmascara_rojo = cv2.bitwise_or(mascara_rojo1, mascara_rojo2)\n\n\n# ============================================\n# LIMPIAR MÁSCARAS CON MORFOLOGÍA\n# ============================================\n# Las máscaras suelen tener ruido (píxeles aislados)\n# Usamos operaciones morfológicas para limpiarlas\n\n# Crear kernel para operaciones morfológicas\nkernel = np.ones((5, 5), np.uint8)\n\n# Aplicar CIERRE seguido de APERTURA a la máscara azul\n# - MORPH_CLOSE: rellena huecos pequeños DENTRO de objetos\n#   * Dilatación + Erosión\n# - MORPH_OPEN: elimina ruido pequeño FUERA de objetos\n#   * Erosión + Dilatación\n# Resultado: máscara más limpia y continua\nmascara_azul = cv2.morphologyEx(mascara_azul, cv2.MORPH_CLOSE, kernel)\nmascara_azul = cv2.morphologyEx(mascara_azul, cv2.MORPH_OPEN, kernel)\n\n\n# ============================================\n# APLICAR MÁSCARAS A LA IMAGEN ORIGINAL\n# ============================================\n# Extraer solo las regiones de color específico de la imagen original\n\n# cv2.bitwise_and(imagen, imagen, mask=máscara)\n# - imagen_ejemplo: imagen original a la que aplicar la máscara\n# - imagen_ejemplo: segunda copia (necesaria por sintaxis de OpenCV)\n# - mask: máscara binaria\n# Resultado: imagen donde solo se ven los píxeles blancos de la máscara\n#           el resto aparece negro\nresultado_azul = cv2.bitwise_and(imagen_ejemplo, imagen_ejemplo, mask=mascara_azul)\nresultado_verde = cv2.bitwise_and(imagen_ejemplo, imagen_ejemplo, mask=mascara_verde)\nresultado_rojo = cv2.bitwise_and(imagen_ejemplo, imagen_ejemplo, mask=mascara_rojo)\n\n\n# ============================================\n# VISUALIZACIÓN DE RESULTADOS\n# ============================================\n# Crear cuadrícula de 2x4 para mostrar todo el proceso\nfig, axes = plt.subplots(2, 4, figsize=(18, 9))\n\n\n# FILA 1, COLUMNA 1: Imagen original\naxes[0, 0].imshow(cv2.cvtColor(imagen_ejemplo, cv2.COLOR_BGR2RGB))\naxes[0, 0].set_title('Imagen Original')\naxes[0, 0].axis('off')\n\n\n# FILA 1, COLUMNA 2-4: Máscaras binarias\naxes[0, 1].imshow(mascara_azul, cmap='gray')\naxes[0, 1].set_title('Máscara Azul')\naxes[0, 1].axis('off')\n\naxes[0, 2].imshow(mascara_verde, cmap='gray')\naxes[0, 2].set_title('Máscara Verde')\naxes[0, 2].axis('off')\n\naxes[0, 3].imshow(mascara_rojo, cmap='gray')\naxes[0, 3].set_title('Máscara Roja')\naxes[0, 3].axis('off')\n\n\n# FILA 2, COLUMNA 1: Canal Hue de HSV (para referencia)\n# Muestra la distribución de tonos en la imagen\naxes[1, 0].imshow(imagen_hsv[:, :, 0], cmap='hsv')\naxes[1, 0].set_title('Canal Hue (Tono)')\naxes[1, 0].axis('off')\n\n\n# FILA 2, COLUMNA 2-4: Segmentaciones aplicadas\naxes[1, 1].imshow(cv2.cvtColor(resultado_azul, cv2.COLOR_BGR2RGB))\naxes[1, 1].set_title('Segmentación Azul')\naxes[1, 1].axis('off')\n\naxes[1, 2].imshow(cv2.cvtColor(resultado_verde, cv2.COLOR_BGR2RGB))\naxes[1, 2].set_title('Segmentación Verde')\naxes[1, 2].axis('off')\n\naxes[1, 3].imshow(cv2.cvtColor(resultado_rojo, cv2.COLOR_BGR2RGB))\naxes[1, 3].set_title('Segmentación Roja')\naxes[1, 3].axis('off')\n\n\n# ============================================\n# AJUSTAR Y MOSTRAR\n# ============================================\nplt.tight_layout()\nplt.show()\n\n\n# GUÍA PARA LA CLASE - RANGOS HSV COMUNES:\n# ==========================================\n# Color      | Hue (H)  | Saturation (S) | Value (V)\n# -----------|----------|----------------|------------\n# Rojo       | 0-10,    | 50-255         | 50-255\n#            | 170-180  |                |\n# Naranja    | 10-25    | 50-255         | 50-255\n# Amarillo   | 25-35    | 50-255         | 50-255\n# Verde      | 35-85    | 50-255         | 50-255\n# Azul       | 85-130   | 50-255         | 50-255\n# Violeta    | 130-160  | 50-255         | 50-255\n#\n# CONSEJOS:\n# - S bajo (0-50): colores muy desaturados (grises)\n# - V bajo (0-50): colores muy oscuros\n# - Ajusta rangos según iluminación de tu imagen específica\n# - Usa trackbars para encontrar rangos óptimos interactivamente"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Transformaciones Geométricas\n",
    "\n",
    "Las transformaciones geométricas modifican la geometría de la imagen.\n",
    "\n",
    "### Tipos principales:\n",
    "1. **Traslación**: Mover la imagen\n",
    "2. **Rotación**: Girar la imagen\n",
    "3. **Escalado**: Cambiar el tamaño\n",
    "4. **Transformación Afín**: Combinación de las anteriores\n",
    "5. **Transformación Perspectiva**: Cambios de perspectiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================\n# OBTENER DIMENSIONES DE LA IMAGEN\n# ============================================\n# Extraer alto y ancho de la imagen para cálculos posteriores\n# .shape retorna (alto, ancho, canales)\n# [:2] selecciona solo los primeros dos valores (alto, ancho)\nalto, ancho = imagen_ejemplo.shape[:2]\n\n\n# ============================================\n# TRANSFORMACIÓN 1: TRASLACIÓN (DESPLAZAMIENTO)\n# ============================================\n# Mover la imagen a una nueva posición sin rotarla ni cambiar su tamaño\n\n# Crear matriz de transformación afín para traslación\n# Matriz 2x3: [[1, 0, tx],\n#              [0, 1, ty]]\n# - tx = 100: desplazamiento en X (píxeles a la derecha)\n# - ty = 50: desplazamiento en Y (píxeles hacia abajo)\n# np.float32() crea un array de punto flotante\nmatriz_traslacion = np.float32([[1, 0, 100], [0, 1, 50]])\n\n# cv2.warpAffine(imagen, matriz_transformación, (ancho, alto))\n# - imagen_ejemplo: imagen a transformar\n# - matriz_traslacion: matriz 2x3 que define la transformación\n# - (ancho, alto): tamaño de la imagen de salida\n# Aplica la transformación a cada píxel de la imagen\nimagen_trasladada = cv2.warpAffine(imagen_ejemplo, matriz_traslacion, (ancho, alto))\n\n\n# ============================================\n# TRANSFORMACIÓN 2: ROTACIÓN\n# ============================================\n# Rotar la imagen alrededor de un punto central\n\n# Calcular el centro de la imagen\n# // es división entera (sin decimales)\ncentro = (ancho // 2, alto // 2)\n\n# Parámetros de rotación\nangulo = 45    # Grados a rotar (positivo = antihorario, negativo = horario)\nescala = 1.0   # Factor de escala (1.0 = tamaño original, 0.5 = mitad, 2.0 = doble)\n\n# cv2.getRotationMatrix2D(centro, ángulo, escala)\n# Calcula la matriz de transformación 2x3 para rotación\n# - centro: punto alrededor del cual rotar\n# - angulo: grados de rotación (antihorario)\n# - escala: factor de zoom simultáneo\n# Retorna: matriz de transformación afín\nmatriz_rotacion = cv2.getRotationMatrix2D(centro, angulo, escala)\n\n# Aplicar la rotación usando warpAffine\nimagen_rotada = cv2.warpAffine(imagen_ejemplo, matriz_rotacion, (ancho, alto))\n\n\n# ============================================\n# TRANSFORMACIÓN 3: ESCALADO (CAMBIO DE TAMAÑO)\n# ============================================\n# Redimensionar la imagen a un porcentaje del tamaño original\n\n# cv2.resize(imagen, tamaño, fx, fy, interpolación)\n# - None: no especificamos tamaño absoluto, usamos factores\n# - fx=0.7: factor de escala en X (70% del ancho original)\n# - fy=0.7: factor de escala en Y (70% del alto original)\n# - INTER_LINEAR: método de interpolación bilineal (buena calidad/velocidad)\nimagen_escalada = cv2.resize(imagen_ejemplo, None, fx=0.7, fy=0.7, \n                             interpolation=cv2.INTER_LINEAR)\n\n\n# ============================================\n# TRANSFORMACIÓN 4: VOLTEAR (FLIP)\n# ============================================\n# Reflejar la imagen como en un espejo\n\n# cv2.flip(imagen, flip_code)\n# flip_code determina el tipo de volteo:\n# - 1: volteo horizontal (espejo izquierda-derecha)\n# - 0: volteo vertical (espejo arriba-abajo)\n# - -1: volteo en ambos ejes (rotación 180°)\nimagen_flip_horizontal = cv2.flip(imagen_ejemplo, 1)\nimagen_flip_vertical = cv2.flip(imagen_ejemplo, 0)\n\n\n# ============================================\n# TRANSFORMACIÓN 5: TRANSFORMACIÓN PERSPECTIVA\n# ============================================\n# Cambia la perspectiva como si vieras la imagen desde otro ángulo\n# Útil para corregir distorsión de cámara o simular vista en 3D\n\n# Definir 4 puntos en la imagen ORIGINAL\n# Estos son las esquinas de un cuadrilátero en la imagen actual\n# Formato: [[x, y], [x, y], [x, y], [x, y]]\n# np.float32() convierte a tipo requerido por la función\npuntos_origen = np.float32([[50, 50],     # Superior izquierda\n                            [550, 50],    # Superior derecha\n                            [50, 350],    # Inferior izquierda\n                            [550, 350]])  # Inferior derecha\n\n# Definir dónde queremos que esos 4 puntos aparezcan en la imagen TRANSFORMADA\n# Aquí creamos un efecto de perspectiva trapezoidal\npuntos_destino = np.float32([[0, 0],      # Nueva posición punto 1\n                             [600, 0],    # Nueva posición punto 2\n                             [100, 400],  # Nueva posición punto 3 (movido a la derecha)\n                             [500, 400]]) # Nueva posición punto 4 (movido a la izquierda)\n\n# cv2.getPerspectiveTransform(puntos_origen, puntos_destino)\n# Calcula la matriz de transformación perspectiva 3x3\n# que mapea los 4 puntos origen a los 4 puntos destino\nmatriz_perspectiva = cv2.getPerspectiveTransform(puntos_origen, puntos_destino)\n\n# cv2.warpPerspective(imagen, matriz, tamaño_salida)\n# Aplica transformación perspectiva (requiere matriz 3x3)\n# Similar a warpAffine pero permite transformaciones más complejas\nimagen_perspectiva = cv2.warpPerspective(imagen_ejemplo, matriz_perspectiva, \n                                         (ancho, alto))\n\n\n# ============================================\n# VISUALIZACIÓN DE RESULTADOS\n# ============================================\n# Crear cuadrícula de 2x4 para mostrar todas las transformaciones\nfig, axes = plt.subplots(2, 4, figsize=(18, 9))\n\n\n# FILA 1, COLUMNA 1: Imagen original\naxes[0, 0].imshow(cv2.cvtColor(imagen_ejemplo, cv2.COLOR_BGR2RGB))\naxes[0, 0].set_title('Original')\naxes[0, 0].axis('off')\n\n\n# FILA 1, COLUMNA 2: Traslación\naxes[0, 1].imshow(cv2.cvtColor(imagen_trasladada, cv2.COLOR_BGR2RGB))\naxes[0, 1].set_title('Traslación')\naxes[0, 1].axis('off')\n\n\n# FILA 1, COLUMNA 3: Rotación\naxes[0, 2].imshow(cv2.cvtColor(imagen_rotada, cv2.COLOR_BGR2RGB))\naxes[0, 2].set_title(f'Rotación {angulo}°')\naxes[0, 2].axis('off')\n\n\n# FILA 1, COLUMNA 4: Escalado\naxes[0, 3].imshow(cv2.cvtColor(imagen_escalada, cv2.COLOR_BGR2RGB))\naxes[0, 3].set_title('Escalado 70%')\naxes[0, 3].axis('off')\n\n\n# FILA 2, COLUMNA 1: Flip horizontal\naxes[1, 0].imshow(cv2.cvtColor(imagen_flip_horizontal, cv2.COLOR_BGR2RGB))\naxes[1, 0].set_title('Flip Horizontal')\naxes[1, 0].axis('off')\n\n\n# FILA 2, COLUMNA 2: Flip vertical\naxes[1, 1].imshow(cv2.cvtColor(imagen_flip_vertical, cv2.COLOR_BGR2RGB))\naxes[1, 1].set_title('Flip Vertical')\naxes[1, 1].axis('off')\n\n\n# FILA 2, COLUMNA 3: Transformación perspectiva\naxes[1, 2].imshow(cv2.cvtColor(imagen_perspectiva, cv2.COLOR_BGR2RGB))\naxes[1, 2].set_title('Transformación Perspectiva')\naxes[1, 2].axis('off')\n\n\n# ============================================\n# COMBINACIÓN DE TRANSFORMACIONES\n# ============================================\n# Ejemplo: aplicar múltiples transformaciones secuencialmente\n# Primero escalar, luego rotar\n\n# Paso 1: Escalar al 80%\nimagen_combo = cv2.resize(imagen_ejemplo, None, fx=0.8, fy=0.8)\n\n# Obtener nuevo tamaño después de escalar\nh, w = imagen_combo.shape[:2]\n\n# Paso 2: Rotar 30 grados alrededor del nuevo centro\nM = cv2.getRotationMatrix2D((w//2, h//2), 30, 1.0)\nimagen_combo = cv2.warpAffine(imagen_combo, M, (w, h))\n\n# FILA 2, COLUMNA 4: Transformación combinada\naxes[1, 3].imshow(cv2.cvtColor(imagen_combo, cv2.COLOR_BGR2RGB))\naxes[1, 3].set_title('Combinado: Escala + Rotación')\naxes[1, 3].axis('off')\n\n\n# ============================================\n# AJUSTAR Y MOSTRAR\n# ============================================\nplt.tight_layout()\nplt.show()\n\n\n# GUÍA PARA LA CLASE:\n# =========================================\n# TRANSFORMACIONES AFINES (warpAffine):\n# - Traslación: mover imagen\n# - Rotación: girar alrededor de un punto\n# - Escalado: cambiar tamaño\n# - Volteo: reflejo espejo\n# Matriz 2x3, preserva líneas paralelas\n#\n# TRANSFORMACIÓN PERSPECTIVA (warpPerspective):\n# - Cambia perspectiva/punto de vista\n# - Matriz 3x3, NO preserva líneas paralelas\n# - Útil para: corrección de distorsión, vista aérea\n#\n# USOS PRÁCTICOS:\n# - Data augmentation en ML (entrenar con imágenes transformadas)\n# - Corrección de orientación de documentos escaneados\n# - Estabilización de video\n# - Realidad aumentada"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Proyecto Final: Sistema Completo de Análisis de Imagen\n",
    "\n",
    "Vamos a crear una función que combine múltiples técnicas de Computer Vision para analizar una imagen de forma completa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================\n# FUNCIÓN DE ANÁLISIS COMPLETO DE IMAGEN\n# ============================================\n# Esta función integra TODAS las técnicas aprendidas en el notebook\n# Realiza un análisis exhaustivo de cualquier imagen\n\ndef analizar_imagen_completo(imagen):\n    \"\"\"\n    Análisis completo de una imagen usando múltiples técnicas de Computer Vision\n    \n    Args:\n        imagen: Imagen en formato BGR de OpenCV (array de NumPy)\n    \n    Returns:\n        resultados: Diccionario con todas las métricas calculadas\n        gris: Imagen en escala de grises\n        bordes: Imagen con bordes detectados (Canny)\n        umbral: Imagen umbralizada (binaria)\n        contornos: Lista de contornos detectados\n    \"\"\"\n    \n    # Diccionario para almacenar todos los resultados\n    resultados = {}\n    \n    \n    # ============================================\n    # ETAPA 1: INFORMACIÓN BÁSICA\n    # ============================================\n    # Obtener dimensiones y propiedades fundamentales de la imagen\n    \n    # .shape devuelve (alto, ancho, canales)\n    resultados['dimensiones'] = imagen.shape\n    resultados['alto'] = imagen.shape[0]   # Número de filas (píxeles verticales)\n    resultados['ancho'] = imagen.shape[1]  # Número de columnas (píxeles horizontales)\n    \n    # Detectar si es imagen a color o escala de grises\n    # len(imagen.shape) == 3 significa que tiene 3 dimensiones (incluye canales)\n    resultados['canales'] = imagen.shape[2] if len(imagen.shape) == 3 else 1\n    \n    \n    # ============================================\n    # ETAPA 2: CONVERSIÓN A ESCALA DE GRISES\n    # ============================================\n    # Necesaria para muchos análisis posteriores\n    \n    # Verificar si la imagen es a color o ya está en grises\n    if len(imagen.shape) == 3:\n        # Imagen a color → convertir a grises\n        gris = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)\n    else:\n        # Ya está en grises → solo copiar\n        gris = imagen.copy()\n    \n    \n    # ============================================\n    # ETAPA 3: ESTADÍSTICAS DE INTENSIDAD\n    # ============================================\n    # Analizar la distribución de valores de píxeles\n    \n    # np.mean(): promedio de todos los valores de píxeles\n    # Indica el brillo general de la imagen (0-255)\n    resultados['brillo_promedio'] = np.mean(gris)\n    \n    # np.std(): desviación estándar de los valores\n    # Indica el contraste: valores altos = mucha variación (buen contraste)\n    resultados['brillo_std'] = np.std(gris)\n    \n    # np.min(): valor mínimo (píxel más oscuro)\n    resultados['brillo_min'] = np.min(gris)\n    \n    # np.max(): valor máximo (píxel más brillante)\n    resultados['brillo_max'] = np.max(gris)\n    \n    \n    # ============================================\n    # ETAPA 4: DETECCIÓN DE BORDES (CANNY)\n    # ============================================\n    # Identificar dónde hay cambios bruscos de intensidad\n    \n    # Aplicar el detector de bordes Canny\n    # Umbrales 50-150: estándar para la mayoría de imágenes\n    bordes = cv2.Canny(gris, 50, 150)\n    \n    # Calcular qué porcentaje de la imagen son bordes\n    # np.sum(bordes > 0): contar píxeles blancos (bordes)\n    # bordes.size: total de píxeles en la imagen\n    # * 100: convertir a porcentaje\n    resultados['porcentaje_bordes'] = (np.sum(bordes > 0) / bordes.size) * 100\n    \n    \n    # ============================================\n    # ETAPA 5: UMBRALIZACIÓN (OTSU)\n    # ============================================\n    # Convertir a imagen binaria (blanco y negro)\n    \n    # cv2.threshold() con método de Otsu (calcula umbral automáticamente)\n    # _ : ignoramos el valor del umbral calculado\n    # umbral: imagen binaria resultante\n    _, umbral = cv2.threshold(gris, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n    \n    # Calcular porcentaje de píxeles blancos\n    # Útil para entender la distribución claro/oscuro\n    resultados['porcentaje_blancos'] = (np.sum(umbral == 255) / umbral.size) * 100\n    \n    \n    # ============================================\n    # ETAPA 6: DETECCIÓN DE CONTORNOS\n    # ============================================\n    # Encontrar y contar objetos en la imagen\n    \n    # Detectar contornos externos en la imagen umbralizada\n    # RETR_EXTERNAL: solo contornos externos (sin jerarquías)\n    # CHAIN_APPROX_SIMPLE: comprimir contornos eliminando puntos redundantes\n    contornos, _ = cv2.findContours(umbral, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    \n    # Contar número de objetos detectados\n    resultados['num_objetos'] = len(contornos)\n    \n    \n    # ============================================\n    # ETAPA 7: ANÁLISIS DE CONTORNOS SIGNIFICATIVOS\n    # ============================================\n    # Calcular estadísticas sobre los objetos detectados\n    \n    # Calcular área de cada contorno, filtrando los muy pequeños (ruido)\n    # cv2.contourArea(c): área en píxeles² del contorno c\n    # if cv2.contourArea(c) > 100: solo contornos con área > 100 píxeles\n    areas = [cv2.contourArea(c) for c in contornos if cv2.contourArea(c) > 100]\n    \n    # Verificar que hay al menos un objeto significativo\n    if areas:\n        # np.mean(areas): promedio de las áreas\n        # Indica el tamaño típico de los objetos\n        resultados['area_promedio_objetos'] = np.mean(areas)\n        \n        # np.max(areas): área del objeto más grande\n        resultados['area_mayor_objeto'] = np.max(areas)\n    else:\n        # No hay objetos significativos\n        resultados['area_promedio_objetos'] = 0\n        resultados['area_mayor_objeto'] = 0\n    \n    \n    # ============================================\n    # ETAPA 8: DETECCIÓN DE ESQUINAS\n    # ============================================\n    # Encontrar puntos de interés (características)\n    \n    # cv2.goodFeaturesToTrack(): detecta esquinas usando Shi-Tomasi\n    # maxCorners=100: detectar hasta 100 esquinas\n    # qualityLevel=0.01: calidad mínima 1% de la mejor esquina\n    # minDistance=10: separación mínima de 10 píxeles entre esquinas\n    esquinas = cv2.goodFeaturesToTrack(gris, maxCorners=100, \n                                       qualityLevel=0.01, minDistance=10)\n    \n    # Contar esquinas detectadas\n    # if esquinas is not None: verificar que se encontraron esquinas\n    # len(esquinas): número de esquinas\n    resultados['num_esquinas'] = len(esquinas) if esquinas is not None else 0\n    \n    \n    # ============================================\n    # ETAPA 9: ANÁLISIS DE COLOR (SI ES IMAGEN A COLOR)\n    # ============================================\n    # Analizar la distribución de colores en espacio HSV\n    \n    # Solo aplicar si la imagen tiene 3 canales (color)\n    if len(imagen.shape) == 3:\n        # Convertir a HSV para análisis de color\n        hsv = cv2.cvtColor(imagen, cv2.COLOR_BGR2HSV)\n        \n        # Analizar el canal Hue (tono/color)\n        # np.median(): valor mediano (más robusto que el promedio)\n        # hsv[:, :, 0]: canal Hue (índice 0)\n        # Indica el color dominante en la imagen\n        resultados['tono_dominante'] = np.median(hsv[:, :, 0])\n        \n        # Analizar el canal Saturation (intensidad del color)\n        # np.mean(): promedio de saturación\n        # Valores altos = colores vívidos, valores bajos = colores apagados\n        resultados['saturacion_promedio'] = np.mean(hsv[:, :, 1])\n        \n        # Analizar el canal Value (brillo)\n        # np.mean(): promedio de brillo\n        # Similar a brillo_promedio pero en espacio HSV\n        resultados['valor_promedio'] = np.mean(hsv[:, :, 2])\n    \n    \n    # ============================================\n    # RETORNAR TODOS LOS RESULTADOS\n    # ============================================\n    # Devolver diccionario con métricas e imágenes procesadas\n    return resultados, gris, bordes, umbral, contornos\n\n\n# ============================================\n# APLICAR ANÁLISIS A NUESTRA IMAGEN\n# ============================================\n# Llamar a la función con la imagen de ejemplo\nresultados, gris, bordes, umbral, contornos = analizar_imagen_completo(imagen_ejemplo)\n\n\n# ============================================\n# VISUALIZAR CONTORNOS EN LA IMAGEN ORIGINAL\n# ============================================\n# Dibujar todos los contornos detectados sobre la imagen original\nimagen_analizada = imagen_ejemplo.copy()\n\n# Dibujar contornos en verde, grosor 2 píxeles\ncv2.drawContours(imagen_analizada, contornos, -1, (0, 255, 0), 2)\n\n\n# ============================================\n# CREAR VISUALIZACIÓN COMPLETA\n# ============================================\n# Mostrar imagen original y los 3 pasos principales del análisis\nfig, axes = plt.subplots(2, 3, figsize=(16, 10))\n\n\n# FILA 1, COLUMNA 1: Imagen original\naxes[0, 0].imshow(cv2.cvtColor(imagen_ejemplo, cv2.COLOR_BGR2RGB))\naxes[0, 0].set_title('Imagen Original')\naxes[0, 0].axis('off')\n\n\n# FILA 1, COLUMNA 2: Escala de grises\naxes[0, 1].imshow(gris, cmap='gray')\naxes[0, 1].set_title('Escala de Grises')\naxes[0, 1].axis('off')\n\n\n# FILA 1, COLUMNA 3: Bordes detectados\n# Mostrar porcentaje de bordes en el título\naxes[0, 2].imshow(bordes, cmap='gray')\naxes[0, 2].set_title(f'Bordes ({resultados[\"porcentaje_bordes\"]:.2f}% de la imagen)')\naxes[0, 2].axis('off')\n\n\n# FILA 2, COLUMNA 1: Umbralización\naxes[1, 0].imshow(umbral, cmap='gray')\naxes[1, 0].set_title('Umbralización (Otsu)')\naxes[1, 0].axis('off')\n\n\n# FILA 2, COLUMNA 2: Contornos detectados\naxes[1, 1].imshow(cv2.cvtColor(imagen_analizada, cv2.COLOR_BGR2RGB))\naxes[1, 1].set_title(f'Contornos Detectados ({resultados[\"num_objetos\"]})')\naxes[1, 1].axis('off')\n\n\n# ============================================\n# FILA 2, COLUMNA 3: PANEL DE ESTADÍSTICAS\n# ============================================\n# Crear un panel de texto con todas las métricas calculadas\n\n# Formatear el texto con todas las estadísticas\nstats_text = f\"\"\"ESTADÍSTICAS DE LA IMAGEN\n\nDimensiones: {resultados['ancho']}x{resultados['alto']} px\nCanales: {resultados['canales']}\n\nBRILLO:\n  Promedio: {resultados['brillo_promedio']:.1f}\n  Desv. Est.: {resultados['brillo_std']:.1f}\n  Rango: [{resultados['brillo_min']}, {resultados['brillo_max']}]\n\nOBJETOS:\n  Cantidad: {resultados['num_objetos']}\n  Área promedio: {resultados['area_promedio_objetos']:.0f} px²\n  Área mayor: {resultados['area_mayor_objeto']:.0f} px²\n\nCARACTERÍSTICAS:\n  Esquinas detectadas: {resultados['num_esquinas']}\n  % Bordes: {resultados['porcentaje_bordes']:.2f}%\n\"\"\"\n\n# Mostrar el texto en el subplot\n# axes[1, 2].text(): dibuja texto en el subplot\n# 0.1, 0.5: posición del texto (x, y) en coordenadas del subplot\n# verticalalignment='center': alinear verticalmente al centro\n# fontsize=10: tamaño de fuente\n# family='monospace': fuente monoespaciada (alinea columnas)\naxes[1, 2].text(0.1, 0.5, stats_text, fontsize=10, family='monospace',\n               verticalalignment='center', transform=axes[1, 2].transAxes)\naxes[1, 2].axis('off')\n\n\n# ============================================\n# AJUSTAR Y MOSTRAR\n# ============================================\nplt.tight_layout()\nplt.show()\n\n\n# ============================================\n# IMPRIMIR RESULTADOS EN CONSOLA\n# ============================================\nprint(\"\\n✓ Análisis completo finalizado\")\nprint(\"\\nResultados completos:\")\n\n# Iterar sobre cada métrica en el diccionario de resultados\nfor clave, valor in resultados.items():\n    # Formatear números flotantes con 2 decimales\n    if isinstance(valor, float):\n        print(f\"  {clave}: {valor:.2f}\")\n    else:\n        # Imprimir otros valores tal cual\n        print(f\"  {clave}: {valor}\")\n\n\n# RESUMEN PARA LA CLASE:\n# =========================================\n# Esta función demuestra cómo INTEGRAR múltiples técnicas:\n# 1. Preprocesamiento (conversión a grises)\n# 2. Análisis estadístico (mean, std, min, max)\n# 3. Detección de características (bordes, esquinas)\n# 4. Segmentación (umbralización)\n# 5. Detección de objetos (contornos)\n# 6. Análisis de color (HSV)\n#\n# APLICACIONES PRÁCTICAS:\n# - Control de calidad: detectar defectos en productos\n# - Visión robótica: identificar y contar objetos\n# - Análisis médico: detectar anomalías en imágenes\n# - Sistemas de seguridad: detección de movimiento\n# - Procesamiento de documentos: análisis de páginas escaneadas"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones y Próximos Pasos\n",
    "\n",
    "### Lo que hemos aprendido:\n",
    "\n",
    "1. ✅ Fundamentos de imágenes digitales (matrices de píxeles)\n",
    "2. ✅ Carga y manipulación básica de imágenes\n",
    "3. ✅ Espacios de color (BGR, RGB, HSV, escala de grises)\n",
    "4. ✅ Operaciones básicas (redimensionar, rotar, trasladar)\n",
    "5. ✅ Filtros de suavizado (blur, Gaussian, median, bilateral)\n",
    "6. ✅ Detección de bordes (Sobel, Canny, Laplacian)\n",
    "7. ✅ Umbralización (simple, Otsu, adaptativa)\n",
    "8. ✅ Operaciones morfológicas (erosión, dilatación, apertura, cierre)\n",
    "9. ✅ Detección de contornos y análisis de formas\n",
    "10. ✅ Detección de esquinas (Harris, Shi-Tomasi)\n",
    "11. ✅ Segmentación por color\n",
    "12. ✅ Transformaciones geométricas\n",
    "\n",
    "### Próximos pasos para profundizar:\n",
    "\n",
    "#### Nivel Intermedio:\n",
    "- 📊 Template Matching (coincidencia de patrones)\n",
    "- 🎯 Detección de círculos y líneas (Hough Transform)\n",
    "- 🔍 Descriptores de características (SIFT, SURF, ORB)\n",
    "- 📐 Calibración de cámara\n",
    "- 🎥 Procesamiento de video\n",
    "\n",
    "#### Nivel Avanzado:\n",
    "- 🤖 Deep Learning para Computer Vision\n",
    "- 🧠 Redes Neuronales Convolucionales (CNN)\n",
    "- 👁️ Detección de objetos (YOLO, R-CNN)\n",
    "- 😊 Reconocimiento facial\n",
    "- 🎨 Segmentación semántica\n",
    "- 🚗 Visión estéreo y reconstrucción 3D\n",
    "\n",
    "### Recursos recomendados:\n",
    "\n",
    "- 📚 [Documentación oficial de OpenCV](https://docs.opencv.org/)\n",
    "- 🎓 [OpenCV Python Tutorials](https://docs.opencv.org/4.x/d6/d00/tutorial_py_root.html)\n",
    "- 💻 [PyImageSearch](https://www.pyimagesearch.com/)\n",
    "- 📖 \"Learning OpenCV\" por Gary Bradski y Adrian Kaehler\n",
    "\n",
    "---\n",
    "\n",
    "**¡Felicidades por completar este tutorial de Computer Vision!** 🎉\n",
    "\n",
    "Ahora tienes las herramientas fundamentales para comenzar a crear tus propios proyectos de visión por computadora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios Prácticos Propuestos\n",
    "\n",
    "### Ejercicio 1: Contador de Objetos\n",
    "Crea una función que cuente el número de objetos circulares en una imagen.\n",
    "\n",
    "### Ejercicio 2: Filtro de Instagram\n",
    "Crea tu propio filtro de estilo Instagram combinando ajustes de color, contraste y saturación.\n",
    "\n",
    "### Ejercicio 3: Detección de Movimiento\n",
    "Usando dos imágenes consecutivas, detecta las áreas donde hay movimiento.\n",
    "\n",
    "### Ejercicio 4: Reconocimiento de Formas\n",
    "Clasifica contornos en categorías: círculo, rectángulo, triángulo, u otro.\n",
    "\n",
    "### Ejercicio 5: Eliminación de Fondo\n",
    "Crea un programa que elimine el fondo de una imagen basándose en un color específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Espacio para tus propios experimentos\n",
    "# ¡Prueba diferentes parámetros y técnicas!\n",
    "\n",
    "# Tu código aquí...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}