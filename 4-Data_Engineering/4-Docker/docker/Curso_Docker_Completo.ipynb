{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curso de Docker desde Cero - Completo\n",
    "\n",
    "Este notebook contiene todos los capítulos del curso de Docker organizados en orden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 101. Introducción\n",
    "\n",
    "Bienvenido al curso de Docker en el que aprenderás a utilizar esta tecnología en todos sus aspectos, desde la instalación hasta la implementación en producción, desde el punto de vista de un desarrollador, administrador de sistemas o DevOps.\n",
    "\n",
    "Vídeo completo de la presentación del curso y la introducción a Docker:\n",
    "[https://youtu.be/AquOM-ISsnA](https://youtu.be/AquOM-ISsnA)\n",
    "\n",
    "Todo este curso se grabará para youtube y, en paralelo este repositorio de GitHub (aunque seguramente lo estés viendo renderizado en mi web) me servirá de guión para los vídeos aunque también te permitirá seguir el curso de forma paralela. Los vídeos me permitirán explayarme más en los conceptos y en la práctica, mientras que el repositorio te permitirá tener una guía más rápida y concisa, con los comandos y ejemplos para que lo puedas copiar y acceder más rápidamente a la información.\n",
    "\n",
    "Además, **el curso escrito me será más fácil de mantener actualizado y corregir errores, por lo que es una buena forma de complementar los vídeos con todo el feedback que me vayáis dando.**\n",
    "\n",
    "## Historia de los contenedores\n",
    "El concepto de contenedores no nace con Docker, existían tecnologías como LXC (Linux Containers) que permiten la virtualización a nivel de sistema operativo. Sin embargo, Docker los ha popularizado al proporcionar una forma sencilla y eficiente de crear, distribuir y ejecutar software.\n",
    "\n",
    "Docker fue lanzado en 2013 por la empresa Docker, Inc. y rápidamente se ha convertido en una de las tecnologías más populares en el mundo de la informática. Pero, ¿qué es un contenedor?.\n",
    "\n",
    "## ¿Qué es un contenedor?\n",
    "Un contenedor es una unidad de software que encapsula una aplicación y todas sus dependencias en un entorno aislado. Proporciona una forma de empaquetar, distribuir y ejecutar aplicaciones de manera consistente en diferentes entornos, ya sea en un entorno de desarrollo, pruebas o producción.\n",
    "\n",
    "Los contenedores utilizan tecnologías de virtualización a nivel de sistema operativo para crear entornos ligeros y portátiles. Cada contenedor se ejecuta de forma independiente, con su propio sistema de archivos, bibliotecas y configuraciones, pero comparte el mismo kernel del sistema operativo subyacente.\n",
    "\n",
    "Los contenedores ofrecen varias ventajas, como la portabilidad, la escalabilidad y la eficiencia en el uso de recursos. Al estar aislados, los contenedores permiten que las aplicaciones se ejecuten de manera consistente en diferentes entornos, lo que facilita el desarrollo y la implementación. Además, los contenedores se pueden escalar fácilmente para manejar cargas de trabajo variables y aprovechan al máximo los recursos del sistema.\n",
    "\n",
    "## Contenedores vs. máquinas virtuales\n",
    "Los contenedores y las máquinas virtuales (VMs) son tecnologías de virtualización que permiten ejecutar múltiples aplicaciones en un mismo servidor físico. Sin embargo, existen diferencias significativas entre ambas tecnologías en términos de arquitectura, rendimiento y uso de recursos.\n",
    "\n",
    "Las máquinas virtuales emulan un hardware completo, incluido un sistema operativo, una capa de virtualización y una aplicación. Cada VM se ejecuta en su propio hipervisor, que administra los recursos físicos del servidor y proporciona aislamiento entre las VMs. Esto permite que las VMs sean independientes y portátiles, pero también consume más recursos y es menos eficiente que los contenedores.\n",
    "\n",
    "Los contenedores, por otro lado, comparten el mismo kernel del sistema operativo subyacente y se ejecutan en un entorno aislado, pero comparten los recursos del sistema, como la CPU, la memoria y el almacenamiento. Esto hace que los contenedores sean más ligeros y rápidos que las VMs, ya que no tienen la sobrecarga de un sistema operativo completo y una capa de virtualización adicional.\n",
    "\n",
    "## Estandarización de los contenedores\n",
    "Los contenedores se han convertido en una parte fundamental de la infraestructura de TI moderna, ya que ofrecen una forma eficiente y flexible de implementar aplicaciones en entornos de desarrollo, pruebas y producción. Para garantizar la interoperabilidad y la portabilidad de los contenedores, se han desarrollado estándares y especificaciones que definen cómo deben funcionar los contenedores y cómo deben interactuar entre sí.\n",
    "\n",
    "Uno de los estándares más importantes en el mundo de los contenedores es OCI (Open Container Initiative), que define una especificación común para los formatos de imagen y los entornos de ejecución de contenedores. OCI fue creado en 2015 por un grupo de empresas líderes en tecnología, incluidas Docker, CoreOS, Google, Red Hat y VMware, con el objetivo de promover la interoperabilidad y la innovación en el ecosistema de contenedores.\n",
    "\n",
    "Gracias a OCI, los contenedores son más portátiles y compatibles entre diferentes plataformas y proveedores de servicios en la nube. Esto ha permitido que los desarrolladores y las organizaciones adopten los contenedores con confianza, sabiendo que sus aplicaciones se ejecutarán de manera consistente en cualquier entorno.\n",
    "\n",
    "## Casos de uso de los contenedores\n",
    "Los contenedores se pueden utilizar en infinidad de casos. Algunos de los casos de uso más comunes de los contenedores incluyen:\n",
    "* Desarrollo y pruebas de aplicaciones\n",
    "* Implementación de microservicios\n",
    "* Implementación de aplicaciones en la nube\n",
    "* CI/CD (Continuous Integration/Continuous Deployment)\n",
    "* Aislamiento de aplicaciones\n",
    "* Escalabilidad y alta disponibilidad\n",
    "* Desarrollo multiplataforma\n",
    "\n",
    "Aunque sería más fácil resumirlo en, vale para cualquier tipo de servicio, excepto para app móviles, dado las guías de desarrollo tan concretas que requieren estos SO u otras interfaces gráficas nativas de SOs como Windows,Mac.. etc. Por lo demás, se puede utilizar en cualquier tipo de aplicación web, APIs, backends, bases de datos, procesos... etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 102. Instalación\n",
    "\n",
    "La instalación de Docker Desktop es muy sencilla, simplemente debemos descargar el instalador desde la página oficial de Docker y seguir los pasos que nos indica el asistente de instalación. Siguiente, siguiente y listo. Excepto en la versión de Docker Engine/Desktop para Linux. \n",
    "\n",
    "Vídeo completo, utiliza los capítulos de youtube para saltar a la sección que te interese:\n",
    "[https://youtu.be/obALwLV-49U](https://youtu.be/obALwLV-49U)\n",
    "\n",
    "Docker Engine... Docker Desktop... ¿En qué se diferencian?\n",
    "\n",
    "Docker Desktop es una aplicación de escritorio que incluye Docker Engine y, además, una serie de herramientas adicionales, como interfaz gráfica,la opción de desplegar kubernetes, plugins, capacidades empresariales o de equipo (como gestión de imágenes permitidas, trabajo en equipo, más espacios privados en dockerhub...etc). A día de hoy, docker desktop es gratuito para uso personal y empresas de menos de 250 empleados y 10 millones de dólares de facturación.\n",
    "\n",
    "Sin embargo, Docker Engine es parte del motor de Docker, es decir, el software que permite crear y ejecutar contenedores. Docker Engine es totalmente gratuito, sin restricciones, solo se puede instalar en sistemas Linux y es más que suficiente para la mayoría de los casos, aunque solo se puede utilizar en modo CLI, es decir, sin interfaz gráfica.\n",
    "\n",
    "Lo más habitual, es utilizar docker desktop en el entornos de desarrollo y docker engine en los servidores de desarrollo o producción.\n",
    "\n",
    "## Instalación de Docker Desktop\n",
    "Para la instalación, navegamos a la página oficial de Docker y descargamos el instalador para nuestro sistema operativo [Docker Desktop](https://www.docker.com/get-started/).\n",
    "\n",
    "En Linux, la instalación requiere de algunos comandos, previa descarga del paquete de instalación. En el vídeo se detalla la instalación en sistemas Debian/Ubuntu. Aunque también hay soporte oficial para Fedora y Red Hat.\n",
    "\n",
    "**¡Aviso importante para Linux!**  Como vimos en la introducción, los contenedores utilizan características del kernel de Linux, por lo que Docker Desktop utiliza una máquina virtual para ejecutar los contenedores en sistemas Windows y Mac. En Linux, por homogeneidad y soporte de los plugins, si utilizamos Docker Desktop, también se ejecutará en una máquina virtual. Si no necesitas las herramientas adicionales de Docker Desktop, puedes instalar Docker Engine directamente para tener un rendimiento nativo, sin utilizar la máquina virtual.\n",
    "\n",
    "## Instalación de Docker Engine\n",
    "La opción que más me gusta, es utilizar el script de instalación oficial de Docker, que se encarga de instalar todas las dependencias necesarias y configurar el sistema para que Docker funcione correctamente.\n",
    "    \n",
    "```bash\n",
    "curl -fsSL https://get.docker.com -o get-docker.sh && sh get-docker.sh\n",
    "```\n",
    "\n",
    "**Este comando, descarga el script de instalación y lo ejecuta. Este comando, deberás lanzado con permisos root o añadir sudo delante del comando sh que ejecuta el script.**\n",
    "\n",
    "Si os diera algún problema este proceso,tenemos la documentación oficial en [Docker Engine](https://docs.docker.com/engine/install/) de la la web de docker y podrías seguir paso a paso el proceso de instalación de tu sistema operativo.\n",
    "\n",
    "En la sección de \"supported platforms\" podemos elegir el sistema operativo que queremos. En el vídeo se detalla el proceso de los más comunes, si tienes un sistema operativo diferente, puedes seguir la documentación oficial. Creo que esta muy bien explicada y no aportaría nada más.\n",
    "\n",
    "Recuerda que en la sección de issues de este repositorio puedes preguntar cualquier duda que tengas sobre la instalación de Docker.\n",
    "\n",
    "## Comprobación de la instalación\n",
    "Para comprobar que la instalación ha sido correcta, podemos ejecutar el siguiente comando:\n",
    "\n",
    "```bash\n",
    "docker --version\n",
    "```\n",
    "\n",
    "o lanzar el contenedor de prueba de Docker:\n",
    "\n",
    "```bash\n",
    "docker run hello-world\n",
    "```\n",
    "\n",
    "Si todo ha ido bien, deberías ver un mensaje de bienvenida de Docker.\n",
    "\n",
    "## Configuración de Docker Desktop\n",
    "Una vez instalado Docker Desktop, podemos configurar algunas opciones, como la cantidad de CPUs y memoria que queremos asignar a la máquina virtual de Docker, la ubicación de los datos de Docker, el puerto de escucha, etc.\n",
    "\n",
    "Esta sección, la dejo para que la veáis en el vídeo, ya que es muy visual y se hace todo con la interfaz gráfica. Recuerda que puedes utilizar los capítulos de youtube para saltar a la parte del vídeo que te interese."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 103. Conceptos básicos\n",
    "\n",
    "Ahora que ya nos hemos introducido en los contenedores, tenemos que profundizar más en ellos y debemos entender mejor algunos conceptos básicos, como el ciclo de vida de un contenedor, en qué consiste una imagen, cómo se crean y se gestionan...\n",
    "\n",
    "Vídeo del episodio:\n",
    "[https://youtu.be/cWm3_PZR7Os](https://youtu.be/cWm3_PZR7Os)\n",
    "\n",
    "Estos son los conceptos básicos que debemos entender:\n",
    "* **Contenedor**: Es una instancia de una imagen. Es un proceso que se ejecuta en un entorno aislado.\n",
    "* **Imagen**: Es un archivo binario que contiene todos los elementos necesarios para ejecutar un contenedor. Es como una plantilla que se utiliza para crear contenedores.\n",
    "* **Dockerfile**: Es un archivo de texto que contiene las instrucciones necesarias para crear una imagen.\n",
    "* **Docker Hub**: Es un repositorio de imágenes de contenedor. Es como un GitHub pero de imágenes de contenedor.\n",
    "\n",
    "Cada uno de estos conceptos, los veremos en detalle de forma práctica en los siguientes capítulos. Pero antes, vamos a profundizar un poco más en cada uno de ellos.\n",
    "\n",
    "## Contenedor\n",
    "Un contenedor es una instancia de una imagen. Como vimos en la sección de fundamentos e introducción, un contenedor es un proceso que se ejecuta en un entorno aislado, ojo, **un proceso**. Esto es importante, porque un contenedor no es una máquina virtual, no es un sistema operativo, es un proceso que contiene una aplicación y sus dependencias, tanto de librerías del lenguaje de programación que estés usando, como de sistema operativo. Por este último punto, es por lo que se suelen confundir con máquina virtuales. \n",
    "\n",
    "Los contenedores, se ejecutan con un propósito o un comando principal, cuando este comando finaliza, el contenedor también finaliza. Esto es importante, porque un contenedor puede ejecutar una tarea y finalizar, o puede ejecutar un servicio que se mantenga siempre en ejecución.\n",
    "\n",
    "Este comando principal, se define en el Dockerfile antes de construir la imagen, en la instrucción `CMD` o `ENTRYPOINT`. Veremos las diferencias más adelante.\n",
    "\n",
    "Podemos ejecutar un contenedor, pararlo, reiniciarlo, eliminarlo, etc. Aunque un contenedor se elimine, no se elimina la imagen, recordemos que este solo es una instancia de la imagen. Por lo que podemos ejecutar un contenedor con la misma imagen las veces que queramos.\n",
    "\n",
    "Por último, una imagen no solo es una definición de una aplicación, sino que también puede contener datos o incluso el estado de una aplicación. Es decir, podríamos ejecutar un contenedor, almacenar datos, cargar archivos en memoria RAM y salvar el estado del contenedor. Como si fuera una snapshot de una máquina virtual. Este proceso de guardar el estado o \"commit\" nos permite generar una imagen nueva con el estado actual del contenedor.\n",
    "\n",
    "## Imagen\n",
    "Una imagen es un archivo que contiene todos los elementos necesarios para ejecutar un contenedor. Es como una plantilla que se utiliza para crear contenedores. Una imagen contiene los siguientes elementos:\n",
    "* **Aplicación**: La aplicación que queremos ejecutar. Puede ser programada por nosotros o una aplicación de terceros ya empaquetada.\n",
    "* **Librerías de lenguaje**: Las librerías de terceros del lenguaje de programación que utilicemos. Si fuera python, por ejemplo, las librerías de numpy, pandas, etc.\n",
    "* **Librerías de Sistema Operativo**: Aunque no es un sistema operativo completo, si que contiene las librerías y dependencias necesarias para ejecutar una aplicación. Por ejemplo, librerías muy comunes como curl, wget, cat... funcionalidades en las que se basan muchas aplicaciones.\n",
    "* **Configuración**: La configuración de arranque de la aplicación. Que usuario ejecuta la aplicación, comandos de arranque, puertos que expone, etc.\n",
    "\n",
    "Supongamos que tenemos una aplicación escrita en Java, necesitaremos una imagen que tenga instalado como dependencias el JDK o JRE necesarios para ejecutar Java, nuestra aplicación compilada junto a las librerías de terceros (por ejemplo, el framework springboot) y, por último, la definición de como se debe ejecutar la aplicación (por ejemplo, se tiene que ejecutar con el comando `java application.jar`).\n",
    "\n",
    "Normalmente, las imágenes se crean a partir de un Dockerfile, que un archivo que nos permite definir el proceso de construcción de una imagen.\n",
    "\n",
    "Como ya hemos mencionado, se podría guardar el estado de un contenedor en ejecución en una imagen, pero no suele ser lo más común. La buena práctica es que las imágenes sean estáticas y no dependan del estado de un contenedor. Permitiendo así, que desde el primer arranque se comporte de la misma forma en cualquier entorno.\n",
    "\n",
    "Veamos ahora, los dockerfile.\n",
    "\n",
    "## Dockerfile\n",
    "Estos archivos, son un conjunto de instrucciones secuenciales que le especifican a Docker cómo construir una imagen. Permite usar múltiples instrucciones para instalar dependencias, copiar archivos, definir variables de entorno, etc.\n",
    "\n",
    "Suelen comenzar por una instrucción `FROM`, que define la imagen base que se va a utilizar. A partir de ahí, se pueden definir múltiples instrucciones para modificar la imagen base y adaptarla a nuestras necesidades.\n",
    "\n",
    "Por ejemplo, si queremos crear una imagen con un servidor web Apache, podríamos crear un Dockerfile con el siguiente dockerfile:\n",
    "```Dockerfile\n",
    "FROM ubuntu:22.04\n",
    "RUN apt-get update && apt-get install -y apache2\n",
    "COPY index.html /var/www/html/\n",
    "CMD [\"apache2ctl\", \"-D\", \"FOREGROUND\"]\n",
    "```\n",
    "En ejemplo anterior, partimos de una imagen base de Ubuntu 22.04, actualizamos los paquetes e instalamos Apache2. Copiamos un archivo `index.html` de nuestra web estática en la carpeta de Apache y ejecutamos el comando `apache2ctl -D FOREGROUND` para arrancar el servidor.\n",
    "\n",
    "Básicamente, es como si estuviéramos un Linux en el que lanzamos una serie de comandos y configuraciones para posteriormente, pero todos los pasos que hacemos los definimos como código para que el proceso sea fácilmente replicable.\n",
    "\n",
    "## Docker Hub\n",
    "Es un repositorio de imágenes de contenedor. En Docker Hub, podemos encontrar imágenes de contenedores ya creadas por la comunidad, que podemos utilizar para nuestros proyectos. También podemos subir nuestras propias imágenes y compartirlas con la comunidad.\n",
    "\n",
    "Este repositorio es propiedad de Docker, pero no es el único. Dentro del estándar OCI, existen otros repositorios como GitHub Container Registry, GitLab Container Registry, Amazon Elastic Container Registry, Google Container Registry, etc. Es decir, podemos almacenar nuestras imágenes en cualquier repositorio que soporte el estándar de Docker, aunque Docker Hub es de los más populares. \n",
    "\n",
    "Docker nos permite subir y descargar imágenes de estos repositorios de forma sencilla, con el comando `docker push` y `docker pull`, versionar las imágenes, etiquetarlas, etc. Muy similar a como lo haríamos con un repositorio de código fuente de tipo git pero con imágenes de contenedor.\n",
    "\n",
    "## Resumen\n",
    "Para resumir, un contenedor es una instancia de una imagen, una imagen es un archivo binario que contiene todos los elementos necesarios para ejecutar un contenedor, un Dockerfile es un archivo de texto que contiene las instrucciones necesarias para crear una imagen y Docker Hub es un repositorio de imágenes de contenedor.\n",
    "\n",
    "En los siguientes capítulos, profundizaremos de forma práctica en estos conceptos. Veremos cómo crear imágenes, cómo crear contenedores, cómo gestionarlos, cómo compartirlos, cómo trabajar con volúmenes y redes, etc. Pero es importante tener claros estos conceptos para entender el propósito de los contenedores.\n",
    "\n",
    "Ya vemos que la capacidad de empaquetar en imágenes, definidas en Dockerfiles, nos permite o bien compartirte una imagen o el proceso de construcción de una imagen. Esto es muy útil para compartir aplicaciones, para trabajar en equipo, para desplegar aplicaciones en diferentes entornos, etc.\n",
    "\n",
    "Además, una vez generada una imagen, nos olvidamos de cualquier conflicto que pueda surgir con el sistema operativo o con las dependencias de la aplicación. Tradicionalmente, una máquina virtual podía ejecutar múltiples aplicaciones que requerían diferentes versiones de librerías, pero con Docker, cada aplicación se ejecuta en un contenedor aislado con sus propias dependencias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 104. Ejecutar un contenedor\n",
    "\n",
    "En esta sección, vamos a ver cómo arrancar nuestros primeros contenedores, las opciones más comunes para hacerlo. Además de cómo ver los detalles de un contenedor en ejecución, ejecutar un proceso en segundo plano, mapear puertos y entender como un contenedor se comporta como un proceso.\n",
    "\n",
    "Dentro vídeo:\n",
    "[https://youtu.be/ImLoqbY9DNA](https://youtu.be/ImLoqbY9DNA)\n",
    "\n",
    "## Arrancar un contenedor\n",
    "Para arrancar un contenedor, utilizamos el comando `docker run`. Este comando, nos permite arrancar un contenedor a partir de una imagen. Su sintaxis básica es la siguiente:\n",
    "```bash\n",
    "docker run <imagen>\n",
    "```\n",
    "\n",
    "Por ejemplo, si queremos arrancar un contenedor nginx (un conocido servidor web), podríamos hacerlo con el siguiente comando:\n",
    "```bash\n",
    "docker run nginx\n",
    "```\n",
    "\n",
    "Aunque no hayamos descargado una imagen, Docker se encargará de buscar la imagen en Docker Hub, descargarla y arrancar el contenedor de forma automática.\n",
    "\n",
    "Podemos consultar los contenedores que tenemos en ejecución con el comando `docker ps`. Por ejemplo, si queremos ver los contenedores que tenemos en ejecución, podríamos hacerlo con el siguiente comando:\n",
    "```bash\n",
    "docker ps\n",
    "```\n",
    "\n",
    "Además, podemos ver todos los contenedores, tanto los que están en ejecución como los que están parados, con el comando `docker ps -a`. \n",
    "\n",
    "### Opciones comunes de docker run \n",
    "Junto al comando `docker run`, podemos utilizar una serie de opciones para personalizar el comportamiento del contenedor. Algunas de las opciones más comunes son:\n",
    "* `-d`: Arranca el contenedor en segundo plano.\n",
    "* `-p`: Mapea un puerto del contenedor al puerto del host.\n",
    "* `-v`: Mapea un volumen del host al contenedor.\n",
    "* `--name`: Asigna un nombre al contenedor.\n",
    "* `--rm`: Elimina el contenedor al pararlo.\n",
    "* `-e`: Define una variable de entorno.\n",
    "* `--env-file`: Define un archivo de variables de entorno.\n",
    "\n",
    "Vamos a ver varios ejemplos, para entender cómo funcionan estas opciones:\n",
    "\n",
    "## ID y detalles del contenedor\n",
    "Con los contenedores que hemos ejecutado previamente, haciendo un `docker ps`, podemos ver varios valores interesantes. Entre ellos, los más destacados son el ID y el nombre del contenedor, pues nos permitirán referenciarlos en otros comandos, como el logs, attach, stop, commit, etc.\n",
    "\n",
    "Esta es la salida de un comando `docker ps`:\n",
    "```bash\n",
    "❯ docker ps                                                                                        \n",
    "CONTAINER ID   IMAGE     COMMAND                  CREATED             STATUS             PORTS     NAMES\n",
    "e9267a9edf3d   nginx     \"/docker-entrypoint.…\"   About an hour ago   Up About an hour   80/tcp    vigorous_noether\n",
    "```\n",
    "\n",
    "En este caso, el ID del contenedor es `e9267a9edf3d` y el nombre del contenedor es `vigorous_noethe`. Además, podemos ver la imagen que utiliza, el comando que ejecuta, cuando se creó, el estado, los puertos que tiene mapeados, etc.\n",
    "\n",
    "## Proceso del contenedor y ejecución\n",
    "Por defecto, cuando ejecutamos un contenedor en docker, la salida del terminal que vemos, es la salida del contenedor. Es decir, el log del proceso que se está ejecutando dentro. Si estamos depurando puede ser útil verlo pero no siempre es así.\n",
    "\n",
    "Si queremos arrancar un contenedor en segundo plano, podemos utilizar la opción `-d`. Esto hará que se ejecute el contenedor sin mostrar la salida en el terminal.\n",
    "```bash\n",
    "docker run -d nginx\n",
    "```\n",
    "\n",
    "Si hemos lanzado un contenedor en segundo plano, podemos ver la salida del contenedor con el comando `docker logs`. Por ejemplo, si queremos ver la salida del contenedor anterior, podríamos hacerlo con el siguiente comando:\n",
    "```bash\n",
    "docker logs <id_contenedor>\n",
    "```\n",
    "\n",
    "También podríamos seguir la salida en tiempo real con el comando `docker logs -f`. \n",
    "\n",
    "También podríamos acoplarnos al contenedor y ver la salida en tiempo real con el comando `docker attach`. Por ejemplo, si queremos ver la salida del contenedor anterior en tiempo real, podríamos hacerlo con el siguiente comando:\n",
    "```bash\n",
    "docker attach <id_contenedor>\n",
    "```\n",
    "\n",
    "Además del ID también podríamos utilizar el nombre del contenedor para referenciarlo.\n",
    "\n",
    "Por último, si hemos ejecutado un contenedor sin la opción `-d`, podemos hacer \"Control + c\" para parar el contenedor y volver al terminal o, si no queremos pararlo, podemos hacer \"Control + p + q\" para desacoplarnos del contenedor sin pararlo.\n",
    "\n",
    "## Política de reinicio\n",
    "Por defecto, cuando un contenedor falla o termina su proceso, Docker no lo reinicia por defecto. Si queremos que un contenedor se reinicie automáticamente, podemos utilizar la opción `--restart`. Esta opción nos permite definir una política de reinicio. Algunas de las políticas más comunes son:\n",
    "* `no`: No reinicia el contenedor.\n",
    "* `always`: Reinicia el contenedor siempre.\n",
    "* `unless-stopped`: Reinicia el contenedor siempre que no lo paremos.\n",
    "* `on-failure`: Reinicia el contenedor solo si falla.\n",
    "* `on-failure:<n>`: Reinicia el contenedor solo si falla n veces.\n",
    "\n",
    "Por ejemplo, si queremos que un contenedor se reinicie siempre que falle o se reinicie el servidor anfitrión, podríamos hacerlo con el siguiente comando:\n",
    "```bash\n",
    "docker run --restart always nginx\n",
    "```\n",
    "\n",
    "## Mapeo de puertos\n",
    "En este ejemplo, lo que estamos ejecutando es un servidor web. Como ya remarcamos en la introducción, un contenedor se ejecuta en un entorno aislado pero, si que tenemos varios mecanismos para comunicarnos con el contenedor. Uno de ellos es el mapeo de puertos.\n",
    "\n",
    "Podemos utilizar el contenedor de nginx como ejemplo, si hacemos una petición web o accedemos desde el navegador a localhost:80 (localhost o la IP de tu máquina si lo estás haciendo en un servidor externo), no podremos acceder a él. \n",
    "\n",
    "El parámetro `-p`, mencionado anteriormente, nos permite mapear un puerto del host a un puerto del contenedor. En este caso, si queremos acceder al servidor web que hemos arrancado, necesitamos mapear el puerto 80 del contenedor a un puerto del host. En este caso he optado por el 8080, ya que en windows y mac el 80 a veces esta en uso. Para ello, podemos utilizar el siguiente comando:\n",
    "```bash\n",
    "docker run -d -p 8080:80 nginx\n",
    "```\n",
    "\n",
    "Ahora si, si accedemos a localhost:8080, podremos ver el servidor web de nginx respondiendo perfectamente. Esto es porque el puerto 8080 de nuestro host está mapeado al puerto 80 del contenedor y docker se encargará de redirigir las peticiones al contenedor. Esto funciona con cualquier puerto o cualquier aplicación, no solo con servidores web.\n",
    "\n",
    "Por ejemplo, mapear varios puertos:\n",
    "```bash\n",
    "docker run -d -p 8080:80 -p 8081:81 nginx\n",
    "```\n",
    "\n",
    "También podríamos mapear un rango de puertos, por ejemplo del 8080 al 8085 incluidos:\n",
    "```bash\n",
    "docker run -d -p 8080-8085:80 nginx\n",
    "```\n",
    "\n",
    "Con esto, habríamos terminado lo más básico de la ejecución de contenedores. En la siguiente sección, veremos cómo parar, reiniciar y eliminar contenedores. Los parámetros de volúmenes y variables de entorno los veremos en secciones posteriores dedicadas completamente a ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 105. Gestión de contenedores\n",
    "\n",
    "En este episodio, vamos a ver cómo gestionar los contenedores. **Aprenderemos a pararlos, eliminarlos, reiniciarlos... entre otras acciones**, profundizando más en las opciones que nos ofrece Docker.\n",
    "\n",
    "En el episodio anterior, vimos cómo ejecutar un contenedor con el comando `docker run`, ahora toca ver como pararlos, eliminarlos, reiniciarlos, etc. Gestionarlos en definitiva.\n",
    "\n",
    "Dentro vídeo: [https://youtu.be/wlFP0krYphg](https://youtu.be/wlFP0krYphg)\n",
    "\n",
    "## Conectarse a un contenedor\n",
    "En el capítulo anterior, vimos el comando `attach` que nos permitía conectarnos a un contenedor en ejecución. Pero este comando vuelve al proceso principal del contenedor.\n",
    "\n",
    "Por razones de depuración, a veces necesitamos conectarnos a un contenedor en ejecución y ejecutar un comando en él que no sea el principal. Para ello, podemos utilizar el comando `exec`.\n",
    "\n",
    "Por ejemplo, si quisieramos listar el contenido de un contenedor en ejecución, podríamos hacerlo con el siguiente comando:\n",
    "```bash\n",
    "docker exec <id_contenedor> ls\n",
    "```\n",
    "\n",
    "Lo más común, ejecutar el entorno de bash, sh o zsh en un contenedor y así obtener un terminal interactivo. Para poder permitir hay que utilizar los parámtros i, interactive y t, de terminal. Por ejemplo:\n",
    "```bash\n",
    "docker exec -it <id_contenedor> bash\n",
    "```\n",
    "\n",
    "## Parar un contenedor\n",
    "Podemos detener un contenedor en ejecución con el comando `docker stop`. \n",
    "\n",
    "Deberíamos saber el ID o el nombre del contenedor que queremos parar. Recuerda que podemos ver los contenedores que tenemos en ejecución con el comando `docker ps`.\n",
    "\n",
    " Por ejemplo, si queremos parar el contenedor `vigorous_noether`, podríamos hacerlo con el siguiente comando:\n",
    "```bash\n",
    "docker stop vigorous_noether\n",
    "```\n",
    "\n",
    "También podríamos parar el contenedor por ID:\n",
    "```bash\n",
    "docker stop e9267a9edf3d\n",
    "```\n",
    "\n",
    "O, incluso podríamos pararlo solo especificando las primeras letras del ID:\n",
    "```bash\n",
    "docker stop e92\n",
    "```\n",
    "\n",
    "Este truco del id parcial se puede utilizar en la mayoría de los comandos de Docker.\n",
    "\n",
    "## Iniciar un contenedor\n",
    "Podemos iniciar un contenedor que hemos parado con el comando `docker start`.\n",
    "\n",
    "Recordemos que el comando `run` crearía un nuevo contenedor, mientras que el comando `start` iniciará un contenedor que ya ha sido creado previamente y que se encuentra parado.\n",
    "\n",
    "Deberíamos saber el ID o el nombre del contenedor que queremos iniciar. Recuerda que podemos ver los contenedores que tenemos parados con el comando `docker ps -a`. Este nos mostrará todos los contenedores, tanto los que están en ejecución como los que están parados.\n",
    "\n",
    "Otro truco para filtrar la salida del terminal, es complementar los comandos con `grep`. Por ejemplo, si buscamos un contenedor que utilice la imagen `nginx`, podríamos hacerlo con el siguiente comando:\n",
    "```bash\n",
    "docker ps -a | grep nginx\n",
    "```\n",
    "\n",
    "Una vez que tenemos localizado el contenedor que queremos iniciar, por ejemplo, el contenedor con nombre `vigorous_noether`, podríamos hacerlo con el siguiente comando:\n",
    "```bash\n",
    "docker start vigorous_noether\n",
    "```\n",
    "\n",
    "## Reiniciar un contenedor\n",
    "Podemos reiniciar un contenedor con el comando `docker restart`.\n",
    "\n",
    "Reiniciar un contenedor es equivalente a pararlo y volver a iniciarlo. Es decir, es como hacer un `docker stop` seguido de un `docker start`.\n",
    "\n",
    "Por ejemplo, si queremos reiniciar el contenedor `vigorous_noether`, podríamos hacerlo con el siguiente comando:\n",
    "```bash\n",
    "docker restart vigorous_noether\n",
    "```\n",
    "\n",
    "## Eliminar un contenedor\n",
    "Podemos eliminar un contenedor con el comando `docker rm`.\n",
    "\n",
    "Y al igual que en los comandos anteriores, referenciaremos el contenedor por su ID o por su nombre. Por ejemplo:\n",
    "```bash\n",
    "docker rm vigorous_noether\n",
    "```\n",
    "\n",
    "Si hubiera algún problema al eliminar el contenedor, por ejemplo, se queda atascado, podríamos forzar la eliminación con la opción `-f`:\n",
    "```bash\n",
    "docker rm -f vigorous_noether\n",
    "```\n",
    "\n",
    "## Prune de contenedores\n",
    "Podemos **eliminar todos los contenedores parados** con el comando `docker container prune`.\n",
    "\n",
    "Este comando eliminará todos los contenedores que estén parados. Es útil para limpiar el sistema de contenedores que ya no necesitamos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 106. Imágenes\n",
    "\n",
    "En este episodio, vamos a profundizar en el concepto de imagen, como se componen, descargarlas y subirlas a repositorios remotos y gestionarlas en local, eliminándolas y consultando su historial.\n",
    "\n",
    "Vídeo del episodio: [https://youtu.be/Q0AIECxW8Fo](https://youtu.be/Q0AIECxW8Fo)\n",
    "\n",
    "## Imagen\n",
    "Ya hemos visto en los conceptos básico, que una imagen contiene todos los elementos necesarios para ejecutar un contenedor, funcionando como una plantilla que se utiliza para crear contenedores.\n",
    "\n",
    "Además de eso, tiene algunas propiedades más a tener en cuenta:\n",
    "* **Inmutabilidad**: Una vez creada, una imagen no se puede modificar. Si necesitamos hacer cambios, debemos crear una nueva imagen, ya sea a partir de la anterior o desde cero. Este concepto es muy importante, ya que nos permite tener control sobre las versiones de las imágenes y verificar que siempre se comporten de la misma forma en cualquier entorno, garantizando su integridad.\n",
    "  \n",
    "* **Están formadas por capas**: Las imágenes se componen de una serie de capas, cada una de ellas con una funcionalidad concreta. Esto permite reutilizar capas de otras imágenes, lo que reduce el tamaño de las imágenes y el tiempo de construcción. Por ejemplo, si tenemos una imagen con una aplicación en Python y otra con una aplicación en Node.js, ambas podrían compartir las capas de la imagen base de Linux o de alguna librería común. Esto se verá más claro cuando veamos cómo se construyen las imágenes y cómo se definen los Dockerfiles.\n",
    "\n",
    "### Capas de una imagen\n",
    "Todas las imágenes de Docker están formadas por una serie de capas. Cada capa representa un cambio en el sistema de archivos de la imagen. Por ejemplo, si instalamos una librería en una imagen, esa librería se añadirá como una nueva capa en la imagen. \n",
    "\n",
    "Vamos a descargarnos dos imágenes de Docker Hub para ver cómo están formadas. Por ejemplo, vamos a descargar la imagen de `nginx` y la imagen de `alpine`. Para ello, ejecutamos los siguientes comandos:\n",
    "```bash\n",
    "docker pull nginx\n",
    "docker pull alpine\n",
    "```\n",
    "\n",
    "Una vez descargadas, podemos ver las capas de las imágenes con el comando `docker history`. Por ejemplo, si queremos ver las capas de la imagen de `nginx`, podríamos hacerlo con el siguiente comando:\n",
    "```bash\n",
    "docker history nginx\n",
    "```\n",
    "\n",
    "Y si queremos ver las capas de la imagen de `alpine`, podríamos hacerlo con el siguiente comando:\n",
    "```bash\n",
    "docker history alpine\n",
    "```\n",
    "\n",
    "Si ejecutamos estos comandos, veremos que las imágenes están formadas por varias capas, cada una de ellas con una funcionalidad concreta. Por ejemplo, la imagen de `nginx` tiene una capa con la instalación de `nginx`, otra con la configuración de `nginx`, otra con la configuración del sistema operativo, etc.\n",
    "\n",
    "Vamos ahora descargar una versión de nginx que esté basada en alpine, para ver cómo se compone. Por ejemplo, vamos a descargar la imagen de `nginx:alpine`:\n",
    "```bash\n",
    "docker pull alpine:3.19\n",
    "docker pull nginx:stable-alpine3.19\n",
    "```\n",
    "\n",
    "Al hacer pull de la imagen de nginx basada en alpine, podremos ver que hay una capa que se comparte con la imagen de alpine, al estar basada en ella. \n",
    "\n",
    "Todo este proceso de capas, hace muy eficiente el almacenamiento de imágenes y la creación de contenedores, ya que Docker solo necesita descargar las capas que no tenga en local y montarlas en el contenedor.\n",
    "\n",
    "## Borrar imágenes\n",
    "Para borrar una imagen, necesitaremos el ID o el nombre de la imagen. Podemos ver las imágenes que tenemos en local con el comando `docker images` y borrar una imagen con el comando `docker rmi`.\n",
    "\n",
    "Por ejemplo, empezamos listando todas la imágenes que tenemos en local:\n",
    "```bash\n",
    "docker images\n",
    "```\n",
    "\n",
    "Y si queremos borrar una imagen, por ejemplo, la imagen de `nginx`, podríamos hacerlo con el siguiente comando:\n",
    "```bash\n",
    "docker rmi nginx\n",
    "```\n",
    "\n",
    "También podríamos borrar la imagen por ID:\n",
    "```bash\n",
    "docker rmi 7faa5d3a2af2\n",
    "```\n",
    "\n",
    "## Prune de imágenes\n",
    "Si queremos borrar todas las imágenes que no estén en uso, podemos utilizar el comando `docker image prune`. Este comando eliminará todas las imágenes que no estén asociadas a ningún contenedor.\n",
    "\n",
    "El comando es muy sencillo, simplemente ejecutamos:\n",
    "```bash\n",
    "docker image prune\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 107. Dockerfiles y Docker Build\n",
    "\n",
    "En este apartado vamos a ver cómo se construyen las imágenes utilizando docker build y las instrucciones esenciales de un Dockerfile para empaquetar tu aplicación o servicio a un contenedor.\n",
    "\n",
    "Dentro vídeo: [https://youtu.be/A8oXDTDhZWU](https://youtu.be/A8oXDTDhZWU)\n",
    "\n",
    "## Dockerfile\n",
    "Un Dockerfile es un archivo de texto que contiene una serie de instrucciones que Docker leerá y ejecutará para construir una imagen de contenedor. Cada instrucción en un Dockerfile crea una capa en la imagen.\n",
    "\n",
    "Un Dockerfile se compone de una serie de instrucciones, cada una de ellas en una línea diferente. Las instrucciones más comunes son:\n",
    "* `FROM`: Indica la imagen base que se utilizará para construir la nueva imagen.\n",
    "* `RUN`: Ejecuta comandos en la imagen.\n",
    "* `COPY`: Copia archivos o directorios desde el host a la imagen.\n",
    "* `WORKDIR`: Establece el directorio de trabajo por defecto para el resto de instrucciones.\n",
    "* `CMD`: Define el comando que se ejecutará cuando se inicie un contenedor a partir de la imagen.\n",
    "* `ENTRYPOINT`: Define el comando que se ejecutará cuando se inicie un contenedor a partir de la imagen, pero no se puede sobreescribir.\n",
    "\n",
    "Hay más instrucciones que iremos viendo a lo largo del curso, pero para empezar, estas son las más importantes.\n",
    "\n",
    "### Dockerfile para Nginx\n",
    "Supongamos que tenemos un fichero `index.html` en nuestro directorio actual y queremos publicarlo en un servidor web Nginx. El Dockerfile sería algo así:\n",
    "```Dockerfile\n",
    "# Utilizamos la imagen oficial de Nginx\n",
    "FROM nginx:alpine\n",
    "\n",
    "# Copiamos el fichero index.html al directorio /usr/share/nginx/html\n",
    "COPY index.html /usr/share/nginx/html/index.html\n",
    "```\n",
    "\n",
    "Ya ves lo simple que es consumir imágenes oficiales de productos finales como Nginx. Solo necesitas copiar tus archivos al directorio adecuado y listo.\n",
    "\n",
    "### Dockerfile para Python\n",
    "Supongamos que tenemos un script de Python que queremos ejecutar en un contenedor. Por ejemplo, un script que imprime \"¡Hola Dockermaníaco!\" cada segundo. El Dockerfile sería algo así:\n",
    "```Dockerfile\n",
    "# Utilizamos la imagen oficial de Python\n",
    "FROM python:alpine\n",
    "\n",
    "# Establecemos el directorio de trabajo\n",
    "WORKDIR /app\n",
    "\n",
    "# Copiamos el script de Python al directorio de trabajo\n",
    "COPY script.py .\n",
    "\n",
    "# Ejecutamos el script de Python\n",
    "CMD [\"python\", \"script.py\"]\n",
    "```\n",
    "\n",
    "Ahora, nuestro Dockerfile con dependencias sería algo así:\n",
    "```Dockerfile\n",
    "# Utilizamos la imagen oficial de Python\n",
    "FROM python:alpine\n",
    "\n",
    "# Establecemos el directorio de trabajo\n",
    "WORKDIR /app\n",
    "\n",
    "# Copiamos el script de Python y el fichero requirements.txt al directorio de trabajo\n",
    "COPY script.py .\n",
    "COPY requirements.txt .\n",
    "\n",
    "# Instalamos las dependencias\n",
    "RUN pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "### Orden de las instrucciones\n",
    "Es importante tener en cuenta el orden de las instrucciones en un Dockerfile. Se ejecutan de arriba a abajo, secuencialmente, y Docker intenta reutilizar capas de imágenes anteriores para optimizar el proceso de construcción.\n",
    "\n",
    "Veamos como podríamos optimizar el Dockerfile anterior:\n",
    "```Dockerfile\n",
    "# Versión optimizada del Dockerfile\n",
    "FROM python:alpine\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY requirements.txt .\n",
    "\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "COPY script.py .\n",
    "\n",
    "CMD [\"python\", \"script.py\"]\n",
    "```\n",
    "\n",
    "Ahora, si cambiamos el script, Docker reutilizará la capa de la imagen que contiene las dependencias y solo tendrá que volver a ejecutar las instrucciones a partir de la copia del script.\n",
    "\n",
    "## Docker Build\n",
    "Es hora de probar nuestros Dockerfiles. Para ello, utilizaremos el comando `docker build`. Este comando construye una imagen a partir de un Dockerfile y un contexto. El contexto es el directorio desde el que se construye la imagen y se utiliza de referencia para el copiado de archivos y directorios.\n",
    "\n",
    "El comando `docker build` tiene la siguiente sintaxis:\n",
    "```bash\n",
    "docker build -t <nombre_imagen> <directorio_contexto>\n",
    "```\n",
    "\n",
    "El parámetro `-t` nos permite dar un nombre y tag a la imagen que estamos construyendo. Si no lo especificamos, Docker le asignará un nombre aleatorio.\n",
    "\n",
    "Construimos la imagen del servidor web Nginx:\n",
    "```bash\n",
    "docker build -t mi-nginx .\n",
    "```\n",
    "\n",
    "Y la imagen del script de Python:\n",
    "```bash\n",
    "docker build -t mi-python .\n",
    "```\n",
    "\n",
    "Si todo ha ido bien, ya deberías tener tus imágenes construidas. Puedes comprobarlo con el comando `docker images`.\n",
    "\n",
    "Ahora solo nos queda probar las imágenes. Para ello, ejecutamos un contenedor a partir de cada imagen:\n",
    "```bash\n",
    "docker run -d --name mi-nginx -p 8080:80 mi-nginx\n",
    "\n",
    "docker run -d --name mi-python mi-python\n",
    "```\n",
    "\n",
    "Como puedes ver, el nombre de la imagen sirve para referenciarla a la hora de ejecutar el contenedor, descargarla o subirla a un registro de imágenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 108. Entrypoints, argumentos y variables de entorno\n",
    "\n",
    "Ya hemos visto como se consumen imágenes de contenedor, como se construyen imágenes propias y como se gestionan los contenedores pero seguiríamos sin ser capaces de consumir imágenes de dockerhub si no sabemos cómo configurarlas y adaptarlas a nuestras necesidades.\n",
    "\n",
    "Dentro vídeo: [https://youtu.be/bd8EoJbKmwQ](https://youtu.be/bd8EoJbKmwQ)\n",
    "\n",
    "Además, veremos como hacer nuestros contenedores más flexibles y dinámicos, es decir que se puedan adaptar a diferentes situaciones y entornos. Para ello, vamos a ver cómo utilizar las instrucciones `ENTRYPOINT`, `CMD`, argumentos y variables de entorno en nuestros Dockerfiles.\n",
    "\n",
    "## ENTRYPOINT y CMD\n",
    "En Dockerfile, las instrucciones `ENTRYPOINT` y `CMD` son las que definen qué comando se ejecutará cuando se inicie un contenedor. Tienen una funcionalidad similar, pero con una diferencia importante.\n",
    "\n",
    "La instrucción `ENTRYPOINT` define el comando que se ejecutará cuando se inicie un contenedor. Si se especifica un `ENTRYPOINT`, este comando se ejecutará siempre que se inicie el contenedor, y cualquier comando que se pase al contenedor se ejecutará como argumentos del `ENTRYPOINT`.\n",
    "\n",
    "Por otro lado, la instrucción `CMD` también define el comando que se ejecutará cuando se inicie un contenedor, pero si se especifica un `CMD`, será sobre escrito por cualquier comando que se pase al contenedor.\n",
    "\n",
    "Por ejemplo, si tenemos un Dockerfile con las siguientes instrucciones:\n",
    "```Dockerfile\n",
    "FROM alpine\n",
    "ENTRYPOINT [\"echo\", \"Hola\"]\n",
    "CMD [\"Mundo\"]\n",
    "```\n",
    "\n",
    "Y construimos la imagen con el comando `docker build -t saludador .`, al iniciar un contenedor con el comando `docker run saludador`, se ejecutará el comando `echo Hola Mundo`.\n",
    "\n",
    "Si queremos sobreescribir el comando `CMD`, podemos hacerlo con el comando `docker run saludador dockermaniatico`, y se ejecutará el comando `echo Hola dockermaniatico`.\n",
    "\n",
    "## Argumentos en Dockerfile y Docker build\n",
    "Además de `ENTRYPOINT` y `CMD`, podemos pasar argumentos a nuestro proceso de construcción y definir variables de entorno en nuestro Dockerfile.\n",
    "\n",
    "Para pasar argumentos a nuestro proceso de construcción, podemos utilizar la instrucción `ARG`. Por ejemplo:\n",
    "```Dockerfile\n",
    "FROM alpine\n",
    "\n",
    "# Declarar un argumento con un valor predeterminado\n",
    "ARG NOMBRE=\"Mundo\"\n",
    "\n",
    "# Crear un archivo que contenga el mensaje personalizado\n",
    "RUN echo \"Hola $NOMBRE\" > /message \n",
    "\n",
    "# Comando predeterminado para mostrar el contenido del archivo\n",
    "CMD [\"cat\", \"/message\"]\n",
    "```\n",
    "\n",
    "También podemos sobreescribir el argumento `NOMBRE`, durante el proceso de construcción, con el comando `docker build --build-arg NOMBRE=dockermaniatico -t saludador .`\n",
    "\n",
    "## Variables de entorno en Docker run\n",
    "Por último, vamos a ver cómo pasar variables de entorno a nuestros contenedores en el momento de ejecutarlos. Para ello, podemos utilizar el comando `docker run` con la opción `-e` o `--env`. \n",
    "\n",
    "Esto nos permite preparar nuestra aplicación para diferentes entornos o casuísticas, sin tener que modificar el Dockerfile ni reconstruir la imagen. Por ejemplo:\n",
    "```bash\n",
    "docker run -e DEBUG=1 mi_aplicacion\n",
    "```\n",
    "\n",
    "## Ser lo más agnóstico posible\n",
    "La filosofía de los contenedores es ser lo más agnóstico posible, es decir, que no dependan de un entorno concreto y se puedan ejecutar en cualquier entorno, cliente y caso de uso. Por eso, es importante configurar nuestras imágenes para que no dependan de variables estáticas y que se puedan adaptar a diferentes situaciones.\n",
    "\n",
    "Por ejemplo, una base de datos, funciona igual para todas las personas que desplegarían un contenedor con una base de datos de mariadb, pero cada uno necesitaría una configuración diferente, como el nombre de la base de datos, el usuario, la contraseña, etc. Por eso, es importante que nuestra imagen sea lo más flexible posible y se pueda adaptar a diferentes situaciones y entornos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 109. Gestión de imágenes\n",
    "\n",
    "Ya hemos visto como construir imágenes con Dockerfile y Docker build. Ahora vamos a ver cómo gestionar las imágenes que hemos creado, descargado o commiteado, etiquetarlas, versionarlas, exportarlas e importarlas y subirlas nuestros propios repositorios en Docker Hub.\n",
    "\n",
    "Dentro vídeo: [https://youtu.be/5CNQMeYUBPs](https://youtu.be/5CNQMeYUBPs)\n",
    "\n",
    "## Commit - Crear una imagen a partir de un contenedor\n",
    "Ya habíamos comentado la posibilidad de crear una imagen a partir de un dockerfile, pero también podríamos hacerlo desde un contenedor en ejecución. Esto sería similar a hacer una snapshot de una máquina virtual, es decir, guardar el estado actual de un contenedor en una imagen, incluyendo los cambios que se hayan hecho en el sistema de archivos, memoria, etc.\n",
    "\n",
    "Suponiendo que tuviéramos un contenedor en ejecución, podríamos crear una imagen a partir de él con el comando `docker commit`:\n",
    "```bash\n",
    "docker commit <container_id> <nombre_imagen>\n",
    "```\n",
    "\n",
    "## Save y load - Exportar e importar imágenes\n",
    "Estas imágenes que hemos creado, descargado o commiteado, podemos exportarlas a un fichero tar y luego importarlas en otro sistema. Para exportar una imagen a un fichero tar, podemos usar el comando `docker save`:\n",
    "\n",
    "```bash\n",
    "docker save -o <nombre_fichero>.tar <nombre_imagen>\n",
    "```\n",
    "\n",
    "Para importar una imagen desde un fichero tar, podemos usar el comando `docker load`:\n",
    "```bash\n",
    "docker load -i <nombre_fichero>.tar\n",
    "```\n",
    "\n",
    "## Tags - Nombre y etiquetas de las imágenes\n",
    "Al construir una imagen con `docker build`, pudimos especificar un nombre y una etiqueta para la imagen con el argumento `-t`. Este nombre y etiqueta, no solo se usa por darle un nombre familiar a la imagen, sino que también identifica el origen de la imagen y su versión.\n",
    "\n",
    "Podemos alterar el nombre y las etiquetas de una imagen con el comando `docker tag`:\n",
    "```bash\n",
    "docker tag <nombre_imagen>:<etiqueta> <nuevo_nombre>:<nueva_etiqueta>\n",
    "```\n",
    "\n",
    "## Repositorios, subir y descargar imágenes\n",
    "Las imágenes se almacenan en repositorios. El repositorio más conocido es [Docker Hub](https://hub.docker.com/), donde podemos encontrar miles de imágenes de contenedor listas para usar.\n",
    "\n",
    "Podemos interactuar con los repositorios de varias formas:\n",
    "* **Buscar imágenes**: Podemos buscar imágenes en Docker Hub utilizando la página web o la CLI de Docker.\n",
    "* **Descargar imágenes**: Podemos descargar imágenes de Docker Hub con el comando `docker pull`.\n",
    "* **Subir imágenes**: Podemos subir nuestras propias imágenes a Docker Hub con el comando `docker push`.\n",
    "\n",
    "Veamos un ejemplo de cómo buscar una imagen en docker hub:\n",
    "```bash\n",
    "docker search nginx\n",
    "```\n",
    "\n",
    "Una vez tengamos la imagen que queremos, podemos descargarla con el comando `docker pull`:\n",
    "```bash\n",
    "docker pull nginx\n",
    "```\n",
    "\n",
    "### Subir imágenes a Docker Hub\n",
    "Imaginemos que hemos creado una imagen llamada `mi-imagen` y queremos subirla a Docker Hub. Para ello, primero debemos etiquetar la imagen con nuestro nombre de usuario en Docker Hub y el nombre del repositorio. Por ejemplo:\n",
    "```bash\n",
    "docker tag mi-imagen:latest pabpereza/mi-imagen:latest\n",
    "```\n",
    "\n",
    "Luego, podemos subir la imagen a Docker Hub con el comando `docker push`:\n",
    "```bash\n",
    "docker push pabpereza/mi-imagen:latest\n",
    "```\n",
    "\n",
    "### Subir imágenes a repositorios remotos (no Docker Hub)\n",
    "Pero, que pasaría si la imagen que queremos subir no está en Docker Hub, sino que está en nuestro propio sistema. En el nombre de una imagen también podríamos especificar la dirección de un repositorio remoto, por ejemplo:\n",
    "```bash\n",
    "docker tag mi-imagen:latest github.com/pabpereza/mi-imagen:latest\n",
    "```\n",
    "\n",
    "Y luego subir la imagen a ese repositorio remoto con el comando `docker push`:\n",
    "```bash\n",
    "docker push github.com/pabpereza/mi-imagen:latest\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 110. Volúmenes y archivos\n",
    "\n",
    "Los contenedores están diseñados para ser efímeros, es decir, que se puedan crear y destruir fácilmente. Sin embargo, en muchas ocasiones necesitaremos que los datos que se generen en un contenedor sean persistentes, es decir, que se mantengan aunque el contenedor se destruya. Para ello, Docker nos proporciona los volúmenes.\n",
    "\n",
    "Los volúmenes son directorios o archivos que se encuentran fuera del sistema de archivos del contenedor y que se montan en el contenedor para que este pueda acceder a ellos.\n",
    "\n",
    "Dentro vídeo: [https://youtu.be/APgKgrcibvs](https://youtu.be/APgKgrcibvs)\n",
    "\n",
    "## Gestión de volúmenes\n",
    "\n",
    "### Crear un volumen\n",
    "Para crear un volumen, podemos usar el comando `docker volume create`:\n",
    "```bash\n",
    "docker volume create mi-volumen\n",
    "```\n",
    "\n",
    "### Listar volúmenes\n",
    "Podemos listar los volúmenes que tenemos en nuestro sistema con el comando `docker volume ls`:\n",
    "```bash\n",
    "docker volume ls\n",
    "```\n",
    "\n",
    "### Inspeccionar un volumen\n",
    "Podemos inspeccionar un volumen con el comando `docker volume inspect`:\n",
    "```bash\n",
    "docker volume inspect mi-volumen\n",
    "```\n",
    "\n",
    "### Montar un volumen en un contenedor\n",
    "Para montar un volumen en un contenedor, podemos usar la opción `-v` o `--mount` al crear el contenedor:\n",
    "```bash\n",
    "docker run -d --name mi-contenedor -v mi-volumen:/datos nginx\n",
    "```\n",
    "\n",
    "### Eliminar un volumen\n",
    "Para eliminar un volumen, podemos usar el comando `docker volume rm`:\n",
    "```bash\n",
    "docker volume rm mi-volumen\n",
    "```\n",
    "\n",
    "## Copiar archivos entre el host y el contenedor\n",
    "Para copiar archivos entre el host y el contenedor, podemos usar el comando `docker cp`:\n",
    "```bash\n",
    "docker cp /ruta/a/mi/archivo.txt mi-contenedor:/datos/archivo.txt\n",
    "```\n",
    "\n",
    "También podríamos hacerlo al revés, copiar un archivo del contenedor al host:\n",
    "```bash\n",
    "docker cp mi-contenedor:/datos/archivo.txt /ruta/a/mi/archivo.txt\n",
    "```\n",
    "\n",
    "## Montaje de archivos y directorios\n",
    "Hemos visto cómo montar un volumen en un contenedor, aunque una práctica muy habitual es montar un archivo o un directorio de nuestro sistema de archivos en un contenedor. Esto es especialmente común cuando queremos compartir archivos entre el host y el contenedor, durante el desarrollo de aplicaciones, por ejemplo.\n",
    "\n",
    "Podemos realizando con la misma opción de antes, `-v`, pero en este caso, en lugar de especificar un volumen, especificamos un archivo o directorio de nuestro sistema de archivos:\n",
    "```bash\n",
    "docker run -d --name mi-contenedor -v /ruta/a/mi/directorio:/datos nginx\n",
    "```\n",
    "\n",
    "Este método es muy útil pero tenemos que tener en cuenta que, en windows y mac, al ser sistemas de archivos diferentes y tener una capa de virtualización, el rendimiento puede ser peor que un volumen.\n",
    "\n",
    "## Gestión de volúmenes desde el panel de Docker Desktop\n",
    "En Docker Desktop, podemos gestionar los volúmenes desde la interfaz gráfica. Para ello, vamos a la pestaña de \"Volumes\", ahí podremos ver los volúmenes que tenemos en nuestro sistema y crear, eliminar o inspeccionar volúmenes.\n",
    "\n",
    "Una de las funciones más interesantes es la posibilidad de importar/exportar volúmenes, así como acceder a los archivos de su interior, mover archivos entre el host y el contenedor, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 111. Redes\n",
    "\n",
    "Las redes en Docker son un tema muy importante, ya que nos permiten conectar contenedores entre sí o aislarlos unos de otros. Al final, algo que nos permite docker es desplegar múltiples contenedores o servicios en el mismo servidor. En muchos de los casos, estos contenedores serán servicios que no tienen nada que ver unos con otros, y por lo tanto, no deberían poder comunicarse entre sí por seguridad. En otros casos, necesitaremos que los contenedores se comuniquen entre sí, por ejemplo, un contenedor de base de datos y un contenedor de aplicación.\n",
    "\n",
    "Todo esto, lo veremos a través del comando `docker network` y de las opciones de red que podemos especificar al crear un contenedor.\n",
    "\n",
    "Dentro vídeo: [https://youtu.be/lQoh9gaEvvc](https://youtu.be/lQoh9gaEvvc)\n",
    "\n",
    "## Crear una red y tipos de redes\n",
    "Para crear una red, podemos usar el comando `docker network create`:\n",
    "```bash\n",
    "docker network create mi-red\n",
    "```\n",
    "\n",
    "Podemos especificar el driver de red con la opción `--driver`, por defecto, el driver es `bridge`:\n",
    "```bash\n",
    "docker network create --driver bridge mi-red\n",
    "```\n",
    "\n",
    "Los tipos de redes más comunes que podemos crear:\n",
    "- `bridge`: Red por defecto, que permite la comunicación entre contenedores en el mismo host.\n",
    "- `host`: Red que permite que los contenedores compartan la red del host (ojo con la seguridad, porque los contenedores pueden ver la red del host anfitrión).\n",
    "- `overlay`: Red que permite la comunicación entre contenedores en diferentes hosts.\n",
    "- `macvlan`: Red que permite asignar una dirección MAC a un contenedor y que se comporte como un dispositivo físico en la red.\n",
    "- `none`: Sin red, el contenedor no tendrá acceso a la red.\n",
    "\n",
    "Lo más común es usar el driver `bridge` para la mayoría de los casos, aunque para cargas distribuidas, podemos usar el driver `overlay`.\n",
    "\n",
    "## Listar redes\n",
    "Podemos listar las redes que tenemos en nuestro sistema con el comando `docker network ls`:\n",
    "```bash\n",
    "docker network ls\n",
    "```\n",
    "\n",
    "## Inspeccionar una red\n",
    "Podemos inspeccionar una red con el comando `docker network inspect`:\n",
    "```bash\n",
    "docker network inspect mi-red\n",
    "```\n",
    "\n",
    "## Conectar un contenedor a una red\n",
    "Para conectar un contenedor a una red, podemos usar la opción `--network` al crear el contenedor:\n",
    "```bash\n",
    "docker run -d --name mi-contenedor --network mi-red nginx\n",
    "```\n",
    "\n",
    "Aunque también podemos conectar un contenedor a una red (ambos existentes previamente) con el comando `docker network connect`:\n",
    "```bash\n",
    "docker network connect mi-red mi-contenedor\n",
    "```\n",
    "\n",
    "## Desconectar un contenedor de una red\n",
    "Para desconectar un contenedor de una red, podemos usar el comando `docker network disconnect`:\n",
    "```bash\n",
    "docker network disconnect mi-red mi-contenedor\n",
    "```\n",
    "\n",
    "## Eliminar una red\n",
    "Para eliminar una red, podemos usar el comando `docker network rm`:\n",
    "```bash\n",
    "docker network rm mi-red\n",
    "```\n",
    "\n",
    "Con esto, ya tenemos una idea de cómo funcionan las redes en Docker y cómo podemos conectar contenedores entre sí o aislarlos unos de otros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 112. Docker Compose\n",
    "\n",
    "Docker compose es una herramienta que nos permite definir y ejecutar aplicaciones formadas por múltiples contenedores. Con Docker compose podemos definir un archivo YAML con la configuración de los servicios que forman nuestra aplicación y luego ejecutarla con un solo comando. Así de simple, vamos a ver cómo funciona.\n",
    "\n",
    "Dentro vídeo: https://youtu.be/oR0nBx5C9DM\n",
    "\n",
    "## Como funciona\n",
    "Su lógica es simple, nos permite definir en un mismo fichero múltiples servicios, volúmenes, redes, secretos y configuraciones, algo que hasta ahora habríamos trabajado de forma individual y usando el cli. Por defecto, se suele usar un fichero llamado \"compose.yaml\", que es el que docker compose busca por defecto.\n",
    "\n",
    "En este fichero podemos definir:\n",
    "* Servicios: Contiene la definición de la imagen que van a ejecutar, los puertos que exponen, volúmenes, redes, variables de entorno, etc.\n",
    "* Volúmenes: que antes definíamos con `docker volume create` o con el flag `-v` en `docker run`\n",
    "* Redes: que antes definíamos con `docker network create` o con el flag `--network` en `docker run`\n",
    "* Secretos y configuraciones: que antes definíamos con `docker secret create` o con el flag `--secret` en `docker run`\n",
    "\n",
    "## Comandos más comunes\n",
    "A continuación, se muestran los comandos más comunes que podemos usar con docker compose:\n",
    "* `docker compose up`: Levanta todos los servicios definidos en el fichero compose.\n",
    "* `docker compose up -d`: Levanta todos los servicios en segundo plano.\n",
    "* `docker compose down`: Detiene y elimina todos los servicios.\n",
    "* `docker compose ps`: Muestra el estado de los servicios.\n",
    "* `docker compose logs`: Muestra los logs de los servicios.\n",
    "* `docker compose exec <servicio> <comando>`: Ejecuta un comando en un servicio.\n",
    "\n",
    "## Ejecutar un fichero compose\n",
    "Vamos a utilizar un ejemplo sencillo para ver cómo funciona. En este ejemplo, se despliega un servicio nginx:\n",
    "\n",
    "```yaml\n",
    "services:\n",
    "  web:\n",
    "    image: nginx:latest\n",
    "    ports:\n",
    "      - \"8080:80\"\n",
    "```\n",
    "\n",
    "Para ejecutar este servicio, solo tenemos que guardar este fichero y ejecutar el siguiente comando:\n",
    "\n",
    "```bash\n",
    "docker compose up\n",
    "```\n",
    "\n",
    "Esta ejecución se mantendrá en primer plano, es decir, que si cerramos la terminal, se detendrá el servicio. Para ejecutarlo en segundo plano, solo tenemos que añadir el flag `-d`:\n",
    "```bash\n",
    "docker compose up -d\n",
    "```\n",
    "\n",
    "### Ejemplo haciendo build de un Dockerfile\n",
    "En este caso, vamos a hacer un build de un Dockerfile que tengamos en la misma carpeta que el fichero compose:\n",
    "\n",
    "```yaml\n",
    "services:\n",
    "  web:\n",
    "    build: .\n",
    "    ports:\n",
    "      - \"8080:80\"\n",
    "```\n",
    "\n",
    "## Volúmenes\n",
    "En el fichero compose, podemos definir volúmenes:\n",
    "\n",
    "```yaml\n",
    "volumes:\n",
    "  db_data:\n",
    "  wp_data:\n",
    "```\n",
    "\n",
    "Y luego, en el servicio que queramos usarlo:\n",
    "```yaml\n",
    "services:\n",
    "  db:\n",
    "    volumes:\n",
    "      - db_data:/var/lib/mysql\n",
    "```\n",
    "\n",
    "## Redes\n",
    "De la misma forma que los volúmenes, podemos definir redes en el fichero compose:\n",
    "\n",
    "```yaml\n",
    "networks:\n",
    "  mi_red:\n",
    "```\n",
    "\n",
    "Y luego, en el servicio que queramos usarla:\n",
    "```yaml\n",
    "services:\n",
    "  db:\n",
    "    image: nginx\n",
    "    ports:\n",
    "      - \"8080:80\"\n",
    "    networks:\n",
    "      - mi_red\n",
    "```\n",
    "\n",
    "## Conclusiones\n",
    "Estos ficheros compose, junto con su cli específico, nos permite agrupa la declaraciones de varios servicios, configuraciones, volúmenes y redes en un solo fichero. Esto nos permite desplegar aplicaciones complejas en un solo comando, tanto para entornos de desarrollo como de producción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 113. Docker Swarm\n",
    "\n",
    "Docker Swarm es una herramienta de orquestación de contenedores que permite darle escalabilidad a nuestras aplicaciones y cubrir las limitaciones de docker compose. Viene incluido en Docker, permite distribuir contenedores en diferentes nodos y gobernarlos de manera centralizada. \n",
    "\n",
    "Sería una alternativa a Kubernetes, algo más limitado, pero a la vez más sencillo de usar y configurar. Lo más importante, es que usa ficheros YAML como compose, con alguna etiqueta adicional a lo que vimos en el vídeo anterior. Esto hace que de entrada, sea muy sencillo de usar. \n",
    "\n",
    "Dentro vídeo: https://youtu.be/bvUZuANQdhI\n",
    "\n",
    "## Activar Docker Swarm\n",
    "Docker Swarm viene preinstalado tanto en Docker Desktop como en Docker Engine. Lo único que tendremos que hacer, es activar el modo Swarm. Para ello, ejecutamos el siguiente comando:\n",
    "```bash\n",
    "docker swarm init\n",
    "```\n",
    "Con este comando, estamos creando un nodo manager, que es el que se encargará de gobernar el resto de nodos.\n",
    "\n",
    "## Gestión de nodos\n",
    "\n",
    "### Crear nodos o worker\n",
    "Una vez que tenemos el nodo manager, podemos añadir nodos workers. Para ello, ejecutamos el siguiente comando en el nodo que queramos añadir:\n",
    "```bash\n",
    "docker swarm join --token <token> <ip_manager>:<puerto>\n",
    "```\n",
    "\n",
    "### Eliminar nodo o workers\n",
    "Podemos eliminar un nodo de la siguiente manera:\n",
    "```bash\n",
    "docker node rm <nombre_nodo>\n",
    "```\n",
    "\n",
    "### Desactivar Docker Swarm\n",
    "Para desactivar Docker Swarm, ejecutamos el siguiente comando:\n",
    "```bash\n",
    "docker swarm leave\n",
    "```\n",
    "\n",
    "## Servicios\n",
    "\n",
    "### Crear servicios\n",
    "Aunque lo más habitual es definir los servicios en un fichero YAML, también podemos crearlos directamente con el comando `docker service create`. Por ejemplo:\n",
    "```bash\n",
    "docker service create --name web --replicas 5 nginx\n",
    "```\n",
    "\n",
    "### Escalar servicios\n",
    "Podemos escalar un servicio con el comando `docker service scale`:\n",
    "```bash\n",
    "docker service scale web=10\n",
    "```\n",
    "\n",
    "### Actualizar servicios\n",
    "Podemos actualizar un servicio con el comando `docker service update`:\n",
    "```bash\n",
    "docker service update --image nginx:alpine web\n",
    "```\n",
    "\n",
    "### Eliminar servicios\n",
    "Podemos eliminar un servicio con el comando `docker service rm`:\n",
    "```bash\n",
    "docker service rm web\n",
    "```\n",
    "\n",
    "## Compose y stacks\n",
    "Docker Swarm es compatible con Docker Compose, por lo que podemos desplegar servicios con ficheros YAML de Docker Compose. Para ello, usamos el comando `docker stack deploy`:\n",
    "```bash\n",
    "docker stack deploy -c docker-compose.yml myapp\n",
    "```\n",
    "\n",
    "## Próximos pasos\n",
    "Aunque en este curso no vamos a profundizar en Docker Swarm, es importante que conozcas su existencia y cómo funciona. Ya veis el potencial y lo sencillo que es trabajar con Docker Swarm, sobretodo ahora que ya tenemos una base de Docker Compose y más aún si lo comparamos con la complejidad de Kubernetes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 114. Tu primera app\n",
    "\n",
    "Este capítulo es un poco diferente a los anteriores ya que vamos a ver cómo crear una aplicación completa en Docker. Para ejemplificarlos, he creado una aplicación muy simple en Python usando el framework FastAPI. \n",
    "\n",
    "Esta aplicación busca ser un API que nos devuelva citas de películas, series... etc, pero eso es otra historia. Lo importante es que sobre ella se ha ejemplificado la construcción del contenedor, la migración de la configuración a variables de entorno y, por último, la creación de un docker compose para desplegar la aplicación junto con una base de datos de posgresql.\n",
    "\n",
    "Tienes la aplicación en este repositorio de Github para consultar todo lo realizado en el vídeo: [Quotes](https://github.com/pabpereza/quotes)\n",
    "\n",
    "Dentro vídeo: https://youtu.be/hXh_ej-hsMg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 115. Docker en producción\n",
    "\n",
    "Ya hemos visto a lo largo de todo el curso lo sencillo que es ejecutar aplicaciones con Docker y Docker Compose. Pero, de cara a producción, viene bien tener en cuenta algunas buenas prácticas para mejorar la resiliencia y seguridad de nuestras aplicaciones.\n",
    "\n",
    "En este episodio vamos a ver como preparar el servidor instalando Docker Engine y compose, desplegar la aplicación de ejemplo y algunas buenas prácticas para tener en cuenta.\n",
    "\n",
    "Dentro vídeo: https://youtu.be/eh4YS9x9CDU\n",
    "\n",
    "## Instalar docker engine\n",
    "Me gusta utilizar el instalador de Docker en un solo comando:\n",
    "\n",
    "```bash\n",
    "curl -fsSL https://get.docker.com -o get-docker.sh && sh get-docker.sh\n",
    "```\n",
    "\n",
    "## Instalar docker compose\n",
    "En docker desktop, la herramienta compose viene incluida, pero en docker engine (en servidores) no viene incluida, por lo que debemos instalarla a parte, como un plugin de docker.\n",
    "Documentación oficial: [Install Docker Compose](https://docs.docker.com/compose/install/)\n",
    "\n",
    "## Desplegar una aplicación con docker compose\n",
    "Como ya tenemos un fichero de compose en la aplicación de ejemplo, podemos desplegarla con un simple comando.\n",
    "\n",
    "```bash\n",
    "docker-compose up -d\n",
    "```\n",
    "\n",
    "Realmente, con esto ya tendríamos nuestra aplicación funcionando correctamente en producción, pero vamos a ver algunas buenas prácticas para tener en cuenta.\n",
    "\n",
    "## Buenas prácticas para Docker Compose\n",
    "* Limitar los recursos de los contenedores\n",
    "* Cargar variables de entorno desde fichero\n",
    "* Persistir datos en volúmenes\n",
    "* Habilitar reinicio automático\n",
    "* Segregación de redes\n",
    "* Monitorizar contenedores y recursos\n",
    "* Actualizar contenedores y aplicaciones\n",
    "\n",
    "## Buenas prácticas para Linux anfitrión\n",
    "* Vigilar puertos expuestos y firewall\n",
    "* Control acceso SSH\n",
    "* Deshabilitar acceso root\n",
    "* Acceder solo con clave RSA \n",
    "* Fail2ban\n",
    "* Actualizar sistema operativo y docker engine \n",
    "\n",
    "## Bonus para próximos episodios\n",
    "* Docker Swarm para alta disponibilidad\n",
    "* Centralizar logs con Grafana o prometheus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 201. Límites de recursos\n",
    "\n",
    "Si algo nos permite Docker, es compartir infraestructura y recursos entre varios contenedores. Pero, ¿qué pasaría si un contenedor consume todos los recursos de la máquina? ¿Cómo se puede limitar el uso de recursos de un contenedor para evitar un fallo en un servidor o incluso la caída todal del mismo?\n",
    "\n",
    "En este capítulo vamos a ver las distintas opciones que nos da Docker para limitar y controlar los recursos de nuestros contenedores. Además, este será el primer capítulo de la parte más avanzada del curso.\n",
    "\n",
    "## Limitar CPU y memoria\n",
    "Podemos limitar la cantidad de CPU y memoria que un contenedor puede utilizar. Para ello, utilizamos las opciones `--cpus` y `--memory` en el comando `docker run`.\n",
    "\n",
    "Por ejemplo, para limitar un contenedor a 1 CPU y 512MB de memoria, ejecutaríamos:\n",
    "```shell\n",
    "docker run -d --name my-container --cpus 1 --memory 512m nginx\n",
    "```\n",
    "\n",
    "En docker compose:\n",
    "```yaml\n",
    "version: '3'\n",
    "services:\n",
    "  my-container:\n",
    "    image: nginx\n",
    "    deploy:\n",
    "      resources:\n",
    "        limits:\n",
    "          cpus: '1'\n",
    "          memory: 512m\n",
    "```\n",
    "\n",
    "## Reservas de recursos\n",
    "Además de limitar los recursos de un contenedor, también podemos reservar una cantidad mínima de recursos para un contenedor. Esto es útil para garantizar que contenedor los recursos que necesita para arrancar.\n",
    "\n",
    "Por ejemplo:\n",
    "```yaml\n",
    "version: '3'\n",
    "services:\n",
    "  my-container:\n",
    "    image: nginx\n",
    "    deploy:\n",
    "      resources:\n",
    "        limits:\n",
    "          cpus: '1'\n",
    "          memory: 512m\n",
    "      reservations:\n",
    "          cpus: '0.5'\n",
    "          memory: 256m\n",
    "```\n",
    "\n",
    "## Modificar los límites en caliente\n",
    "Si necesitamos modificar los límites de un contenedor en caliente, podemos hacerlo con el comando `docker update`:\n",
    "```shell\n",
    "docker update --memory 1g my-container\n",
    "```\n",
    "\n",
    "## Conclusión\n",
    "Limitar los recursos de un contenedor es una buena práctica para evitar que un contenedor consuma todos los recursos de la máquina y deje de funcionar. Del mismo modo, reservar una cantidad mínima de recursos garantiza que el contenedor tenga siempre los recursos necesarios para funcionar correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 202. Buildx y Multiarquitectura\n",
    "\n",
    "Cada vez es más común tener que crear imágenes de contenedores para distintas arquitecturas. Por ejemplo, si tienes un servidor con una arquitectura ARM, raspberry PI, un Mac con los procesadores M o los PC windows con qualcomm, necesitarás crear imágenes para cada una de estas arquitecturas.\n",
    "\n",
    "La verdad que Docker nos lo pone fácil con la herramienta `Buildx`, que nos permite crear imágenes multiarquitectura de forma sencilla. \n",
    "\n",
    "Dentro vídeo: https://youtu.be/umfTMXWgLlo\n",
    "\n",
    "## Que arquitecturas soporta Docker\n",
    "Docker soporta principalmente las siguientes arquitecturas:\n",
    "- `amd64`: Arquitectura de 64 bits, la más común en los PC de sobremesa y servidores.\n",
    "- `arm64`: Arquitectura de 64 bits, común en dispositivos embebidos y raspberry PI.\n",
    "\n",
    "## Ejecutar imágenes de otras arquitecturas\n",
    "Docker nos permite ejecutar imágenes de otras arquitecturas en nuestro sistema. Para ejecutar una imagen de otra arquitectura, simplemente tenemos que especificar la arquitectura en el comando `docker run`:\n",
    "```shell\n",
    "docker run --platform amd64 nginx\n",
    "```\n",
    "\n",
    "Esto buscará el manifiesto de la imagen `nginx` para la arquitectura `amd64` y usará QEMU para emular la arquitectura.\n",
    "\n",
    "## Crear imágenes multiarquitectura con Docker Buildx\n",
    "Docker Buildx es una herramienta que nos permite crear imágenes multiarquitectura de forma sencilla.\n",
    "\n",
    "Para crear una imagen multiarquitectura, primero tenemos que crear un builder con `docker buildx create`:\n",
    "```shell\n",
    "docker buildx create --name mybuilder\n",
    "```\n",
    "\n",
    "Para construir una imagen multiarquitectura:\n",
    "```shell\n",
    "docker buildx build --platform linux/amd64,linux/arm64 -t pabpereza/nginx .\n",
    "```\n",
    "\n",
    "## Resumen\n",
    "En este capítulo hemos visto como ejecutar imágenes de otras arquitecturas con Docker y como construir imágenes multiarquitectura con Docker Buildx. Esto nos permitirá crear imágenes para distintas arquitecturas de forma sencilla y sin tener que preocuparnos de la arquitectura de nuestro sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 203. Multi-Stage y Distroless\n",
    "\n",
    "En el desarrollo de aplicaciones modernas, la optimización de las imágenes de Docker es crucial para mejorar el rendimiento, reducir los tiempos de despliegue y aumentar la seguridad. En este capítulo aprenderemos dos técnicas fundamentales: los Dockerfiles multi-stage y las imágenes distroless.\n",
    "\n",
    "Estas técnicas nos permiten crear imágenes más pequeñas, seguras y eficientes, separando el entorno de construcción del entorno de ejecución y eliminando componentes innecesarios.\n",
    "\n",
    "## ¿Qué son los Dockerfiles Multi-Stage?\n",
    "Los Dockerfiles multi-stage son una característica de Docker que permite utilizar múltiples instrucciones `FROM` en un mismo Dockerfile. Cada instruccción `FROM` inicia una nueva etapa de construcción, y puedes copiar selectivamente artefactos de una etapa a otra.\n",
    "\n",
    "Es decir, podríamos utilizar una imagen con todos los herramientas necesarias para la construcción y otra imagen más ligera para la ejecución. Ya que no necesitamos incluir herramientas como compiladores, gestores de paquetes, etc... en la imagen final.\n",
    "\n",
    "### Ventajas de los Multi-Stage Builds\n",
    "- **Imágenes más pequeñas**: Solo incluyen los archivos necesarios para ejecutar la aplicación.\n",
    "- **Mayor seguridad**: Eliminan herramientas de desarrollo y dependencias no necesarias.\n",
    "- **Mejor rendimiento**: Menos datos que transferir y almacenar.\n",
    "\n",
    "## Ejemplo Básico de Multi-Stage\n",
    "Veamos un ejemplo simple con una aplicación Go:\n",
    "\n",
    "```dockerfile\n",
    "# Etapa de construcción\n",
    "FROM golang:1.21 AS builder\n",
    "WORKDIR /app\n",
    "COPY go.mod go.sum ./\n",
    "RUN go mod download\n",
    "COPY . .\n",
    "RUN CGO_ENABLED=0 GOOS=linux go build -o main .\n",
    "\n",
    "# Etapa de ejecución\n",
    "FROM alpine:latest\n",
    "RUN apk --no-cache add ca-certificates\n",
    "WORKDIR /root/\n",
    "COPY --from=builder /app/main .\n",
    "CMD [\"./main\"]\n",
    "```\n",
    "\n",
    "## Resumen\n",
    "Los Dockerfiles multi-stage y las imágenes distroless son técnicas esenciales para crear contenedores optimizados. Permiten:\n",
    "- Reducir significativamente el tamaño de las imágenes\n",
    "- Mejorar la seguridad eliminando componentes innecesarios\n",
    "- Acelerar los despliegues y reducir los costos de almacenamiento\n",
    "- Mantener un entorno de producción limpio y controlado"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
