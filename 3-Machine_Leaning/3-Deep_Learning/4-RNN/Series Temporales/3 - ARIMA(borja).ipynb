{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast quality metrics\n",
    "\n",
    "Before we begin forecasting, let's understand how to measure the quality of our predictions and take a look at the most commonly used metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [R squared](http://scikit-learn.org/stable/modules/model_evaluation.html#r2-score-the-coefficient-of-determination): coefficient of determination (in econometrics, this can be interpreted as the percentage of variance explained by the model), $(-\\infty, 1]$\n",
    "\n",
    "$R^2 = 1 - \\frac{SS_{res}}{SS_{tot}}$ \n",
    "\n",
    "```python\n",
    "sklearn.metrics.r2_score\n",
    "```\n",
    "---\n",
    "- [Mean Absolute Error](http://scikit-learn.org/stable/modules/model_evaluation.html#mean-absolute-error): this is an interpretable metric because it has the same unit of measurment as the initial series, $[0, +\\infty)$\n",
    "\n",
    "$MAE = \\frac{\\sum\\limits_{i=1}^{n} |y_i - \\hat{y}_i|}{n}$ \n",
    "\n",
    "```python\n",
    "sklearn.metrics.mean_absolute_error\n",
    "```\n",
    "---\n",
    "- [Median Absolute Error](http://scikit-learn.org/stable/modules/model_evaluation.html#median-absolute-error): again, an interpretable metric that is particularly interesting because it is robust to outliers, $[0, +\\infty)$\n",
    "\n",
    "$MedAE = median(|y_1 - \\hat{y}_1|, ... , |y_n - \\hat{y}_n|)$\n",
    "\n",
    "```python\n",
    "sklearn.metrics.median_absolute_error\n",
    "```\n",
    "---\n",
    "- [Mean Squared Error](http://scikit-learn.org/stable/modules/model_evaluation.html#mean-squared-error): the most commonly used metric that gives a higher penalty to large errors and vice versa, $[0, +\\infty)$\n",
    "\n",
    "$MSE = \\frac{1}{n}\\sum\\limits_{i=1}^{n} (y_i - \\hat{y}_i)^2$\n",
    "\n",
    "```python\n",
    "sklearn.metrics.mean_squared_error\n",
    "```\n",
    "---\n",
    "- [Mean Squared Logarithmic Error](http://scikit-learn.org/stable/modules/model_evaluation.html#mean-squared-logarithmic-error): practically, this is the same as MSE, but we take the logarithm of the series. As a result, we give more weight to small mistakes as well. This is usually used when the data has exponential trends, $[0, +\\infty)$\n",
    "\n",
    "$MSLE = \\frac{1}{n}\\sum\\limits_{i=1}^{n} (log(1+y_i) - log(1+\\hat{y}_i))^2$\n",
    "\n",
    "```python\n",
    "sklearn.metrics.mean_squared_log_error\n",
    "```\n",
    "---\n",
    "- Mean Absolute Percentage Error: this is the same as MAE but is computed as a percentage, which is very convenient when you want to explain the quality of the model to management, $[0, +\\infty)$\n",
    "\n",
    "$MAPE = \\frac{100}{n}\\sum\\limits_{i=1}^{n} \\frac{|y_i - \\hat{y}_i|}{y_i}$ \n",
    "\n",
    "```python\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analítica\n",
    "Vamos a utilizar los datos de ventas de Johnson&Johnson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# IMPORTACIÓN DE LIBRERÍAS NECESARIAS\n",
    "# ============================================\n",
    "\n",
    "# Librerías para análisis de series temporales (statsmodels)\n",
    "from statsmodels.tsa.stattools import pacf  # Función de autocorrelación parcial\n",
    "from statsmodels.tsa.stattools import acf   # Función de autocorrelación\n",
    "from statsmodels.graphics.tsaplots import plot_pacf  # Gráfico de autocorrelación parcial\n",
    "from statsmodels.graphics.tsaplots import plot_acf   # Gráfico de autocorrelación\n",
    "from statsmodels.tsa.stattools import adfuller  # Test de Dickey-Fuller para estacionariedad\n",
    "\n",
    "# Librería pmdarima: facilita la creación de modelos ARIMA con búsqueda automática\n",
    "from pmdarima.arima import auto_arima  # Búsqueda automática de mejores parámetros ARIMA\n",
    "from pmdarima.arima import ARIMA  # Modelo ARIMA\n",
    "\n",
    "# Librerías básicas de visualización y análisis de datos\n",
    "import matplotlib.pyplot as plt  # Para crear gráficos\n",
    "import pandas as pd  # Para manipulación de datos tabulares\n",
    "import numpy as np  # Para operaciones numéricas\n",
    "from sklearn.metrics import mean_squared_error  # Métrica para evaluar el error del modelo\n",
    "\n",
    "# Configuración para ignorar warnings que pueden ensuciar la salida\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si no tienes instalada la librería pmdarima, descomenta la siguiente línea:\n",
    "#!pip install pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CARGA DE DATOS DE JOHNSON & JOHNSON\n",
    "# ============================================\n",
    "\n",
    "# Cargamos el dataset de ventas trimestrales de Johnson & Johnson\n",
    "# index_col=0 indica que la primera columna será el índice (fechas)\n",
    "data = pd.read_csv('data/jj.csv', index_col=0)\n",
    "\n",
    "# Verificamos cuántos registros tenemos en total\n",
    "print(len(data))  # Debemos tener 84 observaciones trimestrales\n",
    "\n",
    "# Mostramos las primeras 5 filas para entender la estructura de los datos\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# VISUALIZACIÓN DE LA SERIE TEMPORAL\n",
    "# ============================================\n",
    "\n",
    "# Graficamos la serie temporal completa para identificar patrones visuales\n",
    "# figsize=(15,6) define un gráfico ancho para apreciar mejor la evolución temporal\n",
    "data['data'].plot(figsize=(15,6))\n",
    "\n",
    "# OBSERVACIONES IMPORTANTES:\n",
    "# - Se observa una tendencia creciente a lo largo del tiempo\n",
    "# - La varianza parece aumentar con el tiempo (heterocedasticidad)\n",
    "# - Posible presencia de estacionalidad (patrones repetitivos)\n",
    "# Esto indica que la serie NO es estacionaria y necesitará diferenciación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aprecia en la gráfica que presenta diferentes estadísticos a lo largo del tiempo.\n",
    "\n",
    "Representamos su gráfica de autocorrelación. Vemos que tenemos muy complicado determinar el orden p y q, de cara al modelo ARIMA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ANÁLISIS DE AUTOCORRELACIÓN (ACF)\n",
    "# ============================================\n",
    "\n",
    "# El gráfico ACF muestra la correlación de la serie consigo misma en diferentes lags (retrasos)\n",
    "plot_acf(data['data'])\n",
    "\n",
    "# INTERPRETACIÓN:\n",
    "# - Si vemos que las barras decaen muy lentamente, indica NO estacionariedad\n",
    "# - Las barras que salen de la zona sombreada son estadísticamente significativas\n",
    "# - Este gráfico nos ayudará a determinar el parámetro 'q' del modelo ARIMA\n",
    "# - En este caso, la autocorrelación se mantiene alta por muchos lags, \n",
    "#   confirmando que necesitamos diferenciar la serie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos en train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# DIVISIÓN DE DATOS EN TRAIN Y TEST\n",
    "# ============================================\n",
    "\n",
    "# Extraemos todos los valores de la columna 'data' como un array numpy\n",
    "X = data['data'].values\n",
    "\n",
    "# Dividimos los datos:\n",
    "# - train: primeros 70 registros (aproximadamente 83% de los datos)\n",
    "# - test: últimos 14 registros (aproximadamente 17% de los datos)\n",
    "train = X[:70]\n",
    "test = X[70:]\n",
    "\n",
    "# Esta división nos permitirá:\n",
    "# 1. Entrenar el modelo con los datos históricos (train)\n",
    "# 2. Evaluar su capacidad predictiva con datos no vistos (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos la forma del array completo\n",
    "# Debería mostrar (84,) indicando 84 observaciones en una dimensión\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos cuántas observaciones tenemos en el conjunto de test\n",
    "# Debería mostrar 14 registros que usaremos para validar nuestras predicciones\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoregressive\n",
    "Tendremos que encontrar el orden de autoregression que mejor encaje con nuestros datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# MODELO AUTOREGRESIVO AR(1,0,0)\n",
    "# ============================================\n",
    "\n",
    "# Creamos un modelo AR puro con orden (p=1, d=0, q=0)\n",
    "# - p=1: usamos solo 1 lag (observación anterior) para predecir\n",
    "# - d=0: no aplicamos diferenciación (asumimos estacionariedad)\n",
    "# - q=0: no usamos errores de predicción pasados\n",
    "model_ar = ARIMA(order=(1,0,0))\n",
    "\n",
    "# Ajustamos (entrenamos) el modelo con nuestros datos de entrenamiento\n",
    "model_ar.fit(train)\n",
    "\n",
    "# NOTA: Un modelo AR predice valores futuros basándose únicamente en valores pasados\n",
    "# Formula: Y_t = c + φ₁*Y_{t-1} + error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# EVALUACIÓN DEL MODELO AR(1,0,0)\n",
    "# ============================================\n",
    "\n",
    "# Generamos predicciones para los próximos 14 periodos (tamaño del conjunto test)\n",
    "predictions = model_ar.predict(14)\n",
    "\n",
    "# Calculamos el Error Cuadrático Medio (MSE) para evaluar la calidad del modelo\n",
    "# MSE mide el promedio de los errores al cuadrado\n",
    "# Valores más bajos indican mejores predicciones\n",
    "print(\"mean_squared_error:\", mean_squared_error(test, predictions))\n",
    "\n",
    "# INTERPRETACIÓN:\n",
    "# Un MSE de ~13.7 indica que las predicciones están bastante alejadas de los valores reales\n",
    "# Esto sugiere que AR(1,0,0) no es adecuado para estos datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos las predicciones generadas por el modelo AR(1,0,0)\n",
    "# Notaremos que son valores decrecientes que tienden a estabilizarse\n",
    "model_ar.predict(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirmamos que el conjunto test tiene 14 observaciones\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# COMPARACIÓN VISUAL: VALORES REALES VS PREDICCIONES\n",
    "# ============================================\n",
    "\n",
    "# Graficamos los valores reales del conjunto test (en azul)\n",
    "plt.plot(test)\n",
    "\n",
    "# Superponemos las predicciones del modelo (en rojo)\n",
    "plt.plot(predictions, color='red')\n",
    "\n",
    "# ANÁLISIS VISUAL:\n",
    "# - La línea azul muestra los valores reales\n",
    "# - La línea roja muestra nuestras predicciones\n",
    "# - Si las líneas están muy separadas, el modelo no está capturando bien el patrón\n",
    "# - En este caso, vemos que el modelo AR(1,0,0) NO predice bien la tendencia creciente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No parece que de buen resultado el AR(1,0,0). Probemos diferentes lags, a ver cuál sería el mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# BÚSQUEDA DEL MEJOR PARÁMETRO 'p' PARA AR\n",
    "# ============================================\n",
    "\n",
    "# Vamos a probar diferentes valores de 'p' (número de lags) para encontrar el mejor\n",
    "lags = []  # Almacenaremos los valores de p probados\n",
    "mse = []   # Almacenaremos el MSE correspondiente a cada p\n",
    "\n",
    "# Iteramos desde p=1 hasta p=14\n",
    "for lag in range(1, 15):\n",
    "    try:\n",
    "        # Creamos un modelo AR con el valor actual de p\n",
    "        # order=(lag, 0, 0) significa AR(p) puro, sin diferenciación ni MA\n",
    "        model_ar = ARIMA(order=(lag, 0, 0))\n",
    "        model_ar.fit(train)\n",
    "        \n",
    "        # Guardamos el lag probado\n",
    "        lags.append(lag)\n",
    "        \n",
    "        # Generamos predicciones y calculamos el error\n",
    "        predictions = model_ar.predict(14)\n",
    "        mse.append(mean_squared_error(test, predictions))\n",
    "    except:\n",
    "        # Algunos valores de p pueden causar errores (ej: sobreajuste)\n",
    "        # En ese caso, simplemente continuamos con el siguiente\n",
    "        continue\n",
    "\n",
    "# Graficamos la evolución del MSE según el valor de p\n",
    "# Buscamos el punto más bajo de la curva\n",
    "plt.plot(lags, mse)\n",
    "\n",
    "# INTERPRETACIÓN:\n",
    "# - El MSE disminuye conforme aumentamos p, pero sigue siendo alto\n",
    "# - Esto confirma que un modelo AR puro no es suficiente para estos datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos nuevamente el gráfico ACF para el conjunto de entrenamiento\n",
    "# Esto nos ayuda a entender por qué los modelos AR puros no funcionan bien\n",
    "plot_acf(train)\n",
    "\n",
    "# La autocorrelación alta en muchos lags sugiere que necesitamos:\n",
    "# 1. Aplicar diferenciación (parámetro d > 0)\n",
    "# 2. O incluir componentes de Media Móvil (parámetro q > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un parámetro p>5 parece que da buen resultado, pero aun asi es muy alto el error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Average\n",
    "En este caso tendremos en cuenta los errores. El problema es que si tenemos muchos errores al principio, los iremos arrastrando durante las predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# MODELO DE MEDIA MÓVIL MA(0,0,1)\n",
    "# ============================================\n",
    "\n",
    "# Creamos un modelo MA puro con orden (p=0, d=0, q=1)\n",
    "# - p=0: no usamos valores pasados de la serie\n",
    "# - d=0: no aplicamos diferenciación\n",
    "# - q=1: usamos 1 error de predicción pasado\n",
    "model_ma = ARIMA(order=(0, 0, 1))\n",
    "\n",
    "# Ajustamos el modelo\n",
    "model_ma.fit(train)\n",
    "\n",
    "# NOTA: Un modelo MA predice valores futuros basándose en errores de predicción pasados\n",
    "# Formula: Y_t = μ + error_t + θ₁*error_{t-1}\n",
    "# donde error_t es la diferencia entre el valor real y el predicho en el momento t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# EVALUACIÓN DEL MODELO MA(0,0,1)\n",
    "# ============================================\n",
    "\n",
    "# Generamos predicciones para los 14 periodos del conjunto test\n",
    "predictions = model_ma.predict(14)\n",
    "\n",
    "# Calculamos el MSE\n",
    "print(\"mean_squared_error:\", mean_squared_error(test, predictions))\n",
    "\n",
    "# INTERPRETACIÓN:\n",
    "# MSE de ~87.15 es MUCHO PEOR que el modelo AR(1,0,0) que tenía ~13.7\n",
    "# Esto indica que un modelo MA puro tampoco es adecuado\n",
    "# El problema es que los errores iniciales se van propagando y acumulando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparación visual: valores reales (azul) vs predicciones MA (rojo)\n",
    "plt.plot(test)\n",
    "plt.plot(predictions, color='red')\n",
    "\n",
    "# Como podemos ver, las predicciones son casi constantes y no capturan\n",
    "# la tendencia creciente de los datos reales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No está dando buen resultado. Probaremos entonces varios lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# BÚSQUEDA DEL MEJOR PARÁMETRO 'q' PARA MA\n",
    "# ============================================\n",
    "\n",
    "# Probamos diferentes valores de q (orden del componente MA)\n",
    "lags = []\n",
    "mse = []\n",
    "\n",
    "for lag in range(1, 20):\n",
    "    try:\n",
    "        # Creamos modelo MA(0, 0, q) con diferentes valores de q\n",
    "        model_ar = ARIMA(order=(0, 0, lag))\n",
    "        model_ar_fit = model_ar.fit(train)\n",
    "        \n",
    "        # Generamos predicciones\n",
    "        predictions = model_ar_fit.predict(14)\n",
    "        \n",
    "        # Almacenamos resultados\n",
    "        lags.append(lag)\n",
    "        mse.append(mean_squared_error(test, predictions))\n",
    "    except:\n",
    "        # Algunos valores pueden causar problemas de convergencia\n",
    "        continue\n",
    "\n",
    "# Graficamos MSE vs valor de q    \n",
    "plt.plot(lags, mse)\n",
    "\n",
    "# OBSERVACIÓN:\n",
    "# El error disminuye conforme aumenta q, pero sigue siendo muy alto\n",
    "# Necesitamos combinar AR y MA, además de aplicar diferenciación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que según vamos aumentando el parámetro `q` del modelo Moving Average, va disminuyendo el error, pero aun así es bastante grande."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA\n",
    "En el arima no solo influyen los parámetros `p` y `q`, sino que también tendremos en cuenta `d`. Parametro con el que diferenciaremos la serie y conseguiremos que sea estacionaria.\n",
    "\n",
    "Ahora bien, ¿cuál es la mejor combinación de parámetros? Tendremos que realizar varias pruebas. Para comparar los modelos se suele utilizar el AIC.\n",
    "\n",
    "### AIC\n",
    "Akaike’s Information Criterion\n",
    "\n",
    "\n",
    "k es el número de parámetros del modelo estadístico y L es el máximo valor de la función de verosimilitud para el modelo estimado. La función de verosimilitud permite realizar inferencias a partir de u conjunto de observaciones.\n",
    "\n",
    "Se utiliza para seleccionar el mejor modelo, que será el que tiene menor AIC. El AIC depende mucho de cada dato, y es una medida de comparación entre modelos, no de presentación de resultados. Un AIC bajo no quiere decir que el modelo sea muy bueno. Por tanto, AIC no nos dice nada sobre la calidad del modelo en terminos absolutos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿Cómo conseguir los mejores p, d, q?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# GENERACIÓN DE COMBINACIONES DE PARÁMETROS PARA ARIMA\n",
    "# ============================================\n",
    "\n",
    "import itertools\n",
    "\n",
    "# Definimos los rangos de búsqueda para cada parámetro\n",
    "p = d = q = range(0, 5)  # Probaremos valores de 0 a 4 para p, d y q\n",
    "\n",
    "# Generamos todas las combinaciones posibles de (p, d, q)\n",
    "# itertools.product crea el producto cartesiano\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "\n",
    "# Mostramos las primeras 6 combinaciones como ejemplo\n",
    "pdq[:6]\n",
    "\n",
    "# Esto generará 5×5×5 = 125 combinaciones posibles\n",
    "# Ejemplo de combinaciones:\n",
    "# (0,0,0) → modelo trivial sin parámetros\n",
    "# (1,0,0) → AR(1) puro\n",
    "# (0,0,1) → MA(1) puro\n",
    "# (1,1,1) → ARIMA con todos los componentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# BÚSQUEDA EXHAUSTIVA DEL MEJOR MODELO ARIMA\n",
    "# ============================================\n",
    "\n",
    "results = []  # Lista para almacenar los resultados\n",
    "\n",
    "# Probamos todas las combinaciones de (p, d, q)\n",
    "for param in pdq:\n",
    "    try:\n",
    "        # Creamos y ajustamos el modelo ARIMA con los parámetros actuales\n",
    "        model_arima = ARIMA(order=param)\n",
    "        model_arima_fit = model_arima.fit(train)\n",
    "        \n",
    "        # Guardamos la combinación de parámetros y su AIC\n",
    "        # AIC (Akaike Information Criterion) mide la calidad del modelo\n",
    "        # Valores más bajos de AIC indican mejores modelos\n",
    "        results.append((param, model_arima_fit.aic()))\n",
    "    except:\n",
    "        # Algunas combinaciones pueden no converger o causar errores\n",
    "        # En esos casos, simplemente las omitimos\n",
    "        continue\n",
    "\n",
    "# NOTA IMPORTANTE:\n",
    "# Estamos usando AIC en lugar de MSE porque:\n",
    "# 1. AIC penaliza la complejidad del modelo (evita sobreajuste)\n",
    "# 2. Balancea precisión y simplicidad\n",
    "# 3. Es el criterio estándar para selección de modelos ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ANÁLISIS DE RESULTADOS: MEJORES MODELOS\n",
    "# ============================================\n",
    "\n",
    "# Convertimos los resultados a un DataFrame para facilitar el análisis\n",
    "resultados_df = pd.DataFrame(results, columns=['ARIMA params', 'AIC'])\n",
    "\n",
    "# Ordenamos por AIC ascendente (menor AIC = mejor modelo)\n",
    "resultados_df = resultados_df.sort_values('AIC')\n",
    "\n",
    "# Mostramos los 5 mejores modelos\n",
    "resultados_df.head()\n",
    "\n",
    "# INTERPRETACIÓN:\n",
    "# El mejor modelo es ARIMA(3,2,2) con AIC ≈ 36.90\n",
    "# - p=3: usa los últimos 3 valores de la serie\n",
    "# - d=2: aplica diferenciación de segundo orden (elimina tendencia y curva)\n",
    "# - q=2: usa los últimos 2 errores de predicción\n",
    "# \n",
    "# La diferenciación de orden 2 es clave aquí, ya que indica que\n",
    "# la serie tiene una tendencia no lineal que requiere doble diferenciación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos la mejor combinación de parámetros para el ARIMA. Probemos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ENTRENAMIENTO DEL MEJOR MODELO ARIMA(3,2,2)\n",
    "# ============================================\n",
    "\n",
    "# Creamos el modelo con los mejores parámetros encontrados\n",
    "best_model = ARIMA(order=(3, 2, 2))\n",
    "\n",
    "# Ajustamos el modelo con los datos de entrenamiento\n",
    "best_model.fit(train)\n",
    "\n",
    "# Este modelo combina:\n",
    "# - Componente autorregresivo de orden 3 (AR(3))\n",
    "# - Diferenciación de segundo orden (I(2))\n",
    "# - Componente de media móvil de orden 2 (MA(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# EVALUACIÓN DEL MEJOR MODELO\n",
    "# ============================================\n",
    "\n",
    "# Generamos predicciones para el conjunto test\n",
    "predictions = best_model.predict(14)\n",
    "\n",
    "# Calculamos el MSE\n",
    "print(\"mean_squared_error:\", mean_squared_error(test, predictions))\n",
    "\n",
    "# COMPARACIÓN DE RESULTADOS:\n",
    "# - AR(1,0,0): MSE ≈ 13.70\n",
    "# - MA(0,0,1): MSE ≈ 87.15\n",
    "# - ARIMA(3,2,2): MSE ≈ 3.93 ← ¡MUCHO MEJOR!\n",
    "#\n",
    "# El MSE se redujo significativamente, demostrando que:\n",
    "# 1. La diferenciación era necesaria para eliminar la tendencia\n",
    "# 2. Combinar componentes AR y MA mejora las predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# AUTO_ARIMA: BÚSQUEDA AUTOMÁTICA DE PARÁMETROS\n",
    "# ============================================\n",
    "\n",
    "# auto_arima es una función que automatiza la búsqueda de los mejores parámetros\n",
    "model = auto_arima(train,\n",
    "                   start_p=1,      # Valor inicial de p para la búsqueda\n",
    "                   start_q=1,      # Valor inicial de q para la búsqueda\n",
    "                   max_p=5,        # Valor máximo de p a probar\n",
    "                   max_q=5,        # Valor máximo de q a probar\n",
    "                   max_d=3,        # Valor máximo de d a probar\n",
    "                   trace=True)     # Mostrar el proceso de búsqueda\n",
    "\n",
    "# VENTAJAS DE AUTO_ARIMA:\n",
    "# 1. No necesitas probar manualmente todas las combinaciones\n",
    "# 2. Usa búsqueda stepwise (más eficiente que grid search)\n",
    "# 3. Aplica tests estadísticos para determinar d automáticamente\n",
    "# 4. Minimiza el AIC por defecto\n",
    "#\n",
    "# El parámetro trace=True nos muestra cada modelo probado y su AIC,\n",
    "# permitiéndonos ver el proceso de optimización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# RESUMEN DEL MODELO ENCONTRADO POR AUTO_ARIMA\n",
    "# ============================================\n",
    "\n",
    "# Recreamos el modelo con los parámetros óptimos encontrados\n",
    "model = ARIMA(order=(3, 2, 2))\n",
    "model.fit(train)\n",
    "\n",
    "# Mostramos el resumen estadístico completo del modelo\n",
    "print(model.summary())\n",
    "\n",
    "# EL RESUMEN INCLUYE:\n",
    "# 1. Coeficientes estimados: valores de los parámetros AR y MA\n",
    "# 2. P-valores: significancia estadística de cada coeficiente\n",
    "# 3. AIC/BIC: criterios de información para comparar modelos\n",
    "# 4. Tests de diagnóstico:\n",
    "#    - Ljung-Box: verifica si los residuos son ruido blanco\n",
    "#    - Jarque-Bera: verifica normalidad de los residuos\n",
    "#    - Heteroskedasticity: verifica varianza constante de los residuos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMAX\n",
    "La X viene de exogenous. Significa que le podemos añadir una variable externa con la que entrenar el modelo.\n",
    "\n",
    "Vamos a probar con los datos de la bolsa. Primero un auto_arima con los datos a cierre. Y después un auto_arima acompañado de los datos de apertura de bolsa, a ver cuánto ayudan a predecir el cierre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CARGA DE DATOS DE BOLSA (FACEBOOK)\n",
    "# ============================================\n",
    "\n",
    "# Cargamos datos históricos de acciones de Facebook\n",
    "stock_df = pd.read_csv('data/FB.csv', header=0, index_col=0)\n",
    "\n",
    "# Verificamos la cantidad de registros\n",
    "print(len(stock_df))  # 1259 días de cotizaciones\n",
    "\n",
    "# Mostramos las primeras filas\n",
    "stock_df.head()\n",
    "\n",
    "# COLUMNAS DEL DATASET:\n",
    "# - Open: precio de apertura\n",
    "# - High: precio máximo del día\n",
    "# - Low: precio mínimo del día\n",
    "# - Close: precio de cierre (variable objetivo)\n",
    "# - Adj Close: precio ajustado por dividendos/splits\n",
    "# - Volume: volumen de transacciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos la evolución del precio de cierre a lo largo del tiempo\n",
    "stock_df['Close'].plot(figsize=(15, 6))\n",
    "\n",
    "# Se observa alta volatilidad, tendencias cambiantes y posibles patrones\n",
    "# que podrían ser capturados por un modelo ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos primero ejemplo sin variable exogena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# DIVISIÓN TRAIN/TEST PARA DATOS DE BOLSA\n",
    "# ============================================\n",
    "\n",
    "# Dividimos los datos:\n",
    "# - train: primeros 1240 días (98.5% de los datos)\n",
    "# - test: últimos 19 días (1.5% de los datos)\n",
    "train = stock_df['Close'][0:1240].values\n",
    "test = stock_df['Close'][1240:].values\n",
    "\n",
    "# Usamos solo la columna 'Close' porque queremos predecir el precio de cierre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a probar varios ARIMAS, a ver cuál sería la mejor combinación de hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# AUTO_ARIMA SIN VARIABLE EXÓGENA (BASELINE)\n",
    "# ============================================\n",
    "\n",
    "# Primero probamos un ARIMA tradicional sin información adicional\n",
    "stepwise_model = auto_arima(train,\n",
    "                            start_p=1,\n",
    "                            start_q=1,\n",
    "                            max_d=3,\n",
    "                            max_p=5,\n",
    "                            max_q=5,\n",
    "                            stationary=False,  # No asumimos estacionariedad\n",
    "                            trace=True,         # Mostramos el proceso\n",
    "                            stepwise=True)      # Búsqueda stepwise (más rápida)\n",
    "\n",
    "# Mostramos el AIC del mejor modelo encontrado\n",
    "print(stepwise_model.aic())\n",
    "\n",
    "# Este modelo solo usa información histórica del precio de cierre\n",
    "# No incorpora ninguna otra variable que pudiera ayudar a predecir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya lo tenemos, ahora montaremos el modelo con esos hiperparámetros y vemos que AIC tiene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el modelo con los parámetros encontrados: ARIMA(1,1,1)\n",
    "model = ARIMA(order=(1, 1, 1))\n",
    "model.fit(train)\n",
    "\n",
    "# Mostramos el resumen completo\n",
    "print(model.summary())\n",
    "\n",
    "# El AIC resultante es ~5973.08\n",
    "# Este será nuestro punto de referencia (baseline) para comparar\n",
    "# con el modelo ARIMAX que incluirá variables exógenas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos predicciones para los 19 días de test\n",
    "predictions = model.predict(19)\n",
    "\n",
    "# Calculamos el MSE\n",
    "print(\"mean_squared_error:\", mean_squared_error(test, predictions))\n",
    "\n",
    "# MSE ≈ 45.03 indica el error promedio al cuadrado de nuestras predicciones\n",
    "# Usaremos este valor para comparar con el modelo ARIMAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ahora a compararlo con el mismo modelo, pero en este caso le añadimos una variable exogena al entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos la forma de los datos de apertura que usaremos como variable exógena\n",
    "# Los transformamos en un array 2D con reshape(-1, 1) porque ARIMA lo requiere\n",
    "stock_df[['Open']][:1240].values\n",
    "\n",
    "# La variable exógena 'Open' (precio de apertura) puede ayudar a predecir 'Close'\n",
    "# porque existe correlación entre el precio de apertura y cierre del mismo día"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ARIMAX: ARIMA CON VARIABLE EXÓGENA\n",
    "# ============================================\n",
    "\n",
    "# Creamos el mismo modelo ARIMA(1,1,1) pero ahora incluyendo información adicional\n",
    "model = ARIMA(order=(1, 1, 1))\n",
    "\n",
    "# Ajustamos el modelo pasando la variable exógena 'Open' (precio de apertura)\n",
    "# exogeneous: datos externos que pueden ayudar a mejorar las predicciones\n",
    "# reshape(-1, 1): convierte el array a formato columna (requerido por ARIMA)\n",
    "model.fit(train, exogeneous=stock_df['Open'][:1240].values.reshape(-1, 1))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# CONCEPTO CLAVE - ARIMAX:\n",
    "# La \"X\" en ARIMAX significa \"eXogenous\" (variable externa)\n",
    "# El modelo ahora considera:\n",
    "# 1. Valores pasados de Close (componente AR)\n",
    "# 2. Diferencias de Close (componente I)\n",
    "# 3. Errores pasados (componente MA)\n",
    "# 4. + Precio de apertura como predictor adicional (componente X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce bastante el AIC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos a entrenar el auto arima con la variable exogena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# AUTO_ARIMA CON UNA VARIABLE EXÓGENA\n",
    "# ============================================\n",
    "\n",
    "# Ahora dejamos que auto_arima encuentre los mejores parámetros\n",
    "# pero incluyendo la variable exógena 'Open'\n",
    "model = auto_arima(train,\n",
    "                   # Variable exógena: precio de apertura\n",
    "                   exogeneous=stock_df['Open'][:1240].values.reshape(-1, 1),\n",
    "                   start_p=1,\n",
    "                   start_q=1,\n",
    "                   max_d=3,\n",
    "                   max_p=5,\n",
    "                   max_q=5,\n",
    "                   stationary=False,\n",
    "                   trace=True,\n",
    "                   stepwise=True)\n",
    "\n",
    "print(model.aic())\n",
    "\n",
    "# COMPARACIÓN:\n",
    "# - ARIMA sin variable exógena: AIC ≈ 5973.08\n",
    "# - ARIMAX con 'Open': AIC ≈ 5973.08 (similar)\n",
    "#\n",
    "# En este caso, añadir 'Open' no mejora significativamente el modelo\n",
    "# porque 'Open' y 'Close' están muy correlacionados de forma lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos varias variables exogenas\n",
    "\n",
    "NOTA: para este apartado se utiliza el valor 'Low', que en la vida real no lo tendriamos para realizar la predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ARIMAX CON MÚLTIPLES VARIABLES EXÓGENAS\n",
    "# ============================================\n",
    "\n",
    "# Probamos con DOS variables exógenas: 'Open' y 'Low'\n",
    "model = auto_arima(train,\n",
    "                   # NOTA: usamos [['Open', 'Low']] para seleccionar múltiples columnas\n",
    "                   exogeneous=stock_df[['Open', 'Low']][:1240].values,\n",
    "                   start_p=1,\n",
    "                   start_q=1,\n",
    "                   max_d=3,\n",
    "                   max_p=5,\n",
    "                   max_q=5,\n",
    "                   stationary=False,\n",
    "                   trace=True,\n",
    "                   stepwise=True)\n",
    "\n",
    "print(model.aic())\n",
    "\n",
    "# ADVERTENCIA IMPORTANTE:\n",
    "# Este ejemplo usa 'Low' (precio mínimo del día) como variable exógena\n",
    "# En la vida real, NO tendríamos el valor 'Low' del día al momento de\n",
    "# predecir el precio de cierre, porque ambos ocurren simultáneamente\n",
    "# \n",
    "# Variables exógenas válidas serían:\n",
    "# - Indicadores técnicos calculados con datos pasados\n",
    "# - Volumen de transacciones del día anterior\n",
    "# - Índices de mercado externos\n",
    "# - Sentimiento de noticias, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARIMA\n",
    "Veamos cómo podemos predecir con datos que tienen estacionalidad, es decir, que cuentan con un patrón que se repite a lo largo del tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CARGA DE DATOS CON ESTACIONALIDAD\n",
    "# ============================================\n",
    "\n",
    "# Cargamos datos de ventas de medicamentos antidiabéticos en Australia\n",
    "# parse_dates: convierte la columna 'date' a formato datetime\n",
    "# index_col: usa 'date' como índice del DataFrame\n",
    "df = pd.read_csv('data/a10.csv', parse_dates=['date'], index_col='date')\n",
    "\n",
    "print(len(df))  # 204 observaciones mensuales\n",
    "df.head()\n",
    "\n",
    "# Estos datos tienen un patrón estacional (se repite anualmente)\n",
    "# porque las ventas de medicamentos pueden variar según la época del año"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos la serie temporal\n",
    "df['value'].plot(figsize=(15, 6))\n",
    "\n",
    "# OBSERVACIONES VISUALES:\n",
    "# 1. Tendencia creciente a largo plazo\n",
    "# 2. Oscilaciones regulares (estacionalidad) que se repiten cada año\n",
    "# 3. La amplitud de las oscilaciones aumenta con el tiempo\n",
    "# \n",
    "# Esto indica que necesitamos un modelo SARIMA que capture\n",
    "# tanto la tendencia como la estacionalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# DESCOMPOSICIÓN ESTACIONAL\n",
    "# ============================================\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Descomponemos la serie en sus componentes\n",
    "# model='additive': asumimos que los componentes se suman (Y = Trend + Seasonal + Residual)\n",
    "# extrapolate_trend='freq': extiende la tendencia en los extremos\n",
    "result_add = seasonal_decompose(df[['value']], model='additive', extrapolate_trend='freq')\n",
    "\n",
    "# Configuramos el tamaño de la figura\n",
    "plt.rcParams.update({'figure.figsize': (6, 6)})\n",
    "\n",
    "# Graficamos la descomposición\n",
    "result_add.plot()\n",
    "\n",
    "# COMPONENTES VISUALIZADOS:\n",
    "# 1. Observed: serie original\n",
    "# 2. Trend: tendencia a largo plazo (crecimiento general)\n",
    "# 3. Seasonal: patrón que se repite cada 12 meses\n",
    "# 4. Residual: variación aleatoria no explicada por tendencia ni estacionalidad\n",
    "#\n",
    "# Esta descomposición confirma la presencia de estacionalidad clara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# DIVISIÓN TRAIN/TEST PARA DATOS ESTACIONALES\n",
    "# ============================================\n",
    "\n",
    "X = df[['value']]\n",
    "\n",
    "# Dividimos:\n",
    "# - train: todos los datos excepto los últimos 20\n",
    "# - test: últimos 20 meses\n",
    "train = X[:-20]\n",
    "test = X[-20:]\n",
    "\n",
    "# Reservamos aproximadamente 1 año y 8 meses para validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos la autocorrelación del conjunto de entrenamiento\n",
    "plot_acf(train)\n",
    "\n",
    "# La ACF muestra un patrón ondulatorio que se repite\n",
    "# Esto es característico de datos con estacionalidad\n",
    "# Las barras significativas cada ~12 lags confirman estacionalidad anual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos el auto arima sin indicarle que hay componente de seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# AUTO_ARIMA SIN COMPONENTE ESTACIONAL (INCORRECTO)\n",
    "# ============================================\n",
    "\n",
    "# Primero probamos auto_arima SIN indicar que hay estacionalidad\n",
    "# Esto nos servirá como baseline para comparar\n",
    "model = auto_arima(train,\n",
    "                   start_p=1,\n",
    "                   start_q=1,\n",
    "                   max_d=3,\n",
    "                   max_p=5,\n",
    "                   max_q=5,\n",
    "                   trace=True,\n",
    "                   stepwise=True)\n",
    "\n",
    "print(model.aic())\n",
    "\n",
    "# Generamos predicciones\n",
    "predictions = model.predict(20)\n",
    "print(\"mean_squared_error:\", mean_squared_error(test, predictions))\n",
    "\n",
    "# RESULTADO ESPERADO:\n",
    "# El modelo encontrará buenos parámetros (p,d,q) para la tendencia\n",
    "# PERO no capturará el patrón estacional porque no se lo indicamos\n",
    "# Por tanto, el MSE será relativamente alto (≈19.52)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora le añadimos el componente seasonality mediante el parametro `m`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SARIMA: AUTO_ARIMA CON ESTACIONALIDAD\n",
    "# ============================================\n",
    "\n",
    "# Ahora incluimos el parámetro m=12 para indicar estacionalidad\n",
    "model = auto_arima(train,\n",
    "                   start_p=1,\n",
    "                   start_q=1,\n",
    "                   max_d=3,\n",
    "                   max_p=5,\n",
    "                   max_q=5,\n",
    "                   m=12,           # CLAVE: periodo estacional de 12 meses\n",
    "                   trace=True,\n",
    "                   stepwise=True)\n",
    "\n",
    "print(model.aic())\n",
    "\n",
    "# Generamos predicciones\n",
    "predictions = model.predict(20)\n",
    "print(\"mean_squared_error:\", mean_squared_error(test, predictions))\n",
    "\n",
    "# MODELO SARIMA: ARIMA(p,d,q)(P,D,Q)[m]\n",
    "# - (p,d,q): componentes ARIMA tradicionales para la tendencia\n",
    "# - (P,D,Q): componentes ARIMA para la estacionalidad\n",
    "# - [m]: periodo estacional (12 = anual)\n",
    "#\n",
    "# RESULTADOS ESPERADOS:\n",
    "# - AIC mucho menor (≈346.05 vs ≈671.52)\n",
    "# - MSE mucho menor (≈11.36 vs ≈19.52)\n",
    "# \n",
    "# INTERPRETACIÓN:\n",
    "# El mejor modelo es ARIMA(3,1,2)(2,1,0)[12]\n",
    "# - (3,1,2): tendencia con AR(3), I(1), MA(2)\n",
    "# - (2,1,0)[12]: estacionalidad con AR estacional de orden 2 y diferenciación estacional\n",
    "# - El componente estacional captura el patrón que se repite cada 12 meses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
