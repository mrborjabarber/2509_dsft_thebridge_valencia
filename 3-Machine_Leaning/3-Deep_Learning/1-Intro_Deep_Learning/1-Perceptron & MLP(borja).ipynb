{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Perceptron\n",
    "\n",
    "<img src=\"./img/perceptron-6168423.jpg\" alt=\"drawing\" width=\"650\"/>\n",
    "\n",
    "Empezamos cargando librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORTACIÓN DE LIBRERÍAS\n",
    "# =============================================================================\n",
    "# NumPy: Librería fundamental para cálculos numéricos y operaciones con arrays\n",
    "import numpy as np\n",
    "\n",
    "# Pandas: Herramienta para manipulación y análisis de datos estructurados\n",
    "import pandas as pd\n",
    "\n",
    "# Seaborn: Librería de visualización de datos basada en matplotlib\n",
    "# También incluye datasets de ejemplo como el de pingüinos que usaremos\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos datos. Utilizaremos el dataset de pinguinos de seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "\n",
       "   body_mass_g     sex  \n",
       "0       3750.0    Male  \n",
       "1       3800.0  Female  \n",
       "2       3250.0  Female  \n",
       "3          NaN     NaN  \n",
       "4       3450.0  Female  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CARGA DEL DATASET DE PINGÜINOS\n",
    "# =============================================================================\n",
    "# Cargamos el dataset de pingüinos de Palmer, que incluye mediciones\n",
    "# de 3 especies diferentes de pingüinos (Adelie, Chinstrap, Gentoo)\n",
    "df = sns.load_dataset(\"penguins\")\n",
    "\n",
    "# Visualizamos las primeras 5 filas para entender la estructura de los datos\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 344 entries, 0 to 343\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   species            344 non-null    object \n",
      " 1   island             344 non-null    object \n",
      " 2   bill_length_mm     342 non-null    float64\n",
      " 3   bill_depth_mm      342 non-null    float64\n",
      " 4   flipper_length_mm  342 non-null    float64\n",
      " 5   body_mass_g        342 non-null    float64\n",
      " 6   sex                333 non-null    object \n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 18.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# INFORMACIÓN DEL DATASET\n",
    "# =============================================================================\n",
    "# Usamos .info() para ver:\n",
    "# - El número total de registros (344 pingüinos)\n",
    "# - Los tipos de datos de cada columna\n",
    "# - Valores nulos (importante: hay algunos NaN en las columnas numéricas y en 'sex')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\borja\\AppData\\Local\\Temp\\ipykernel_10800\\2354517574.py:20: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.replace(cleanup_nums, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>island_Biscoe</th>\n",
       "      <th>island_Dream</th>\n",
       "      <th>island_Torgersen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   species  bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g  \\\n",
       "0        0            39.1           18.7              181.0       3750.0   \n",
       "1        0            39.5           17.4              186.0       3800.0   \n",
       "2        0            40.3           18.0              195.0       3250.0   \n",
       "4        0            36.7           19.3              193.0       3450.0   \n",
       "5        0            39.3           20.6              190.0       3650.0   \n",
       "\n",
       "   sex  island_Biscoe  island_Dream  island_Torgersen  \n",
       "0    0          False         False              True  \n",
       "1    1          False         False              True  \n",
       "2    1          False         False              True  \n",
       "4    1          False         False              True  \n",
       "5    0          False         False              True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# LIMPIEZA Y PREPROCESAMIENTO DE DATOS\n",
    "# =============================================================================\n",
    "# Volvemos a cargar el dataset\n",
    "df = sns.load_dataset(\"penguins\")\n",
    "\n",
    "# PASO 1: Eliminar filas con valores nulos\n",
    "# inplace=True modifica el DataFrame directamente sin crear una copia\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# PASO 2: Codificación de variables categóricas a numéricas\n",
    "# Las redes neuronales necesitan datos numéricos, no texto\n",
    "cleanup_nums = {\"species\": {\"Adelie\": 0,      # Especie Adelie -> 0\n",
    "                            \"Chinstrap\": 1,   # Especie Chinstrap -> 1\n",
    "                            \"Gentoo\": 2},     # Especie Gentoo -> 2\n",
    "               \"sex\": {\"Male\": 0,             # Macho -> 0\n",
    "                       \"Female\": 1}}          # Hembra -> 1\n",
    "\n",
    "# Aplicamos el mapeo de valores categóricos a numéricos\n",
    "df.replace(cleanup_nums, inplace=True)\n",
    "\n",
    "# PASO 3: One-Hot Encoding para la variable 'island'\n",
    "# get_dummies() convierte variables categóricas en columnas binarias (0 o 1)\n",
    "# Por ejemplo: 'island' se convierte en 'island_Biscoe', 'island_Dream', 'island_Torgersen'\n",
    "df = pd.get_dummies(df)\n",
    "\n",
    "# Mostramos el resultado del preprocesamiento\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 333 entries, 0 to 343\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   species            333 non-null    int64  \n",
      " 1   bill_length_mm     333 non-null    float64\n",
      " 2   bill_depth_mm      333 non-null    float64\n",
      " 3   flipper_length_mm  333 non-null    float64\n",
      " 4   body_mass_g        333 non-null    float64\n",
      " 5   sex                333 non-null    int64  \n",
      " 6   island_Biscoe      333 non-null    bool   \n",
      " 7   island_Dream       333 non-null    bool   \n",
      " 8   island_Torgersen   333 non-null    bool   \n",
      "dtypes: bool(3), float64(4), int64(2)\n",
      "memory usage: 19.2 KB\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# VERIFICACIÓN DESPUÉS DEL PREPROCESAMIENTO\n",
    "# =============================================================================\n",
    "# Comprobamos que:\n",
    "# - Ahora tenemos 333 registros (eliminamos los que tenían NaN)\n",
    "# - Todas las columnas son numéricas\n",
    "# - Las islas se han convertido en 3 columnas binarias (one-hot encoding)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>333.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.918919</td>\n",
       "      <td>43.992793</td>\n",
       "      <td>17.164865</td>\n",
       "      <td>200.966967</td>\n",
       "      <td>4207.057057</td>\n",
       "      <td>0.495495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.889718</td>\n",
       "      <td>5.468668</td>\n",
       "      <td>1.969235</td>\n",
       "      <td>14.015765</td>\n",
       "      <td>805.215802</td>\n",
       "      <td>0.500732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.100000</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>2700.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.500000</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>3550.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>17.300000</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>4050.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>48.600000</td>\n",
       "      <td>18.700000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>4775.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>59.600000</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>6300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          species  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "count  333.000000      333.000000     333.000000         333.000000   \n",
       "mean     0.918919       43.992793      17.164865         200.966967   \n",
       "std      0.889718        5.468668       1.969235          14.015765   \n",
       "min      0.000000       32.100000      13.100000         172.000000   \n",
       "25%      0.000000       39.500000      15.600000         190.000000   \n",
       "50%      1.000000       44.500000      17.300000         197.000000   \n",
       "75%      2.000000       48.600000      18.700000         213.000000   \n",
       "max      2.000000       59.600000      21.500000         231.000000   \n",
       "\n",
       "       body_mass_g         sex  \n",
       "count   333.000000  333.000000  \n",
       "mean   4207.057057    0.495495  \n",
       "std     805.215802    0.500732  \n",
       "min    2700.000000    0.000000  \n",
       "25%    3550.000000    0.000000  \n",
       "50%    4050.000000    0.000000  \n",
       "75%    4775.000000    1.000000  \n",
       "max    6300.000000    1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ESTADÍSTICAS DESCRIPTIVAS\n",
    "# =============================================================================\n",
    "# describe() nos muestra estadísticas como media, desviación estándar, \n",
    "# mínimo, máximo y cuartiles de cada variable numérica\n",
    "# Esto es importante para entender la escala de nuestras variables\n",
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos en train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DIVISIÓN EN TRAIN Y TEST\n",
    "# =============================================================================\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separamos las características (X) de la variable objetivo (y)\n",
    "# iloc[:, 1:] selecciona todas las filas y desde la columna 1 en adelante (features)\n",
    "X = df.iloc[:, 1:]  # Características: todas las columnas excepto 'species'\n",
    "\n",
    "# iloc[:, 0] selecciona la primera columna (species), nuestra variable objetivo\n",
    "y = df.iloc[:, 0]   # Variable objetivo: especie del pingüino (0, 1 o 2)\n",
    "\n",
    "# Dividimos los datos en conjuntos de entrenamiento (80%) y prueba (20%)\n",
    "# test_size=0.2 significa que el 20% de los datos se usarán para test\n",
    "# random_state=42 asegura que la división sea reproducible\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(266, 8)\n",
      "(67, 8)\n",
      "(266,)\n",
      "(67,)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# VERIFICACIÓN DE LAS DIMENSIONES\n",
    "# =============================================================================\n",
    "# Imprimimos las dimensiones de cada conjunto para confirmar la división\n",
    "print(X_train.shape)  # (266, 8) -> 266 muestras de entrenamiento, 8 características\n",
    "print(X_test.shape)   # (67, 8) -> 67 muestras de test, 8 características\n",
    "print(y_train.shape)  # (266,) -> 266 etiquetas de entrenamiento\n",
    "print(y_test.shape)   # (67,) -> 67 etiquetas de test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a probar un Perceptrón"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19402985074626866"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PRIMER MODELO: PERCEPTRÓN SIMPLE SIN ESTANDARIZAR\n",
    "# =============================================================================\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# Creamos un Perceptrón (red neuronal de una sola capa)\n",
    "# El perceptrón es el modelo más simple de red neuronal\n",
    "per_clf = Perceptron(random_state=1)\n",
    "\n",
    "# Entrenamos el modelo con los datos de entrenamiento\n",
    "per_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluamos el modelo en el conjunto de test\n",
    "# score() devuelve la precisión (accuracy): % de predicciones correctas\n",
    "# RESULTADO: ~19% de precisión - ¡MUY MALO! Peor que adivinar al azar\n",
    "per_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# COMPARACIÓN: REGRESIÓN LOGÍSTICA SIN ESTANDARIZAR\n",
    "# =============================================================================\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Probamos con Regresión Logística para comparar\n",
    "# max_iter=10000 establece el número máximo de iteraciones para convergencia\n",
    "log_reg = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# Entrenamos el modelo\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluamos en el conjunto de test\n",
    "# RESULTADO: ~98.5% de precisión - ¡EXCELENTE!\n",
    "# Esto demuestra que el Perceptrón simple tiene problemas con estos datos\n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos a estandarizar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que el perceptrón por si solo es bastante inútil, habrá que probar configuraciones más complejas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43283582089552236"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# MULTI LAYER PERCEPTRON (MLP) - CONFIGURACIÓN POR DEFECTO\n",
    "# =============================================================================\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# También existe MLPRegressor para problemas de regresión\n",
    "\n",
    "# Creamos un MLP con configuración por defecto\n",
    "# Por defecto tiene una capa oculta con 100 neuronas\n",
    "mlp = MLPClassifier(random_state=42)\n",
    "\n",
    "# Entrenamos el modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Evaluamos en el conjunto de test\n",
    "# RESULTADO: ~43% de precisión - Mejor que el Perceptrón simple, pero aún malo\n",
    "# El MLP no está funcionando bien sin estandarización\n",
    "mlp.score(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos otra configuración. Es posible crear una red neuronal desde la propia función de MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4626865671641791"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# MLP CON CONFIGURACIÓN PERSONALIZADA (SIN ESTANDARIZAR)\n",
    "# =============================================================================\n",
    "# Intentamos mejorar el MLP con una arquitectura más compleja\n",
    "mlp = MLPClassifier(max_iter=500,                      # Aumentamos iteraciones\n",
    "                   activation='relu',                  # Función de activación ReLU\n",
    "                   hidden_layer_sizes = (150, 150, 150),  # 3 capas ocultas con 150 neuronas cada una\n",
    "                   random_state=42)\n",
    "\n",
    "# Entrenamos el modelo con la nueva arquitectura\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Evaluamos en el conjunto de test\n",
    "# RESULTADO: ~46% de precisión - Apenas mejoró\n",
    "# CONCLUSIÓN: El problema NO es la arquitectura, es la FALTA DE ESTANDARIZACIÓN\n",
    "mlp.score(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizan descenso del gradiente, y por tanto son muy sensibles al escalado. Estandarizamos para el siguiente ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ESTANDARIZACIÓN DE DATOS + PERCEPTRÓN\n",
    "# =============================================================================\n",
    "# Las redes neuronales utilizan descenso del gradiente para optimización\n",
    "# Este algoritmo es MUY SENSIBLE a la escala de las características\n",
    "# Por ejemplo: body_mass_g está en miles, pero sex está entre 0 y 1\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# PASO 1: Crear el escalador\n",
    "# StandardScaler transforma los datos para que tengan media=0 y desviación estándar=1\n",
    "sc = StandardScaler()\n",
    "\n",
    "# PASO 2: Ajustar el escalador SOLO con los datos de entrenamiento\n",
    "# fit() calcula la media y desviación estándar de X_train\n",
    "sc.fit(X_train)\n",
    "\n",
    "# PASO 3: Transformar tanto train como test usando las estadísticas de train\n",
    "# ¡IMPORTANTE! Usamos las mismas estadísticas para evitar data leakage\n",
    "X_train_s = sc.transform(X_train)  # Estandarizamos el conjunto de entrenamiento\n",
    "X_test_s = sc.transform(X_test)    # Estandarizamos el conjunto de test\n",
    "\n",
    "# PASO 4: Entrenar Perceptrón con datos estandarizados\n",
    "per_clf = Perceptron()\n",
    "per_clf.fit(X_train_s, y_train)\n",
    "\n",
    "# PASO 5: Evaluar el modelo\n",
    "print(per_clf.score(X_train_s, y_train))  # RESULTADO: 100% en train\n",
    "print(per_clf.score(X_test_s, y_test))    # RESULTADO: 100% en test\n",
    "# ¡INCREÍBLE MEJORA! De 19% a 100% solo con estandarización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# REGRESIÓN LOGÍSTICA CON DATOS ESTANDARIZADOS\n",
    "# =============================================================================\n",
    "# Probamos también la Regresión Logística con datos estandarizados\n",
    "log_reg = LogisticRegression(max_iter=500)\n",
    "\n",
    "# Entrenamos con los datos estandarizados\n",
    "log_reg.fit(X_train_s, y_train)\n",
    "\n",
    "# Evaluamos en ambos conjuntos\n",
    "print(log_reg.score(X_train_s, y_train))  # 100% en train\n",
    "print(log_reg.score(X_test_s, y_test))    # 100% en test\n",
    "# La Regresión Logística ya funcionaba bien, pero la estandarización la hace perfecta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# MLP CON ESTANDARIZACIÓN - SOLUCIÓN DEFINITIVA\n",
    "# =============================================================================\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# PASO 1: Crear y ajustar el escalador\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# PASO 2: Transformar los datos\n",
    "X_train_scal = scaler.transform(X_train)\n",
    "X_test_scal = scaler.transform(X_test)\n",
    "\n",
    "# PASO 3: Crear y entrenar el MLP (con configuración por defecto)\n",
    "mlp = MLPClassifier(max_iter=500)\n",
    "mlp.fit(X_train_scal, y_train)\n",
    "\n",
    "# PASO 4: Evaluar el modelo\n",
    "print(mlp.score(X_train_scal, y_train))  # RESULTADO: 100% en train\n",
    "print(mlp.score(X_test_scal, y_test))    # RESULTADO: 100% en test\n",
    "\n",
    "# LECCIÓN CLAVE: La estandarización es CRÍTICA para redes neuronales\n",
    "# Sin ella: 43% de precisión\n",
    "# Con ella: 100% de precisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31,  0,  0],\n",
       "       [ 0, 13,  0],\n",
       "       [ 0,  0, 23]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# MATRIZ DE CONFUSIÓN - ANÁLISIS DETALLADO DE RESULTADOS\n",
    "# =============================================================================\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# La matriz de confusión muestra cómo se distribuyen las predicciones\n",
    "# Filas: clases reales | Columnas: clases predichas\n",
    "# Diagonal principal: predicciones correctas\n",
    "confusion_matrix(y_test, mlp.predict(X_test_scal))\n",
    "\n",
    "# INTERPRETACIÓN DEL RESULTADO:\n",
    "# [[31  0  0]   <- 31 Adelie correctamente clasificados, 0 errores\n",
    "#  [ 0 13  0]   <- 13 Chinstrap correctamente clasificados, 0 errores\n",
    "#  [ 0  0 23]]  <- 23 Gentoo correctamente clasificados, 0 errores\n",
    "# ¡PERFECTO! No hay errores de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
