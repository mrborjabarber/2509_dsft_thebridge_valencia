{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/juansensio/IntroDLCode/blob/master/01_mnist.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, descargamos los datos que usaremos para entrenar la red neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# CELDA 1: CARGA DE DATOS\n# ======================\n# Importamos las librerías necesarias\nfrom sklearn.datasets import fetch_openml  # Para descargar el dataset MNIST\nimport numpy as np  # Para operaciones numéricas\n\n# MNIST es un dataset clásico de ML: 70,000 imágenes de dígitos escritos a mano (0-9)\n# Cada imagen es de 28x28 píxeles = 784 valores\nmnist = fetch_openml('mnist_784', version=1)\n\n# Separamos features (X) y labels (y)\n# X: matriz de 70,000 filas x 784 columnas (cada fila es una imagen aplanada)\n# y: vector de 70,000 elementos con los dígitos correspondientes (0-9)\nX, y = mnist[\"data\"].values.astype(np.float32), mnist[\"target\"].values.astype(int)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a visualizar algunos ejemplos de los datos que acabamos de descargar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# CELDA 2: VISUALIZACIÓN DE DATOS\n# ================================\nimport matplotlib.pyplot as plt\n\n# Creamos una cuadrícula de 8x8 para visualizar 64 ejemplos\nr, c = 8, 8  # r = filas, c = columnas\nfig = plt.figure(figsize=(2*c, 2*r))  # Tamaño de la figura\n\n# Recorremos cada posición de la cuadrícula\nfor _r in range(r):\n    for _c in range(c):\n        ix = _r*c + _c  # Índice de la imagen en el dataset\n        ax = plt.subplot(r, c, ix + 1)  # Creamos un subplot\n        ax.axis(\"off\")  # Ocultamos los ejes\n        \n        # Reshape de 784 valores a matriz 28x28 para visualizar como imagen\n        ax.imshow(X[ix].reshape(28,28), cmap=\"gray\")\n        \n        # Título = etiqueta verdadera (el dígito que representa)\n        ax.set_title(y[ix])\n        \nplt.tight_layout()  # Ajusta el espaciado entre subplots\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen tiene asociada su etiqueta, que indica el número que representa, y que es lo que queremos que nuestra red neuronal aprenda a predecir dada una imagen de entrada.\n",
    "\n",
    "![](https://miro.medium.com/v2/resize:fit:679/0*u5-PcKYVfUE5s2by.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a usar una red neuronal sencilla, conocida como perceptrón multicapa, que consiste en una serie de capas de neuronas conectadas entre sí. Cada neurona recibe como entrada las salidas de las neuronas de la capa anterior, y produce una salida que es la entrada de las neuronas de la capa siguiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# CELDA 3: DEFINICIÓN DEL MODELO (RED NEURONAL)\n# ==============================================\nfrom torch.nn import Sequential as S  # Contenedor para apilar capas\nfrom torch.nn import Linear as L      # Capa densa (fully connected)\nfrom torch.nn import ReLU as R        # Función de activación\n\n# ARQUITECTURA DEL MODELO: Perceptrón Multicapa (MLP)\n# ====================================================\nmodel = S(\n    L(784, 128),  # Capa 1: 784 neuronas de entrada → 128 neuronas ocultas\n                  # (784 = 28x28 píxeles de cada imagen aplanada)\n    \n    R(),          # Función de activación ReLU: f(x) = max(0, x)\n                  # Introduce no-linealidad para aprender patrones complejos\n    \n    L(128, 10)    # Capa 2: 128 neuronas ocultas → 10 neuronas de salida\n                  # (10 = número de clases: dígitos del 0 al 9)\n)\n\n# Visualizamos la arquitectura del modelo\nmodel"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado un conjunto de imágenes de entrada, la red neuronal produce una salida para cada una de ellas, que es la predicción que hace la red neuronal sobre la etiqueta de la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# CELDA 4: PREDICCIONES SIN ENTRENAR (ALEATORIAS)\n# ================================================\nimport torch \n\n# Tomamos las primeras 10 imágenes y las pasamos por la red\ny_hat = model(torch.tensor(X[:10]))  # y_hat tiene shape (10, 10)\n                                      # 10 muestras x 10 probabilidades (una por clase)\n\n# argmax extrae el índice de la probabilidad más alta = predicción\npreds = torch.argmax(y_hat, dim=1)  # dim=1 significa \"por fila\"\n\n# Mostramos las predicciones\npreds  # Serán aleatorias porque el modelo aún NO está entrenado"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como la red aún no está entrenada, las predicciones que hace son aleatorias. El siguiente bloque de código se encarga de entrenar la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# CELDA 5: ENTRENAMIENTO DEL MODELO\n# ==================================\nfrom tqdm import tqdm  # Para mostrar barras de progreso\n\n# PREPARACIÓN DE LOS DATOS\n# -------------------------\n# Dividimos en train (primeros 60k) y test (últimos 10k)\nX_train, X_test = torch.from_numpy(X[:60000] / 255.), torch.from_numpy(X[60000:] / 255.)\n# Dividimos por 255 para normalizar los píxeles de [0, 255] a [0, 1]\n\ny_train, y_test = torch.from_numpy(y[:60000]), torch.from_numpy(y[60000:])\n\n# HIPERPARÁMETROS\n# ----------------\nbs = 32  # Batch size: procesamos 32 imágenes a la vez (más eficiente)\nnum_batches = len(X_train) // bs  # Número total de batches por época\n\n# FUNCIÓN DE PÉRDIDA Y OPTIMIZADOR\n# ---------------------------------\nloss_fn = torch.nn.CrossEntropyLoss()  # Función de pérdida para clasificación\n                                        # Combina Softmax + Negative Log Likelihood\n                                        \noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)  # Optimizador Adam\n                                                           # lr = learning rate (tasa de aprendizaje)\n\n# BUCLE DE ENTRENAMIENTO\n# -----------------------\nfor epoch in range(10):  # 10 épocas = 10 pasadas completas por el dataset\n    \n    for b in tqdm(range(num_batches)):  # Iteramos por cada batch\n        # Extraemos un batch de datos\n        x = X_train[b*bs:(b+1)*bs]  # 32 imágenes\n        y = y_train[b*bs:(b+1)*bs]  # 32 etiquetas\n        \n        # FORWARD PASS: predicciones del modelo\n        y_hat = model(x)\n        \n        # Calculamos la pérdida (error) entre predicciones y etiquetas reales\n        loss = loss_fn(y_hat, y)\n        \n        # BACKWARD PASS: calculamos gradientes\n        optimizer.zero_grad()  # Limpiamos gradientes anteriores\n        loss.backward()        # Calculamos nuevos gradientes (backpropagation)\n        optimizer.step()       # Actualizamos los pesos del modelo\n        \n    # Mostramos la pérdida al final de cada época\n    print(f\"Epoch {epoch+1} loss: {loss.item():.3f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez entrenada la red, podemos evaluar su rendimiento sobre los datos de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# CELDA 6: EVALUACIÓN EN TEST\n# ============================\nacc = 0  # Contador de aciertos\n\n# torch.no_grad() desactiva el cálculo de gradientes (no necesitamos entrenar)\n# Esto ahorra memoria y acelera la inferencia\nwith torch.no_grad():\n    for b in range(num_batches):\n        # Extraemos un batch del conjunto de test\n        x = X_test[b*bs:(b+1)*bs]\n        y = y_test[b*bs:(b+1)*bs]\n        \n        # Hacemos predicciones\n        y_hat = model(x)\n        \n        # Comparamos predicciones con etiquetas reales\n        # torch.argmax convierte probabilidades en clase predicha\n        acc += torch.sum(torch.argmax(y_hat, dim=1) == y).item()\n\n# Mostramos accuracy = aciertos / total\nprint(f\"Accuracy: {acc} / {len(X_test)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# CELDA 7: VISUALIZACIÓN DE RESULTADOS\n# =====================================\nr, c = 5, 5  # Cuadrícula de 5x5 = 25 ejemplos\nfig = plt.figure(figsize=(2*c, 2*r))\n\nfor _r in range(r):\n    for _c in range(c):\n        ix = _r*c + _c\n        ax = plt.subplot(r, c, ix + 1)\n        ax.axis(\"off\")\n        \n        # Hacemos predicción para una imagen del test\n        pred = torch.argmax(model(X_test[ix]).unsqueeze(0)).item()\n        # unsqueeze(0) añade dimensión de batch (modelo espera batches)\n        \n        # Mostramos la imagen\n        ax.imshow(X_test[ix].reshape(28,28), cmap=\"gray\")\n        \n        # Título = predicción\n        # Color VERDE si es correcta, ROJO si es incorrecta\n        ax.set_title(pred, color=\"green\" if pred == y_test[ix] else \"red\")\n        \nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestra red es capaz de predecir correctamente el 98% de las imágenes de test. ¡Felicidades! Has entrenado tu primera red neuronal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}