{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio Python de Regresión Logística\n",
    "Realizaremos un ejercicio de prueba para comprender como funciona este algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías necesarias para el análisis de datos y machine learning\n",
    "import pandas as pd  # Para manipulación de dataframes\n",
    "import numpy as np   # Para operaciones numéricas\n",
    "from sklearn import linear_model  # Para modelos lineales\n",
    "from sklearn import model_selection  # Para división de datos y validación cruzada\n",
    "from sklearn.metrics import classification_report  # Para reportes de clasificación\n",
    "from sklearn.metrics import confusion_matrix  # Para matriz de confusión\n",
    "from sklearn.metrics import accuracy_score  # Para calcular la precisión del modelo\n",
    "import matplotlib.pyplot as plt  # Para crear gráficos\n",
    "import seaborn as sns  # Para visualizaciones estadísticas\n",
    "# %matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargamos los datos de entrada del archivo csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Cargamos el dataset desde un archivo CSV que contiene datos de usuarios\n",
    "dataframe = pd.read_csv(\"data/usuarios_win_mac_lin.csv\")\n",
    "\n",
    "# Definimos un diccionario para mapear los valores numéricos de clase a nombres legibles\n",
    "clases = {\n",
    "    0: 'Windows',  # Clase 0 representa usuarios de Windows\n",
    "    1: 'Linux',    # Clase 1 representa usuarios de Linux\n",
    "    2: 'Mac'       # Clase 2 representa usuarios de Mac\n",
    "}\n",
    "\n",
    "# Mostramos las primeras 5 filas del dataframe para entender la estructura de los datos\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizamos la distribución de las clases en el dataset\n",
    "# normalize=True nos da las proporciones (porcentajes) en lugar de conteos absolutos\n",
    "dataframe['clase'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Obtenemos estadísticas descriptivas de todas las variables numéricas\n",
    "# Esto incluye media, desviación estándar, mínimo, máximo y cuartiles\n",
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un boxplot para visualizar la distribución de la variable 'duracion'\n",
    "# Esto nos ayuda a identificar valores atípicos (outliers) y la distribución general\n",
    "sns.boxplot(x= dataframe['duracion']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretación del diagrama de caja (boxplot) y efecto de los outliers** (sin contexto)\n",
    "\n",
    "El boxplot de la variable **duración** muestra que existen varios **valores atípicos (outliers)** muy alejados del resto de los datos.  \n",
    "La mayoría de las observaciones se concentran por debajo de los 200, pero algunos valores superan los 400, 600 o incluso 900.\n",
    "\n",
    "**Qué significan los outliers:**\n",
    "- Representan observaciones que son **inusualmente altas** comparadas con el resto.\n",
    "- Pueden deberse a **errores en los datos**, situaciones excepcionales o casos legítimos pero poco frecuentes.\n",
    "\n",
    "**Problemas que pueden causar en el modelo:**\n",
    "1. **Distorsión del entrenamiento:** Los outliers pueden influir demasiado en la estimación de los parámetros del modelo, especialmente en algoritmos sensibles a los valores extremos como la **regresión logística**, **SVM** o **KNN**.\n",
    "2. **Escalado incorrecto:** Al aplicar técnicas de normalización o estandarización, los outliers pueden hacer que las demás observaciones parezcan muy pequeñas.\n",
    "3. **Menor capacidad de generalización:** El modelo puede sobreajustarse a esos casos extremos y perder precisión en los datos típicos.\n",
    "4. **Afectación de métricas:** Los errores causados por outliers pueden empeorar el desempeño medido en métricas como accuracy o F1-score.\n",
    "\n",
    "**Posibles soluciones:**\n",
    "- Aplicar una **transformación logarítmica** o de tipo **Box-Cox** para reducir la asimetría.\n",
    "- Utilizar **modelos robustos** que toleren valores extremos.\n",
    "- Detectar y **eliminar o recodificar** outliers si se identifican como errores de registro.\n",
    "- Usar **escalado robusto** (por ejemplo, `RobustScaler` en scikit-learn) en lugar de `StandardScaler`.\n",
    "\n",
    "**Interpretación general considerando los outliers en contexto**\n",
    "\n",
    "Si observas los histogramas de las variables `duracion`, `paginas`, `acciones` y `valor`, se confirma que todas presentan una **distribución fuertemente asimétrica hacia la derecha** (right-skewed).  \n",
    "Esto significa que la mayoría de los valores son bajos y solo unas pocas observaciones tienen valores muy altos.\n",
    "\n",
    "**Conclusión respecto a los outliers:**\n",
    "- Los valores extremos (outliers) detectados en el boxplot de `duracion` no son errores aislados, sino parte del comportamiento natural de los datos.  \n",
    "- En contextos como análisis de comportamiento de usuarios o transacciones, este tipo de distribución es **normal**: pocos usuarios generan mucha actividad o duración.\n",
    "- Por tanto, los outliers **no necesariamente son problemáticos**, pero siguen siendo observaciones que podrían afectar modelos sensibles a la escala.\n",
    "\n",
    "**Qué hacer:**\n",
    "- No es obligatorio eliminarlos, pero sí conviene aplicar **transformaciones logarítmicas o escalado robusto** para reducir su influencia.\n",
    "- Si el modelo elegido es **no lineal** (por ejemplo, árboles de decisión o Random Forest), estos outliers no representan un gran problema, ya que estos algoritmos son menos sensibles a valores extremos.\n",
    "\n",
    "**En resumen:**\n",
    "Desde esta perspectiva, los outliers son coherentes con la naturaleza de los datos y no necesariamente \"malos\", aunque sigue siendo recomendable tratarlos o transformarlos para mejorar la estabilidad del modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos información general sobre el dataframe\n",
    "# Incluye tipos de datos, valores no nulos y uso de memoria\n",
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Contamos cuántas observaciones hay en cada clase\n",
    "# Esto nos ayuda a entender si tenemos un dataset balanceado o desbalanceado\n",
    "print(dataframe.groupby('clase').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Conclusión:\n",
    "Este conjunto no está perfectamente balanceado, ya que la clase 0 tiene el doble de ejemplos que las clases 1 y 2.\n",
    "Sin embargo, no está extremadamente desbalanceado: sigue siendo una diferencia moderada (50% vs 25%)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una vista del dataframe sin la columna 'clase'\n",
    "# Esto nos permite ver solo las variables predictoras (features)\n",
    "dataframe.drop(columns=['clase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos histogramas para todas las variables numéricas (excepto 'clase')\n",
    "# Esto nos ayuda a visualizar la distribución de cada variable predictora\n",
    "dataframe.drop(columns=['clase']).hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variable     | Interpretación                                                                                                                                     |\n",
    "| ------------ | -------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **duracion** | La mayoría de las sesiones (o eventos) duran poco tiempo, pero hay algunas que duran mucho más (hasta cerca de 900). Indica una gran variabilidad. |\n",
    "| **paginas**  | La mayoría de los casos visitan 1 o 2 páginas, muy pocos visitan más de 5 o 6.                                                                     |\n",
    "| **acciones** | Similar: la mayoría realiza pocas acciones (menos de 10), con unos pocos usuarios muy activos.                                                     |\n",
    "| **valor**    | La mayoría de los valores (quizá monetarios o de interacción) son bajos, con unos pocos casos muy altos.                                           |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un gráfico de pares (pairplot) para visualizar relaciones entre variables\n",
    "# hue='clase' colorea los puntos según la clase, permitiendo ver patrones por grupo\n",
    "# kind='reg' añade líneas de regresión a cada gráfico de dispersión\n",
    "sns.pairplot(dataframe.dropna(),\n",
    "            hue='clase',\n",
    "            height=4,\n",
    "            vars=[\"duracion\", \"paginas\",\"acciones\",\"valor\"],\n",
    "            kind='reg'); # \"reg\" de regresión lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Propósito del Pair Plot en un modelo de clasificación**\n",
    "\n",
    "Un **pair plot** (o gráfico de pares) se utiliza para **visualizar las relaciones entre todas las variables numéricas** de un conjunto de datos y cómo se distribuyen según las clases del modelo de clasificación.\n",
    "\n",
    "**Objetivos principales:**\n",
    "\n",
    "1. **Explorar relaciones entre variables:**\n",
    "   Permite observar si existen **correlaciones** o patrones entre pares de variables (por ejemplo, si una aumenta cuando otra también lo hace).\n",
    "\n",
    "2. **Visualizar la separación entre clases:**\n",
    "   Al colorear los puntos según la clase, el gráfico muestra si las diferentes clases están **claramente separadas** en el espacio de las variables o si se **superponen**.  \n",
    "   Esto ayuda a evaluar si el problema es **linealmente separable** o si se necesita un modelo más complejo.\n",
    "\n",
    "3. **Detectar valores atípicos o distribuciones anómalas:**\n",
    "   Los puntos alejados del resto pueden indicar **outliers** o comportamientos inusuales que podrían afectar el entrenamiento.\n",
    "\n",
    "4. **Evaluar la relevancia de las variables:**\n",
    "   Si una variable muestra una clara diferenciación entre clases, puede ser **muy informativa** para el modelo.  \n",
    "   En cambio, si no hay separación visible, puede tener **bajo poder predictivo**.\n",
    "\n",
    "**En resumen:**\n",
    "El pair plot se utiliza en clasificación para **entender la estructura de los datos antes de entrenar el modelo**, identificar **relaciones entre variables**, **distinguir clases visualmente** y detectar **posibles outliers o redundancias** en las características.\n",
    "\n",
    "**Resumen del pairplot:**\n",
    "Las variables `duracion`, `paginas`, `acciones` y `valor` presentan distribuciones asimétricas hacia la derecha, con la mayoría de los valores concentrados en rangos bajos y algunos valores atípicos muy altos. Se observa una correlación positiva entre todas las variables: a mayor duración, tienden a aumentar las páginas visitadas, las acciones realizadas y el valor generado. Aunque las clases (0, 1 y 2) muestran cierta superposición, las clases 1 y 2 tienden a concentrarse en valores más altos en comparación con la clase 0. En general, las relaciones no son lineales, por lo que modelos no lineales podrían capturar mejor las diferencias entre clases."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Preparamos los datos para el modelo de machine learning\n",
    "# X contiene las variables predictoras (features) - todo excepto la columna 'clase'\n",
    "X = np.array(dataframe.drop(columns=['clase']))\n",
    "# y contiene la variable objetivo (target) - la columna 'clase' que queremos predecir\n",
    "y = np.array(dataframe['clase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos el algoritmo de Regresión Logística desde scikit-learn\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Creamos una instancia del modelo de Regresión Logística\n",
    "# max_iter=1000 aumenta el número máximo de iteraciones para asegurar convergencia\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "# Entrenamos el modelo con nuestros datos (X = features, y = target)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explicación de `max_iter` en la Regresión Logística**\n",
    "\n",
    "En un modelo de Regresión Logística, el parámetro `max_iter` define el número máximo de iteraciones que el algoritmo de optimización puede ejecutar para ajustar los coeficientes del modelo.\n",
    "\n",
    "Durante el entrenamiento, el algoritmo busca minimizar la función de costo (log-loss) ajustando los pesos paso a paso. Este proceso se repite hasta que el cambio entre iteraciones sea muy pequeño (convergencia) o hasta alcanzar el límite definido por `max_iter`.\n",
    "\n",
    "Si el valor de `max_iter` es demasiado bajo, el modelo puede no converger y aparecerá una advertencia como:\n",
    "\n",
    "En ese caso, se recomienda aumentar el número de iteraciones, por ejemplo de 100 a 1000, para permitir que el optimizador encuentre una mejor solución.\n",
    "\n",
    "`ConvergenceWarning: lbfgs failed to converge (Increase the number of iterations)`.\n",
    "\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "modelo = LogisticRegression(max_iter=1000)\n",
    "modelo.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos predicciones sobre el mismo conjunto de datos usado para entrenar\n",
    "# Esto nos permite evaluar cómo está funcionando el modelo\n",
    "predictions = model.predict(X)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Obtenemos las probabilidades de predicción para cada clase\n",
    "# (cada fila corresponde a una muestra y cada columna a una clase posible)\n",
    "predicions_proba = model.predict_proba(X)\n",
    "\n",
    "# Convertimos el resultado a un array de NumPy, redondeamos a 2 decimales\n",
    "# y lo imprimimos en consola\n",
    "print(np.round(np.array(predicions_proba), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Calculamos la precisión (accuracy) del modelo\n",
    "# Esto nos dice qué porcentaje de predicciones fueron correctas\n",
    "model.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos qué clases puede predecir el modelo\n",
    "# Debería mostrar [0, 1, 2] correspondientes a Windows, Linux y Mac\n",
    "model.classes_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validación del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validación Cruzada (Cross-Validation) y el parámetro `kfolds`**\n",
    "\n",
    "La **validación cruzada** (cross-validation) es una técnica que permite evaluar el rendimiento de un modelo de manera más confiable, reduciendo el riesgo de sobreajuste (*overfitting*). En lugar de usar una única división de los datos en entrenamiento y prueba, la validación cruzada divide el conjunto de datos en varias partes o *folds* y realiza múltiples entrenamientos y evaluaciones.\n",
    "\n",
    "**Cómo funciona:**\n",
    "1. Los datos se dividen en *k* subconjuntos aproximadamente iguales, llamados *folds*.\n",
    "2. El modelo se entrena *k* veces, utilizando en cada iteración *k-1* folds para entrenar y 1 fold diferente para validar.\n",
    "3. Al final, se calcula el promedio de las métricas obtenidas en cada iteración (por ejemplo, el accuracy promedio).\n",
    "\n",
    "**Ejemplo con k=5:**\n",
    "- Se divide el dataset en 5 partes.\n",
    "- El modelo se entrena 5 veces, usando 4 partes para entrenamiento y 1 diferente para validación en cada iteración.\n",
    "- Se obtiene una medida promedio del rendimiento, que es más estable y generalizable que una sola partición.\n",
    "\n",
    "**Parámetro `kfolds`:**\n",
    "- Define el número de divisiones (*folds*) que se harán en la validación cruzada.\n",
    "- Un valor común es `k=5` o `k=10`.\n",
    "- Valores más altos proporcionan una estimación más precisa, pero aumentan el tiempo de cómputo, ya que el modelo se entrena más veces.\n",
    "\n",
    "**Ejemplo en código:**\n",
    "```python\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "modelo = LogisticRegression(max_iter=1000)\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "resultados = cross_val_score(modelo, X, y, cv=kfold, scoring='accuracy')\n",
    "\n",
    "print(\"Accuracy promedio:\", resultados.mean())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resumen: Validación Cruzada y parámetro `kfolds`**\n",
    "\n",
    "| Concepto | Descripción |\n",
    "|-----------|-------------|\n",
    "| **Validación cruzada (Cross-Validation)** | Técnica que evalúa el rendimiento del modelo dividiendo los datos en varios subconjuntos (*folds*) y repitiendo el entrenamiento varias veces. |\n",
    "| **Objetivo principal** | Obtener una estimación más confiable del desempeño del modelo y reducir el riesgo de sobreajuste (*overfitting*). |\n",
    "| **Parámetro `kfolds` o `n_splits`** | Indica el número de divisiones del dataset. Por ejemplo, `k=5` significa que los datos se dividen en 5 partes. |\n",
    "| **Funcionamiento básico** | El modelo se entrena *k* veces, usando *k-1* folds para entrenar y 1 fold diferente para validar en cada iteración. |\n",
    "| **Resultados** | Se calcula el promedio de la métrica (por ejemplo, accuracy) de las *k* ejecuciones para obtener una medida más estable. |\n",
    "| **Valores comunes de `k`** | 5 o 10, según el tamaño del dataset y los recursos computacionales. |\n",
    "| **Ventajas** | Mejora la estimación del rendimiento, reduce la varianza y aprovecha mejor los datos. |\n",
    "| **Desventajas** | Aumenta el tiempo de entrenamiento, ya que el modelo se ajusta varias veces. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos los datos en conjuntos de entrenamiento y prueba\n",
    "# 20% de los datos se reservan para prueba (test_size=0.20)\n",
    "# random_state=7 asegura que la división sea reproducible\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X,\n",
    "                                                                    y,\n",
    "                                                                    test_size=validation_size,\n",
    "                                                                    random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Nombre del modelo, solo para mostrar en los resultados\n",
    "name = 'Logistic Regression'\n",
    "\n",
    "# Definimos la validación cruzada (cross-validation) con 10 particiones (k=10)\n",
    "# Esto significa que los datos se dividen en 10 partes: \n",
    "# en cada iteración, 9 partes se usan para entrenar y 1 para validar.\n",
    "kfold = model_selection.KFold(n_splits=10)\n",
    "\n",
    "# Ejecutamos validación cruzada usando accuracy como métrica\n",
    "# - model: es el clasificador ya definido (ej. LogisticRegression)\n",
    "# - X_train: variables predictoras de entrenamiento\n",
    "# - Y_train: etiquetas de entrenamiento\n",
    "# - cv=kfold: especifica el esquema de validación cruzada\n",
    "# - scoring='accuracy': evalúa el modelo en términos de exactitud\n",
    "cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n",
    "\n",
    "# Creamos un mensaje con:\n",
    "# - el nombre del modelo\n",
    "# - la media de los resultados de validación\n",
    "# - la desviación estándar (para ver qué tan estables son los resultados)\n",
    "msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "\n",
    "# Mostramos todos los resultados de las 10 iteraciones\n",
    "print(cv_results)\n",
    "\n",
    "# Mostramos el resumen con media y desviación estándar\n",
    "print(msg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretación de los resultados de validación cruzada**\n",
    "\n",
    "El modelo de Regresión Logística obtuvo una **precisión promedio de 0.7286 (72.9%)** con una **desviación estándar de 0.0942**.  \n",
    "Esto indica que, en promedio, el modelo acierta aproximadamente en 7 de cada 10 predicciones.  \n",
    "La desviación estándar moderada sugiere que el rendimiento varía algo entre las diferentes particiones, pero se mantiene relativamente estable.  \n",
    "En general, el modelo muestra un desempeño aceptable y consistente en las distintas divisiones de los datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GridSearchCV**\n",
    "\n",
    "GridSearchCV es una técnica que se utiliza para encontrar automáticamente la mejor combinación de hiperparámetros de un modelo.  \n",
    "Funciona probando todas las combinaciones posibles de los valores definidos por el usuario y evaluando el rendimiento de cada una mediante validación cruzada.\n",
    "\n",
    "Durante el proceso, el modelo se entrena varias veces con diferentes configuraciones y se calcula el promedio de la métrica de evaluación (por ejemplo, accuracy) en cada caso.  \n",
    "Finalmente, GridSearchCV devuelve los parámetros que lograron el mejor resultado y el valor promedio de desempeño asociado.\n",
    "\n",
    "En resumen, GridSearchCV permite optimizar el modelo de forma sistemática y objetiva, aunque requiere más tiempo de cómputo porque entrena el modelo muchas veces.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos una búsqueda en cuadrícula (Grid Search) para encontrar el mejor hiperparámetro C\n",
    "# C es el parámetro de regularización - valores más altos = menos regularización\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definimos el rango de valores de C a probar (de 0.1 a 10 en pasos de 0.1)\n",
    "params = {\"C\" : np.arange(0.1,10,0.1)}\n",
    "\n",
    "# Creamos el objeto GridSearchCV que probará todos los valores de C\n",
    "# cv=3 significa validación cruzada con 3 particiones\n",
    "# verbose=3 muestra información detallada del proceso\n",
    "gs = GridSearchCV(estimator=model, param_grid=params, cv=3, scoring='accuracy', verbose=3)\n",
    "gs.fit(X_train, Y_train)\n",
    "\n",
    "# Mostramos los mejores resultados encontrados\n",
    "print(gs.best_estimator_)  # El modelo con los mejores parámetros\n",
    "print(gs.best_score_)      # La mejor puntuación obtenida\n",
    "print(gs.best_params_)     # Los mejores parámetros encontrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos un nuevo modelo con los parámetros por defecto\n",
    "# model = gs.best_estimator_  # Comentado: podríamos usar el mejor modelo del Grid Search\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluamos el modelo en el conjunto de prueba (datos no vistos durante el entrenamiento)\n",
    "# Esto nos da una estimación más realista del rendimiento del modelo\n",
    "predictions = model.predict(X_test)\n",
    "print(accuracy_score(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculamos el porcentaje de acierto y error del modelo\n",
    "acierto = accuracy_score(Y_test, predictions)\n",
    "error = 1 - acierto  # El error es el complemento del acierto\n",
    "\n",
    "# Mostramos los resultados en porcentajes redondeados a 2 decimales\n",
    "print(\"Acierto:\", round(acierto*100, 2), \"%\")\n",
    "print(\"Error:\", round(error*100, 2), \"%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las métricas necesarias para evaluar el modelo\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos la matriz de confusión que muestra las predicciones correctas e incorrectas\n",
    "c_matrix = confusion_matrix(Y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mostramos la matriz de confusión en formato numérico\n",
    "# Filas = clases reales, Columnas = clases predichas\n",
    "print(c_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos la matriz de confusión como un mapa de calor (heatmap)\n",
    "# annot=True muestra los números dentro de cada celda\n",
    "import seaborn as sns\n",
    "sns.heatmap(c_matrix, annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretación de la matriz de confusión**\n",
    "\n",
    "La matriz de confusión muestra el desempeño del modelo al comparar las predicciones con las clases reales:\n",
    "\n",
    "| Clase real | Predicha como 0 | Predicha como 1 | Predicha como 2 |\n",
    "|-------------|----------------|----------------|----------------|\n",
    "| **0** | 16 | 0 | 2 |\n",
    "| **1** | 3 | 3 | 0 |\n",
    "| **2** | 0 | 0 | 10 |\n",
    "\n",
    "**Análisis:**\n",
    "- La **clase 0** fue clasificada correctamente en 16 casos, con 2 errores que fueron confundidos con la clase 2.  \n",
    "- La **clase 1** presenta el peor desempeño: solo 3 aciertos y 3 errores (predichos como clase 0).  \n",
    "- La **clase 2** fue reconocida correctamente en los 10 casos, sin confusiones.\n",
    "\n",
    "**Conclusión:**\n",
    "El modelo clasifica correctamente la mayoría de las instancias de las clases 0 y 2, pero tiene dificultades para identificar la clase 1, que se confunde principalmente con la clase 0.  \n",
    "En general, el rendimiento es aceptable, aunque se podría mejorar la discriminación de la clase 1 (por ejemplo, ajustando hiperparámetros, balanceando los datos o revisando las características usadas).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Nice confusion matrix catalog visuals examples](https://medium.com/@dtuk81/confusion-matrix-visualization-fc31e3f30fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculamos la matriz de confusión por cada clase\n",
    "# Esto devuelve un array 3D: una matriz (2x2) por cada clase\n",
    "mcm = multilabel_confusion_matrix(Y_test, predictions)\n",
    "\n",
    "# Seleccionamos la matriz de confusión de la clase con índice 2 (la tercera clase)\n",
    "matriz_clase_2 = mcm[2]\n",
    "\n",
    "# Dibujamos un heatmap con anotaciones de los valores\n",
    "sns.heatmap(matriz_clase_2, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicción\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.title(\"Matriz de confusión - Clase 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretación de la matriz de confusión - Clase 2**\n",
    "\n",
    "| Clase real | Predicha como 0 | Predicha como 1 |\n",
    "|-------------|----------------|----------------|\n",
    "| **0** | 22 | 2 |\n",
    "| **1** | 0 | 10 |\n",
    "\n",
    "**Análisis:**\n",
    "- El modelo predijo correctamente **22** casos de la clase 0 y **10** casos de la clase 1.\n",
    "- Solo se produjeron **2 errores**, donde instancias reales de la clase 0 fueron clasificadas incorrectamente como clase 1.\n",
    "- No hubo falsos negativos para la clase 1, lo que significa que el modelo identificó correctamente todos los casos positivos.\n",
    "\n",
    "**Conclusión:**\n",
    "El modelo muestra un desempeño **muy sólido** para esta clasificación binaria.  \n",
    "La precisión y el recall para la clase 1 son altos, indicando que el modelo distingue bien entre ambas clases, con muy pocos errores de clasificación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos matrices de confusión multilabel (una por cada clase)\n",
    "# Esto es útil para problemas de clasificación multiclase\n",
    "multilabel_confusion_matrix(Y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de cálculo manual de recall para la clase 2\n",
    "# Recall = Verdaderos Positivos / (Verdaderos Positivos + Falsos Negativos)\n",
    "10 / (0  + 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos un reporte completo de clasificación con métricas detalladas\n",
    "# Incluye precision, recall, f1-score y support para cada clase\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explicación de las métricas de evaluación en un modelo de clasificación**\n",
    "\n",
    "Las métricas **precision**, **recall**, **f1-score** y **accuracy** permiten evaluar el rendimiento de un modelo de clasificación comparando las predicciones con los valores reales.\n",
    "\n",
    "| Métrica | Descripción | Interpretación |\n",
    "|----------|-------------|----------------|\n",
    "| **Precision (Precisión)** | Porcentaje de predicciones correctas dentro de las instancias clasificadas como una clase. | Mide cuántos de los elementos que el modelo predijo como positivos realmente lo eran. Alta precisión significa pocos falsos positivos. |\n",
    "| **Recall (Exhaustividad o Sensibilidad)** | Porcentaje de verdaderos positivos detectados correctamente por el modelo. | Mide cuántos de los elementos realmente positivos fueron detectados. Alto recall significa pocos falsos negativos. |\n",
    "| **F1-score** | Media armónica entre precisión y recall. | Equilibra ambas métricas; útil cuando hay desequilibrio entre clases. Un valor alto indica un buen balance entre precisión y recall. |\n",
    "| **Support** | Número de instancias reales de cada clase en el conjunto de prueba. | Sirve para entender el peso que tiene cada clase en el cálculo de las métricas globales. |\n",
    "| **Accuracy (Exactitud global)** | Proporción total de predicciones correctas entre todas las muestras. | Mide el desempeño general del modelo. En este caso, 0.85 significa que el modelo acierta el 85% de las veces. |\n",
    "| **Macro avg** | Promedio simple de las métricas entre todas las clases. | Da el mismo peso a cada clase, sin importar cuántas instancias tenga. Útil cuando las clases están desbalanceadas. |\n",
    "| **Weighted avg** | Promedio ponderado por el número de muestras de cada clase. | Refleja mejor el desempeño global cuando las clases tienen distinto tamaño. |\n",
    "\n",
    "**Interpretación de los resultados:**\n",
    "- El modelo tiene una **exactitud general del 85%**, lo cual indica un buen rendimiento.  \n",
    "- La **clase 0** y la **clase 2** presentan buenos valores de precisión y recall, lo que significa que son bien clasificadas.  \n",
    "- La **clase 1** tiene una precisión perfecta (1.00) pero un recall bajo (0.50), lo que indica que aunque el modelo casi no comete falsos positivos, deja sin identificar la mitad de los casos reales de esa clase.  \n",
    "- En conjunto, el modelo funciona bien, pero sería conveniente mejorar la detección de la clase 1 para equilibrar el desempeño entre todas las clases.\n",
    "\n",
    "\n",
    "**Análisis por clase:**\n",
    "- **Clase 0:** Buen desempeño general, con alta precisión y recall.  \n",
    "- **Clase 1:** Alta precisión (1.00) pero bajo recall (0.50), lo que significa que el modelo casi no se equivoca al predecir clase 1, pero deja escapar muchos casos que pertenecen a ella.  \n",
    "- **Clase 2:** Excelente recall (1.00) y buen balance entre precisión y F1-score.\n",
    "\n",
    "**Conclusión:**\n",
    "El modelo muestra un rendimiento general bueno (**85% de exactitud**) y predice bien las clases 0 y 2. Sin embargo, necesita mejorar la detección de la **clase 1**, ya que identifica solo la mitad de sus casos reales. Ajustar el modelo o balancear los datos podría mejorar este comportamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos métricas globales usando promedio macro (sin considerar el soporte de cada clase)\n",
    "# average='macro' da el mismo peso a todas las clases independientemente de su frecuencia\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "\n",
    "print(\"recall\", recall_score(Y_test, predictions, average='macro'))\n",
    "print(\"precision\", precision_score(Y_test, predictions, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos métricas globales usando promedio ponderado (considerando el soporte de cada clase)\n",
    "# average='weighted' pondera las métricas según la frecuencia de cada clase en el dataset\n",
    "print(\"recall\", recall_score(Y_test, predictions, average='weighted'))\n",
    "print(\"precision\", precision_score(Y_test, predictions, average='weighted'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación de nuevos registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Creamos un nuevo registro para clasificar (simulando un nuevo usuario)\n",
    "# Contiene las mismas variables que nuestros datos de entrenamiento\n",
    "X_new = pd.DataFrame({'duracion': [8],\n",
    "                     'paginas': [5],\n",
    "                     'acciones': [5],\n",
    "                     'valor': [2]})\n",
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos el DataFrame a un array de NumPy para hacer la predicción\n",
    "# .values extrae solo los valores numéricos del DataFrame\n",
    "X_new.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos la clase para el nuevo registro\n",
    "# El modelo retorna la clase más probable (0=Windows, 1=Linux, 2=Mac)\n",
    "model.predict(X_new.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos las probabilidades de pertenencia a cada clase\n",
    "# Redondeamos a enteros para facilitar la interpretación\n",
    "np.round(model.predict_proba(X_new.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
