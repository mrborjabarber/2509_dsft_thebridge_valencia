{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación de imágenes\n",
    "Para este ejemplo vas a montar un clasificador de imágenes del 0 al 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos numpy para operaciones numéricas (comentado porque se carga automáticamente)\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el dataset de dígitos manuscritos de scikit-learn\n",
    "# Es un dataset limpio de imágenes 8x8 (64 píxeles) con dígitos del 0 al 9\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits() # 8x8 = 64 pixels  -- Very clean Dataset "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that you have the dataset loaded you can use the commands below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploramos qué contiene el objeto dataset\n",
    "# Muestra las claves disponibles como 'data', 'target', 'images', etc.\n",
    "digits.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos la descripción completa del dataset\n",
    "# Incluye información sobre el origen, características y estructura de los datos\n",
    "print(digits['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Verificamos las dimensiones de los datos\n",
    "# digits.data: matriz de 1797 imágenes x 64 características (8x8 píxeles aplanados)\n",
    "# digits.target: vector de 1797 etiquetas (números del 0 al 9)\n",
    "print(\"Image Data Shape\" , digits.data.shape)\n",
    "print(\"Label Data Shape\", digits.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examinamos los datos de la segunda imagen (índice 1) en formato aplanado\n",
    "# Cada valor representa la intensidad de un píxel (0-16)\n",
    "digits['data'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganizamos los datos aplanados de vuelta a una matriz 8x8\n",
    "# Esto nos permite visualizar la imagen como se vería originalmente\n",
    "digits['data'][1].reshape(8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos la etiqueta (clase) de la segunda imagen\n",
    "# Debería mostrar el dígito que representa esta imagen\n",
    "digits['target'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos el conjunto único de todas las clases en el dataset\n",
    "# Confirma que tenemos dígitos del 0 al 9 (10 clases)\n",
    "set(digits.target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convertimos los datos a un DataFrame de pandas para análisis\n",
    "# Cada columna (0-63) representa un píxel de la imagen 8x8 aplanada\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data= digits['data'])\n",
    "df['target'] = digits['target']  # Añadimos la columna target con las etiquetas\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos todas las etiquetas del dataset en un array\n",
    "# Cada posición corresponde a la etiqueta de una imagen\n",
    "digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contamos cuántas imágenes hay de cada dígito\n",
    "# Verificamos si el dataset está balanceado entre las clases\n",
    "df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos las primeras 50 etiquetas para ver la secuencia\n",
    "# Observamos que inicialmente están ordenadas del 0 al 9\n",
    "digits.target[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examinamos los datos de la primera imagen (índice 0) en formato aplanado\n",
    "# Array de 64 valores que representan los píxeles de una imagen 8x8\n",
    "digits.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos y mostramos la primera imagen como matriz 8x8\n",
    "# Cada número representa la intensidad del píxel en esa posición\n",
    "print(digits.data[0].reshape(8,8))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot some numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualizamos las primeras 5 imágenes del dataset con sus etiquetas\n",
    "# Creamos una figura con 5 subplots para mostrar las imágenes lado a lado\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20,2))  # Establecemos el tamaño de la figura\n",
    "for index, (image, label) in enumerate(zip(digits.data[0:5], digits.target[0:5])):\n",
    "    plt.subplot(1, 5, index + 1)  # Creamos subplot en posición index+1\n",
    "    plt.imshow(np.reshape(image, (8,8)), cmap='binary')  # Mostramos imagen en escala binaria\n",
    "    plt.title('Training: ' + str(label), fontsize = 20)  # Añadimos título con la etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos que cada imagen tiene 64 píxeles (8x8)\n",
    "# Confirmamos la dimensionalidad de nuestros datos\n",
    "8*8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data into Training and Test Sets (Digits Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos los datos en conjuntos de entrenamiento y prueba\n",
    "# 75% para entrenamiento, 25% para prueba (test_size = 0.25)\n",
    "# random_state=0 asegura reproducibilidad de la división aleatoria\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(digits.data,\n",
    "                                                   digits.target,\n",
    "                                                   test_size = 0.25,\n",
    "                                                   random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos los datos de entrenamiento\n",
    "# Matriz con las imágenes de entrenamiento (75% del dataset)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creamos y entrenamos el modelo de Regresión Logística\n",
    "# max_iter=10000 aumenta las iteraciones para garantizar convergencia en este dataset complejo\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logisticRegr = LogisticRegression(max_iter=10000)\n",
    "logisticRegr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el tamaño total de elementos en el conjunto de entrenamiento\n",
    "# 1347 imágenes × 64 píxeles = 86208 elementos totales\n",
    "x_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos la precisión del modelo en el conjunto de entrenamiento\n",
    "# Resultado de 1.0 indica ajuste perfecto (posible sobreajuste)\n",
    "logisticRegr.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos la precisión del modelo en el conjunto de prueba\n",
    "# Esta es la métrica más importante - rendimiento en datos no vistos\n",
    "logisticRegr.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos las clases que el modelo puede predecir\n",
    "# Debe mostrar los dígitos del 0 al 9\n",
    "logisticRegr.classes_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos las primeras 5 imágenes del conjunto de prueba con sus etiquetas reales\n",
    "# Esto nos permite ver qué tipo de dígitos estamos intentando predecir\n",
    "plt.figure(figsize=(20,2))\n",
    "for index, (image, label) in enumerate(zip(x_test[0:5], y_test[0:5])):\n",
    "    plt.subplot(1, 5, index + 1)\n",
    "    plt.title('Test: ' + str(label), fontsize = 20)\n",
    "    plt.imshow(np.reshape(image, (8,8)), cmap='binary');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos la segunda imagen del conjunto de prueba\n",
    "# Utilizamos escala de grises para una mejor visualización\n",
    "first_test_image = x_test[1]\n",
    "plt.imshow(np.reshape(first_test_image, (8,8)), cmap=plt.cm.gray);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos los valores de píxeles de la segunda imagen del conjunto de prueba\n",
    "# Array de 64 valores que representan las intensidades de los píxeles\n",
    "x_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraemos la primera imagen del conjunto de prueba para predicción\n",
    "# Mantenemos la forma de array 2D (1 muestra × 64 características)\n",
    "x_test[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos la clase de la segunda imagen del conjunto de prueba\n",
    "# El modelo retorna el dígito que cree que representa la imagen\n",
    "logisticRegr.predict(x_test[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos las primeras 10 imágenes del conjunto de prueba con sus etiquetas\n",
    "# Esto nos permite comparar visualmente las etiquetas reales con las predicciones\n",
    "plt.figure(figsize=(20,2))\n",
    "for index, (image, label) in enumerate(zip(x_test[0:10], y_test[0:10])):\n",
    "    plt.subplot(1, 10, index + 1)\n",
    "    plt.title('Test: ' + str(label), fontsize = 20)\n",
    "    plt.imshow(np.reshape(image, (8,8)), cmap='binary');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos las clases para las primeras 10 imágenes del conjunto de prueba\n",
    "# Retorna un array con las predicciones del modelo\n",
    "logisticRegr.predict(x_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos las etiquetas reales de las primeras 10 imágenes\n",
    "# Podemos compararlas con las predicciones del modelo\n",
    "y_test[:10]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos la etiqueta real de la segunda imagen del conjunto de prueba\n",
    "# Para verificar si nuestra predicción fue correcta\n",
    "y_test[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos las probabilidades de predicción para la segunda imagen\n",
    "# Cada posición corresponde a la probabilidad de ser cada dígito (0-9)\n",
    "# Redondeamos a 2 decimales para mejor legibilidad\n",
    "np.round(logisticRegr.predict_proba(x_test[1:2])[0],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontramos la probabilidad máxima de predicción para la primera imagen\n",
    "# Esto nos indica qué tan confiado está el modelo en su predicción\n",
    "max(logisticRegr.predict_proba(x_test[0:1])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repetimos las etiquetas reales de las primeras 10 imágenes para comparación\n",
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtramos y visualizamos una imagen donde la predicción coincide con la etiqueta real\n",
    "# Esto nos muestra un ejemplo de predicción correcta\n",
    "pred = x_test[logisticRegr.predict(x_test) == y_test][0]\n",
    "plt.imshow(pred.reshape(8,8), cmap=plt.cm.gray);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos la forma de los coeficientes del modelo entrenado\n",
    "# 10 filas (una por cada dígito) × 64 columnas (una por cada píxel)\n",
    "logisticRegr.coef_.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring Model Performance (Digits Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculamos y mostramos la precisión del modelo en el conjunto de prueba\n",
    "# Convertimos a porcentaje para mejor interpretación\n",
    "score = logisticRegr.score(x_test, y_test)\n",
    "print(score * 100, \"%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusión"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eje horizontal: falso positivo\n",
    "\n",
    "Eje vertical: falso negativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculamos la matriz de confusión para evaluar el rendimiento por clase\n",
    "# Comparamos las predicciones del modelo con las etiquetas reales\n",
    "import sklearn.metrics as metrics\n",
    "predictions = logisticRegr.predict(x_test)\n",
    "cm = metrics.confusion_matrix(y_test, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos la matriz de confusión como un mapa de calor\n",
    "# Facilita la interpretación del rendimiento del modelo por cada dígito\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.heatmap(cm, annot=True, linewidths=.5, square = True, cmap = 'Blues_r')\n",
    "plt.ylabel('Actual label')  # Etiqueta del eje Y\n",
    "plt.xlabel('Predicted label')  # Etiqueta del eje X\n",
    "all_sample_title = 'Accuracy Score: {0}'.format(score)  # Título con la precisión\n",
    "plt.title(all_sample_title, size = 15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una matriz de confusión normalizada (en proporciones)\n",
    "# normalize='true' convierte los conteos a porcentajes por fila\n",
    "sns.heatmap(metrics.confusion_matrix(y_test, predictions, normalize='true'), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos matrices de confusión multilabel\n",
    "# Genera una matriz de confusión binaria para cada clase (dígito)\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "multilabel_confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos la función para generar reportes de clasificación detallados\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos un reporte completo de clasificación\n",
    "# Incluye precision, recall, f1-score y support para cada dígito\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimentamos con regularización L2 y parámetro C=1\n",
    "# C controla la fuerza de regularización (valores menores = más regularización)\n",
    "logisticRegr = LogisticRegression(max_iter=10000, penalty='l2', C=1)\n",
    "logisticRegr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos el rendimiento con C=1\n",
    "# Comparamos precisión en entrenamiento vs prueba para detectar sobreajuste\n",
    "print(logisticRegr.score(x_train, y_train))\n",
    "print(logisticRegr.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probamos con mayor regularización (C=0.01) y (Ridge)\n",
    "# Más regularización puede reducir el sobreajuste pero también la precisión\n",
    "logisticRegr = LogisticRegression(max_iter=10000, penalty='l2', C=0.01) \n",
    "logisticRegr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos el rendimiento con C=0.01\n",
    "# Observamos si mejora la generalización (menor diferencia entre train y test)\n",
    "print(logisticRegr.score(x_train, y_train))\n",
    "print(logisticRegr.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimentamos con regularización muy fuerte (C=0.0001)\n",
    "# Esto podría causar subajuste (underfitting)\n",
    "logisticRegr = LogisticRegression(max_iter=10000, penalty='l2', C=0.0001)\n",
    "logisticRegr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos el rendimiento con regularización muy fuerte\n",
    "# Esperamos ver precisión reducida tanto en train como test\n",
    "print(logisticRegr.score(x_train, y_train))\n",
    "print(logisticRegr.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probamos con muy poca regularización (C=100000)\n",
    "# Valores altos de C permiten mayor flexibilidad del modelo\n",
    "logisticRegr = LogisticRegression(max_iter=10000, penalty='l2', C=100000)\n",
    "logisticRegr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos el rendimiento con poca regularización\n",
    "# Podría mostrar sobreajuste si hay gran diferencia entre train y test\n",
    "print(logisticRegr.score(x_train, y_train))\n",
    "print(logisticRegr.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparamos con Random Forest como algoritmo alternativo\n",
    "# Random Forest suele tener buen rendimiento en tareas de clasificación de imágenes\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=12)  # Limitamos la profundidad para evitar sobreajuste\n",
    "rf.fit(x_train, y_train)  # Entrenamos el modelo\n",
    "y_pred = rf.predict(x_test)  # Hacemos predicciones\n",
    "\n",
    "# Evaluamos el rendimiento\n",
    "print(\"accuracy\", rf.score(x_test, y_test))\n",
    "print(\"confusion_matrix\\n\", metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretación de los resultados del modelo Random Forest (clasificación de dígitos 0–9)**\n",
    "\n",
    "**Resultados:**\n",
    "- **Accuracy:** 0.98 → El modelo clasifica correctamente el **98% de los dígitos**, lo que indica un rendimiento excelente.  \n",
    "- **Matriz de confusión:**  \n",
    "  La mayoría de los valores se concentran en la diagonal principal, lo que significa que casi todos los dígitos fueron reconocidos correctamente.\n",
    "\n",
    "**Análisis detallado:**\n",
    "- Los dígitos **0, 6, 7, 8 y 9** fueron clasificados correctamente en casi todos los casos, sin errores relevantes.  \n",
    "- El dígito **1** tuvo un solo error, confundido con el dígito **5**.  \n",
    "- El dígito **2** fue confundido una vez con **0** y una vez con **3**.  \n",
    "- El dígito **3** tuvo un error leve, confundido con **8**.  \n",
    "- El dígito **4** se confundió una vez con **7**.  \n",
    "- El dígito **5** tuvo un error mínimo, confundido con **9**.  \n",
    "- En general, las confusiones son **muy pocas y esporádicas**, lo que refleja un modelo bien ajustado.\n",
    "\n",
    "**Conclusión:**\n",
    "El modelo **Random Forest** logra un desempeño **muy alto (98% de acierto)**, mostrando una capacidad excelente para distinguir los dígitos del 0 al 9.  \n",
    "Los errores que aparecen se dan entre números visualmente similares, lo cual es esperable en este tipo de tarea.  \n",
    "El modelo generaliza bien y **no presenta signos de sobreajuste significativos**, especialmente considerando que la profundidad de los árboles fue limitada a 12.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "\n",
    "# Calculamos la matriz de confusión\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Creamos la figura\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Dibujamos el mapa de calor\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=range(10), yticklabels=range(10))\n",
    "\n",
    "# Etiquetas y título\n",
    "plt.xlabel('Etiqueta Predicha')\n",
    "plt.ylabel('Etiqueta Real')\n",
    "plt.title('Matriz de Confusión - Random Forest (Clasificación de Dígitos)')\n",
    "\n",
    "# Mostramos la gráfica\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizamos la importancia de características (feature importance) del Random Forest\n",
    "# Reorganizamos como matriz 8x8 para visualizar qué píxeles son más importantes\n",
    "# Redondeamos a 2 decimales para mejor legibilidad\n",
    "np.round(rf.feature_importances_,2).reshape(8,8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
