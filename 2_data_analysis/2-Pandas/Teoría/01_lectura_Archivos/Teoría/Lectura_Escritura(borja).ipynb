{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![imagen](./img/python.jpg)\n",
    "\n",
    "# Lectura Escritura\n",
    "\n",
    "En este módulo vas a ver diferentes maneras de leer y escribir datos desde archivos locales. Rara vez trabajarás únicamente con los datos que genere tu programa de Python, sino que lo normal será acudir a una fuente de datos, o leer de algún archivo.\n",
    "\n",
    "1. [Archivos](#1.-Archivos)\n",
    "2. [Abrir ficheros](#2.-Abrir-ficheros)\n",
    "3. [CSV](#3.-CSV)\n",
    "4. [Excel](#4.-Excel)\n",
    "5. [JSON](#5.-JSON)\n",
    "6. [TXT](#6.-TXT)\n",
    "7. [ZIP](#7.-ZIP)\n",
    "8. [pickle](#8.-pickle)\n",
    "9. [Encoding](#9.-Encoding)\n",
    "10. [Archivos y carpetas](#10.-Archivos-y-carpetas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Archivos\n",
    "Antes de ir a leer o escribir archivos, es importante saber exáctamente qué es un archivo. **Un archivo es un conjunto de datos almacenados en el ordenador en forma de bits.** Los datos se organizan en un formato específico, pudiendo ser un archivo de texto, un ejecutable... pero en el fondo todos esos archivos se traducen a nivel binario para el procesado del ordenador. Los archivos se componen de:\n",
    "\n",
    "1. **Header**: metadatos del archivo (nombre, tamaño, tipo...)\n",
    "2. **Data**: contenido del archivo\n",
    "3. **End of file (EOF)**: caracter especial que indica el final del archivo.\n",
    "\n",
    "![imagen](./img/file.png)\n",
    "\n",
    "#### File path\n",
    "Hay tres elementos que tenemos que conocer cuando leamos un archivo:\n",
    "1. **Folder path**: en que lugar del ordenador está el archivo. Y no solo eso, si no en qué directorio está apuntando el programa de Python.\n",
    "2. **File name**\n",
    "3. **Extension**: lo que va después del punto\n",
    "\n",
    "Fíjate en la siguiente imagen:\n",
    "\n",
    "![imagen](./img/path.png)\n",
    "\n",
    "* Si estamos trabajando en el directorio *to*, accederemos a *cats.gif* como `cats.gif`\n",
    "* Si queremos leer *dog_breeds.txt*, hay que ir un directorio hacia atrás, `../dog_breeds.txt`\n",
    "* Y si queremos acceder a `animals.csv`, son dos directorios hacia atrás: `../../animals.csv`\n",
    "\n",
    "Siempre podemos poner la ruta absoluta (`C/Users/usuario/Archivos/Bootcamp/Python/animals.csv`) para el acceso a cada archivo, **aunque no es lo recomendable**.\n",
    "\n",
    "[Buena guía para iniciarse en la lectura/escritura de archivos con Python.](https://realpython.com/read-write-files-python/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Abrir ficheros\n",
    "A lo largo de este notebook verás diferentes funciones para leer archivos, en función de la extensión cada uno. Estas funciones provienen de otras librerías y nos facilitan mucho la vida a la hora de leer o escribir archivos. No obstante, Python tiene sus propias funciones *built-in*, con las que no es necesario utilizar otros paquetes. \n",
    "\n",
    "Para ello **usaremos la función `open`**, que devuelve un objeto de tipo `File`, con unos métodos y atributos propios empleados para obtener información de los archivos abiertos. `open` sigue la siguiente sitaxis:\n",
    "\n",
    "```Python\n",
    "file_object  = open(\"filename\", \"mode\")\n",
    "```\n",
    "\n",
    "El primer argumento es el nombre del archivo, mientras que en el modo tendremos que especificar si queremos leer, o escribir. Por defecto leerá, es decir, el parámetro valdrá *r*, de read. [Te dejo el enlace a la documentación para consultar el resto de modos](https://docs.python.org/3/library/functions.html#open).\n",
    "\n",
    "Vamos a probar a leer un archivo. La siguiente sintaxis de línea se utiliza porque en algún momento se tiene que cerrar el archivo. Se abre, leemos, realizamos operaciones, y cuando acaba el `with open()`, se cierra el archivo. **Leer y escribir mientras los archivos están abiertos nos dará errores**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 1: Lectura básica de archivos TXT con open()\n",
    "# Abrimos el archivo 'dog_breeds.txt' en modo lectura ('r')\n",
    "# El contexto 'with' asegura que el archivo se cierra automáticamente al terminar\n",
    "with open('data/dog_breeds.txt', 'r') as open_file:\n",
    "    # Leemos todo el contenido del archivo como un único string\n",
    "    all_text = open_file.read()\n",
    "    # Verificamos el tipo de dato retornado (será 'str')\n",
    "    print(type(all_text))\n",
    "    # Imprimimos el contenido completo del archivo\n",
    "    print(all_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método `.read()` nos devuelve un string con todo el texto, que no es lo ideal para tratar luego los datos.\n",
    "\n",
    "En el siguiente ejemplo vemos como también lo leemos, pero en este caso cada línea la guarda en una lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 2: Lectura de archivos línea por línea con readlines()\n",
    "# Nuevamente abrimos el archivo en modo lectura\n",
    "with open('data/dog_breeds.txt', 'r') as open_file:\n",
    "    # readlines() devuelve una LISTA donde cada elemento es una línea del archivo\n",
    "    all_text = open_file.readlines()\n",
    "    # Verificamos que el tipo es 'list'\n",
    "    print(type(all_text))\n",
    "    # Imprimimos la lista completa (cada línea incluye '\\n' al final)\n",
    "    print(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 3: Iterar sobre las líneas del archivo\n",
    "# Abrimos el archivo y leemos todas las líneas\n",
    "with open('data/dog_breeds.txt', 'r') as open_file:\n",
    "    # Recorremos cada línea de la lista retornada por readlines()\n",
    "    for line in open_file.readlines():\n",
    "        # Imprimimos cada línea, usando end='' para evitar saltos de línea adicionales\n",
    "        print(line, end = '')\n",
    "        \n",
    "# Imprimimos 'Fin' para marcar el final del contenido\n",
    "print('Fin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 4: Iterar directamente sobre el objeto archivo\n",
    "# Esta es la forma más eficiente de leer archivos grandes línea por línea\n",
    "with open('data/dog_breeds.txt', 'r') as reader:\n",
    "    # Iteramos directamente sobre el objeto 'reader' (sin usar readlines())\n",
    "    # Esto es más eficiente en memoria para archivos grandes\n",
    "    for line in reader:\n",
    "        # Imprimimos cada línea sin saltos adicionales\n",
    "        print(line, end='')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos escribir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 5: Escritura de archivos con write()\n",
    "# Abrimos un archivo en modo escritura ('w') - si existe, se sobrescribe\n",
    "with open('data/preguntas.py', 'w') as new_file:\n",
    "    # Escribimos varias líneas en el archivo (cada write() escribe una línea)\n",
    "    new_file.write(\"print(\\\"Hola mundo\\\")\\n\")\n",
    "    new_file.write(\"#Esto se crea?\\n\")\n",
    "    new_file.write(\"#Segunda linea\\n\")\n",
    "    new_file.write(\"#Tercera linea\\n\")\n",
    "    print(\"Ya se ha escrito\")\n",
    "\n",
    "# Ahora leemos el archivo que acabamos de crear para verificar su contenido\n",
    "with open(\"data/preguntas.py\", \"r\") as new_file:\n",
    "    # readlines() devuelve todas las líneas como una lista\n",
    "    print(new_file.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 6: Escritura de código Python en un archivo\n",
    "# Creamos un archivo con código Python válido (una clase)\n",
    "with open('data/class_hlf.py', 'w') as new_file:\n",
    "    # Escribimos la definición de una clase\n",
    "    new_file.write(\"class Barco():\\n\")\n",
    "    # \\t representa un tabulador para la indentación\n",
    "    new_file.write(\"\\teslora = 4\")\n",
    "    print(\"Ya se ha escrito\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 7: Añadir contenido a un archivo existente con modo append\n",
    "# Modo 'a' (append) añade contenido al final sin borrar lo existente\n",
    "with open('data/class_hlf.py', 'a') as new_file:\n",
    "    # Añadimos saltos de línea y una nueva clase al archivo\n",
    "    new_file.write(\"\\n\\nclass Tablero():\\n\")\n",
    "    new_file.write(\"\\tjugadores = 4\")\n",
    "    print(\"Ya se ha escrito\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CSV\n",
    "***Comma Separated Values*. Es el estándar de la industria que se utiliza para leer/escribir datos en formato tabla**, en dos dimensiones. Se llaman *Comma Separeted Values* ya que todos los valores de las columnas van separados por comas, y las filas por saltos de línea. **Su extension de archivo es `.csv`**. Además, el 99% de las veces llevan la cabecera de columnas en la primera línea. Aunque no siempre se dará el caso, depende de la manera en la que se haya generado el CSV.\n",
    "\n",
    "**Es el archivo más común utilizado para guardar datos tabulares, puesto que ocupa muy poco espacio** ya que es simplemente un archivo de texto plano, con todos los datos separados por el caracter coma. Y además, sencillo de entender, los datos no van en un árbol json o xml... Si lo abrimos como texto plano, son los datos separados por coma, tal cual. \n",
    "\n",
    "Por supuesto, tenemos el otro gran protagonista en cuanto a almacenamiento de datos en formato tabla, **el Excel**. A ver, son cosas diferentes. El Excel tiene sus formatos (.xlsx, .xls), que encima son muy eficientes ya que el dato va comprimido, pero no deja de ser un software de pago para tratar los datos, mientras que **el CSV es un formato estándar que se utiliza en todos los sistemas operativos para el exportado/importado de datos**.\n",
    "\n",
    "Como decíamos al principio, los CSVs se llaman *Comma Separated Values* porque todos los valores van separados por comas... bueno, esto no es del todo cierto ya que **puede haber otro caracter que no sea la coma**, como por ejemplo el punto y coma. ¿Por qué? Simplemente porque si tenemos datos decimales, separados por comas, no vamos a saber distinguir cuando una coma es de un decimal, o es el separador de columnas.\n",
    "\n",
    "**¿Cómo podemos leer un CSV en Python?** Con Pandas! [Aquí tienes la documentación](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 8: Lectura de archivos CSV con Pandas\n",
    "# Importamos las librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read_csv() es el método principal de Pandas para leer archivos CSV\n",
    "# Por defecto asume que el separador es coma (,)\n",
    "df = pd.read_csv('data/laliga.csv')\n",
    "# head() muestra las primeras 5 filas del DataFrame\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parámetros interesantes del `read_csv()`**\n",
    "1. `filepath_or_buffer`: ruta donde está el CSV\n",
    "2. `sep`: el separador de los datos, por defecto es coma, pero podría ser otro como veremos en ejemplos posteriores.\n",
    "3. `header`: dónde se encuentran los nombre de columnas. Por defecto es en la primera línea.\n",
    "\n",
    "Probemos a leer el CSV desde otra ruta del ordenador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CELDA 9: Lectura de CSV desde una ruta almacenada en variable\n",
    "# Guardamos la ruta en una variable para mejor organización del código\n",
    "tu_ruta = 'data/laliga.csv'\n",
    "# Leemos el CSV usando la variable con la ruta\n",
    "df = pd.read_csv(tu_ruta)\n",
    "\n",
    "# Mostramos las primeras 5 filas\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una de las columnas, la podremos usar como index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 10: Uso de index_col para establecer el índice del DataFrame\n",
    "# El parámetro index_col permite usar una columna existente como índice\n",
    "# En este caso usamos \"Unnamed: 0\" como índice en lugar del numérico por defecto\n",
    "df = pd.read_csv('data/laliga.csv', index_col = \"Unnamed: 0\")\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos pasar el índice a una nueva columna, simplemente creamos una columna nueva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 11: Conversión del índice a columna y reseteo del índice\n",
    "# Creamos una nueva columna con los valores del índice actual\n",
    "df['nueva columna'] = df.index\n",
    "# reset_index() restablece el índice a valores numéricos (0, 1, 2...)\n",
    "# inplace=True modifica el DataFrame directamente sin crear una copia\n",
    "# drop=True elimina el índice antiguo en lugar de convertirlo en columna\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 12: Visualización del DataFrame tras el reseteo\n",
    "# Comprobamos cómo quedó el DataFrame después de resetear el índice\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos resetear también el índice, y poner ahi un numérico que vaya desde el 0 al número de filas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CELDA 13: Reseteo del índice sin modificar el DataFrame original\n",
    "# Al no usar inplace=True, devuelve un nuevo DataFrame sin modificar el original\n",
    "# drop=True asegura que no se conserve el índice antiguo como columna\n",
    "df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CELDA 14: Personalización manual del índice\n",
    "# Cambiamos el índice para que comience en 1 en lugar de 0\n",
    "# range(1, df.shape[0] + 1) genera números desde 1 hasta el número de filas\n",
    "df.index = range(1, df.shape[0] + 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 15: Obtención de las dimensiones del DataFrame\n",
    "# shape devuelve una tupla (filas, columnas)\n",
    "print(df.shape)      # Ambas dimensiones\n",
    "print(df.shape[0])   # Solo número de filas\n",
    "print(df.shape[1])   # Solo número de columnas\n",
    "print(len(df))       # len() también devuelve el número de filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 16: Visualización de las primeras filas con parámetro personalizado\n",
    "# head(2) muestra solo las 2 primeras filas (por defecto son 5)\n",
    "df.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También es posible aplicarle nombres de columnas en la lectura de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 17: Visualización de los nombres de las columnas\n",
    "# columns devuelve un objeto Index con todos los nombres de columnas\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CELDA 18: Renombrar columnas durante la lectura del CSV\n",
    "# El parámetro 'names' permite asignar nombres personalizados a las columnas\n",
    "# header=0 indica que la primera fila contiene encabezados (se ignorarán)\n",
    "df = pd.read_csv('data/laliga.csv',\n",
    "                 names = ['Indice', 'Temporada', 'Division', 'Jornada',\n",
    "                          'Equipo local', 'Equipo visitante', 'Goles local',\n",
    "                          'Goles visitante', 'fecha', 'timestamp'],\n",
    "                header = 0)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos cambiar los tipos de los datos, en la propia lectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CELDA 19: Verificación de tipos de datos de las columnas\n",
    "# dtypes muestra el tipo de dato de cada columna\n",
    "# object = texto/string, int64 = entero de 64 bits\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 20: Lectura selectiva de columnas con tipos de datos específicos\n",
    "# usecols: selecciona solo las columnas especificadas\n",
    "# dtype: asigna tipos de datos específicos a cada columna\n",
    "# np.int16 ocupa menos memoria que np.int64\n",
    "df = pd.read_csv(\"data/laliga.csv\",\n",
    "                usecols = ['Unnamed: 0', 'division', 'localTeam'],\n",
    "                dtype = {'Unnamed: 0': object,\n",
    "                         'division': np.int16,  # int16 ahorra memoria\n",
    "                         'localTeam': object})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 21: Verificación de los tipos de datos aplicados\n",
    "# Comprobamos que los tipos se aplicaron correctamente\n",
    "# Notar que 'division' ahora es int16 en lugar de int64\n",
    "df.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Cómo leer un archivo CSV que no esté separado por comas?**\n",
    "Probemos a leer un archivo CSV, que no tiene comas como delimitador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 22: Intento de lectura de CSV con separador incorrecto\n",
    "# Este archivo usa punto y coma (;) como separador, no coma\n",
    "# Al no especificar sep=';', Pandas no detecta las columnas correctamente\n",
    "df = pd.read_csv(\"data/laligaPC.csv\")\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo lee todo como una única línea ya que no encuentra comas. **Se recomienda trabajar con CSVs cuyo separador sea el ; así evitamos problemas por los decimales**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CELDA 23: Lectura correcta de CSV con separador punto y coma\n",
    "# sep=';' indica que el separador es punto y coma\n",
    "# Esto es común en países donde la coma se usa para decimales\n",
    "df = pd.read_csv(\"data/laligaPC.csv\", sep=';')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Podemos tener otros caracteres que separen los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CELDA 24: Intento de lectura con separador personalizado (virgulilla)\n",
    "# Este archivo usa ~ como separador\n",
    "# Sin especificar sep='~', Pandas no lo interpreta correctamente\n",
    "df = pd.read_csv(\"data/laliga4.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 25: Lectura correcta con separador virgulilla (~)\n",
    "# Pandas puede usar cualquier carácter como separador\n",
    "# sep='~' indica que usamos virgulilla como delimitador\n",
    "df = pd.read_csv(\"data/laliga4.csv\", sep='~')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 26: Lectura completa de archivo con punto y coma\n",
    "# Esta celda muestra el DataFrame completo (4940 filas)\n",
    "# sin el parámetro head(), mostrando todas las filas\n",
    "pd.read_csv(\"data/laligaPC.csv\", sep=\";\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Escritura de CSV**\n",
    "\n",
    "Para escribir un CSV usamos el método `to_csv()`. Tienes [el enlace a la documentación para ver más detalle](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 27: Escritura de DataFrame a archivo CSV\n",
    "# to_csv() guarda el DataFrame en formato CSV\n",
    "# sep=';' establece punto y coma como separador\n",
    "# index=False evita guardar el índice como columna adicional\n",
    "df.to_csv(\"data/laligaWrite.csv\", sep = ';', index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    " <tr><td width=\"80\"><img src=\"./img/ejercicio.png\" style=\"width:auto;height:auto\"></td>\n",
    "     <td style=\"text-align:left\">\n",
    "         <h3>Ejercicio CSV</h3>\n",
    "\n",
    "Crea un fichero de CSV llamado ejercicio_clase.csv en la carpeta de data a partir de estas Series con separador de ; y leelo a continuación.\n",
    "         \n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 28: Creación de Series de Pandas para ejercicio\n",
    "# Creamos dos Series: una con población y otra con superficie\n",
    "# Series es una estructura de datos unidimensional de Pandas\n",
    "poblacion = pd.Series({\"Madrid\": 6685471, \"Galicia\": 2698764,\n",
    "                       \"Murcia\": 1494442, \"Andalucia\": 8446561})\n",
    "\n",
    "# Podemos crear Series con lista de valores e índices separados\n",
    "superficie = pd.Series([8028, 29575, 11314, 87599],\n",
    "                       index = [\"Madrid\", \"Galicia\", \"Murcia\", \"Andalucia\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 29: Creación de DataFrame a partir de Series\n",
    "# Combinamos las dos Series en un DataFrame\n",
    "# Cada Serie se convierte en una columna del DataFrame\n",
    "df = pd.DataFrame({\"poblacion\": poblacion,\n",
    "                   \"superficie\": superficie})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 30: Guardar y leer CSV con índice personalizado\n",
    "# Guardamos el DataFrame en CSV con separador punto y coma\n",
    "df.to_csv(\"data/ejercicio.csv\", sep=\";\")\n",
    "\n",
    "# Leemos el CSV recién creado\n",
    "# index_col=0 usa la primera columna como índice\n",
    "df_lectura = pd.read_csv(\"data/ejercicio.csv\", sep=\";\", index_col=0)\n",
    "df_lectura"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Excel\n",
    "¿Qué empresa no trabaja con Excel? **Nos vamos a encontrar los formatos de datos de Excel en cualquier sitio**. Las extensiones de archivo más habituales son `.xlsx` y `.xls`. Por suerte, **`pandas` tiene métodos para leer los formatos de archivo de Excel**.\n",
    "\n",
    "El problema que presenta este tipo de lectura de datos es que **no es un formato tan cerrado como el CSV**. En el CSV tenemos una estructura compacta, con todos los datos separados por comas y con una línea de cabecera en la primera fila. El Excel permite tener datos en un formato mucho más flexible, con tablas en cualquier sitio de las hojas, información en varias hojas y demás.\n",
    "\n",
    "Teniendo esto en cuenta, y sabiendo bien el formato del Excel en cuestión, podremos leerlo sin problemas con `pandas`, debido a la cantidad de argumentos que tiene la función `read_excel`. [En la documentación tienes todo el detalle](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html).\n",
    "\n",
    "Leemos nuestro archivo de laliga, pero en este caso en Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CELDA 31: Lectura de archivos Excel con Pandas\n",
    "# read_excel() permite leer archivos .xlsx y .xls\n",
    "# Por defecto lee la primera hoja del archivo\n",
    "df = pd.read_excel('data/laliga.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No tenemos problemas cuando los datos están perfectos, con una única hoja, y empezando en la celda A1. ¿Qué argumentos nos pueden resultar útiles?\n",
    "\n",
    "1. `io`: dónde está el archivo\n",
    "2. `sheet_name`: el nombre de la hoja\n",
    "3. `header`: dónde está la cabecera\n",
    "4. `usecols`: indica el rango de columnas Excel en el que se encuentran. Por ejemplo: 'A:F'\n",
    "5. `skiprows`: filas que deberia ignorar\n",
    "\n",
    "Veamos más ejemplos. El Excel de `laliga.xlsx` tiene varias pestañas. Por defecto, lee la primera, `Hoja1`, pero podemos especificar otras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 32: Lectura de una hoja específica de Excel\n",
    "# sheet_name permite especificar qué hoja leer\n",
    "# En este caso 'Hoja2' que tiene filas vacías al inicio\n",
    "df = pd.read_excel('data/laliga.xlsx', sheet_name = 'Hoja2')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que hay algún problema con los datos. Las primeras líneas están en blanco en el Excel. Podemos, o bien ignorarlas, o indicarle donde está la cabecera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CELDA 33: Manejo de encabezados en Excel con filas vacías\n",
    "# header=2 indica que los nombres de columnas están en la fila 3 (índice 2)\n",
    "# Esto omite las filas vacías al principio del archivo\n",
    "df = pd.read_excel('data/laliga.xlsx', sheet_name = 'Hoja2', header = 2)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro problema que nos puede surgir es que la tabla no esté ni en las primeas filas, ni en las primeras columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CELDA 34: Selección de rango de columnas en Excel\n",
    "# usecols='B:K' selecciona solo las columnas B hasta K (en notación Excel)\n",
    "# Útil cuando los datos no están en las primeras columnas\n",
    "df = pd.read_excel('data/laliga.xlsx',\n",
    "                   sheet_name = 'Hoja3',\n",
    "                  header = 2,\n",
    "                  usecols = 'B:K')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 35: Lectura limitada de filas en Excel\n",
    "# nrows=10 limita la lectura a las primeras 10 filas de datos\n",
    "# Combinado con header y usecols para datos en ubicaciones específicas\n",
    "df = pd.read_excel('data/laliga.xlsx',\n",
    "                   sheet_name = 'Hoja4',\n",
    "                  header = 3,\n",
    "                  usecols = 'C:L',\n",
    "                  nrows = 10)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 36: Omitir filas específicas al leer Excel\n",
    "# skiprows permite omitir filas específicas\n",
    "# list(range(4942,4952)) omite las filas 4942 a 4951\n",
    "# Útil para eliminar filas de totales o notas al final del archivo\n",
    "df = pd.read_excel('data/laliga.xlsx',\n",
    "                   sheet_name = 'Hoja5',\n",
    "                   skiprows=list(range(4942,4952)))\n",
    "len(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Escritura de Excel**\n",
    "\n",
    "Al igual que con el CSV, tenemos el método `to_excel()`, para escribir el `DataFame` en un archivo Excel. **Recuerda poner la extensión del Excel (.xlsx) en el nombre del archivo**. Tienes [el enlace a la documentación para ver más detalle](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_excel.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 37: Escritura de DataFrame a Excel\n",
    "# to_excel() guarda el DataFrame en formato Excel (.xlsx)\n",
    "# Es importante incluir la extensión .xlsx en el nombre del archivo\n",
    "df.to_excel('data/laligaExcelWrite.xlsx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. JSON\n",
    "***JavaScript Objet Notation* es otro formato de texto plano que se utiliza para el itercambio de datos**. Originalmente se utilizaba como notación literal de objetos en JavaScript, pero actualmente es un formato de datos independiente del lenguaje. JavaScript es un lenguaje de programción web, por lo que JSON se utiliza mucho en el intercambio de objetos entre cliente y servidor.\n",
    "\n",
    "**¿Qué diferencia hay con un CSV o un Excel?** Ya no tenemos esa estructura de fila/columna, sino que ahora es un formato tipo clave/valor, como si fuese un diccionario. En una tabla en la fila 1, columna 1, tienes un valor. En un JSON no, en la clave \"mi_clave\" puedes tener almacenado un valor, una lista o incluso un objeto. Salimos del formato tabla al que estamos acostubrados para ganar en flexibilidad.\n",
    "\n",
    "Un JSON tiene la siguiente pinta:\n",
    "\n",
    "![imagen](./img/json_image.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 38: Creación de estructura JSON con diccionarios anidados\n",
    "# JSON permite estructuras jerárquicas con diccionarios y listas\n",
    "# Esta estructura representa una persona con hijos\n",
    "data =  {\n",
    "        \"firstName\": \"Jane\",\n",
    "        \"lastName\": \"Doe\",\n",
    "        \"hobbies\": [\"running\", \"sky diving\", \"singing\"],  # Lista de hobbies\n",
    "        \"age\": 35,\n",
    "        \"children\": [  # Lista de diccionarios (objetos anidados)\n",
    "            {\n",
    "                \"firstName\": \"Alice\",\n",
    "                \"age\": 6\n",
    "            },\n",
    "            {\n",
    "                \"firstName\": \"Bob\",\n",
    "                \"age\": 8\n",
    "            }\n",
    "        ]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 39: Acceso a elementos de listas en JSON\n",
    "# Accedemos al primer hobby usando indexación de listas\n",
    "# data['hobbies'] devuelve la lista, [0] toma el primer elemento\n",
    "data['hobbies'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 40: Acceso a datos anidados en JSON\n",
    "# Navegamos por la estructura: children (lista) -> segundo elemento [1] -> firstName\n",
    "# Esto demuestra cómo acceder a datos en estructuras JSON complejas\n",
    "data['children'][1]['firstName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 41: Iteración sobre listas en JSON\n",
    "# Recorremos la lista de hijos e imprimimos el nombre de cada uno\n",
    "# Útil para procesar colecciones de objetos en JSON\n",
    "for kid in data['children']:\n",
    "    print(kid['firstName'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Puedo guardar el JSON en un archivo. Para ello, usamos la librería `json`**, que viene incluida en la instalación de Anaconda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 42: Escritura de JSON en archivo\n",
    "# Importamos la librería json para trabajar con archivos JSON\n",
    "import json\n",
    "\n",
    "# Modo 'w' (write) para crear/sobrescribir el archivo\n",
    "# json.dump() serializa el objeto Python a formato JSON y lo guarda\n",
    "with open(\"data/data_file.json\", \"w\") as write_file:\n",
    "    json.dump(data, write_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O también objetos de una clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 43: Definición de clase y creación de objetos\n",
    "# Creamos una clase Persona con atributos firstName, lastName y hobbies\n",
    "class Persona:\n",
    "    \n",
    "    def __init__(self, firstName, lastName, hobbies):\n",
    "        self.firstName = firstName\n",
    "        self.lastName = lastName\n",
    "        self.hobbies = hobbies\n",
    "\n",
    "# Instanciamos dos objetos de la clase Persona        \n",
    "pers1 = Persona(\"Pepe\", \"Carrasco\", [\"Bricolaje\", \"Tenis\"])\n",
    "pers2 = Persona(\"Jose\", \"Carrasco\", [\"Bricolaje\", \"Tenis\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 44: Visualización de objeto en memoria\n",
    "# Al imprimir un objeto sin __str__ o __repr__, muestra su ubicación en memoria\n",
    "# No es una representación legible de los datos del objeto\n",
    "pers1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 45: Acceso al diccionario interno de un objeto\n",
    "# __dict__ contiene todos los atributos del objeto como un diccionario\n",
    "# Esto es útil para serializar objetos a JSON\n",
    "pers1.__dict__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo puedo guardar en un archivo *pepe.json*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 46: Guardar objeto Python como JSON\n",
    "# Convertimos el objeto pers2 a diccionario con __dict__\n",
    "# y lo guardamos como JSON en un archivo\n",
    "with open(\"data/pepe.json\", \"w\") as write_file:\n",
    "    json.dump(pers2.__dict__, write_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego lo puedo volver a cargar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 47: Lectura de archivo JSON\n",
    "# json.load() lee el archivo JSON y lo convierte en un diccionario Python\n",
    "with open(\"data/pepe.json\", \"r\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Imprimimos el diccionario completo y luego un valor específico    \n",
    "print(data)\n",
    "print(data['firstName'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el siguiente ejemplo, utilizamos `pandas` y leeremos el archivo JSON, de tal manera que nos transforme los datos en formato tabla, en un `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 48: Lectura de JSON con múltiples objetos (formato lines)\n",
    "# lines=True indica que cada línea del archivo es un objeto JSON independiente\n",
    "# Este formato es común en datasets grandes (JSON Lines o JSONL)\n",
    "df = pd.read_json('data/Musical_Instruments_5.json', lines = True)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. TXT\n",
    "**Son simplemente archivos donde hay texto**. Hemos visto que los CSVs y los JSON tienen su propio formato y extension. En el caso del .txt no tienen ninguno específico aunque no quita para que sus elementos estén separados por comas, y se pueda leer igualmente como si fuese un CSV.\n",
    "\n",
    "Cuando almancenamos datos siempre tienen una estructura, por lo que aunque sea un `.txt`, llevará los datos en formato json, separados por comas, tabulaciones, puntos y comas...\n",
    "\n",
    "Por ejemplo, si tenemos los datos de la liga guardados en un `.txt`, separados por tabulaciones, lo podremos leer con el `pd.read_csv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 49: Importación de Pandas para trabajar con archivos TXT\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CELDA 50: Lectura de archivo TXT con tabulaciones como separador\n",
    "# Los archivos .txt pueden tener datos tabulares\n",
    "# sep='\\t' indica que el separador es tabulación (tab)\n",
    "df = pd.read_csv('data/laligaTXT.txt', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuerda que la separación por tabulaciones, también tiene su propia extensión: el `.tsv`, que igualmente lo podremos leer con `read_csv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CELDA 51: Lectura de archivo TSV (Tab-Separated Values)\n",
    "# TSV es un formato similar a CSV pero usa tabulaciones\n",
    "# .tsv es la extensión estándar, pero se lee igual que un TXT tabulado\n",
    "df = pd.read_csv('data/laligaTSV.tsv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método `read_csv()` no se ciñe únicamente a leer CSVs, sino a prácticamente cualquier archivo que lleve un acarácter concreto en la separación de sus campos. Si conocemos ese caracter, sabremos leer el archivo con `pandas`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ZIP\n",
    "En ocasiones los datos que recibimos en nuestros programas están comprimidos, ya sea en un formato `.zip`, `.rar`, `.7z`, u otro tipo de archivo.\n",
    "\n",
    "En este apartado verás un ejemplo de cómo descomprimir archivos `.zip`. Para ello empleamos la librería `zipfile` que viene incluida en la instalación de Anaconda. [Tienes el enlace a la documentación para más detalle](https://docs.python.org/3/library/zipfile.html#zipfile-objects).\n",
    "\n",
    "Para extraer todos los archivos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 52: Extracción completa de archivos ZIP\n",
    "# Importamos zipfile para trabajar con archivos comprimidos\n",
    "import zipfile\n",
    "\n",
    "# ZipFile abre el archivo .zip\n",
    "# extractall() extrae todos los archivos a la carpeta especificada\n",
    "with zipfile.ZipFile('data/laligaZIP.zip') as zip_ref:\n",
    "    zip_ref.extractall('data')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si quieres descomprimir un archivo `.rar` [tendrás que descargarte un paquete como por ejemplo `unrar`.](https://pypi.org/project/unrar/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    " <tr><td width=\"80\"><img src=\"./img/ejercicio.png\" style=\"width:auto;height:auto\"></td>\n",
    "     <td style=\"text-align:left\">\n",
    "         <h3>Ejercicio zip</h3>\n",
    "\n",
    "Consulta la documentación para extrar un único archivo por nombre de data/laligaZIP.zip en la carpeta extracted_files.\n",
    "         \n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 53: Extracción selectiva de archivos ZIP\n",
    "# printdir() lista los archivos contenidos en el ZIP\n",
    "# extract() extrae un archivo específico por nombre a una carpeta destino\n",
    "with zipfile.ZipFile('data/laligaZIP.zip') as zip_ref:\n",
    "    zip_ref.printdir()\n",
    "    zip_ref.extract(\"laligaZIP.csv\", 'data/extracted_files')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. pickle\n",
    "**`pickle` es el módulo que nos permite serializar y deserializar un objeto de Python**. Esta operación lo que hace es traducirlo a un stream de bytes.\n",
    "\n",
    "A efectos prácticos, lo que nos permite es guardar objetos de Python, y recuperarlos más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 54: Serialización de múltiples objetos con pickle\n",
    "# pickle permite guardar objetos Python en formato binario\n",
    "import pickle\n",
    "\n",
    "# Preparamos varios objetos: DataFrame, JSON y objeto de clase\n",
    "df = pd.read_csv(\"data/laliga.csv\")\n",
    "\n",
    "with open('data/pepe.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Modo 'wb' (write binary) para archivos pickle\n",
    "# Guardamos múltiples objetos en el mismo archivo con dump() sucesivos\n",
    "with open('data/importante', 'wb') as f:\n",
    "    pickle.dump(pers1, f)\n",
    "    pickle.dump(df, f)\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 55: Deserialización de objetos pickle\n",
    "# Modo 'rb' (read binary) para leer archivos pickle\n",
    "# pickle.load() recupera los objetos en el MISMO ORDEN en que fueron guardados\n",
    "with open('data/importante', 'rb') as f:\n",
    "    a = pickle.load(f)  # Primer objeto: pers1\n",
    "    b = pickle.load(f)  # Segundo objeto: df\n",
    "    c = pickle.load(f)  # Tercer objeto: data\n",
    "\n",
    "# Imprimimos los objetos recuperados    \n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Encoding\n",
    "**Los strings se almacenan internamente en un conjunto de bytes**, caracter a caracter. Esta operación es lo que se conoce como ***encoding***, mientras que pasar de bytes a string sería *decoding*. Bien, ¿y eso en qué nos afecta? Dependiendo del encoding, se suelen almacenar en un espacio de bits de 0 a 255, es decir, en esa combinación de bits tienen que entrar todos los caracteres del lenguaje.\n",
    "\n",
    "El problema es que en toda esa combinación de bits no entran todos los caracteres del planeta, por lo que **dependiendo del encoding que usemos, una combinación de bits significará una cosa u otra**. Por ejemplo, una A mayuscula será lo mismo en el encodig europeo que en el americano, pero los bits reservados para representar una Ñ, en el encodig americano se traduce en otro caracter.\n",
    "\n",
    "Por tanto, **hay que tener claro en qué encoding está el archivo y con qué encoding lo vamos a leer**. [En la documentación](https://docs.python.org/3/library/codecs.html#encodings-and-unicode) puedes realizar esta comprobación. Hay algunos que te tienen que ir sonando:\n",
    "\n",
    "1. 'utf-8': normalmente se trabaja con este encoding que engloba la mayor parte de caracteres.\n",
    "2. 'unicode': estándar universal con el que no deberiamos tener problemas.\n",
    "3. 'ascii': encoding americano. Solo tiene 128 caracteres.\n",
    "4. 'latin': para oeste de Europa, Oceanía y Latinoamérica\n",
    "\n",
    "![imagen](./img/encoding.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 56: Lectura de CSV con encoding UTF-8\n",
    "# encoding especifica cómo interpretar los caracteres del archivo\n",
    "# utf-8 es el estándar universal que soporta caracteres especiales (ñ, á, etc.)\n",
    "pd.read_csv('data/encoding.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CELDA 57: Error al leer con encoding incorrecto\n",
    "# ascii solo soporta 128 caracteres (sin acentos ni ñ)\n",
    "# Esta lectura generará un error si el archivo contiene caracteres especiales\n",
    "pd.read_csv('data/encoding.csv', encoding = 'ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 58: Lectura con encoding incorrecto muestra caracteres corruptos\n",
    "# iso8859_10 es un encoding diferente que interpreta los bytes de forma distinta\n",
    "# Los caracteres especiales se muestran incorrectamente (EspaÃąa en lugar de España)\n",
    "pd.read_csv('data/encoding.csv', encoding='iso8859_10')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Archivos y carpetas\n",
    "Resulta de gran utilidad automatizar lecturas/escrituras/borrado/movimientos de archivos entre carpetas. Si tenemos un proceso definido en Python, podremos ejecutarlo tantas veces queramos y de este modo evitar dedicarle tiempo tareas tediosas y rutinarias. Para ello tendremos que apoyarnos en el módulo de Python `os`.\n",
    "\n",
    "Lo primero de todo es saber en qué directorio estamos trabajando. Esto es fundamental para elegir bien la ruta relativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 59: Obtener el directorio de trabajo actual\n",
    "# os.getcwd() (get current working directory) devuelve la ruta actual\n",
    "# Es importante conocerla para usar rutas relativas correctamente\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El directorio de trabajo lo podríamos cambiar si quisiéramos, por ejemplo, al escritorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 60: Cambiar y verificar el directorio de trabajo\n",
    "# os.chdir() (change directory) cambia el directorio de trabajo actual\n",
    "os.chdir('d:\\\\Bootcamps_DS\\\\25_3_Bootcamp_DS\\\\')\n",
    "print(os.getcwd())\n",
    "# os.listdir() lista archivos y carpetas en el directorio actual\n",
    "print(os.listdir())\n",
    "# Volvemos al directorio original\n",
    "os.chdir('d:\\\\Bootcamps_DS\\\\25_3_Bootcamp_DS\\\\2503_dsft_thebridge\\\\2-Data_Analysis\\\\3-Sources\\\\Archivos\\\\Teoría')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos juntar rutas en un único path. Realiza un concatenado con barras entendibles por Windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 61: Construcción de rutas multiplataforma\n",
    "# os.path.join() une rutas de forma compatible con Windows, Linux y Mac\n",
    "# Añade automáticamente las barras correctas según el sistema operativo\n",
    "os.path.join(\"C:\\\\path\\\\directory\", \"some_file.txt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si quieres buscar algún tipo de archivo concreto, tienes varias opciones:\n",
    "- Buscar por nombre\n",
    "- Buscar por extensión\n",
    "\n",
    "En función de lo que encuentres, realizarás una operación u otra. Ahora bien, igualmente para buscar, tendrás que recorrer todos los archivos que estén en un directorio o en varios directorios. Para listar todos los ARCHIVOS y CARPETAS que hay en el directorio actual de trabajo, utilizamos `os.listdir()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 62: Verificación del directorio actual\n",
    "# Confirmamos en qué directorio estamos trabajando antes de buscar archivos\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 63: Listar contenido del directorio actual\n",
    "# os.listdir() devuelve una lista con nombres de archivos y carpetas\n",
    "# Sin argumentos, lista el directorio actual\n",
    "os.listdir()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a quedarme con todos los notebooks del actual directorio de trabajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 64: Filtrar archivos por extensión\n",
    "# Iteramos sobre todos los archivos del directorio\n",
    "# endswith('.ipynb') filtra solo los notebooks de Jupyter\n",
    "for i in os.listdir():\n",
    "    if i.endswith('.ipynb'):\n",
    "        print(\"Notebook\", i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si quiero acceder sólo a los directorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 65: Identificar solo directorios (carpetas)\n",
    "# Los directorios no tienen extensión (punto en el nombre)\n",
    "# Esta es una forma simple de distinguir carpetas de archivos\n",
    "for i in os.listdir():\n",
    "    if '.' not in i:\n",
    "        print(\"directorio\", i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro método interesante para bucear en los archivos y carpetas de un directorio concreto es el `os.walk()`. Va a devoler un iterable que podremos recorrer en un for y obtener en formato tupla todos los archivos, subcarpetas y ficheros de subcarpetas. Para cada elemento de la tupla tenemos:\n",
    "- El directorio donde está apuntando.\n",
    "- Los directorios que hay ahí.\n",
    "- Los archivos que hay ahí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 66: Recorrido recursivo de directorios con os.walk()\n",
    "# os.walk() recorre el directorio y todos sus subdirectorios\n",
    "# Devuelve tuplas con: (directorio_actual, lista_subdirectorios, lista_archivos)\n",
    "result_generator = os.walk(os.getcwd())\n",
    "\n",
    "# Convertimos el generador en lista para visualizar toda la estructura\n",
    "files_result = [x for x in result_generator]\n",
    "files_result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué podemos hacer dentro de un directorio, aparte de listar ficheros y subdirectorios? Las principales operaciones serían:\n",
    "- Crear o eliminar directorios\n",
    "- Crear o eliminar ficheros\n",
    "- Mover ficheros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 67: Crear un nuevo directorio\n",
    "# os.mkdir() crea una carpeta en el directorio actual\n",
    "# Si la carpeta ya existe, generará un error\n",
    "os.mkdir('direct_prueba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 68: Verificar directorio tras creación\n",
    "# Comprobamos la ruta actual después de crear el directorio\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 69: Eliminar un directorio vacío\n",
    "# os.rmdir() elimina un directorio SOLO si está vacío\n",
    "# Si contiene archivos, generará un error\n",
    "os.rmdir('direct_prueba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 70: Crear y escribir archivo de texto manualmente\n",
    "# open() con modo 'w' crea un archivo nuevo\n",
    "f = open(\"fichero.txt\", \"w\")\n",
    "\n",
    "# Escribimos 10 líneas en el archivo\n",
    "for i in range(10):\n",
    "    f.write(\"Line:\" + str(i))\n",
    "\n",
    "# IMPORTANTE: siempre cerrar el archivo después de escribir\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 71: Mover archivos entre directorios\n",
    "# shutil.move() mueve un archivo de una ubicación a otra\n",
    "# También puede usarse para renombrar archivos\n",
    "import shutil\n",
    "shutil.move(\"fichero.txt\", \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 72: Eliminar un archivo\n",
    "# os.remove() elimina permanentemente un archivo\n",
    "# ¡PRECAUCIÓN! Esta operación no se puede deshacer\n",
    "os.remove('data/fichero.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 73: Obtener el directorio del script actual\n",
    "# os.path.dirname() obtiene el directorio padre de una ruta\n",
    "# os.path.abspath() convierte una ruta relativa a absoluta\n",
    "# '__file__' es una variable especial que contiene la ruta del script\n",
    "os.path.dirname(os.path.abspath('__file__'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 74: Uso de __file__ en scripts (comentado)\n",
    "# __file__ funciona en scripts .py pero puede dar error en notebooks\n",
    "# Se usa para obtener la ubicación del archivo Python en ejecución\n",
    "import os\n",
    "# os.path.dirname(os.path.abspath(__file__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 75: Obtener ruta absoluta de un archivo\n",
    "# os.path.abspath() convierte cualquier ruta (relativa o con '..') a ruta absoluta\n",
    "# Útil para asegurar que trabajamos con la ruta completa del archivo\n",
    "os.path.abspath('__file__')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
