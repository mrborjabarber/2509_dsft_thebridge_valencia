{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otros modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# IMPORTACIÓN DE LIBRERÍAS NECESARIAS\n# =============================================================================\n\n# pandas: para manipulación y análisis de datos estructurados (DataFrames)\nimport pandas as pd\n\n# numpy: para operaciones numéricas y manejo de arrays\nimport numpy as np\n\n# matplotlib.pyplot: para visualización de datos (gráficos)\nimport matplotlib.pyplot as plt\n\n# mean_squared_error: métrica para evaluar el error cuadrático medio en modelos de regresión\nfrom sklearn.metrics import mean_squared_error"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# CARGA DEL DATASET\n# =============================================================================\n\n# Leemos el archivo CSV con los datos de la serie temporal\n# index_col=0: usa la primera columna como índice (las fechas)\ndf = pd.read_csv('data/jj.csv', index_col=0)\n\n# Mostramos el número total de registros en el dataset\nprint(len(df))\n\n# Visualizamos las primeras 5 filas para entender la estructura de los datos\n# Este dataset contiene información trimestral de Johnson & Johnson\ndf.head()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# VISUALIZACIÓN DE LA SERIE TEMPORAL\n# =============================================================================\n\n# Graficamos la serie temporal completa para observar:\n# - Tendencia general (crecimiento/decrecimiento)\n# - Estacionalidad (patrones que se repiten)\n# - Valores atípicos (outliers)\ndf.plot()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparamos las features del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# INGENIERÍA DE CARACTERÍSTICAS (FEATURE ENGINEERING) - CREACIÓN DE LAGS\n# =============================================================================\n\n# Creamos features basadas en valores históricos (LAGS)\n# Un LAG es el valor de la serie en momentos anteriores en el tiempo\n# \n# ¿Por qué hacemos esto?\n# Para predecir el valor actual, usaremos los 12 valores anteriores (1 año de datos trimestrales)\n# \n# Ejemplo: Si estamos en 1963-01-01:\n#   t-1  = valor del trimestre anterior (1962-10-01)\n#   t-2  = valor de hace 2 trimestres (1962-07-01)\n#   t-12 = valor de hace 12 trimestres (1960-01-01)\n\nfor i in range(12, 0, -1):  # Iteramos desde 12 hasta 1 (en orden descendente)\n    # shift(i): desplaza los valores i posiciones hacia abajo\n    # Esto crea una nueva columna con el valor de i trimestres atrás\n    df['t-'+str(i)] = df['data'].shift(i)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# LIMPIEZA DE DATOS - ELIMINACIÓN DE VALORES NULOS\n# =============================================================================\n\n# Al crear los lags, las primeras 12 filas tendrán valores NaN (nulos)\n# porque no tienen suficiente historia previa\n# \n# Ejemplo: La primera fila (1960-01-01) no puede tener t-1, t-2, etc.\n# porque no hay datos anteriores a 1960-01-01\n\n# dropna(): elimina todas las filas que contienen valores NaN\n# inplace=True: modifica el DataFrame original sin crear una copia\ndf.dropna(inplace=True)\n\n# Mostramos las primeras 15 filas para verificar:\n# - Que no hay NaN\n# - Que ahora tenemos 13 columnas (data + 12 lags)\n# - Que los datos empiezan en 1963 (después de perder las primeras 12 filas)\ndf.head(15)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# VERIFICACIÓN DE LOS ÚLTIMOS REGISTROS\n# =============================================================================\n\n# Mostramos las últimas 30 filas para ver:\n# - Cómo terminan nuestros datos (1980)\n# - Que la estructura de lags está correcta\n# - Los valores más recientes que usaremos para test\ndf.tail(30)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividimos en train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# DIVISIÓN DEL DATASET EN TRAIN Y TEST\n# =============================================================================\n\n# PREPARACIÓN DE VARIABLES X (features) e Y (target)\n# ===================================================\n\n# X: Todas las columnas EXCEPTO la primera (columna 'data')\n# Son los LAGS: t-12, t-11, ..., t-2, t-1\n# iloc[:,1:] significa: todas las filas, desde la columna 1 en adelante\nX = df.iloc[:, 1:].values  # Shape: (72, 12) - 72 filas, 12 características\n\n# Y: Solo la primera columna (columna 'data')\n# Es el valor ACTUAL que queremos predecir\nY = df.iloc[:, 0].values   # Shape: (72,) - 72 valores objetivo\n\n\n# DIVISIÓN TEMPORAL (NO ALEATORIA)\n# ================================\n# En series temporales NO usamos train_test_split aleatorio\n# porque debemos respetar el orden temporal\n\n# TRAIN: Primeras 60 observaciones (años 1963-1978)\nX_train = X[:60]   # Features de entrenamiento\ny_train = Y[:60]   # Target de entrenamiento\n\n# TEST: Últimas 12 observaciones (4 trimestres de 1978-1980)\nX_test = X[60:]    # Features de prueba\ny_test = Y[60:]    # Target de prueba\n\n\n# VERIFICACIÓN DE DIMENSIONES\n# ============================\nprint(\"Shape X_train:\", X_train.shape)  # Esperado: (60, 12)\nprint(\"Shape X_test:\", X_test.shape)    # Esperado: (12, 12)\nprint(\"Shape y_train:\", y_train.shape)  # Esperado: (60,)\nprint(\"Shape y_test:\", y_test.shape)    # Esperado: (12,)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# VISUALIZACIÓN DEL CONJUNTO DE TEST\n# =============================================================================\n\n# Convertimos X_test a DataFrame para visualizarlo mejor\n# Cada fila es una predicción que haremos\n# Cada columna representa un lag (t-12 hasta t-1)\npd.DataFrame(X_test)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos de predicción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementa varios modelos de regresión para predecir la serie temporal. ¿Cuál ofrece mejor resultados?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTA: Para predecir los resultados de test, hay que iterar e ir prediciendo cada muestra en función del lag utilizado. \n",
    "\n",
    "Por ejemplo, para un lag = 3 (predecimos usando los últimos 3 registros):\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# MODELO 1: ÁRBOL DE DECISIÓN PARA REGRESIÓN\n# =============================================================================\n\n# Importamos el modelo de Árbol de Decisión para regresión\nfrom sklearn.tree import DecisionTreeRegressor\n\n# Creamos una instancia del modelo\n# Un árbol de decisión divide el espacio de features mediante reglas jerárquicas\ntree = DecisionTreeRegressor()\n\n# Entrenamos el modelo con los datos de train\n# El árbol aprende patrones en los 12 lags para predecir el valor actual\ntree.fit(X_train, y_train)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# FUNCIÓN DE PREDICCIÓN ITERATIVA PARA SERIES TEMPORALES\n# =============================================================================\n\ndef prediction(model, x_test):\n    \"\"\"\n    Realiza predicciones iterativas para series temporales.\n    \n    ¿POR QUÉ NECESITAMOS ESTA FUNCIÓN?\n    ==================================\n    En series temporales, NO podemos hacer predict(X_test) directamente porque:\n    - La primera predicción usa los valores reales (históricos)\n    - La segunda predicción debe usar la PRIMERA PREDICCIÓN como t-1\n    - La tercera predicción usa la segunda predicción como t-1, y así sucesivamente\n    \n    EJEMPLO PASO A PASO:\n    ====================\n    Si queremos predecir 3 valores futuros con lag=3:\n    \n    1) Predicción 1:\n       Input: [valor_real_t-3, valor_real_t-2, valor_real_t-1]\n       Output: predicción_1\n       \n    2) Predicción 2:\n       Input: [valor_real_t-2, valor_real_t-1, predicción_1]  ← usamos predicción_1\n       Output: predicción_2\n       \n    3) Predicción 3:\n       Input: [valor_real_t-1, predicción_1, predicción_2]    ← usamos predicciones previas\n       Output: predicción_3\n    \n    Args:\n        model: Modelo de ML ya entrenado\n        x_test: Array con los datos de test\n    \n    Returns:\n        preds_out: Lista con todas las predicciones\n    \"\"\"\n    \n    # Inicializamos con la primera fila de X_test\n    # Estos son los 12 valores históricos reales para la primera predicción\n    preds = x_test[0]\n    \n    # Lista para almacenar las predicciones\n    preds_out = []\n    \n    # Iteramos sobre cada muestra del conjunto de test\n    for i in range(len(X_test)):\n        \n        # PASO 1: Predecir el siguiente valor\n        # El modelo recibe los 12 lags actuales y devuelve una predicción\n        pred = model.predict([preds])[0]\n        \n        # Guardamos la predicción\n        preds_out.append(pred)\n        \n        # PASO 2: Actualizar los lags para la siguiente iteración\n        # Eliminamos el valor más antiguo (t-12)\n        preds2 = np.array([preds[1:]])  # Quitamos el primer elemento\n        \n        # PASO 3: Añadir la predicción como el nuevo t-1\n        # np.c_: concatena arrays por columnas\n        # Ahora: [antiguo_t-11, antiguo_t-10, ..., antiguo_t-1, nueva_predicción]\n        # Esto se convierte en: [nuevo_t-12, nuevo_t-11, ..., nuevo_t-2, nuevo_t-1]\n        preds = np.c_[preds2, np.array([pred])][0]\n    \n    return preds_out"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# PREDICCIONES CON EL ÁRBOL DE DECISIÓN\n# =============================================================================\n\n# Usamos nuestra función personalizada para hacer predicciones iterativas\n# El árbol de decisión predice los 12 valores futuros, usando sus propias predicciones\npreds = prediction(tree, X_test)\n\n# Mostramos las predicciones\npreds"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# VISUALIZACIÓN DE RESULTADOS - ÁRBOL DE DECISIÓN\n# =============================================================================\n\n# Graficamos los valores reales vs las predicciones\n# 'o-': círculos conectados con líneas\nplt.plot(y_test, 'o-')                  # Azul: valores REALES\nplt.plot(preds, 'o-', color='red')      # Rojo: valores PREDICHOS\n\n# OBSERVACIÓN: Si las predicciones son constantes (todas iguales),\n# el árbol ha sufrido OVERFITTING y no generaliza bien"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# MODELO 2: RANDOM FOREST (BOSQUE ALEATORIO)\n# =============================================================================\n\n# Importamos Random Forest, un ensemble de árboles de decisión\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Creamos el modelo con parámetros específicos:\n# - n_estimators=200: usamos 200 árboles diferentes (más árboles = más robusto)\n# - max_depth=5: limitamos la profundidad de cada árbol a 5 niveles\n#                (evita overfitting que vimos con el árbol único)\nrfr = RandomForestRegressor(n_estimators=200, max_depth=5)\n\n# Entrenamos el modelo con los datos de train\nrfr.fit(X_train, y_train)\n\n# Hacemos predicciones iterativas (igual que con el árbol)\npred2 = prediction(rfr, X_test)\n\n# Calculamos el Error Cuadrático Medio (MSE)\n# MSE mide la diferencia promedio al cuadrado entre predicciones y valores reales\n# Cuanto más bajo, mejor es el modelo\nprint(\"MSE:\", mean_squared_error(pred2, y_test))\n\n# Visualizamos resultados\nplt.plot(y_test, 'o-')                  # Azul: valores REALES\nplt.plot(pred2, 'o-', color='red')      # Rojo: valores PREDICHOS por Random Forest\n\n# Random Forest suele dar mejores resultados que un solo árbol porque:\n# 1) Reduce overfitting mediante el promedio de múltiples árboles\n# 2) Cada árbol ve diferentes subconjuntos de datos (bootstrap)\n# 3) La combinación de árboles es más robusta"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# MODELO 3: REGRESIÓN LINEAL\n# =============================================================================\n\n# Importamos el modelo de Regresión Lineal\nfrom sklearn.linear_model import LinearRegression\n\n# Creamos el modelo\n# La regresión lineal busca la mejor combinación lineal de los lags:\n# y = β₀ + β₁·(t-12) + β₂·(t-11) + ... + β₁₂·(t-1)\nlin_reg = LinearRegression()\n\n# Entrenamos el modelo\nlin_reg.fit(X_train, y_train)\n\n\n# =============================================================================\n# COMPARACIÓN DE DOS ENFOQUES DE PREDICCIÓN\n# =============================================================================\n\n# ENFOQUE 1: Predicción directa (INCORRECTO para forecast multi-paso)\n# ====================================================================\n# Usamos directamente X_test sin actualizar con predicciones previas\n# Esto está BIEN para evaluación del modelo, pero NO para forecasting real\npred = lin_reg.predict(X_test)\nprint(\"MSE (predicción directa):\", mean_squared_error(pred, y_test))\n\n\n# ENFOQUE 2: Predicción iterativa (CORRECTO para forecast multi-paso)\n# =====================================================================\n# Cada predicción usa las predicciones anteriores como inputs\n# Este es el enfoque REAL cuando queremos predecir el futuro\npred2 = prediction(lin_reg, X_test)\nprint(\"MSE (predicción iterativa):\", mean_squared_error(pred2, y_test))\n\n\n# NOTA IMPORTANTE:\n# ================\n# El MSE suele ser MAYOR en predicción iterativa porque:\n# - Los errores se acumulan (error de predicción 1 afecta a predicción 2, etc.)\n# - En producción, SIEMPRE usaremos predicción iterativa\n# - La predicción directa solo sirve para evaluar la calidad del modelo base"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# VISUALIZACIÓN FINAL - REGRESIÓN LINEAL\n# =============================================================================\n\n# Graficamos los resultados de la regresión lineal\nplt.plot(y_test, 'o-')                  # Azul: valores REALES\nplt.plot(pred2, 'o-', color='red')      # Rojo: valores PREDICHOS (iterativos)\n\n\n# =============================================================================\n# CONCLUSIONES DEL NOTEBOOK\n# =============================================================================\n\"\"\"\nRESUMEN DE MODELOS PROBADOS:\n=============================\n\n1. Árbol de Decisión:\n   - Problema: Overfitting severo\n   - Las predicciones son constantes (no captura la variabilidad)\n   - No recomendado para este problema\n\n2. Random Forest:\n   - Mejor que el árbol único\n   - Reduce overfitting con ensemble de árboles\n   - MSE razonable gracias a max_depth=5\n\n3. Regresión Lineal:\n   - Modelo más simple\n   - MSE aceptable (1.34 directo, 2.22 iterativo)\n   - Buena opción por su simplicidad e interpretabilidad\n\n\nCONCEPTOS CLAVE APRENDIDOS:\n===========================\n\n✓ Feature Engineering con LAGS para series temporales\n✓ División temporal (NO aleatoria) de datos\n✓ Predicción iterativa vs predicción directa\n✓ Acumulación de errores en forecasting multi-paso\n✓ Comparación de modelos: árboles vs ensemble vs lineal\n✓ Importancia de limitar complejidad (max_depth) para evitar overfitting\n\n\nPARA MEJORAR LOS RESULTADOS:\n============================\n\n- Probar otros modelos (ARIMA, Prophet, LSTM)\n- Experimentar con diferentes números de lags\n- Añadir features estacionales (trimestre del año)\n- Aplicar transformaciones (logaritmo, diferencias)\n- Usar validación cruzada específica para series temporales (TimeSeriesSplit)\n\"\"\""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}