{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Completo: FastAPI para Modelos de Machine Learning\n",
    "\n",
    "## Introducci√≥n\n",
    "\n",
    "En este tutorial aprender√°s a crear una API REST completa usando **FastAPI** para servir modelos de Machine Learning. FastAPI es un framework moderno y r√°pido para construir APIs con Python 3.7+.\n",
    "\n",
    "### ¬øQu√© vamos a construir?\n",
    "\n",
    "Crearemos una aplicaci√≥n que incluye:\n",
    "1. **Endpoint b√°sico** - Para verificar que la API funciona\n",
    "2. **Endpoint de predicci√≥n** - Para hacer inferencias con nuestro modelo\n",
    "3. **Endpoint de monitorizaci√≥n** - Para ver m√©tricas y estado del modelo\n",
    "4. **Endpoint de reentrenamiento** - Para actualizar el modelo con nuevos datos\n",
    "\n",
    "### Requisitos previos\n",
    "\n",
    "- Python 3.7+\n",
    "- Conocimientos b√°sicos de Machine Learning\n",
    "- Familiaridad con APIs REST (recomendado)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instalaci√≥n de Dependencias\n",
    "\n",
    "Primero necesitamos instalar todas las bibliotecas necesarias:\n",
    "\n",
    "- **fastapi**: Framework para crear la API\n",
    "- **uvicorn**: Servidor ASGI para ejecutar FastAPI\n",
    "- **tensorflow**: Para crear y usar modelos de deep learning\n",
    "- **numpy**: Para manipulaci√≥n de arrays\n",
    "- **pandas**: Para manejo de datos\n",
    "- **scikit-learn**: Para m√©tricas y preprocesamiento\n",
    "- **pydantic**: Para validaci√≥n de datos (incluido con FastAPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalaci√≥n de todas las dependencias necesarias\n",
    "# Ejecuta esta celda una sola vez\n",
    "!pip install fastapi uvicorn tensorflow numpy pandas scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importaci√≥n de Bibliotecas\n",
    "\n",
    "Importamos todas las bibliotecas que usaremos en el tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones para FastAPI y servidor\n",
    "from fastapi import FastAPI, HTTPException, File, UploadFile\n",
    "from pydantic import BaseModel, Field\n",
    "import uvicorn\n",
    "\n",
    "# Importaciones para Machine Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Importaciones para utilidades\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any\n",
    "import pickle\n",
    "\n",
    "print(\"‚úì Todas las bibliotecas importadas correctamente\")\n",
    "print(f\"Versi√≥n de TensorFlow: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creaci√≥n y Guardado de un Modelo de Ejemplo\n",
    "\n",
    "### 3.1 ¬øPor qu√© necesitamos guardar modelos?\n",
    "\n",
    "Cuando entrenamos un modelo de Machine Learning, queremos poder reutilizarlo sin tener que reentrenarlo cada vez. Keras ofrece dos formatos principales:\n",
    "\n",
    "- **.keras** (recomendado): Formato nativo de Keras 3.0+, guarda todo en un solo archivo\n",
    "- **.h5**: Formato HDF5, compatible con versiones anteriores\n",
    "\n",
    "### 3.2 Creaci√≥n de un dataset sint√©tico\n",
    "\n",
    "Para este tutorial, crearemos un problema de regresi√≥n simple: predecir el precio de una casa bas√°ndose en caracter√≠sticas como tama√±o, n√∫mero de habitaciones, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n de semilla para reproducibilidad\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Generaci√≥n de datos sint√©ticos para predicci√≥n de precios de casas\n",
    "# Caracter√≠sticas: tama√±o (m2), habitaciones, ba√±os, antig√ºedad (a√±os)\n",
    "n_samples = 1000\n",
    "\n",
    "# Generamos caracter√≠sticas aleatorias\n",
    "tamano = np.random.uniform(50, 300, n_samples)  # Tama√±o entre 50 y 300 m2\n",
    "habitaciones = np.random.randint(1, 6, n_samples)  # Entre 1 y 5 habitaciones\n",
    "banos = np.random.randint(1, 4, n_samples)  # Entre 1 y 3 ba√±os\n",
    "antiguedad = np.random.uniform(0, 50, n_samples)  # Antig√ºedad entre 0 y 50 a√±os\n",
    "\n",
    "# Creamos la variable objetivo (precio) con una f√≥rmula l√≥gica + ruido\n",
    "# Precio base: 1000‚Ç¨/m2, +20000‚Ç¨ por habitaci√≥n, +15000‚Ç¨ por ba√±o, -500‚Ç¨ por a√±o de antig√ºedad\n",
    "precio = (\n",
    "    tamano * 1000 + \n",
    "    habitaciones * 20000 + \n",
    "    banos * 15000 - \n",
    "    antiguedad * 500 +\n",
    "    np.random.normal(0, 20000, n_samples)  # A√±adimos ruido\n",
    ")\n",
    "\n",
    "# Combinamos todas las caracter√≠sticas en una matriz\n",
    "X = np.column_stack([tamano, habitaciones, banos, antiguedad])\n",
    "y = precio\n",
    "\n",
    "print(f\"Dataset creado:\")\n",
    "print(f\"  - N√∫mero de muestras: {n_samples}\")\n",
    "print(f\"  - N√∫mero de caracter√≠sticas: {X.shape[1]}\")\n",
    "print(f\"  - Rango de precios: {y.min():.0f}‚Ç¨ - {y.max():.0f}‚Ç¨\")\n",
    "print(f\"\\nPrimeras 5 muestras:\")\n",
    "print(f\"{'Tama√±o':<10} {'Habit.':<8} {'Ba√±os':<8} {'Antig√ºedad':<12} {'Precio':<10}\")\n",
    "for i in range(5):\n",
    "    print(f\"{X[i,0]:<10.1f} {X[i,1]:<8.0f} {X[i,2]:<8.0f} {X[i,3]:<12.1f} {y[i]:<10.0f}‚Ç¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Preparaci√≥n de los datos\n",
    "\n",
    "Antes de entrenar, debemos:\n",
    "1. Dividir los datos en entrenamiento y prueba\n",
    "2. Normalizar las caracter√≠sticas (importante para redes neuronales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisi√≥n de datos en entrenamiento (80%) y prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,  # 20% para prueba\n",
    "    random_state=42  # Para reproducibilidad\n",
    ")\n",
    "\n",
    "# Normalizaci√≥n de caracter√≠sticas usando StandardScaler\n",
    "# Esto convierte los datos para que tengan media=0 y desviaci√≥n est√°ndar=1\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Ajustamos y transformamos training\n",
    "X_test_scaled = scaler.transform(X_test)  # Solo transformamos test (sin fit)\n",
    "\n",
    "# Guardamos el scaler para usarlo despu√©s en las predicciones\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(f\"‚úì Datos divididos:\")\n",
    "print(f\"  - Training set: {X_train.shape[0]} muestras\")\n",
    "print(f\"  - Test set: {X_test.shape[0]} muestras\")\n",
    "print(f\"\\n‚úì Scaler guardado en 'scaler.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Creaci√≥n del Modelo\n",
    "\n",
    "Crearemos una red neuronal simple con:\n",
    "- Capa de entrada: 4 caracter√≠sticas\n",
    "- 2 capas ocultas con activaci√≥n ReLU\n",
    "- Capa de salida: 1 neurona (predicci√≥n del precio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construcci√≥n del modelo usando la API Sequential de Keras\n",
    "modelo = models.Sequential([\n",
    "    # Capa de entrada: especificamos el n√∫mero de caracter√≠sticas\n",
    "    layers.Input(shape=(4,)),  # 4 caracter√≠sticas\n",
    "    \n",
    "    # Primera capa oculta: 64 neuronas con activaci√≥n ReLU\n",
    "    layers.Dense(64, activation='relu', name='capa_oculta_1'),\n",
    "    \n",
    "    # Segunda capa oculta: 32 neuronas con activaci√≥n ReLU\n",
    "    layers.Dense(32, activation='relu', name='capa_oculta_2'),\n",
    "    \n",
    "    # Capa de salida: 1 neurona (predicci√≥n del precio)\n",
    "    # Sin activaci√≥n porque es un problema de regresi√≥n\n",
    "    layers.Dense(1, name='salida')\n",
    "])\n",
    "\n",
    "# Compilaci√≥n del modelo\n",
    "# - Optimizer: Adam (buen optimizer por defecto)\n",
    "# - Loss: MSE (Mean Squared Error) para regresi√≥n\n",
    "# - Metrics: MAE (Mean Absolute Error) para seguimiento\n",
    "modelo.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mean_absolute_error']\n",
    ")\n",
    "\n",
    "# Mostramos la arquitectura del modelo\n",
    "print(\"Arquitectura del modelo:\\n\")\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Entrenamiento del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento del modelo\n",
    "print(\"Entrenando el modelo...\\n\")\n",
    "\n",
    "history = modelo.fit(\n",
    "    X_train_scaled,  # Datos de entrada normalizados\n",
    "    y_train,  # Precios objetivo\n",
    "    epochs=100,  # N√∫mero de √©pocas\n",
    "    batch_size=32,  # Tama√±o del batch\n",
    "    validation_split=0.2,  # 20% de training para validaci√≥n\n",
    "    verbose=1  # Mostrar progreso\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Entrenamiento completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Evaluaci√≥n del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluaci√≥n en el conjunto de prueba\n",
    "test_loss, test_mae = modelo.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "\n",
    "# Hacemos predicciones para calcular m√°s m√©tricas\n",
    "y_pred = modelo.predict(X_test_scaled, verbose=0)\n",
    "\n",
    "# Calculamos m√©tricas adicionales\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"M√©tricas en el conjunto de prueba:\")\n",
    "print(f\"  - MSE (Mean Squared Error): {mse:,.0f}\")\n",
    "print(f\"  - RMSE (Root Mean Squared Error): {rmse:,.0f}‚Ç¨\")\n",
    "print(f\"  - MAE (Mean Absolute Error): {mae:,.0f}‚Ç¨\")\n",
    "print(f\"  - R¬≤ Score: {r2:.4f}\")\n",
    "print(f\"\\nInterpretaci√≥n: En promedio, nuestras predicciones se desv√≠an ¬±{mae:,.0f}‚Ç¨ del precio real\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Guardado del Modelo\n",
    "\n",
    "Ahora guardaremos el modelo en ambos formatos para que puedas ver c√≥mo funciona cada uno:\n",
    "\n",
    "#### Formato .keras (Recomendado)\n",
    "- Formato nativo y moderno\n",
    "- Guarda todo: arquitectura, pesos, optimizer, etc.\n",
    "- M√°s eficiente y r√°pido\n",
    "\n",
    "#### Formato .h5 (Legado)\n",
    "- Formato HDF5\n",
    "- Compatible con versiones anteriores de Keras\n",
    "- M√°s com√∫n en proyectos antiguos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear carpeta para modelos si no existe\n",
    "os.makedirs('modelos', exist_ok=True)\n",
    "\n",
    "# 1. Guardar en formato .keras (RECOMENDADO)\n",
    "modelo.save('modelos/modelo_precios.keras')\n",
    "print(\"‚úì Modelo guardado en formato .keras\")\n",
    "\n",
    "# 2. Guardar en formato .h5 (compatibilidad)\n",
    "modelo.save('modelos/modelo_precios.h5')\n",
    "print(\"‚úì Modelo guardado en formato .h5\")\n",
    "\n",
    "# 3. Guardar metadatos del modelo (√∫til para monitorizaci√≥n)\n",
    "metadata = {\n",
    "    'fecha_entrenamiento': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'metricas': {\n",
    "        'mse': float(mse),\n",
    "        'rmse': float(rmse),\n",
    "        'mae': float(mae),\n",
    "        'r2': float(r2)\n",
    "    },\n",
    "    'arquitectura': {\n",
    "        'capas': len(modelo.layers),\n",
    "        'parametros_totales': modelo.count_params()\n",
    "    },\n",
    "    'datos_entrenamiento': {\n",
    "        'n_muestras_train': len(X_train),\n",
    "        'n_muestras_test': len(X_test),\n",
    "        'n_caracteristicas': X_train.shape[1]\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('modelos/metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(\"‚úì Metadatos guardados en 'modelos/metadata.json'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ARCHIVOS CREADOS:\")\n",
    "print(\"  üìÅ modelos/\")\n",
    "print(\"    üìÑ modelo_precios.keras  (formato recomendado)\")\n",
    "print(\"    üìÑ modelo_precios.h5     (formato legado)\")\n",
    "print(\"    üìÑ metadata.json         (informaci√≥n del modelo)\")\n",
    "print(\"  üìÑ scaler.pkl              (normalizador de datos)\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 Verificaci√≥n: Carga del Modelo\n",
    "\n",
    "Vamos a verificar que podemos cargar correctamente el modelo guardado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelo desde formato .keras\n",
    "modelo_cargado_keras = keras.models.load_model('modelos/modelo_precios.keras')\n",
    "print(\"‚úì Modelo .keras cargado correctamente\")\n",
    "\n",
    "# Cargar modelo desde formato .h5\n",
    "modelo_cargado_h5 = keras.models.load_model('modelos/modelo_precios.h5')\n",
    "print(\"‚úì Modelo .h5 cargado correctamente\")\n",
    "\n",
    "# Verificar que las predicciones son id√©nticas\n",
    "pred_original = modelo.predict(X_test_scaled[:5], verbose=0)\n",
    "pred_keras = modelo_cargado_keras.predict(X_test_scaled[:5], verbose=0)\n",
    "pred_h5 = modelo_cargado_h5.predict(X_test_scaled[:5], verbose=0)\n",
    "\n",
    "print(\"\\nComparaci√≥n de predicciones (primeras 5 muestras):\")\n",
    "print(f\"{'Original':<15} {'Cargado .keras':<15} {'Cargado .h5':<15} {'Real':<15}\")\n",
    "for i in range(5):\n",
    "    print(f\"{pred_original[i][0]:<15.0f} {pred_keras[i][0]:<15.0f} {pred_h5[i][0]:<15.0f} {y_test.iloc[i] if isinstance(y_test, pd.Series) else y_test[i]:<15.0f}\")\n",
    "\n",
    "print(\"\\n‚úì Verificaci√≥n completada: Los modelos cargados funcionan correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Creaci√≥n de la API con FastAPI\n",
    "\n",
    "Ahora que tenemos nuestro modelo guardado, vamos a crear la API REST.\n",
    "\n",
    "### 4.1 Modelos de Datos con Pydantic\n",
    "\n",
    "Pydantic nos permite definir esquemas de datos con validaci√≥n autom√°tica. Esto asegura que los datos que recibe nuestra API sean correctos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos de datos para validaci√≥n de requests/responses\n",
    "\n",
    "# Modelo para recibir datos de predicci√≥n\n",
    "class DatosCasa(BaseModel):\n",
    "    \"\"\"Datos de entrada para predecir el precio de una casa\"\"\"\n",
    "    tamano: float = Field(..., description=\"Tama√±o en m2\", gt=0, example=150.0)\n",
    "    habitaciones: int = Field(..., description=\"N√∫mero de habitaciones\", ge=1, le=10, example=3)\n",
    "    banos: int = Field(..., description=\"N√∫mero de ba√±os\", ge=1, le=5, example=2)\n",
    "    antiguedad: float = Field(..., description=\"Antig√ºedad en a√±os\", ge=0, le=100, example=10.0)\n",
    "    \n",
    "    class Config:\n",
    "        json_schema_extra = {\n",
    "            \"example\": {\n",
    "                \"tamano\": 150.0,\n",
    "                \"habitaciones\": 3,\n",
    "                \"banos\": 2,\n",
    "                \"antiguedad\": 10.0\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Modelo para respuesta de predicci√≥n\n",
    "class PrediccionRespuesta(BaseModel):\n",
    "    \"\"\"Respuesta con la predicci√≥n del precio\"\"\"\n",
    "    precio_predicho: float = Field(..., description=\"Precio predicho en euros\")\n",
    "    confianza: str = Field(..., description=\"Nivel de confianza de la predicci√≥n\")\n",
    "    timestamp: str = Field(..., description=\"Fecha y hora de la predicci√≥n\")\n",
    "\n",
    "# Modelo para datos de reentrenamiento\n",
    "class DatosReentrenamiento(BaseModel):\n",
    "    \"\"\"Datos para reentrenar el modelo\"\"\"\n",
    "    datos: List[DatosCasa] = Field(..., description=\"Lista de datos de casas\")\n",
    "    precios: List[float] = Field(..., description=\"Precios reales correspondientes\")\n",
    "    epochs: int = Field(default=50, description=\"N√∫mero de √©pocas para reentrenamiento\", ge=1, le=200)\n",
    "\n",
    "print(\"‚úì Modelos de datos definidos correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Variables Globales y Carga Inicial\n",
    "\n",
    "Definimos variables globales para mantener el estado del modelo, m√©tricas y scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables globales para la aplicaci√≥n\n",
    "modelo_actual = None  # Modelo cargado en memoria\n",
    "scaler_actual = None  # Scaler para normalizaci√≥n\n",
    "metadata_actual = {}  # Metadatos del modelo\n",
    "historial_predicciones = []  # Historial para monitorizaci√≥n\n",
    "\n",
    "# Funci√≥n para cargar el modelo y sus componentes\n",
    "def cargar_modelo():\n",
    "    \"\"\"\n",
    "    Carga el modelo, scaler y metadata desde disco.\n",
    "    Esta funci√≥n se ejecuta al iniciar la aplicaci√≥n.\n",
    "    \"\"\"\n",
    "    global modelo_actual, scaler_actual, metadata_actual\n",
    "    \n",
    "    try:\n",
    "        # Cargar el modelo (intentamos .keras primero, luego .h5)\n",
    "        if os.path.exists('modelos/modelo_precios.keras'):\n",
    "            modelo_actual = keras.models.load_model('modelos/modelo_precios.keras')\n",
    "            print(\"‚úì Modelo .keras cargado\")\n",
    "        elif os.path.exists('modelos/modelo_precios.h5'):\n",
    "            modelo_actual = keras.models.load_model('modelos/modelo_precios.h5')\n",
    "            print(\"‚úì Modelo .h5 cargado\")\n",
    "        else:\n",
    "            raise FileNotFoundError(\"No se encontr√≥ ning√∫n modelo guardado\")\n",
    "        \n",
    "        # Cargar el scaler\n",
    "        with open('scaler.pkl', 'rb') as f:\n",
    "            scaler_actual = pickle.load(f)\n",
    "        print(\"‚úì Scaler cargado\")\n",
    "        \n",
    "        # Cargar metadata si existe\n",
    "        if os.path.exists('modelos/metadata.json'):\n",
    "            with open('modelos/metadata.json', 'r') as f:\n",
    "                metadata_actual = json.load(f)\n",
    "            print(\"‚úì Metadata cargada\")\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al cargar el modelo: {e}\")\n",
    "        return False\n",
    "\n",
    "# Cargar el modelo al inicio\n",
    "if cargar_modelo():\n",
    "    print(\"\\n‚úì Sistema listo para usar\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è El sistema no est√° completamente inicializado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. ENDPOINT 1: Endpoint B√°sico de Saludo\n",
    "\n",
    "Este es el endpoint m√°s simple. Sirve para:\n",
    "- Verificar que la API est√° funcionando\n",
    "- Health check b√°sico\n",
    "- Prueba de conectividad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la aplicaci√≥n FastAPI\n",
    "app = FastAPI(\n",
    "    title=\"API de Predicci√≥n de Precios de Casas\",\n",
    "    description=\"API REST para servir modelos de ML con FastAPI\",\n",
    "    version=\"1.0.0\"\n",
    ")\n",
    "\n",
    "# ENDPOINT 1: Ruta ra√≠z - Saludo b√°sico\n",
    "@app.get(\"/\", tags=[\"General\"])\n",
    "async def raiz():\n",
    "    \"\"\"\n",
    "    Endpoint b√°sico de bienvenida.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Mensaje de bienvenida y estado del sistema\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"mensaje\": \"¬°Hola! Bienvenido a la API de predicci√≥n de precios de casas\",\n",
    "        \"version\": \"1.0.0\",\n",
    "        \"status\": \"operativo\",\n",
    "        \"modelo_cargado\": modelo_actual is not None,\n",
    "        \"endpoints_disponibles\": [\n",
    "            \"/docs - Documentaci√≥n interactiva\",\n",
    "            \"/predecir - Hacer predicciones\",\n",
    "            \"/monitorizar - Ver m√©tricas del modelo\",\n",
    "            \"/reentrenar - Reentrenar el modelo\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# ENDPOINT 1.1: Health check\n",
    "@app.get(\"/health\", tags=[\"General\"])\n",
    "async def health_check():\n",
    "    \"\"\"\n",
    "    Verifica el estado de salud de la API.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Estado detallado del sistema\n",
    "    \"\"\"\n",
    "    # Verificamos todos los componentes\n",
    "    estado = {\n",
    "        \"status\": \"healthy\",\n",
    "        \"timestamp\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        \"componentes\": {\n",
    "            \"modelo\": \"OK\" if modelo_actual is not None else \"ERROR\",\n",
    "            \"scaler\": \"OK\" if scaler_actual is not None else \"ERROR\",\n",
    "            \"metadata\": \"OK\" if metadata_actual else \"WARNING\"\n",
    "        },\n",
    "        \"estadisticas\": {\n",
    "            \"predicciones_realizadas\": len(historial_predicciones),\n",
    "            \"fecha_ultimo_entrenamiento\": metadata_actual.get('fecha_entrenamiento', 'Desconocida')\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Si alg√∫n componente cr√≠tico falla, cambiamos el estado\n",
    "    if modelo_actual is None or scaler_actual is None:\n",
    "        estado[\"status\"] = \"unhealthy\"\n",
    "        raise HTTPException(status_code=503, detail=\"Servicio no disponible\")\n",
    "    \n",
    "    return estado\n",
    "\n",
    "print(\"‚úì Endpoints b√°sicos creados\")\n",
    "print(\"  - GET /\")\n",
    "print(\"  - GET /health\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. ENDPOINT 2: Predicci√≥n con el Modelo\n",
    "\n",
    "Este es el endpoint principal de la API. Permite hacer predicciones usando el modelo cargado.\n",
    "\n",
    "### Flujo de predicci√≥n:\n",
    "1. Recibir datos de entrada (validados por Pydantic)\n",
    "2. Normalizar los datos con el scaler\n",
    "3. Hacer la predicci√≥n con el modelo\n",
    "4. Guardar en el historial para monitorizaci√≥n\n",
    "5. Retornar el resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENDPOINT 2: Predicci√≥n\n",
    "@app.post(\"/predecir\", response_model=PrediccionRespuesta, tags=[\"Predicci√≥n\"])\n",
    "async def predecir_precio(datos: DatosCasa):\n",
    "    \"\"\"\n",
    "    Predice el precio de una casa bas√°ndose en sus caracter√≠sticas.\n",
    "    \n",
    "    Args:\n",
    "        datos (DatosCasa): Caracter√≠sticas de la casa\n",
    "        \n",
    "    Returns:\n",
    "        PrediccionRespuesta: Precio predicho y metadatos\n",
    "        \n",
    "    Raises:\n",
    "        HTTPException: Si el modelo no est√° cargado o hay un error en la predicci√≥n\n",
    "    \"\"\"\n",
    "    # Verificar que el modelo est√© cargado\n",
    "    if modelo_actual is None or scaler_actual is None:\n",
    "        raise HTTPException(\n",
    "            status_code=503,\n",
    "            detail=\"El modelo no est√° cargado. Por favor, reinicia el servidor.\"\n",
    "        )\n",
    "    \n",
    "    try:\n",
    "        # Paso 1: Preparar los datos de entrada\n",
    "        # Convertimos los datos de Pydantic a un array numpy\n",
    "        entrada = np.array([[\n",
    "            datos.tamano,\n",
    "            datos.habitaciones,\n",
    "            datos.banos,\n",
    "            datos.antiguedad\n",
    "        ]])\n",
    "        \n",
    "        # Paso 2: Normalizar los datos usando el scaler\n",
    "        # Es CR√çTICO usar el mismo scaler que se us√≥ en el entrenamiento\n",
    "        entrada_normalizada = scaler_actual.transform(entrada)\n",
    "        \n",
    "        # Paso 3: Hacer la predicci√≥n\n",
    "        prediccion = modelo_actual.predict(entrada_normalizada, verbose=0)\n",
    "        precio_predicho = float(prediccion[0][0])\n",
    "        \n",
    "        # Paso 4: Calcular nivel de confianza (simplificado)\n",
    "        # En un sistema real, usar√≠amos intervalos de confianza o predicci√≥n\n",
    "        # Aqu√≠ usamos una heur√≠stica basada en el MAE del modelo\n",
    "        mae_modelo = metadata_actual.get('metricas', {}).get('mae', 20000)\n",
    "        error_relativo = (mae_modelo / precio_predicho) * 100\n",
    "        \n",
    "        if error_relativo < 10:\n",
    "            confianza = \"alta\"\n",
    "        elif error_relativo < 20:\n",
    "            confianza = \"media\"\n",
    "        else:\n",
    "            confianza = \"baja\"\n",
    "        \n",
    "        # Paso 5: Guardar en historial para monitorizaci√≥n\n",
    "        historial_predicciones.append({\n",
    "            \"timestamp\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            \"entrada\": {\n",
    "                \"tamano\": datos.tamano,\n",
    "                \"habitaciones\": datos.habitaciones,\n",
    "                \"banos\": datos.banos,\n",
    "                \"antiguedad\": datos.antiguedad\n",
    "            },\n",
    "            \"prediccion\": precio_predicho,\n",
    "            \"confianza\": confianza\n",
    "        })\n",
    "        \n",
    "        # Limitar el historial a las √∫ltimas 1000 predicciones\n",
    "        if len(historial_predicciones) > 1000:\n",
    "            historial_predicciones.pop(0)\n",
    "        \n",
    "        # Paso 6: Retornar la respuesta\n",
    "        return PrediccionRespuesta(\n",
    "            precio_predicho=round(precio_predicho, 2),\n",
    "            confianza=confianza,\n",
    "            timestamp=datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Manejo de errores\n",
    "        raise HTTPException(\n",
    "            status_code=500,\n",
    "            detail=f\"Error al realizar la predicci√≥n: {str(e)}\"\n",
    "        )\n",
    "\n",
    "# ENDPOINT 2.1: Predicci√≥n por lotes (batch prediction)\n",
    "@app.post(\"/predecir/lote\", tags=[\"Predicci√≥n\"])\n",
    "async def predecir_lote(datos_lista: List[DatosCasa]):\n",
    "    \"\"\"\n",
    "    Predice precios para m√∫ltiples casas a la vez.\n",
    "    M√°s eficiente que hacer m√∫ltiples llamadas individuales.\n",
    "    \n",
    "    Args:\n",
    "        datos_lista (List[DatosCasa]): Lista de casas\n",
    "        \n",
    "    Returns:\n",
    "        dict: Lista de predicciones\n",
    "    \"\"\"\n",
    "    if modelo_actual is None or scaler_actual is None:\n",
    "        raise HTTPException(status_code=503, detail=\"Modelo no disponible\")\n",
    "    \n",
    "    try:\n",
    "        # Convertir todos los datos a un array numpy\n",
    "        entrada = np.array([\n",
    "            [d.tamano, d.habitaciones, d.banos, d.antiguedad]\n",
    "            for d in datos_lista\n",
    "        ])\n",
    "        \n",
    "        # Normalizar y predecir\n",
    "        entrada_normalizada = scaler_actual.transform(entrada)\n",
    "        predicciones = modelo_actual.predict(entrada_normalizada, verbose=0)\n",
    "        \n",
    "        # Formatear resultados\n",
    "        resultados = [\n",
    "            {\n",
    "                \"indice\": i,\n",
    "                \"entrada\": {\n",
    "                    \"tamano\": datos_lista[i].tamano,\n",
    "                    \"habitaciones\": datos_lista[i].habitaciones,\n",
    "                    \"banos\": datos_lista[i].banos,\n",
    "                    \"antiguedad\": datos_lista[i].antiguedad\n",
    "                },\n",
    "                \"precio_predicho\": round(float(predicciones[i][0]), 2)\n",
    "            }\n",
    "            for i in range(len(predicciones))\n",
    "        ]\n",
    "        \n",
    "        return {\n",
    "            \"n_predicciones\": len(resultados),\n",
    "            \"timestamp\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            \"predicciones\": resultados\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"Error: {str(e)}\")\n",
    "\n",
    "print(\"‚úì Endpoints de predicci√≥n creados\")\n",
    "print(\"  - POST /predecir\")\n",
    "print(\"  - POST /predecir/lote\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. ENDPOINT 3: Monitorizaci√≥n del Modelo\n",
    "\n",
    "La monitorizaci√≥n es crucial en producci√≥n. Este endpoint permite:\n",
    "- Ver m√©tricas del modelo actual\n",
    "- Analizar el historial de predicciones\n",
    "- Detectar posibles problemas o degradaci√≥n del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENDPOINT 3: Monitorizaci√≥n\n",
    "@app.get(\"/monitorizar\", tags=[\"Monitorizaci√≥n\"])\n",
    "async def monitorizar_modelo():\n",
    "    \"\"\"\n",
    "    Devuelve m√©tricas y estad√≠sticas sobre el modelo en producci√≥n.\n",
    "    \n",
    "    Incluye:\n",
    "    - M√©tricas de entrenamiento\n",
    "    - Estad√≠sticas de uso\n",
    "    - Informaci√≥n de la arquitectura\n",
    "    - An√°lisis del historial de predicciones\n",
    "    \n",
    "    Returns:\n",
    "        dict: M√©tricas completas del modelo\n",
    "    \"\"\"\n",
    "    if modelo_actual is None:\n",
    "        raise HTTPException(status_code=503, detail=\"Modelo no disponible\")\n",
    "    \n",
    "    # 1. Informaci√≥n b√°sica del modelo\n",
    "    info_basica = {\n",
    "        \"nombre\": \"Modelo de Predicci√≥n de Precios de Casas\",\n",
    "        \"version\": \"1.0.0\",\n",
    "        \"estado\": \"activo\",\n",
    "        \"fecha_carga\": metadata_actual.get('fecha_entrenamiento', 'Desconocida')\n",
    "    }\n",
    "    \n",
    "    # 2. M√©tricas de entrenamiento (del archivo metadata.json)\n",
    "    metricas_entrenamiento = metadata_actual.get('metricas', {\n",
    "        \"mse\": \"No disponible\",\n",
    "        \"rmse\": \"No disponible\",\n",
    "        \"mae\": \"No disponible\",\n",
    "        \"r2\": \"No disponible\"\n",
    "    })\n",
    "    \n",
    "    # 3. Informaci√≥n de la arquitectura\n",
    "    arquitectura = {\n",
    "        \"n_capas\": len(modelo_actual.layers),\n",
    "        \"parametros_totales\": modelo_actual.count_params(),\n",
    "        \"parametros_entrenables\": sum([tf.size(w).numpy() for w in modelo_actual.trainable_weights]),\n",
    "        \"capas_detalle\": [\n",
    "            {\n",
    "                \"nombre\": layer.name,\n",
    "                \"tipo\": layer.__class__.__name__,\n",
    "                \"forma_salida\": str(layer.output_shape)\n",
    "            }\n",
    "            for layer in modelo_actual.layers\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # 4. Estad√≠sticas de uso (desde el inicio del servidor)\n",
    "    estadisticas_uso = {\n",
    "        \"total_predicciones\": len(historial_predicciones),\n",
    "        \"predicciones_ultima_hora\": sum(\n",
    "            1 for p in historial_predicciones\n",
    "            if (datetime.now() - datetime.strptime(p['timestamp'], '%Y-%m-%d %H:%M:%S')).seconds < 3600\n",
    "        ) if historial_predicciones else 0\n",
    "    }\n",
    "    \n",
    "    # 5. An√°lisis del historial de predicciones\n",
    "    if historial_predicciones:\n",
    "        precios_predichos = [p['prediccion'] for p in historial_predicciones]\n",
    "        distribucion_confianza = {\n",
    "            \"alta\": sum(1 for p in historial_predicciones if p['confianza'] == 'alta'),\n",
    "            \"media\": sum(1 for p in historial_predicciones if p['confianza'] == 'media'),\n",
    "            \"baja\": sum(1 for p in historial_predicciones if p['confianza'] == 'baja')\n",
    "        }\n",
    "        \n",
    "        analisis_predicciones = {\n",
    "            \"precio_promedio\": round(np.mean(precios_predichos), 2),\n",
    "            \"precio_mediano\": round(np.median(precios_predichos), 2),\n",
    "            \"precio_min\": round(np.min(precios_predichos), 2),\n",
    "            \"precio_max\": round(np.max(precios_predichos), 2),\n",
    "            \"desviacion_estandar\": round(np.std(precios_predichos), 2),\n",
    "            \"distribucion_confianza\": distribucion_confianza\n",
    "        }\n",
    "    else:\n",
    "        analisis_predicciones = {\n",
    "            \"mensaje\": \"No hay predicciones registradas a√∫n\"\n",
    "        }\n",
    "    \n",
    "    # 6. Recomendaciones y alertas\n",
    "    recomendaciones = []\n",
    "    \n",
    "    # Alerta si hay muchas predicciones de baja confianza\n",
    "    if historial_predicciones:\n",
    "        pct_baja_confianza = (distribucion_confianza.get('baja', 0) / len(historial_predicciones)) * 100\n",
    "        if pct_baja_confianza > 30:\n",
    "            recomendaciones.append({\n",
    "                \"tipo\": \"warning\",\n",
    "                \"mensaje\": f\"Alto porcentaje de predicciones con baja confianza ({pct_baja_confianza:.1f}%). Considera reentrenar el modelo.\"\n",
    "            })\n",
    "    \n",
    "    # Alerta si el modelo es antiguo (ejemplo: m√°s de 30 d√≠as)\n",
    "    # En producci√≥n real, comparar√≠as con la fecha actual\n",
    "    recomendaciones.append({\n",
    "        \"tipo\": \"info\",\n",
    "        \"mensaje\": \"Recomendaci√≥n: Reentrena el modelo peri√≥dicamente con datos nuevos para mantener su precisi√≥n.\"\n",
    "    })\n",
    "    \n",
    "    # 7. Retornar todo el an√°lisis\n",
    "    return {\n",
    "        \"timestamp\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        \"info_basica\": info_basica,\n",
    "        \"metricas_entrenamiento\": metricas_entrenamiento,\n",
    "        \"arquitectura\": arquitectura,\n",
    "        \"estadisticas_uso\": estadisticas_uso,\n",
    "        \"analisis_predicciones\": analisis_predicciones,\n",
    "        \"recomendaciones\": recomendaciones\n",
    "    }\n",
    "\n",
    "# ENDPOINT 3.1: Historial de predicciones\n",
    "@app.get(\"/monitorizar/historial\", tags=[\"Monitorizaci√≥n\"])\n",
    "async def obtener_historial(limite: int = 100):\n",
    "    \"\"\"\n",
    "    Devuelve las √∫ltimas N predicciones realizadas.\n",
    "    \n",
    "    Args:\n",
    "        limite (int): N√∫mero m√°ximo de predicciones a devolver (default: 100)\n",
    "        \n",
    "    Returns:\n",
    "        dict: Historial de predicciones\n",
    "    \"\"\"\n",
    "    # Limitar el n√∫mero de resultados\n",
    "    limite = min(limite, 1000)  # M√°ximo 1000 predicciones\n",
    "    \n",
    "    return {\n",
    "        \"total_predicciones\": len(historial_predicciones),\n",
    "        \"limite\": limite,\n",
    "        \"predicciones\": historial_predicciones[-limite:]  # √öltimas N predicciones\n",
    "    }\n",
    "\n",
    "print(\"‚úì Endpoints de monitorizaci√≥n creados\")\n",
    "print(\"  - GET /monitorizar\")\n",
    "print(\"  - GET /monitorizar/historial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. ENDPOINT 4: Reentrenamiento del Modelo\n",
    "\n",
    "El reentrenamiento permite actualizar el modelo con nuevos datos sin tener que reconstruir toda la API.\n",
    "\n",
    "### Consideraciones importantes:\n",
    "- En producci√≥n, esto se har√≠a de forma as√≠ncrona (usando Celery, por ejemplo)\n",
    "- Se deber√≠a validar la calidad de los nuevos datos\n",
    "- Es recomendable hacer validaci√≥n cruzada antes de actualizar el modelo en producci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENDPOINT 4: Reentrenamiento\n",
    "@app.post(\"/reentrenar\", tags=[\"Reentrenamiento\"])\n",
    "async def reentrenar_modelo(datos_entrenamiento: DatosReentrenamiento):\n",
    "    \"\"\"\n",
    "    Reentrena el modelo con nuevos datos.\n",
    "    \n",
    "    IMPORTANTE: En producci√≥n, este proceso deber√≠a ser as√≠ncrono y\n",
    "    realizarse en un worker separado (ej: Celery) para no bloquear la API.\n",
    "    \n",
    "    Args:\n",
    "        datos_entrenamiento (DatosReentrenamiento): Nuevos datos para entrenar\n",
    "        \n",
    "    Returns:\n",
    "        dict: Resultado del reentrenamiento con m√©tricas\n",
    "        \n",
    "    Raises:\n",
    "        HTTPException: Si hay errores en los datos o el entrenamiento\n",
    "    \"\"\"\n",
    "    global modelo_actual, metadata_actual\n",
    "    \n",
    "    if modelo_actual is None or scaler_actual is None:\n",
    "        raise HTTPException(status_code=503, detail=\"Modelo no disponible\")\n",
    "    \n",
    "    try:\n",
    "        # 1. Validar que tenemos suficientes datos\n",
    "        if len(datos_entrenamiento.datos) < 10:\n",
    "            raise HTTPException(\n",
    "                status_code=400,\n",
    "                detail=\"Se necesitan al menos 10 muestras para reentrenar\"\n",
    "            )\n",
    "        \n",
    "        # 2. Validar que el n√∫mero de datos coincide con el n√∫mero de precios\n",
    "        if len(datos_entrenamiento.datos) != len(datos_entrenamiento.precios):\n",
    "            raise HTTPException(\n",
    "                status_code=400,\n",
    "                detail=\"El n√∫mero de datos debe coincidir con el n√∫mero de precios\"\n",
    "            )\n",
    "        \n",
    "        # 3. Preparar los datos de entrenamiento\n",
    "        # Convertir los datos de Pydantic a arrays numpy\n",
    "        X_nuevo = np.array([\n",
    "            [d.tamano, d.habitaciones, d.banos, d.antiguedad]\n",
    "            for d in datos_entrenamiento.datos\n",
    "        ])\n",
    "        y_nuevo = np.array(datos_entrenamiento.precios)\n",
    "        \n",
    "        # 4. Dividir en train/test para validaci√≥n\n",
    "        X_train_nuevo, X_test_nuevo, y_train_nuevo, y_test_nuevo = train_test_split(\n",
    "            X_nuevo, y_nuevo,\n",
    "            test_size=0.2,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # 5. Normalizar los datos usando el scaler existente\n",
    "        # IMPORTANTE: Usamos transform(), NO fit_transform()\n",
    "        # para mantener la misma escala que el modelo original\n",
    "        X_train_scaled = scaler_actual.transform(X_train_nuevo)\n",
    "        X_test_scaled = scaler_actual.transform(X_test_nuevo)\n",
    "        \n",
    "        # 6. Guardar m√©tricas del modelo antes del reentrenamiento\n",
    "        metricas_antes = metadata_actual.get('metricas', {})\n",
    "        \n",
    "        # 7. Reentrenar el modelo\n",
    "        # Usamos el modelo existente (transfer learning)\n",
    "        print(f\"Iniciando reentrenamiento con {len(X_train_nuevo)} muestras...\")\n",
    "        \n",
    "        history = modelo_actual.fit(\n",
    "            X_train_scaled,\n",
    "            y_train_nuevo,\n",
    "            epochs=datos_entrenamiento.epochs,\n",
    "            batch_size=min(32, len(X_train_nuevo) // 4),  # Ajustamos batch size\n",
    "            validation_split=0.2,\n",
    "            verbose=0  # Silencioso para no saturar logs\n",
    "        )\n",
    "        \n",
    "        # 8. Evaluar el modelo reentrenado\n",
    "        y_pred = modelo_actual.predict(X_test_scaled, verbose=0)\n",
    "        \n",
    "        # Calcular m√©tricas\n",
    "        mse_nuevo = mean_squared_error(y_test_nuevo, y_pred)\n",
    "        rmse_nuevo = np.sqrt(mse_nuevo)\n",
    "        mae_nuevo = mean_absolute_error(y_test_nuevo, y_pred)\n",
    "        r2_nuevo = r2_score(y_test_nuevo, y_pred)\n",
    "        \n",
    "        metricas_despues = {\n",
    "            'mse': float(mse_nuevo),\n",
    "            'rmse': float(rmse_nuevo),\n",
    "            'mae': float(mae_nuevo),\n",
    "            'r2': float(r2_nuevo)\n",
    "        }\n",
    "        \n",
    "        # 9. Actualizar metadata\n",
    "        metadata_actual['fecha_entrenamiento'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        metadata_actual['metricas'] = metricas_despues\n",
    "        metadata_actual['datos_entrenamiento'] = {\n",
    "            'n_muestras_train': len(X_train_nuevo),\n",
    "            'n_muestras_test': len(X_test_nuevo),\n",
    "            'n_caracteristicas': X_nuevo.shape[1]\n",
    "        }\n",
    "        \n",
    "        # 10. Guardar el modelo reentrenado\n",
    "        modelo_actual.save('modelos/modelo_precios.keras')\n",
    "        with open('modelos/metadata.json', 'w') as f:\n",
    "            json.dump(metadata_actual, f, indent=2)\n",
    "        \n",
    "        # 11. Preparar respuesta con comparaci√≥n\n",
    "        return {\n",
    "            \"status\": \"exitoso\",\n",
    "            \"timestamp\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            \"datos_utilizados\": {\n",
    "                \"total_muestras\": len(X_nuevo),\n",
    "                \"muestras_entrenamiento\": len(X_train_nuevo),\n",
    "                \"muestras_test\": len(X_test_nuevo),\n",
    "                \"epochs\": datos_entrenamiento.epochs\n",
    "            },\n",
    "            \"metricas_antes\": metricas_antes,\n",
    "            \"metricas_despues\": metricas_despues,\n",
    "            \"mejora\": {\n",
    "                \"mae\": f\"{((metricas_antes.get('mae', 0) - mae_nuevo) / metricas_antes.get('mae', 1)) * 100:.2f}%\" if metricas_antes.get('mae') else \"N/A\",\n",
    "                \"r2\": f\"{((r2_nuevo - metricas_antes.get('r2', 0)) / metricas_antes.get('r2', 1)) * 100:.2f}%\" if metricas_antes.get('r2') else \"N/A\"\n",
    "            },\n",
    "            \"modelo_guardado\": \"modelos/modelo_precios.keras\",\n",
    "            \"mensaje\": \"Modelo reentrenado y guardado exitosamente\"\n",
    "        }\n",
    "        \n",
    "    except HTTPException:\n",
    "        raise  # Re-lanzar excepciones HTTP\n",
    "    except Exception as e:\n",
    "        raise HTTPException(\n",
    "            status_code=500,\n",
    "            detail=f\"Error durante el reentrenamiento: {str(e)}\"\n",
    "        )\n",
    "\n",
    "# ENDPOINT 4.1: Validar datos antes de reentrenar\n",
    "@app.post(\"/reentrenar/validar\", tags=[\"Reentrenamiento\"])\n",
    "async def validar_datos_reentrenamiento(datos_entrenamiento: DatosReentrenamiento):\n",
    "    \"\"\"\n",
    "    Valida los datos de reentrenamiento sin ejecutar el entrenamiento.\n",
    "    √ötil para verificar que los datos son correctos antes de reentrenar.\n",
    "    \n",
    "    Args:\n",
    "        datos_entrenamiento (DatosReentrenamiento): Datos a validar\n",
    "        \n",
    "    Returns:\n",
    "        dict: Resultado de la validaci√≥n\n",
    "    \"\"\"\n",
    "    # Validaciones b√°sicas\n",
    "    problemas = []\n",
    "    advertencias = []\n",
    "    \n",
    "    # N√∫mero de muestras\n",
    "    if len(datos_entrenamiento.datos) < 10:\n",
    "        problemas.append(\"Se necesitan al menos 10 muestras (recomendado: 100+)\")\n",
    "    elif len(datos_entrenamiento.datos) < 50:\n",
    "        advertencias.append(\"Se recomienda al menos 50 muestras para un buen reentrenamiento\")\n",
    "    \n",
    "    # Concordancia de datos y precios\n",
    "    if len(datos_entrenamiento.datos) != len(datos_entrenamiento.precios):\n",
    "        problemas.append(f\"Discordancia: {len(datos_entrenamiento.datos)} datos vs {len(datos_entrenamiento.precios)} precios\")\n",
    "    \n",
    "    # Validar rangos de valores\n",
    "    precios = datos_entrenamiento.precios\n",
    "    if any(p <= 0 for p in precios):\n",
    "        problemas.append(\"Hay precios negativos o cero\")\n",
    "    \n",
    "    # Estad√≠sticas de los datos\n",
    "    if precios:\n",
    "        estadisticas = {\n",
    "            \"precio_promedio\": np.mean(precios),\n",
    "            \"precio_min\": np.min(precios),\n",
    "            \"precio_max\": np.max(precios),\n",
    "            \"desviacion_estandar\": np.std(precios)\n",
    "        }\n",
    "    else:\n",
    "        estadisticas = {}\n",
    "    \n",
    "    # Resultado de validaci√≥n\n",
    "    es_valido = len(problemas) == 0\n",
    "    \n",
    "    return {\n",
    "        \"valido\": es_valido,\n",
    "        \"n_muestras\": len(datos_entrenamiento.datos),\n",
    "        \"n_precios\": len(datos_entrenamiento.precios),\n",
    "        \"problemas\": problemas,\n",
    "        \"advertencias\": advertencias,\n",
    "        \"estadisticas\": estadisticas,\n",
    "        \"mensaje\": \"Datos v√°lidos para reentrenamiento\" if es_valido else \"Corrige los problemas antes de reentrenar\"\n",
    "    }\n",
    "\n",
    "print(\"‚úì Endpoints de reentrenamiento creados\")\n",
    "print(\"  - POST /reentrenar\")\n",
    "print(\"  - POST /reentrenar/validar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Ejecuci√≥n del Servidor\n",
    "\n",
    "### Opci√≥n 1: Ejecutar desde el notebook (para desarrollo)\n",
    "\n",
    "**IMPORTANTE**: Si ejecutas el servidor desde Jupyter, la celda quedar√° bloqueada mientras el servidor est√© corriendo. Para detenerlo, usa el bot√≥n de \"stop\" del notebook.\n",
    "\n",
    "### Opci√≥n 2: Ejecutar desde terminal (recomendado para producci√≥n)\n",
    "\n",
    "```bash\n",
    "uvicorn nombre_archivo:app --reload --host 0.0.0.0 --port 8000\n",
    "```\n",
    "\n",
    "Donde:\n",
    "- `nombre_archivo` es el nombre de tu archivo Python (sin .py)\n",
    "- `--reload`: Reinicia autom√°ticamente cuando cambias c√≥digo (solo desarrollo)\n",
    "- `--host 0.0.0.0`: Permite acceso desde cualquier IP\n",
    "- `--port 8000`: Puerto donde escucha el servidor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTA: Esta celda iniciar√° el servidor. \n",
    "# Para detenerlo en Jupyter, usa el bot√≥n de \"stop\" o interrumpe el kernel\n",
    "\n",
    "# Cargar el modelo antes de iniciar el servidor\n",
    "print(\"Inicializando servidor...\")\n",
    "cargar_modelo()\n",
    "\n",
    "# Configuraci√≥n del servidor\n",
    "# Para desarrollo local:\n",
    "# - host=\"127.0.0.1\" = solo accesible desde tu m√°quina\n",
    "# - host=\"0.0.0.0\" = accesible desde otras m√°quinas en la red\n",
    "config = uvicorn.Config(\n",
    "    app,\n",
    "    host=\"127.0.0.1\",  # Cambia a \"0.0.0.0\" para acceso externo\n",
    "    port=8000,\n",
    "    log_level=\"info\"\n",
    ")\n",
    "\n",
    "server = uvicorn.Server(config)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ SERVIDOR FASTAPI INICIADO\")\n",
    "print(\"=\"*60)\n",
    "print(f\"üìç URL: http://127.0.0.1:8000\")\n",
    "print(f\"üìö Documentaci√≥n interactiva: http://127.0.0.1:8000/docs\")\n",
    "print(f\"üìñ Documentaci√≥n alternativa: http://127.0.0.1:8000/redoc\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nPara detener el servidor: Interrumpe el kernel o presiona el bot√≥n 'stop'\\n\")\n",
    "\n",
    "# Iniciar el servidor\n",
    "# NOTA: Esta l√≠nea bloquear√° la ejecuci√≥n hasta que detengas el servidor\n",
    "await server.serve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Testing de la API\n",
    "\n",
    "### 10.1 Testing con Python (requests)\n",
    "\n",
    "Una vez que el servidor est√© corriendo, puedes probar los endpoints desde otra terminal o notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANTE: Ejecuta esta celda SOLO si el servidor est√° corriendo en otra terminal o celda\n",
    "import requests\n",
    "\n",
    "# URL base de la API\n",
    "BASE_URL = \"http://127.0.0.1:8000\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PROBANDO ENDPOINTS DE LA API\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# 1. Test del endpoint ra√≠z\n",
    "print(\"1Ô∏è‚É£ GET / (Endpoint de bienvenida)\")\n",
    "print(\"-\" * 40)\n",
    "response = requests.get(f\"{BASE_URL}/\")\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "print(f\"Respuesta: {response.json()}\")\n",
    "print()\n",
    "\n",
    "# 2. Test del health check\n",
    "print(\"2Ô∏è‚É£ GET /health (Health check)\")\n",
    "print(\"-\" * 40)\n",
    "response = requests.get(f\"{BASE_URL}/health\")\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "print(f\"Respuesta: {json.dumps(response.json(), indent=2)}\")\n",
    "print()\n",
    "\n",
    "# 3. Test de predicci√≥n individual\n",
    "print(\"3Ô∏è‚É£ POST /predecir (Predicci√≥n individual)\")\n",
    "print(\"-\" * 40)\n",
    "datos_casa = {\n",
    "    \"tamano\": 120.0,\n",
    "    \"habitaciones\": 3,\n",
    "    \"banos\": 2,\n",
    "    \"antiguedad\": 5.0\n",
    "}\n",
    "print(f\"Datos enviados: {datos_casa}\")\n",
    "response = requests.post(f\"{BASE_URL}/predecir\", json=datos_casa)\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "print(f\"Respuesta: {json.dumps(response.json(), indent=2)}\")\n",
    "print()\n",
    "\n",
    "# 4. Test de predicci√≥n por lotes\n",
    "print(\"4Ô∏è‚É£ POST /predecir/lote (Predicci√≥n por lotes)\")\n",
    "print(\"-\" * 40)\n",
    "datos_lote = [\n",
    "    {\"tamano\": 100.0, \"habitaciones\": 2, \"banos\": 1, \"antiguedad\": 10.0},\n",
    "    {\"tamano\": 150.0, \"habitaciones\": 3, \"banos\": 2, \"antiguedad\": 5.0},\n",
    "    {\"tamano\": 200.0, \"habitaciones\": 4, \"banos\": 3, \"antiguedad\": 2.0}\n",
    "]\n",
    "print(f\"N√∫mero de casas: {len(datos_lote)}\")\n",
    "response = requests.post(f\"{BASE_URL}/predecir/lote\", json=datos_lote)\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "resultado = response.json()\n",
    "print(f\"Predicciones obtenidas: {resultado['n_predicciones']}\")\n",
    "for pred in resultado['predicciones']:\n",
    "    print(f\"  Casa {pred['indice']}: {pred['precio_predicho']:.2f}‚Ç¨\")\n",
    "print()\n",
    "\n",
    "# 5. Test de monitorizaci√≥n\n",
    "print(\"5Ô∏è‚É£ GET /monitorizar (Monitorizaci√≥n)\")\n",
    "print(\"-\" * 40)\n",
    "response = requests.get(f\"{BASE_URL}/monitorizar\")\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "resultado = response.json()\n",
    "print(f\"Predicciones totales: {resultado['estadisticas_uso']['total_predicciones']}\")\n",
    "print(f\"M√©tricas del modelo:\")\n",
    "for metrica, valor in resultado['metricas_entrenamiento'].items():\n",
    "    print(f\"  - {metrica.upper()}: {valor}\")\n",
    "print()\n",
    "\n",
    "# 6. Test de validaci√≥n de datos para reentrenamiento\n",
    "print(\"6Ô∏è‚É£ POST /reentrenar/validar (Validar datos)\")\n",
    "print(\"-\" * 40)\n",
    "datos_validacion = {\n",
    "    \"datos\": datos_lote,\n",
    "    \"precios\": [180000.0, 250000.0, 320000.0],\n",
    "    \"epochs\": 50\n",
    "}\n",
    "response = requests.post(f\"{BASE_URL}/reentrenar/validar\", json=datos_validacion)\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "print(f\"Respuesta: {json.dumps(response.json(), indent=2)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úì TODOS LOS TESTS COMPLETADOS\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 Testing con cURL (desde terminal)\n",
    "\n",
    "Tambi√©n puedes probar la API usando cURL desde la terminal:\n",
    "\n",
    "```bash\n",
    "# GET /\n",
    "curl http://127.0.0.1:8000/\n",
    "\n",
    "# POST /predecir\n",
    "curl -X POST \"http://127.0.0.1:8000/predecir\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d '{\"tamano\": 120, \"habitaciones\": 3, \"banos\": 2, \"antiguedad\": 5}'\n",
    "\n",
    "# GET /monitorizar\n",
    "curl http://127.0.0.1:8000/monitorizar\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11. Exportar la API a un Archivo Python Standalone\n",
    "\n",
    "Para usar la API en producci√≥n, es mejor tenerla en un archivo `.py` independiente.\n",
    "Esta celda exporta todo el c√≥digo necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar la API a un archivo Python standalone\n",
    "codigo_api = '''\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "API REST para Predicci√≥n de Precios de Casas usando FastAPI\n",
    "Generado desde el tutorial de Jupyter Notebook\n",
    "\"\"\"\n",
    "\n",
    "# Importaciones\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel, Field\n",
    "import uvicorn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import List\n",
    "import pickle\n",
    "\n",
    "# Variables globales\n",
    "modelo_actual = None\n",
    "scaler_actual = None\n",
    "metadata_actual = {}\n",
    "historial_predicciones = []\n",
    "\n",
    "# [AQU√ç IR√çA TODO EL C√ìDIGO DE LOS MODELOS PYDANTIC Y ENDPOINTS]\n",
    "# Por brevedad, este es un esqueleto. En la pr√°ctica, copiar√≠as todo el c√≥digo anterior.\n",
    "\n",
    "# Funci√≥n principal\n",
    "if __name__ == \"__main__\":\n",
    "    # Cargar el modelo al inicio\n",
    "    cargar_modelo()\n",
    "    \n",
    "    # Iniciar servidor\n",
    "    uvicorn.run(\n",
    "        app,\n",
    "        host=\"0.0.0.0\",\n",
    "        port=8000,\n",
    "        log_level=\"info\"\n",
    "    )\n",
    "'''\n",
    "\n",
    "# Guardar el archivo\n",
    "with open('api_precios_casas.py', 'w', encoding='utf-8') as f:\n",
    "    f.write(codigo_api)\n",
    "\n",
    "print(\"‚úì Archivo 'api_precios_casas.py' exportado\")\n",
    "print(\"\\nPara ejecutarlo:\")\n",
    "print(\"  python api_precios_casas.py\")\n",
    "print(\"\\nO con uvicorn:\")\n",
    "print(\"  uvicorn api_precios_casas:app --reload\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12. Resumen y Mejores Pr√°cticas\n",
    "\n",
    "### ‚úÖ Lo que hemos aprendido:\n",
    "\n",
    "1. **Guardado de modelos**: Diferencias entre `.keras` y `.h5`\n",
    "2. **FastAPI b√°sico**: Crear endpoints REST\n",
    "3. **Validaci√≥n con Pydantic**: Asegurar datos correctos\n",
    "4. **Predicciones**: Individual y por lotes\n",
    "5. **Monitorizaci√≥n**: Tracking de m√©tricas y uso\n",
    "6. **Reentrenamiento**: Actualizar modelos sin reconstruir la API\n",
    "\n",
    "### üéØ Mejores pr√°cticas para producci√≥n:\n",
    "\n",
    "1. **Seguridad**:\n",
    "   - A√±adir autenticaci√≥n (OAuth2, API Keys)\n",
    "   - Usar HTTPS (TLS/SSL)\n",
    "   - Limitar rate limiting (evitar abuso)\n",
    "   - Validar TODOS los inputs\n",
    "\n",
    "2. **Escalabilidad**:\n",
    "   - Usar workers m√∫ltiples (`uvicorn --workers 4`)\n",
    "   - Implementar cach√© (Redis)\n",
    "   - Load balancing (Nginx)\n",
    "   - Contenedores Docker\n",
    "\n",
    "3. **Monitorizaci√≥n**:\n",
    "   - Logging estructurado\n",
    "   - M√©tricas con Prometheus\n",
    "   - Alertas autom√°ticas\n",
    "   - Tracking de performance\n",
    "\n",
    "4. **Datos y Modelos**:\n",
    "   - Versionado de modelos (MLflow, DVC)\n",
    "   - A/B testing de modelos\n",
    "   - Validaci√≥n de datos (Great Expectations)\n",
    "   - Backup autom√°tico\n",
    "\n",
    "5. **C√≥digo**:\n",
    "   - Tests unitarios (pytest)\n",
    "   - Tests de integraci√≥n\n",
    "   - CI/CD (GitHub Actions, GitLab CI)\n",
    "   - Documentaci√≥n completa\n",
    "\n",
    "### üìö Recursos adicionales:\n",
    "\n",
    "- FastAPI: https://fastapi.tiangolo.com/\n",
    "- TensorFlow/Keras: https://www.tensorflow.org/\n",
    "- Pydantic: https://pydantic-docs.helpmanual.io/\n",
    "- MLOps: https://ml-ops.org/\n",
    "\n",
    "---\n",
    "\n",
    "## üéì Ejercicios propuestos:\n",
    "\n",
    "1. **B√°sico**: A√±adir un endpoint para eliminar el historial de predicciones\n",
    "2. **Intermedio**: Implementar autenticaci√≥n con API Key\n",
    "3. **Avanzado**: Crear un sistema de versionado de modelos (cargar diferentes versiones)\n",
    "4. **Experto**: Implementar A/B testing entre dos modelos diferentes\n",
    "\n",
    "---\n",
    "\n",
    "**¬°Gracias por completar este tutorial!** üöÄ\n",
    "\n",
    "Si tienes preguntas o sugerencias, no dudes en consultarlas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
