{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85f38008",
   "metadata": {},
   "source": [
    "## IA generativa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0417cea6",
   "metadata": {},
   "source": [
    "En esta clase exploraremos el mundo de la IA generativa utilizando la API de OpenAI. Aprenderás a conectarte a la API (aunque también podrás usar modelos gratuitos si lo prefieres) y a interactuar con diferentes capacidades avanzadas de los modelos generativos. Veremos cómo chatear directamente desde la API, generar imágenes con DALL·E, convertir texto en voz, y experimentar con otras funciones que hacen posible crear contenido de manera inteligente y automatizada.\n",
    "\n",
    "El objetivo es que entiendas cómo funcionan estas herramientas, cómo integrarlas en tus propios proyectos y cómo aprovechar su potencial para resolver problemas reales o crear experiencias innovadoras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b98c997",
   "metadata": {},
   "source": [
    "### Basic Chat\n",
    "\"La primera aproximación a los LLM generativos de OpenAI es conectarse a su API y comenzar a trabajar sobre el modelo.\"\n",
    "\n",
    "Aprenderás a construir un chatbot básico utilizando la API de OpenAI. Veremos cómo enviar mensajes al modelo, recibir respuestas y manejar una conversación sencilla entre el usuario y la inteligencia artificial. Este ejercicio es ideal para comprender los fundamentos de la comunicación con modelos de lenguaje: cómo formular solicitudes, cómo interpretar las respuestas y cómo estructurar un flujo de conversación.\n",
    "\n",
    "Al finalizar, tendrás un chatbot funcional que podrás adaptar y mejorar para proyectos más avanzados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56087a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# Cargar variables de entorno\n",
    "load_dotenv()\n",
    "\n",
    "# Crear cliente OpenAI\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Crear la solicitud de chat\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': 'Te llamas Boruto y respondes como si fueras un ninja de la aldea de la hoja'\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'Hola como estas'\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=100,\n",
    "    temperature=0.2,\n",
    "    top_p=1, #Ajustan la creatividad y diversidad de la respuesta.\n",
    "    frequency_penalty=0.5,\n",
    "    presence_penalty=0\n",
    ")\n",
    "\n",
    "# Imprimir la respuesta del modelo\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9130d7b",
   "metadata": {},
   "source": [
    "### Introducción al chat en directo con OpenAI\n",
    "Aprenderemos a crear un chat en directo utilizando la API de OpenAI, permitiendo que un usuario escriba mensajes y reciba respuestas inmediatas del modelo. Veremos cómo configurar el entorno, cómo conectar el código con la API y cómo construir una función que envíe mensajes y reciba respuestas en tiempo real.\n",
    "\n",
    "A través de este ejercicio descubriremos cómo funciona la comunicación con un modelo conversacional: cómo establecer un rol o personalidad, cómo controlar la creatividad de las respuestas y cómo gestionar el flujo de la conversación.\n",
    "\n",
    "Al finalizar, tendrás un chat funcional por consola, capaz de interpretar lo que escribas y responder de manera coherente y contextualizada. Esta base te permitirá más adelante construir asistentes personalizados, integrar chatbots en aplicaciones más grandes o desarrollar sistemas interactivos más avanzados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ce7de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos los módulos necesarios\n",
    "import os  # Para acceder a variables de entorno del sistema\n",
    "from dotenv import load_dotenv  # Para cargar variables de entorno desde un archivo .env\n",
    "from openai import OpenAI  # Cliente de la API de OpenAI\n",
    "\n",
    "# Cargamos las variables de entorno desde un archivo .env (como la API key de OpenAI)\n",
    "load_dotenv()\n",
    "\n",
    "# Creamos un cliente de OpenAI usando la clave API almacenada en las variables de entorno\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Definimos una función que toma el mensaje del usuario y devuelve una respuesta del modelo\n",
    "def responder_mensaje(mensaje_usuario):\n",
    "    # Prompt del sistema (rol cinematográfico de detective noir)\n",
    "    prompt_sistema = \"\"\"\n",
    "Eres un detective noir de los años 50, el tipo de hombre que camina por la ciudad como si avanzara entre los fotogramas de una película en blanco y negro. \n",
    "Tu mundo está hecho de contraste: luces de neón que parpadean como mentiras baratas, sombras profundas donde cualquiera podría esconder un secreto, \n",
    "y lluvia constante golpeando el asfalto como si la ciudad misma quisiera confesar algo.\n",
    "\n",
    "Tu voz interior suena como la narración de una película antigua: grave, cansada, pero afilada como una navaja recién abierta. Hablas con metáforas densas, \n",
    "frases cortas y un ritmo que parece acompañado por un saxofón solitario en algún club de mala muerte. Cada palabra que dices podría ser la línea de diálogo \n",
    "de un clásico del cine negro.\n",
    "\n",
    "Eres un detective privado que lo ha visto todo: policías corruptos, tratos que se hacen en callejones húmedos, clientes que llegan con historias que no terminan \n",
    "de cuadrar. Tu oficina huele a whisky, papel viejo y un pasado que preferirías olvidar.\n",
    "\n",
    "A partir de ahora, tu misión es resolver los misterios que te presento.\n",
    "Analiza cada pista como si fuera una prueba encontrada bajo la luz vacilante de una lámpara de escritorio.\n",
    "Haz preguntas cuando necesites más claridad, igual que un detective que sabe que la verdad suele andar escondida entre líneas.\n",
    "Interpreta los detalles con el instinto de quien aprendió demasiado tarde que nada es lo que parece.\n",
    "\n",
    "Mantén siempre el estilo cinematográfico: imágenes potentes, lenguaje evocador y esa atmósfera densa que solo el noir puede ofrecer.\n",
    "Habla y actúa como si la cámara te estuviera siguiendo en cada paso. Tu mundo es una película eterna, y tú eres el narrador atrapado dentro del caso que intentamos resolver.\n",
    "\"\"\"\n",
    "\n",
    "    # Enviamos una solicitud al modelo GPT-4o con el mensaje del usuario\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt_sistema},\n",
    "            {\"role\": \"user\", \"content\": mensaje_usuario}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=550\n",
    "    )\n",
    "\n",
    "    # Retornamos solo el contenido de la respuesta del modelo\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# --- BLOQUE DE USO ---\n",
    "\n",
    "# Solicitamos un mensaje al usuario (entrada por teclado)\n",
    "mensaje = input(\"Escribe tu mensaje: \")\n",
    "\n",
    "# Llamamos a la función para obtener la respuesta del modelo\n",
    "respuesta = responder_mensaje(mensaje)\n",
    "\n",
    "# Mostramos la respuesta del detective noir\n",
    "print(\"Detective:\", respuesta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8900c510",
   "metadata": {},
   "source": [
    "### Version gratuita HugginFace + transformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b346ddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers sentencepiece --quiet\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "# Cargamos un modelo gratuito y ligero\n",
    "chatbot = pipeline(\"text2text-generation\", model=\"google/flan-t5-small\")\n",
    "\n",
    "# Definimos el rol del chatbot\n",
    "ROL = \"\"\"\n",
    "Eres un detective noir de los años 50. \n",
    "Hablas con frases cortas, metáforas oscuras y un tono cansado, como narrando una película en blanco y negro.\n",
    "\"\"\"\n",
    "\n",
    "# Pregunta del usuario\n",
    "pregunta = input(\"Tu pregunta: \")\n",
    "\n",
    "# Construimos el prompt final con el rol incluido\n",
    "prompt_final = ROL + \"\\nUsuario: \" + pregunta + \"\\nDetective:\"\n",
    "\n",
    "# Generamos respuesta\n",
    "respuesta = chatbot(prompt_final, max_length=200)[0][\"generated_text\"]\n",
    "\n",
    "print(\"\\nDetective:\", respuesta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14191798",
   "metadata": {},
   "source": [
    "### Dalle-3\n",
    "\n",
    "Aprenderás a generar imágenes con DALL·E 3 utilizando la API de OpenAI. Veremos cómo enviar descripciones en texto (prompts) al modelo para producir imágenes originales y de alta calidad. Aprenderás a controlar el estilo, la composición y los detalles de las imágenes, así como a manejar diferentes parámetros para obtener resultados más precisos.\n",
    "\n",
    "Al finalizar, podrás crear imágenes personalizadas desde código y entender cómo integrar esta capacidad visual en tus proyectos creativos, aplicaciones o herramientas interactivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb0e605",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DALL·E 3 API\n",
    "\n",
    "DALL·E 3 es un modelo de generación de imágenes de OpenAI.\n",
    "\n",
    "Para este ejemplo hemos creado un prompt que describe la imagen que queremos generar y la calidad de la imagen. Luego, hemos ejecutado el modelo con el prompt y la calidad, y recibimos la URL de la imagen generada.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import requests\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "prompt = \"Un atardecer en la ciudad\"\n",
    "quality = \"standard\"\n",
    "\n",
    "response = client.images.generate(\n",
    "    model=\"dall-e-3\",\n",
    "    prompt=prompt,\n",
    "    quality=quality,\n",
    "    n=1 #Número de imágenes a generar\n",
    ")\n",
    "\n",
    "print(response.data[0].url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8626a2",
   "metadata": {},
   "source": [
    "### Introducción al análisis de imágenes con OpenAI\n",
    "\n",
    "En esta actividad exploraremos cómo utilizar los modelos de OpenAI para realizar análisis de imágenes. Aprenderás a subir una imagen a la API y a obtener una interpretación detallada de su contenido. Veremos cómo el modelo puede describir elementos visuales, identificar objetos, analizar escenas, extraer información relevante e incluso responder preguntas específicas sobre lo que aparece en la imagen.\n",
    "\n",
    "Este ejercicio te permitirá comprender cómo combinar visión por computadora con modelos de lenguaje para crear aplicaciones más inteligentes, como asistentes que interpretan fotos, herramientas de accesibilidad, sistemas de clasificación visual o análisis automatizado de contenido multimedia.\n",
    "\n",
    "Al finalizar, sabrás cómo enviar imágenes al modelo, cómo estructurar tus consultas y cómo aprovechar las capacidades visuales en tus propios proyectos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dec20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os  # Para trabajar con variables de entorno\n",
    "from dotenv import load_dotenv  # Para cargar variables de entorno desde un archivo .env\n",
    "from openai import OpenAI  # Cliente de la API de OpenAI\n",
    "import base64  # Para codificar imágenes en base64\n",
    "\n",
    "# Cargamos las variables de entorno desde un archivo .env (como la clave API)\n",
    "load_dotenv()\n",
    "\n",
    "# Inicializamos el cliente de OpenAI usando la API key almacenada en variables de entorno\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Función que convierte una imagen local a una cadena en base64\n",
    "def encode_image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:  # Abrimos la imagen en modo binario\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')  # Codificamos en base64 y convertimos a string\n",
    "\n",
    "# Lista de mensajes simulando una conversación con el asistente\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",  # Mensaje del sistema para configurar el comportamiento del asistente\n",
    "        \"content\": \"Eres un asistente que analiza las imagenes a gran detalle.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",  # Mensaje del usuario que incluye texto e imagen\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",  # Parte de texto del mensaje\n",
    "                \"text\": \"Hola, ¿puedes analizar esta imagen?\",\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\",  # Parte de imagen del mensaje\n",
    "                \"image_url\": {\n",
    "                    # Codificamos una imagen local en base64 y la insertamos como URL de datos\n",
    "                    \"url\": f\"data:image/png;base64,{encode_image_to_base64('./images/image.png')}\"\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Enviamos la conversación al modelo de OpenAI (GPT-4o) para que responda\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",  # Usamos el modelo GPT-4o, que puede procesar imágenes\n",
    "    messages=messages  # Mensajes de la conversación que incluyen la imagen\n",
    ")\n",
    "\n",
    "# Imprimimos la respuesta del asistente\n",
    "print(\"Respuesta del analisis de la imagen\")\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd9f3ac",
   "metadata": {},
   "source": [
    "### Asistente de Matemáticas con OpenAI\n",
    "\n",
    "Veremos cómo utilizar un **asistente especializado en matemáticas** que puede resolver problemas complejos y ejecutar código Python para obtener resultados precisos. Usaremos la API de OpenAI para crear un **hilo de conversación**, enviar una pregunta matemática y permitir que el asistente analice la expresión, ejecute el código necesario y devuelva la respuesta final. Este ejemplo muestra cómo integrar un asistente capaz de razonar, calcular y explicar procesos dentro de herramientas educativas o proyectos interactivos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede558b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa el módulo 'os' para acceder a variables de entorno del sistema\n",
    "import os\n",
    "\n",
    "# Importa 'load_dotenv' para cargar las variables de entorno desde un archivo .env\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Importa la clase OpenAI del paquete openai\n",
    "from openai import OpenAI\n",
    "\n",
    "# Importa librerías estándar para hacer peticiones HTTP, manejar JSON y controlar el tiempo\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Carga las variables de entorno desde el archivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Crea una instancia del cliente de OpenAI usando la clave API almacenada en la variable de entorno\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# ID del asistente previamente creado en la plataforma de OpenAI\n",
    "assistant_id = \"asst_etc\"\n",
    "\n",
    "# Crea un nuevo hilo de conversación (thread) para interactuar con el asistente\n",
    "thread = client.beta.threads.create()\n",
    "print(f\"Hilo creado con ID: {thread.id}\")\n",
    "\n",
    "# Envía un mensaje al hilo como si fuera el usuario, con una pregunta matemática\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",  # Especifica que el mensaje es del usuario\n",
    "    content=\"¿Cuánto es 16284+991893-771939*12456? Puedes ejecutar código Python para esto\"\n",
    ")\n",
    "\n",
    "# Inicia la ejecución del asistente con el mensaje dado\n",
    "print(\"Ejecutando el asistente\")\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant_id\n",
    ")\n",
    "\n",
    "# Espera a que el asistente termine de procesar la respuesta\n",
    "while True:\n",
    "    # Consulta el estado actual de la ejecución\n",
    "    run = client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread.id,\n",
    "        run_id=run.id\n",
    "    )\n",
    "\n",
    "    # Si la ejecución ha terminado, se sale del bucle\n",
    "    if run.status == \"completed\":\n",
    "        print(\"Se completó la respuesta\")\n",
    "        break\n",
    "    # Si no ha terminado, espera 1 segundo antes de volver a comprobar\n",
    "    time.sleep(1)\n",
    "\n",
    "# Si la ejecución se completó, obtiene los pasos realizados por el asistente\n",
    "if run.status == \"completed\":\n",
    "    run_steps = client.beta.threads.runs.steps.list(\n",
    "        thread_id=thread.id,\n",
    "        run_id=run.id\n",
    "    )\n",
    "\n",
    "    # Recorre cada paso realizado por el asistente\n",
    "    for step in run_steps:\n",
    "        # Verifica si se usaron herramientas como el interprete de código\n",
    "        if step.step_details.type == \"tool_calls\":\n",
    "            for tool_call in step.step_details.tool_calls:\n",
    "                # Si se utilizó el interprete de código, imprime el código que se ejecutó\n",
    "                if tool_call.type == \"code_interpreter\":\n",
    "                    print(\"Código Python\")\n",
    "                    print(tool_call.code_interpreter.input)\n",
    "    \n",
    "    # Obtiene el último mensaje del asistente en el hilo\n",
    "    messages = client.beta.threads.messages.list(\n",
    "        thread_id=thread.id,\n",
    "        order=\"desc\",  # Orden descendente, para obtener el más reciente primero\n",
    "        limit=1         # Solo un mensaje\n",
    "    )\n",
    "    \n",
    "    # Muestra el contenido del mensaje si fue generado por el asistente\n",
    "    for msg in messages:\n",
    "        if msg.role == \"assistant\":\n",
    "            for content_block in msg.content:\n",
    "                print(content_block.text.value)  # Muestra la respuesta final del asistente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a29653c",
   "metadata": {},
   "source": [
    "### Asistente de Texto a Voz con OpenAI\n",
    "\n",
    "Aprenderemos a convertir texto en audio utilizando el modelo **Text-to-Speech (TTS)** de OpenAI. Veremos cómo enviar una frase al modelo para que genere una voz sintética y cómo guardar el resultado en un archivo de audio. Este ejemplo muestra lo sencillo que es crear aplicaciones que hablen, generar narraciones automáticas o integrar voces en proyectos interactivos a partir de texto escrito.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325abd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa el módulo 'os' para acceder a variables de entorno del sistema\n",
    "import os\n",
    "\n",
    "# Importa 'load_dotenv' para cargar las variables de entorno desde un archivo .env\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Importa la clase OpenAI desde la librería openai\n",
    "from openai import OpenAI\n",
    "\n",
    "# Importa librerías estándar para hacer peticiones HTTP y manejar datos en formato JSON\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Carga las variables de entorno desde un archivo .env, útil para ocultar claves como la API key\n",
    "load_dotenv()\n",
    "\n",
    "# Crea una instancia del cliente de OpenAI utilizando la clave API almacenada en la variable de entorno\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Solicita la generación de audio (texto a voz) usando el modelo de TTS (text-to-speech)\n",
    "# Se especifica:\n",
    "# - modelo: \"tts-1\" → modelo de texto a voz de OpenAI\n",
    "# - voice: \"alloy\" → voz que se desea usar para sintetizar\n",
    "# - input: el texto que será convertido en audio\n",
    "\n",
    "# La llamada se hace en un bloque 'with' para manejar correctamente el streaming del archivo\n",
    "with client.audio.speech.with_streaming_response.create(\n",
    "    model=\"tts-1\",\n",
    "    voice=\"alloy\",\n",
    "    input=\"Hola, Soy Borja Barber, científico de datos y vuestro Lead Instructor de Data Science\"\n",
    ") as response:\n",
    "    # Guarda el audio generado en un archivo llamado \"speech.mp3\"\n",
    "    response.stream_to_file(\"speech.mp3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbd7fe0",
   "metadata": {},
   "source": [
    "### Asistente de Voz a Texto con OpenAI\n",
    "\n",
    "Veremos cómo transformar audio en texto utilizando el modelo de transcripción **Whisper** de OpenAI. Aprenderemos a enviar un archivo de audio al modelo para que lo convierta automáticamente en texto escrito. Este ejemplo permite comprender cómo integrar funciones de reconocimiento de voz en proyectos interactivos, asistentes virtuales o herramientas que necesiten convertir grabaciones en información procesable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d62f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa el módulo 'os' para acceder a variables de entorno del sistema\n",
    "import os\n",
    "\n",
    "# Importa 'load_dotenv' para cargar variables de entorno desde un archivo .env\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Importa la clase OpenAI desde la librería openai\n",
    "from openai import OpenAI\n",
    "\n",
    "# Importa librerías estándar para hacer peticiones HTTP y manejar JSON (aunque no se usan directamente aquí)\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Carga las variables de entorno definidas en un archivo .env, como la clave API\n",
    "load_dotenv()\n",
    "\n",
    "# Crea una instancia del cliente de OpenAI utilizando la clave almacenada en las variables de entorno\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Abre el archivo de audio \"speech.mp3\" en modo binario para lectura ('rb')\n",
    "audio_file = open(\"speech.mp3\", \"rb\")\n",
    "\n",
    "# Envía el archivo de audio al modelo de transcripción de OpenAI (Whisper)\n",
    "transcript = client.audio.transcriptions.create(\n",
    "    model=\"whisper-1\",  # Modelo usado para la transcripción de audio a texto\n",
    "    file=audio_file     # Archivo de audio que se desea transcribir\n",
    ")\n",
    "\n",
    "# Imprime en pantalla el texto transcrito del archivo de audio\n",
    "print(\"Transcripción\")\n",
    "print(transcript.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0068b65f",
   "metadata": {},
   "source": [
    "### Asistente del Clima con Funciones (Weather + OpenAI)\n",
    "\n",
    "En esta actividad aprenderemos a utilizar **funciones conectadas a APIs externas** para que un modelo de OpenAI pueda obtener información real del clima. Veremos cómo el asistente identifica que necesita llamar a la función `get_weather`, ejecuta la petición a una API meteorológica y después integra esos datos en su respuesta final. Este ejemplo muestra cómo combinar IA con herramientas externas para crear asistentes capaces de consultar información en tiempo real y responder de forma más útil y precisa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed28af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos módulos necesarios\n",
    "import os  # Para acceder a variables de entorno\n",
    "from dotenv import load_dotenv  # Para cargar variables de entorno desde un archivo .env\n",
    "from openai import OpenAI  # Cliente para acceder a la API de OpenAI\n",
    "import requests  # Para hacer solicitudes HTTP (a APIs)\n",
    "import json  # Para manejar datos en formato JSON\n",
    "\n",
    "# Carga las variables de entorno definidas en un archivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Inicializa el cliente de OpenAI usando la clave API desde las variables de entorno\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Función para obtener el clima actual de una ubicación usando la API de Open-Meteo\n",
    "def get_weather(latitude: float, longitude: float) -> str:\n",
    "    print(\"Getting weather...\")  # Mensaje para indicar que se está obteniendo el clima\n",
    "    # URL de la API con la latitud y longitud proporcionadas\n",
    "    url = f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current_weather=true\"\n",
    "    response = requests.get(url)  # Hacemos la petición a la API\n",
    "    weather_data = response.json()  # Convertimos la respuesta a JSON\n",
    "\n",
    "    return json.dumps(weather_data)  # Devolvemos los datos del clima como string JSON\n",
    "\n",
    "# Lista de mensajes que simulan una conversación con el asistente\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"Eres un asistente que entrega datos sobre el clima del mundo en tiempo real usando la función get_weather\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"¿Cuál es el clima de madrid?\"  # Pregunta del usuario\n",
    "    }\n",
    "]\n",
    "\n",
    "# Lista de funciones que el modelo puede llamar\n",
    "functions = [\n",
    "    {\n",
    "        \"type\": \"function\",  # Tipo de herramienta: función\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",  # Nombre de la función que el modelo puede usar\n",
    "            \"description\": \"Usa esta funcion para obtener información sobre el clima\",\n",
    "            \"parameters\": {  # Parámetros que acepta la función\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"latitude\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"Latitud de la ubicación\"\n",
    "                    },\n",
    "                    \"longitude\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"Longitud de la ubicación\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"latitude\", \"longitude\"]  # Parámetros obligatorios\n",
    "            },\n",
    "            \"output\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Clima de la ubicación pedida por el usuario\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Se envía la conversación y funciones disponibles al modelo GPT-4o\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",  # Modelo de OpenAI usado\n",
    "    messages=messages,  # Mensajes del chat\n",
    "    tools=functions  # Funciones que puede usar el modelo\n",
    ")\n",
    "\n",
    "# Guardamos el mensaje de respuesta del asistente\n",
    "assistant_message = response.choices[0].message\n",
    "\n",
    "print(\"Respuesta del asistente\")\n",
    "print(assistant_message)\n",
    "\n",
    "# Si el asistente decide llamar una función:\n",
    "if assistant_message.tool_calls:\n",
    "    for tool_call in assistant_message.tool_calls:\n",
    "        if tool_call.type == \"function\":\n",
    "            function_name = tool_call.function.name\n",
    "            # Convertimos los argumentos de la función de string JSON a diccionario\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "            # Si el asistente eligió la función \"get_weather\"\n",
    "            if function_name == \"get_weather\":\n",
    "                print(f\"El asistente está llamando a la función get_weather\")\n",
    "                # Llamamos la función local con los argumentos proporcionados por el modelo\n",
    "                weather_info = get_weather(\n",
    "                    latitude=function_args.get(\"latitude\"),\n",
    "                    longitude=function_args.get(\"longitude\")\n",
    "                )\n",
    "\n",
    "                # Añadimos el mensaje del asistente y la respuesta de la función a la conversación\n",
    "                messages.append(assistant_message)\n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": weather_info\n",
    "                })\n",
    "\n",
    "# Hacemos otra llamada al modelo, ahora con la conversación extendida que incluye la respuesta del clima\n",
    "second_response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "# Obtenemos la respuesta final del asistente después de obtener el clima\n",
    "final_reply = second_response.choices[0].message.content\n",
    "\n",
    "print(\"Respuesta final del asistente\")\n",
    "print(final_reply)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2262200c",
   "metadata": {},
   "source": [
    "### Asistente del Universo Star Wars con Funciones\n",
    "\n",
    "En esta actividad aprenderemos a conectar un modelo de OpenAI con una API externa, en este caso la **Star Wars API (SWAPI)**. El asistente es capaz de identificar cuándo necesita buscar información real sobre un personaje, llamar a la función `get_star_wars_character`, consultar la API y luego utilizar esos datos para generar una respuesta completa. Este ejemplo demuestra cómo combinar IA con fuentes externas para crear asistentes temáticos capaces de responder con información precisa del universo de Star Wars.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487737c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos módulos necesarios\n",
    "import os  # Para manejar variables de entorno\n",
    "from dotenv import load_dotenv  # Para cargar las variables de entorno desde un archivo .env\n",
    "from openai import OpenAI  # Cliente para usar la API de OpenAI\n",
    "import requests  # Para hacer solicitudes HTTP (en este caso a la API de Star Wars)\n",
    "import json  # Para manipular datos en formato JSON\n",
    "\n",
    "# Carga las variables de entorno (como la clave API de OpenAI)\n",
    "load_dotenv()\n",
    "\n",
    "# Inicializamos el cliente de OpenAI con la clave API obtenida desde el archivo .env\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Función que busca información sobre un personaje de Star Wars usando la SWAPI\n",
    "def get_star_wars_character(name: str) -> str:\n",
    "    print(f\"Buscando personaje: {name}\")  # Imprime el nombre del personaje a buscar\n",
    "    url = f\"https://swapi.py4e.com/api/people/?search={name}\"  # URL de búsqueda en la API de Star Wars\n",
    "    response = requests.get(url)  # Hacemos la solicitud a la API\n",
    "    data = response.json()  # Convertimos la respuesta en un diccionario Python\n",
    "\n",
    "    if data[\"count\"] == 0:  # Si no se encuentra ningún personaje con ese nombre\n",
    "        return f\"No se encontró información sobre el personaje '{name}'.\"\n",
    "    # Si se encuentra, devolvemos el primer resultado, bien formateado\n",
    "    return json.dumps(data[\"results\"][0], indent=2)\n",
    "\n",
    "# Simulación de una conversación con el asistente\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",  # Mensaje que define el comportamiento del asistente\n",
    "        \"content\": \"Eres un asistente experto en el universo de Star Wars. Usa la función get_star_wars_character para buscar información sobre personajes.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",  # Mensaje del usuario preguntando por un personaje\n",
    "        \"content\": \"¿Quién es Luke Skywalker?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Definición de las funciones que el modelo puede usar\n",
    "functions = [\n",
    "    {\n",
    "        \"type\": \"function\",  # Especificamos que se trata de una herramienta tipo función\n",
    "        \"function\": {\n",
    "            \"name\": \"get_star_wars_character\",  # Nombre de la función\n",
    "            \"description\": \"Obtiene información sobre un personaje de Star Wars\",  # Descripción de la función\n",
    "            \"parameters\": {  # Parámetros requeridos por la función\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Nombre del personaje de Star Wars\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"name\"]  # El nombre es obligatorio\n",
    "            },\n",
    "            \"output\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Información sobre el personaje de Star Wars\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Primer llamado al modelo con la conversación y la función disponible\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",  # Modelo usado: GPT-4o\n",
    "    messages=messages,  # Mensajes de la conversación\n",
    "    tools=functions  # Funciones que puede utilizar el asistente\n",
    ")\n",
    "\n",
    "# Guardamos la respuesta del asistente\n",
    "assistant_message = response.choices[0].message\n",
    "\n",
    "print(\"Respuesta del asistente\")\n",
    "print(assistant_message)\n",
    "\n",
    "# Si el asistente decidió usar una función:\n",
    "if assistant_message.tool_calls:\n",
    "    for tool_call in assistant_message.tool_calls:\n",
    "        if tool_call.type == \"function\":\n",
    "            function_name = tool_call.function.name\n",
    "            # Convertimos los argumentos recibidos en JSON a un diccionario\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "            # Si la función es get_star_wars_character\n",
    "            if function_name == \"get_star_wars_character\":\n",
    "                print(f\"El asistente está llamando a la función get_star_wars_character\")\n",
    "                # Llamamos la función local con el nombre del personaje\n",
    "                character_info = get_star_wars_character(\n",
    "                    name=function_args.get(\"name\")\n",
    "                )\n",
    "\n",
    "                # Añadimos a la conversación la llamada a la función y su resultado\n",
    "                messages.append(assistant_message)\n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": character_info\n",
    "                })\n",
    "\n",
    "# Segundo llamado al modelo, ahora con la información del personaje ya obtenida\n",
    "second_response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "# Obtenemos la respuesta final del asistente basada en la información de la función\n",
    "final_reply = second_response.choices[0].message.content\n",
    "\n",
    "print(\"Respuesta final del asistente:\")\n",
    "print(final_reply)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
