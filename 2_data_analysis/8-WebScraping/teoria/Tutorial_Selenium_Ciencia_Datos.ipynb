{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selenium para Ciencia de Datos\n",
    "\n",
    "#### Borja Barber Lead Instructor DS\n",
    "\n",
    "##  Índice\n",
    "1. [Introducción](#introduccion)\n",
    "2. [Instalación y Configuración](#instalacion)\n",
    "3. [Conceptos Básicos](#conceptos-basicos)\n",
    "4. [Navegación Web](#navegacion)\n",
    "5. [Localización de Elementos](#localizacion)\n",
    "6. [Extracción de Datos](#extraccion)\n",
    "7. [Web Scraping Avanzado](#scraping-avanzado)\n",
    "8. [Caso Práctico Completo](#caso-practico)\n",
    "9. [Mejores Prácticas](#mejores-practicas)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción <a name=\"introduccion\"></a>\n",
    "\n",
    "### ¿Qué es Selenium?\n",
    "\n",
    "Selenium es una herramienta de automatización de navegadores web que permite:\n",
    "- **Automatizar** interacciones con páginas web\n",
    "- **Extraer datos** de sitios web dinámicos (JavaScript)\n",
    "- **Simular** comportamiento humano (clicks, scroll, formularios)\n",
    "- **Recopilar datos** para análisis y ciencia de datos\n",
    "\n",
    "### ¿Por qué usar Selenium en Ciencia de Datos?\n",
    "\n",
    "- Muchas páginas web modernas cargan datos con JavaScript (AJAX)\n",
    "- BeautifulSoup y requests no pueden ejecutar JavaScript\n",
    "- Selenium permite acceder a datos que se cargan dinámicamente\n",
    "- Ideal para crear datasets personalizados mediante web scraping\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Instalación y Configuración <a name=\"instalacion\"></a>\n",
    "\n",
    "### Paso 1: Instalar Selenium\n",
    "\n",
    "Ejecuta el siguiente comando para instalar Selenium:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELDA 1: INSTALACIÓN DE SELENIUM\n",
    "# ========================================\n",
    "\n",
    "# El símbolo ! ejecuta comandos del sistema operativo desde Jupyter\n",
    "# pip es el gestor de paquetes de Python que instala librerías\n",
    "\n",
    "# Instalar Selenium - La librería principal para automatizar navegadores\n",
    "# Selenium permite controlar Chrome, Firefox, Safari, etc. mediante código Python\n",
    "!pip install selenium\n",
    "\n",
    "# Instalar Pandas - Para manipular y analizar datos en formato tabular (DataFrames)\n",
    "# Pandas es esencial en ciencia de datos para trabajar con datos estructurados\n",
    "!pip install pandas\n",
    "\n",
    "# Instalar NumPy - Para operaciones numéricas y arrays\n",
    "# NumPy es la base del ecosistema científico de Python\n",
    "!pip install numpy\n",
    "\n",
    "# NOTA PEDAGÓGICA:\n",
    "# Estas instalaciones solo necesitan ejecutarse UNA VEZ en tu entorno.\n",
    "# Si ya las tienes instaladas, verás un mensaje indicando que ya existen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 2: Instalar WebDriver Manager\n",
    "\n",
    "WebDriver Manager descarga automáticamente el driver del navegador:\n",
    "\n",
    "**⚠️ NOTA IMPORTANTE SOBRE SELECTORES:**\n",
    "Los sitios web cambian frecuentemente su estructura HTML. Si encuentras errores como `NoSuchElementException`, significa que el selector CSS o XPath ya no es válido. En el tutorial aprenderás cómo:\n",
    "- Usar try-except para manejar estos casos\n",
    "- Tener selectores alternativos como plan B\n",
    "- Verificar selectores usando las DevTools del navegador (F12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELDA 2: INSTALACIÓN DE WEBDRIVER MANAGER\n",
    "# ========================================\n",
    "\n",
    "# WebDriver Manager es una herramienta que SIMPLIFICA enormemente trabajar con Selenium\n",
    "# \n",
    "# ¿QUÉ PROBLEMA RESUELVE?\n",
    "# Antes, tenías que:\n",
    "# 1. Descargar manualmente el driver del navegador (chromedriver.exe)\n",
    "# 2. Colocarlo en una ruta específica\n",
    "# 3. Actualizar manualmente cada vez que el navegador se actualiza\n",
    "#\n",
    "# WebDriver Manager hace todo esto AUTOMÁTICAMENTE por ti\n",
    "# Detecta tu navegador, descarga el driver correcto y lo gestiona\n",
    "\n",
    "!pip install webdriver-manager\n",
    "\n",
    "# VENTAJAS PARA CIENCIA DE DATOS:\n",
    "# - Código portable: funciona en cualquier máquina sin configuración manual\n",
    "# - Siempre actualizado: descarga la versión compatible con tu navegador\n",
    "# - Menos errores: evita problemas de incompatibilidad de versiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 3: Importar librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELDA 3: IMPORTAR LIBRERÍAS NECESARIAS\n",
    "# ========================================\n",
    "\n",
    "# --- IMPORTACIONES DE SELENIUM ---\n",
    "\n",
    "# webdriver: El módulo principal que controla el navegador\n",
    "from selenium import webdriver\n",
    "\n",
    "# By: Clase que define CÓMO buscar elementos en la página\n",
    "# Ejemplo: By.ID, By.CSS_SELECTOR, By.XPATH, etc.\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Keys: Simula teclas del teclado (Enter, Tab, flechas, etc.)\n",
    "# Útil para enviar formularios o navegar con teclado\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "# WebDriverWait: Implementa ESPERAS INTELIGENTES\n",
    "# Espera hasta que se cumpla una condición (elemento visible, clickeable, etc.)\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "# expected_conditions (EC): Condiciones predefinidas para usar con WebDriverWait\n",
    "# Ejemplo: element_to_be_clickable, presence_of_element_located, etc.\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Service: Maneja el servicio del driver del navegador\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "# ChromeDriverManager: Descarga y configura automáticamente el driver de Chrome\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# --- IMPORTACIONES PARA CIENCIA DE DATOS ---\n",
    "\n",
    "# pandas: Manipulación de datos en formato tabular (DataFrames)\n",
    "# Lo usaremos para almacenar y procesar los datos scrapeados\n",
    "import pandas as pd\n",
    "\n",
    "# numpy: Operaciones numéricas y arrays\n",
    "# Complementa pandas para análisis numérico\n",
    "import numpy as np\n",
    "\n",
    "# time: Control de tiempos y pausas\n",
    "# Útil para dar tiempo a que las páginas carguen completamente\n",
    "import time\n",
    "\n",
    "print(\"Todas las librerías importadas correctamente\")\n",
    "\n",
    "# CONSEJO PEDAGÓGICO:\n",
    "# Si alguna importación falla, significa que la librería no está instalada.\n",
    "# Vuelve a las celdas anteriores y ejecuta los pip install correspondientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Conceptos Básicos <a name=\"conceptos-basicos\"></a>\n",
    "\n",
    "### 3.1 Inicializar el navegador\n",
    "\n",
    "El primer paso es crear una instancia del navegador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELDA 4: INICIALIZAR EL NAVEGADOR CHROME\n",
    "# ========================================\n",
    "\n",
    "# PASO 1: Configurar las opciones de Chrome\n",
    "# ChromeOptions() permite personalizar cómo se ejecuta el navegador\n",
    "options = webdriver.ChromeOptions()\n",
    "\n",
    "# OPCIÓN 1: Modo headless (sin interfaz gráfica)\n",
    "# Descomenta la siguiente línea si quieres que el navegador se ejecute en segundo plano\n",
    "# Útil para servidores o cuando no necesitas ver el navegador\n",
    "# options.add_argument('--headless')\n",
    "\n",
    "# OPCIÓN 2: Desactivar detección de automatización\n",
    "# Algunos sitios detectan que Selenium está controlando el navegador\n",
    "# Esta opción ayuda a que el navegador parezca \"normal\"\n",
    "options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "\n",
    "# OPCIÓN 3: Iniciar maximizado\n",
    "# Abre el navegador en pantalla completa\n",
    "# Útil para asegurar que todos los elementos sean visibles\n",
    "options.add_argument('--start-maximized')\n",
    "\n",
    "# PASO 2: Inicializar el driver (el controlador del navegador)\n",
    "# Esto ABRE el navegador Chrome y te da control sobre él\n",
    "driver = webdriver.Chrome(\n",
    "    # Service: Configura el servicio del driver\n",
    "    # ChromeDriverManager().install(): Descarga automáticamente el driver correcto\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    \n",
    "    # Aplica las opciones que configuramos arriba\n",
    "    options=options\n",
    ")\n",
    "\n",
    "print(\"✅ Navegador Chrome iniciado correctamente\")\n",
    "\n",
    "# QUÉ ESTÁ PASANDO EN SEGUNDO PLANO:\n",
    "# 1. ChromeDriverManager verifica tu versión de Chrome\n",
    "# 2. Descarga el chromedriver compatible (si no lo tiene)\n",
    "# 3. Chrome se abre y queda bajo control de Python\n",
    "# 4. Ahora puedes enviar comandos al navegador usando 'driver'\n",
    "\n",
    "# IMPORTANTE PARA LA CLASE:\n",
    "# - 'driver' es tu ROBOT que controla el navegador\n",
    "# - Todo lo que hagas con Selenium usa este objeto 'driver'\n",
    "# - Ejemplo: driver.get(), driver.find_element(), etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Abrir una página web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELDA 5: NAVEGAR A UNA PÁGINA WEB\n",
    "# ========================================\n",
    "\n",
    "# PASO 1: Definir la URL que queremos visitar\n",
    "# En este caso, vamos a Wikipedia (sitio perfecto para practicar web scraping)\n",
    "url = \"https://www.wikipedia.org\"\n",
    "\n",
    "# PASO 2: Usar driver.get() para navegar a la URL\n",
    "# Esto es equivalente a escribir la URL en la barra de direcciones y presionar Enter\n",
    "driver.get(url)\n",
    "\n",
    "# QUÉ HACE driver.get():\n",
    "# 1. Navega a la URL especificada\n",
    "# 2. Espera a que la página cargue completamente (carga inicial del HTML)\n",
    "# 3. Devuelve el control una vez cargada\n",
    "\n",
    "# PASO 3: Obtener el título de la página\n",
    "# La propiedad driver.title devuelve el contenido de la etiqueta <title> del HTML\n",
    "# Esto es útil para verificar que estamos en la página correcta\n",
    "print(f\"Título de la página: {driver.title}\")\n",
    "\n",
    "# PASO 4: Obtener la URL actual\n",
    "# driver.current_url devuelve la URL en la que estamos ahora\n",
    "# Puede ser diferente a la URL original si hubo redirecciones\n",
    "print(f\"URL actual: {driver.current_url}\")\n",
    "\n",
    "# APLICACIÓN EN CIENCIA DE DATOS:\n",
    "# Verificar el título y URL nos ayuda a:\n",
    "# - Confirmar que la navegación fue exitosa\n",
    "# - Detectar redirecciones inesperadas\n",
    "# - Validar que estamos en la página correcta antes de extraer datos\n",
    "# - Debugging: si algo falla, sabemos dónde estamos realmente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Cerrar el navegador\n",
    "\n",
    "**Importante:** Siempre cierra el navegador al terminar para liberar recursos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cerrar la pestaña actual\n",
    "# driver.close()\n",
    "\n",
    "# Cerrar el navegador completamente\n",
    "# driver.quit()\n",
    "\n",
    "print(\"💡 No ejecutes esto aún, lo usaremos al final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Navegación Web <a name=\"navegacion\"></a>\n",
    "\n",
    "### 4.1 Operaciones básicas de navegación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reiniciar el driver si es necesario\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=options\n",
    ")\n",
    "\n",
    "# Navegar a diferentes páginas\n",
    "driver.get(\"https://www.wikipedia.org\")\n",
    "time.sleep(2)\n",
    "\n",
    "driver.get(\"https://www.python.org\")\n",
    "time.sleep(2)\n",
    "\n",
    "# Retroceder\n",
    "driver.back()\n",
    "time.sleep(1)\n",
    "print(f\"Después de retroceder: {driver.title}\")\n",
    "\n",
    "# Avanzar\n",
    "driver.forward()\n",
    "time.sleep(1)\n",
    "print(f\"Después de avanzar: {driver.title}\")\n",
    "\n",
    "# Refrescar la página\n",
    "driver.refresh()\n",
    "print(\"Página refrescada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Capturas de pantalla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomar una captura de pantalla\n",
    "driver.get(\"https://www.wikipedia.org\")\n",
    "time.sleep(2)\n",
    "\n",
    "driver.save_screenshot(\"captura_wikipedia.png\")\n",
    "print(\"✅ Captura de pantalla guardada como 'captura_wikipedia.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Localización de Elementos <a name=\"localizacion\"></a>\n",
    "\n",
    "### 5.1 Métodos de localización\n",
    "\n",
    "Selenium ofrece varias formas de encontrar elementos en una página:\n",
    "\n",
    "| Método | Descripción | Ejemplo |\n",
    "|--------|-------------|----------|\n",
    "| `By.ID` | Por el atributo id | `driver.find_element(By.ID, \"search\")` |\n",
    "| `By.NAME` | Por el atributo name | `driver.find_element(By.NAME, \"q\")` |\n",
    "| `By.CLASS_NAME` | Por la clase CSS | `driver.find_element(By.CLASS_NAME, \"btn\")` |\n",
    "| `By.TAG_NAME` | Por la etiqueta HTML | `driver.find_element(By.TAG_NAME, \"h1\")` |\n",
    "| `By.CSS_SELECTOR` | Por selector CSS | `driver.find_element(By.CSS_SELECTOR, \"div.container\")` |\n",
    "| `By.XPATH` | Por expresión XPath | `driver.find_element(By.XPATH, \"//div[@id='content']\")` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Ejemplos prácticos de localización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELDA 6: LOCALIZAR ELEMENTOS EN LA PÁGINA\n",
    "# ========================================\n",
    "\n",
    "# CONTEXTO: Estamos en la página principal de Wikipedia\n",
    "# Ahora vamos a aprender a ENCONTRAR elementos específicos en la página\n",
    "\n",
    "# Navegar a Wikipedia\n",
    "driver.get(\"https://www.wikipedia.org\")\n",
    "time.sleep(2)  # Pausa de 2 segundos para asegurar que la página cargó\n",
    "\n",
    "# --- EJEMPLO 1: Localizar por ID ---\n",
    "# El ID es único en toda la página, es la forma MÁS RÁPIDA y CONFIABLE\n",
    "# Equivale a: document.getElementById(\"searchInput\") en JavaScript\n",
    "\n",
    "search_box = driver.find_element(By.ID, \"searchInput\")\n",
    "print(f\"✅ Caja de búsqueda encontrada: {search_box.tag_name}\")\n",
    "\n",
    "# EXPLICACIÓN:\n",
    "# - find_element() busca UN SOLO elemento (el primero que encuentre)\n",
    "# - By.ID indica que buscaremos por el atributo 'id' del HTML\n",
    "# - \"searchInput\" es el valor del id que buscamos: <input id=\"searchInput\">\n",
    "# - tag_name nos dice qué tipo de elemento HTML es (probablemente 'input')\n",
    "\n",
    "\n",
    "# --- EJEMPLO 2: Localizar por CSS Selector ---\n",
    "# Los selectores CSS son muy potentes y flexibles\n",
    "# Si conoces CSS, este método te resultará familiar\n",
    "\n",
    "try:\n",
    "    # Intentar varios selectores que Wikipedia usa\n",
    "    logo = driver.find_element(By.CSS_SELECTOR, \".central-featured\")\n",
    "    print(f\"✅ Sección central encontrada\")\n",
    "except:\n",
    "    print(\"⚠️ Selector específico no encontrado (la estructura puede variar)\")\n",
    "\n",
    "# EXPLICACIÓN:\n",
    "# - \".central-featured\" busca elementos con la clase CSS \"central-featured\"\n",
    "# - El punto (.) indica que es una clase\n",
    "# - CSS Selector puede ser muy específico: \"div.clase #id > p\"\n",
    "# - IMPORTANTE: Los selectores pueden cambiar si el sitio actualiza su diseño\n",
    "\n",
    "\n",
    "# --- EJEMPLO 3: Localizar MÚLTIPLES elementos ---\n",
    "# find_elements() (plural) encuentra TODOS los elementos que coinciden\n",
    "\n",
    "# Buscar todos los enlaces en la página principal\n",
    "language_links = driver.find_elements(By.CSS_SELECTOR, \"a.link-box\")\n",
    "if len(language_links) > 0:\n",
    "    print(f\"✅ Se encontraron {len(language_links)} enlaces de idiomas\")\n",
    "else:\n",
    "    # Plan B: buscar todos los enlaces en general\n",
    "    all_links = driver.find_elements(By.TAG_NAME, \"a\")\n",
    "    print(f\"✅ Se encontraron {len(all_links)} enlaces en total en la página\")\n",
    "\n",
    "# DIFERENCIA CLAVE:\n",
    "# - find_element()  -> Devuelve 1 elemento (o error si no existe)\n",
    "# - find_elements() -> Devuelve una LISTA de elementos (puede ser vacía)\n",
    "\n",
    "# APLICACIÓN EN CIENCIA DE DATOS:\n",
    "# - Usar find_elements() para extraer múltiples productos, artículos, precios, etc.\n",
    "# - Luego iterar sobre la lista para procesar cada elemento\n",
    "# - Ejemplo: extraer todos los títulos de noticias, todos los precios de productos\n",
    "\n",
    "# CONSEJO PEDAGÓGICO:\n",
    "# Para encontrar el selector correcto:\n",
    "# 1. Abre las DevTools del navegador (F12)\n",
    "# 2. Click en el inspector de elementos (icono de flecha)\n",
    "# 3. Click en el elemento que quieres\n",
    "# 4. Click derecho en el HTML -> Copy -> Copy selector\n",
    "\n",
    "# IMPORTANTE: Siempre usa try-except cuando busques elementos específicos\n",
    "# porque los sitios web cambian frecuentemente su estructura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Interactuar con elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELDA 7: INTERACTUAR CON ELEMENTOS (ESCRIBIR)\n",
    "# ========================================\n",
    "\n",
    "# Una vez que ENCONTRAMOS un elemento, podemos INTERACTUAR con él\n",
    "# Las interacciones más comunes son: escribir texto, hacer click, enviar formularios\n",
    "\n",
    "# PASO 1: Localizar el campo de búsqueda\n",
    "search_box = driver.find_element(By.ID, \"searchInput\")\n",
    "\n",
    "# PASO 2: Limpiar el campo (por si tiene texto previo)\n",
    "search_box.clear()\n",
    "# clear() vacía completamente el campo de texto\n",
    "# Buena práctica: siempre limpiar antes de escribir\n",
    "\n",
    "# PASO 3: Escribir texto en el campo\n",
    "search_box.send_keys(\"Python programming\")\n",
    "print(\"✅ Texto ingresado en la búsqueda\")\n",
    "\n",
    "# EXPLICACIÓN de send_keys():\n",
    "# - Simula que un usuario escribe en el teclado\n",
    "# - Escribe carácter por carácter (como un humano)\n",
    "# - Puede recibir texto normal o teclas especiales (Keys.ENTER, Keys.TAB, etc.)\n",
    "# - Es más realista que simplemente cambiar el valor del campo\n",
    "\n",
    "\n",
    "# PASO 4: Enviar el formulario presionando Enter\n",
    "search_box.send_keys(Keys.RETURN)\n",
    "# Keys.RETURN simula presionar la tecla Enter\n",
    "# Esto envía el formulario de búsqueda\n",
    "\n",
    "time.sleep(3)  # Esperar 3 segundos para que cargue la página de resultados\n",
    "\n",
    "print(f\"Navegado a: {driver.title}\")\n",
    "\n",
    "# ALTERNATIVAS para enviar formularios:\n",
    "# 1. send_keys(Keys.RETURN) - Presionar Enter (lo que usamos aquí)\n",
    "# 2. elemento.submit() - Enviar el formulario directamente\n",
    "# 3. Hacer click en el botón de búsqueda\n",
    "\n",
    "# APLICACIÓN EN CIENCIA DE DATOS:\n",
    "# - Automatizar búsquedas: buscar múltiples términos y recopilar resultados\n",
    "# - Rellenar formularios: extraer datos de sitios que requieren login\n",
    "# - Filtrar datos: seleccionar fechas, categorías, etc. antes de extraer\n",
    "# \n",
    "# EJEMPLO DE USO REAL:\n",
    "# for termino in [\"Python\", \"Machine Learning\", \"Data Science\"]:\n",
    "#     search_box.clear()\n",
    "#     search_box.send_keys(termino)\n",
    "#     search_box.send_keys(Keys.RETURN)\n",
    "#     # ... extraer resultados ...\n",
    "#     # ... guardar en DataFrame ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Hacer click en elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresar a la página principal\n",
    "driver.get(\"https://www.wikipedia.org\")\n",
    "time.sleep(2)\n",
    "\n",
    "# Encontrar y hacer click en el enlace de español\n",
    "try:\n",
    "    # Método 1: Intentar por ID específico\n",
    "    spanish_link = driver.find_element(By.XPATH, \"//a[@id='js-link-box-es']\")\n",
    "    spanish_link.click()\n",
    "    time.sleep(2)\n",
    "    print(f\"✅ Click exitoso. Ahora en: {driver.title}\")\n",
    "except:\n",
    "    try:\n",
    "        # Método 2: Buscar el enlace que contiene \"Español\"\n",
    "        spanish_link = driver.find_element(By.XPATH, \"//a[contains(@href, 'es.wikipedia.org')]\")\n",
    "        spanish_link.click()\n",
    "        time.sleep(2)\n",
    "        print(f\"✅ Click exitoso usando método alternativo. Ahora en: {driver.title}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ No se pudo hacer click en el enlace: {e}\")\n",
    "        print(\"Esto puede pasar si Wikipedia cambió su estructura HTML\")\n",
    "\n",
    "# EXPLICACIÓN DE LOS MÉTODOS:\n",
    "# Método 1: Busca por ID exacto (más específico pero puede cambiar)\n",
    "# Método 2: Busca cualquier enlace que contenga 'es.wikipedia.org' (más flexible)\n",
    "#\n",
    "# LECCIÓN IMPORTANTE:\n",
    "# Siempre ten un Plan B cuando trabajes con selectores\n",
    "# Los sitios web actualizan su código HTML frecuentemente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Extracción de Datos <a name=\"extraccion\"></a>\n",
    "\n",
    "### 6.1 Extraer texto de elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navegar a la Wikipedia en español\n",
    "driver.get(\"https://es.wikipedia.org\")\n",
    "time.sleep(2)\n",
    "\n",
    "# Extraer el título principal\n",
    "try:\n",
    "    # Intentar método 1: por clase específica\n",
    "    titulo = driver.find_element(By.CSS_SELECTOR, \"img.central-featured-logo\")\n",
    "    print(f\"Título (alt text): {titulo.get_attribute('alt')}\")\n",
    "except:\n",
    "    try:\n",
    "        # Método 2: por el título de la página\n",
    "        print(f\"Título de la página: {driver.title}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error al extraer título: {e}\")\n",
    "\n",
    "# Extraer artículos destacados\n",
    "# NOTA: La estructura de Wikipedia cambia, usaremos selectores más genéricos\n",
    "try:\n",
    "    # Buscar en la sección de artículo destacado\n",
    "    featured_section = driver.find_element(By.ID, \"mp-tfa\")\n",
    "    # Buscar enlaces dentro de esa sección\n",
    "    featured_articles = featured_section.find_elements(By.TAG_NAME, \"a\")\n",
    "    \n",
    "    print(\"\\n📰 Enlaces en artículo destacado:\")\n",
    "    for article in featured_articles[:3]:  # Primeros 3 enlaces\n",
    "        if article.text.strip():  # Solo mostrar si tiene texto\n",
    "            print(f\"  - {article.text}\")\n",
    "except:\n",
    "    print(\"\\n⚠️ No se encontró la sección de artículos destacados\")\n",
    "    print(\"Esto es normal: Wikipedia cambia su estructura frecuentemente\")\n",
    "\n",
    "# LECCIÓN IMPORTANTE PARA LA CLASE:\n",
    "# En web scraping real, SIEMPRE debes:\n",
    "# 1. Usar try-except para manejar cambios en la estructura\n",
    "# 2. Tener métodos alternativos de extracción\n",
    "# 3. Verificar periódicamente que tus scrapers sigan funcionando\n",
    "# 4. Usar selectores lo más genéricos posible (cuando sea apropiado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Extraer atributos de elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# EXTRAER ENLACES Y ATRIBUTOS\n",
    "# ========================================\n",
    "\n",
    "# Buscar enlaces en la sección principal de Wikipedia\n",
    "try:\n",
    "    # Buscar en la sección de artículo destacado\n",
    "    tfa_section = driver.find_element(By.ID, \"mp-tfa\")\n",
    "    links = tfa_section.find_elements(By.TAG_NAME, \"a\")\n",
    "except:\n",
    "    # Si no encuentra esa sección, buscar en toda la página\n",
    "    links = driver.find_elements(By.CSS_SELECTOR, \"#content a\")\n",
    "\n",
    "print(\"🔗 Enlaces encontrados:\")\n",
    "\n",
    "# Contador para limitar la salida\n",
    "count = 0\n",
    "for link in links:\n",
    "    texto = link.text.strip()\n",
    "    url = link.get_attribute(\"href\")\n",
    "    \n",
    "    # Solo mostrar enlaces con texto y URL válida\n",
    "    if texto and url and count < 5:  # Limitar a 5 para no saturar la salida\n",
    "        print(f\"  Texto: {texto}\")\n",
    "        print(f\"  URL: {url}\\n\")\n",
    "        count += 1\n",
    "\n",
    "if count == 0:\n",
    "    print(\"  ⚠️ No se encontraron enlaces con texto en esta sección\")\n",
    "\n",
    "# CONCEPTOS CLAVE:\n",
    "# - .text -> Obtiene el TEXTO VISIBLE del elemento\n",
    "# - .get_attribute(\"href\") -> Obtiene el ATRIBUTO href (la URL del enlace)\n",
    "# - Otros atributos útiles: \"class\", \"id\", \"src\" (para imágenes), \"value\" (para inputs)\n",
    "\n",
    "# APLICACIÓN EN CIENCIA DE DATOS:\n",
    "# Extraer:\n",
    "# - URLs de productos para visitar después\n",
    "# - Precios de elementos (get_attribute(\"data-price\"))\n",
    "# - IDs únicos para seguimiento\n",
    "# - Clases CSS para categorización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Esperas explícitas (muy importante)\n",
    "\n",
    "Las esperas explícitas son cruciales para trabajar con contenido dinámico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELDA 8: ESPERAS EXPLÍCITAS (MUY IMPORTANTE)\n",
    "# ========================================\n",
    "\n",
    "# ⚠️ PROBLEMA CON time.sleep():\n",
    "# - time.sleep(5) siempre espera 5 segundos, aunque la página cargue en 1 segundo\n",
    "# - Si la página tarda más de 5 segundos, el código fallará\n",
    "# - Es INEFICIENTE y NO CONFIABLE\n",
    "\n",
    "# ✅ SOLUCIÓN: ESPERAS EXPLÍCITAS (WebDriverWait)\n",
    "# - Espera SOLO hasta que se cumpla una condición\n",
    "# - Si la condición se cumple antes, continúa inmediatamente\n",
    "# - Si no se cumple en el tiempo límite, lanza una excepción\n",
    "# - Es EFICIENTE y CONFIABLE\n",
    "\n",
    "driver.get(\"https://es.wikipedia.org\")\n",
    "\n",
    "try:\n",
    "    # EJEMPLO 1: Esperar hasta que un elemento EXISTA en el DOM\n",
    "    # WebDriverWait(driver, 10) -> Espera MÁXIMO 10 segundos\n",
    "    # until() -> Espera hasta que la condición sea True\n",
    "    # presence_of_element_located -> El elemento existe en el HTML\n",
    "    \n",
    "    search_input = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.ID, \"searchInput\"))\n",
    "    )\n",
    "    print(\"✅ Elemento de búsqueda encontrado con espera explícita\")\n",
    "    \n",
    "    # QUÉ HACE ESTO:\n",
    "    # 1. Busca el elemento cada 0.5 segundos (por defecto)\n",
    "    # 2. Si lo encuentra, devuelve el elemento inmediatamente\n",
    "    # 3. Si pasan 10 segundos y no lo encuentra, lanza TimeoutException\n",
    "    \n",
    "    \n",
    "    # EJEMPLO 2: Esperar hasta que un elemento sea CLICKEABLE\n",
    "    # element_to_be_clickable verifica que:\n",
    "    # - El elemento existe\n",
    "    # - Es visible\n",
    "    # - Está habilitado (no disabled)\n",
    "    \n",
    "    search_button = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.CSS_SELECTOR, \"button[type='submit']\"))\n",
    "    )\n",
    "    print(\"✅ Botón de búsqueda es clickeable\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error en espera: {e}\")\n",
    "\n",
    "# OTRAS CONDICIONES ÚTILES:\n",
    "# - visibility_of_element_located: Elemento visible (no oculto con CSS)\n",
    "# - invisibility_of_element_located: Elemento NO visible\n",
    "# - text_to_be_present_in_element: Texto específico presente\n",
    "# - element_to_be_selected: Checkbox/radio seleccionado\n",
    "# - staleness_of: Elemento ya no está en el DOM\n",
    "\n",
    "# POR QUÉ ES CRUCIAL EN CIENCIA DE DATOS:\n",
    "# - Sitios modernos cargan datos con JavaScript (AJAX)\n",
    "# - Los datos pueden tardar tiempo en aparecer\n",
    "# - Sin esperas explícitas, extraerás datos incompletos o vacíos\n",
    "# - Las esperas explícitas garantizan que los datos estén listos\n",
    "\n",
    "# REGLA DE ORO:\n",
    "# ❌ NO uses time.sleep() para esperar elementos\n",
    "# ✅ USA WebDriverWait con expected_conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Web Scraping Avanzado <a name=\"scraping-avanzado\"></a>\n",
    "\n",
    "### 7.1 Scroll en la página\n",
    "\n",
    "Muchas páginas cargan contenido al hacer scroll:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navegar a una página\n",
    "# Abre la URL de Wikipedia sobre Python en el navegador controlado por Selenium\n",
    "driver.get(\"https://es.wikipedia.org/wiki/Python\")\n",
    "# Pausa la ejecución durante 2 segundos para permitir que la página cargue completamente\n",
    "time.sleep(2)\n",
    "\n",
    "# Scroll hacia abajo\n",
    "# Ejecuta código JavaScript que desplaza la ventana hasta el final de la página\n",
    "# scrollHeight obtiene la altura total del documento\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "# Espera 1 segundo después del desplazamiento\n",
    "time.sleep(1)\n",
    "print(\"✅ Scroll hacia abajo completado\")\n",
    "\n",
    "# Scroll hacia arriba\n",
    "# Ejecuta JavaScript para volver al inicio de la página (posición 0,0)\n",
    "driver.execute_script(\"window.scrollTo(0, 0);\")\n",
    "# Pausa de 1 segundo para visualizar el movimiento\n",
    "time.sleep(1)\n",
    "print(\"✅ Scroll hacia arriba completado\")\n",
    "\n",
    "# Scroll a un elemento específico\n",
    "try:\n",
    "    # Intenta localizar un elemento HTML con el ID \"Historia\"\n",
    "    elemento = driver.find_element(By.ID, \"Historia\")\n",
    "    # Ejecuta JavaScript para hacer scroll hasta que el elemento sea visible\n",
    "    # scrollIntoView(true) alinea el elemento en la parte superior de la ventana\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView(true);\", elemento)\n",
    "    # Espera 1 segundo después del desplazamiento\n",
    "    time.sleep(1)\n",
    "    print(\"✅ Scroll a elemento específico completado\")\n",
    "except:\n",
    "    # Si el elemento no existe o hay algún error, muestra este mensaje\n",
    "    print(\"Elemento no encontrado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Manejar múltiples pestañas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrir una nueva pestaña\n",
    "driver.execute_script(\"window.open('https://www.python.org', '_blank');\")\n",
    "time.sleep(2)\n",
    "\n",
    "# Obtener todas las pestañas\n",
    "tabs = driver.window_handles\n",
    "print(f\"Número de pestañas abiertas: {len(tabs)}\")\n",
    "\n",
    "# Cambiar a la segunda pestaña\n",
    "driver.switch_to.window(tabs[1])\n",
    "print(f\"Pestaña activa: {driver.title}\")\n",
    "time.sleep(2)\n",
    "\n",
    "# Volver a la primera pestaña\n",
    "driver.switch_to.window(tabs[0])\n",
    "print(f\"Pestaña activa: {driver.title}\")\n",
    "\n",
    "# Cerrar la segunda pestaña\n",
    "driver.switch_to.window(tabs[1])\n",
    "driver.close()\n",
    "driver.switch_to.window(tabs[0])\n",
    "print(\"✅ Segunda pestaña cerrada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Extraer tablas HTML a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELDA 9: EXTRAER TABLAS HTML A DATAFRAME\n",
    "# ========================================\n",
    "\n",
    "# 🎯 OBJETIVO: Convertir una tabla HTML en un DataFrame de pandas\n",
    "# Esto es FUNDAMENTAL en ciencia de datos porque muchos datos están en tablas web\n",
    "\n",
    "# PASO 1: Navegar a una página con tablas\n",
    "driver.get(\"https://es.wikipedia.org/wiki/Anexo:Pa%C3%ADses_por_poblaci%C3%B3n\")\n",
    "time.sleep(3)  # Dar tiempo a que cargue la tabla\n",
    "\n",
    "try:\n",
    "    # PASO 2: Localizar la tabla usando CSS Selector\n",
    "    # \"table.wikitable\" busca una tabla con la clase \"wikitable\"\n",
    "    tabla = driver.find_element(By.CSS_SELECTOR, \"table.wikitable\")\n",
    "    \n",
    "    # PASO 3: Extraer los ENCABEZADOS de la tabla\n",
    "    encabezados = []\n",
    "    # Las etiquetas <th> contienen los encabezados de las columnas\n",
    "    headers = tabla.find_elements(By.TAG_NAME, \"th\")\n",
    "    \n",
    "    for header in headers[:5]:  # Solo los primeros 5 encabezados\n",
    "        # .strip() elimina espacios en blanco al inicio y final\n",
    "        encabezados.append(header.text.strip())\n",
    "    \n",
    "    # QUÉ HICIMOS:\n",
    "    # - Encontramos todos los <th> dentro de la tabla\n",
    "    # - Extraemos el texto de cada uno\n",
    "    # - Los guardamos en una lista que será el header del DataFrame\n",
    "    \n",
    "    \n",
    "    # PASO 4: Extraer las FILAS de datos\n",
    "    filas = []\n",
    "    # Las etiquetas <tr> representan filas (table row)\n",
    "    rows = tabla.find_elements(By.TAG_NAME, \"tr\")\n",
    "    \n",
    "    # Iteramos sobre las filas (saltamos la primera que son encabezados)\n",
    "    for row in rows[1:11]:  # Filas 1 a 10 (primeros 10 países)\n",
    "        # Las etiquetas <td> son las celdas de datos (table data)\n",
    "        celdas = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        \n",
    "        # Verificar que la fila tiene suficientes celdas\n",
    "        if len(celdas) >= 3:\n",
    "            # Extraer el texto de cada celda (primeras 5 columnas)\n",
    "            fila_datos = [celda.text.strip() for celda in celdas[:5]]\n",
    "            # Añadir la fila a nuestra lista\n",
    "            filas.append(fila_datos)\n",
    "    \n",
    "    # ESTRUCTURA HTML DE UNA TABLA:\n",
    "    # <table>\n",
    "    #   <tr>                    <- Fila\n",
    "    #     <th>Encabezado 1</th> <- Celda de encabezado\n",
    "    #     <th>Encabezado 2</th>\n",
    "    #   </tr>\n",
    "    #   <tr>\n",
    "    #     <td>Dato 1</td>        <- Celda de datos\n",
    "    #     <td>Dato 2</td>\n",
    "    #   </tr>\n",
    "    # </table>\n",
    "    \n",
    "    \n",
    "    # PASO 5: Crear el DataFrame de pandas\n",
    "    df = pd.DataFrame(filas, columns=encabezados if encabezados else None)\n",
    "    \n",
    "    print(\"✅ Tabla extraída exitosamente\\\\n\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # AHORA TIENES UN DATAFRAME CON LOS DATOS DE LA TABLA WEB!\n",
    "    # Puedes hacer análisis, limpiar datos, exportar a CSV, etc.\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error al extraer tabla: {e}\")\n",
    "\n",
    "# APLICACIONES EN CIENCIA DE DATOS:\n",
    "# 1. Extraer tablas de estadísticas deportivas\n",
    "# 2. Recopilar datos financieros de sitios de bolsa\n",
    "# 3. Obtener rankings de universidades, empresas, etc.\n",
    "# 4. Compilar datos demográficos de múltiples fuentes\n",
    "# 5. Crear datasets para Machine Learning\n",
    "\n",
    "# SIGUIENTE PASO TÍPICO:\n",
    "# df.to_csv('paises_poblacion.csv', index=False)  # Guardar a CSV\n",
    "# df.describe()  # Análisis estadístico\n",
    "# df.plot()  # Visualización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Caso Práctico Completo <a name=\"caso-practico\"></a>\n",
    "\n",
    "### Proyecto: Extraer datos de búsqueda de Wikipedia\n",
    "\n",
    "Vamos a crear un scraper que:\n",
    "1. Busca un término en Wikipedia\n",
    "2. Extrae información de los resultados\n",
    "3. Guarda los datos en un DataFrame\n",
    "4. Exporta a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_wikipedia(termino_busqueda, num_resultados=5):\n",
    "    \"\"\"\n",
    "    ========================================\n",
    "    CASO PRÁCTICO COMPLETO: SCRAPER DE WIKIPEDIA\n",
    "    ========================================\n",
    "    \n",
    "    Esta función demuestra un FLUJO COMPLETO de web scraping para ciencia de datos:\n",
    "    1. Configurar el navegador\n",
    "    2. Navegar a un sitio web\n",
    "    3. Realizar una búsqueda\n",
    "    4. Extraer datos estructurados\n",
    "    5. Limpiar y organizar los datos\n",
    "    6. Retornar un DataFrame listo para análisis\n",
    "    \n",
    "    Args:\n",
    "        termino_busqueda (str): Término que queremos investigar\n",
    "        num_resultados (int): Cantidad de resultados a extraer (no usado en esta versión)\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame con información estructurada del artículo\n",
    "    \"\"\"\n",
    "    \n",
    "    # ==========================================\n",
    "    # PASO 1: CONFIGURACIÓN DEL NAVEGADOR\n",
    "    # ==========================================\n",
    "    \n",
    "    options = webdriver.ChromeOptions()\n",
    "    \n",
    "    # Opción anti-detección: algunos sitios bloquean bots\n",
    "    options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "    \n",
    "    # Maximizar ventana para asegurar que todos los elementos sean visibles\n",
    "    options.add_argument('--start-maximized')\n",
    "    \n",
    "    # Inicializar el driver con configuración automática\n",
    "    driver = webdriver.Chrome(\n",
    "        service=Service(ChromeDriverManager().install()),\n",
    "        options=options\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # ==========================================\n",
    "        # PASO 2: NAVEGACIÓN Y BÚSQUEDA\n",
    "        # ==========================================\n",
    "        \n",
    "        # Navegar a Wikipedia en español\n",
    "        driver.get(\"https://es.wikipedia.org\")\n",
    "        print(f\"🔍 Buscando: {termino_busqueda}\")\n",
    "        \n",
    "        # ESPERA EXPLÍCITA: Asegurar que el campo de búsqueda existe\n",
    "        # Esto es MÁS CONFIABLE que time.sleep()\n",
    "        search_box = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.ID, \"searchInput\"))\n",
    "        )\n",
    "        \n",
    "        # Limpiar y escribir el término de búsqueda\n",
    "        search_box.clear()\n",
    "        search_box.send_keys(termino_busqueda)\n",
    "        search_box.send_keys(Keys.RETURN)  # Enviar formulario\n",
    "        \n",
    "        # Esperar a que la página de resultados cargue\n",
    "        time.sleep(3)\n",
    "        \n",
    "        # ==========================================\n",
    "        # PASO 3: EXTRACCIÓN DE DATOS\n",
    "        # ==========================================\n",
    "        \n",
    "        # Inicializar lista para almacenar los datos\n",
    "        datos = []\n",
    "        \n",
    "        # --- EXTRAER TÍTULO DEL ARTÍCULO ---\n",
    "        try:\n",
    "            # El título principal está en un <h1> con id \"firstHeading\"\n",
    "            titulo = driver.find_element(By.ID, \"firstHeading\").text\n",
    "        except:\n",
    "            # Si no se encuentra, usar valor por defecto\n",
    "            titulo = \"No disponible\"\n",
    "        \n",
    "        \n",
    "        # --- EXTRAER PRIMER PÁRRAFO (RESUMEN) ---\n",
    "        try:\n",
    "            # Encontrar TODOS los párrafos en el contenido principal\n",
    "            parrafos = driver.find_elements(By.CSS_SELECTOR, \"#mw-content-text p\")\n",
    "            primer_parrafo = \"\"\n",
    "            \n",
    "            # Buscar el primer párrafo con contenido significativo\n",
    "            for p in parrafos:\n",
    "                texto = p.text.strip()\n",
    "                # Filtrar párrafos vacíos o muy cortos\n",
    "                if len(texto) > 50:\n",
    "                    # Limitar a 200 caracteres para mantener el DataFrame manejable\n",
    "                    primer_parrafo = texto[:200] + \"...\"\n",
    "                    break\n",
    "        except:\n",
    "            primer_parrafo = \"No disponible\"\n",
    "        \n",
    "        \n",
    "        # --- EXTRAER NÚMERO DE SECCIONES ---\n",
    "        try:\n",
    "            # Los encabezados de sección tienen la clase \"mw-headline\"\n",
    "            secciones = driver.find_elements(By.CSS_SELECTOR, \".mw-headline\")\n",
    "            num_secciones = len(secciones)\n",
    "            # Este dato nos indica la \"profundidad\" del artículo\n",
    "        except:\n",
    "            num_secciones = 0\n",
    "        \n",
    "        \n",
    "        # --- EXTRAER CATEGORÍAS ---\n",
    "        try:\n",
    "            # Las categorías están en la parte inferior del artículo\n",
    "            categorias = driver.find_elements(By.CSS_SELECTOR, \"#mw-normal-catlinks ul li\")\n",
    "            # Extraer solo las primeras 3 categorías\n",
    "            lista_categorias = [cat.text for cat in categorias[:3]]\n",
    "            # Unirlas en un string separado por comas\n",
    "            categorias_texto = \", \".join(lista_categorias)\n",
    "        except:\n",
    "            categorias_texto = \"No disponible\"\n",
    "        \n",
    "        \n",
    "        # ==========================================\n",
    "        # PASO 4: ESTRUCTURAR LOS DATOS\n",
    "        # ==========================================\n",
    "        \n",
    "        # Crear un diccionario con los datos extraídos\n",
    "        # Esto facilita la conversión a DataFrame\n",
    "        datos.append({\n",
    "            'Título': titulo,\n",
    "            'Descripción': primer_parrafo,\n",
    "            'Número de secciones': num_secciones,\n",
    "            'Categorías': categorias_texto,\n",
    "            'URL': driver.current_url  # URL final (puede haber habido redirección)\n",
    "        })\n",
    "        \n",
    "        \n",
    "        # ==========================================\n",
    "        # PASO 5: CONVERTIR A DATAFRAME\n",
    "        # ==========================================\n",
    "        \n",
    "        # pandas.DataFrame convierte nuestra lista de diccionarios en una tabla\n",
    "        df = pd.DataFrame(datos)\n",
    "        \n",
    "        print(f\"✅ Extracción completada: {len(datos)} resultados\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        # MANEJO DE ERRORES: Si algo falla, mostrar el error\n",
    "        print(f\"❌ Error: {e}\")\n",
    "        # Retornar DataFrame vacío para evitar que el programa se detenga\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    finally:\n",
    "        # ==========================================\n",
    "        # PASO 6: LIMPIEZA (SIEMPRE SE EJECUTA)\n",
    "        # ==========================================\n",
    "        \n",
    "        # IMPORTANTE: Siempre cerrar el navegador para liberar recursos\n",
    "        # finally: se ejecuta SIEMPRE, incluso si hubo un error\n",
    "        driver.quit()\n",
    "\n",
    "# ==========================================\n",
    "# EJECUTAR LA FUNCIÓN\n",
    "# ==========================================\n",
    "\n",
    "# Buscar información sobre \"Inteligencia Artificial\"\n",
    "df_resultados = buscar_wikipedia(\"Inteligencia Artificial\")\n",
    "\n",
    "print(\"\\\\n📊 Resultados:\")\n",
    "print(df_resultados)\n",
    "\n",
    "# EXPLICACIÓN PEDAGÓGICA DEL FLUJO:\n",
    "# 1. Configuramos el navegador con opciones específicas\n",
    "# 2. Navegamos a Wikipedia y realizamos una búsqueda\n",
    "# 3. Esperamos a que cargue la página (con esperas explícitas)\n",
    "# 4. Extraemos múltiples tipos de datos del artículo\n",
    "# 5. Estructuramos los datos en un diccionario\n",
    "# 6. Convertimos a DataFrame para análisis\n",
    "# 7. Cerramos el navegador (limpieza de recursos)\n",
    "\n",
    "# PRÓXIMOS PASOS:\n",
    "# - Guardar el DataFrame en CSV\n",
    "# - Analizar los datos con pandas\n",
    "# - Crear visualizaciones\n",
    "# - Escalar para buscar múltiples términos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar los resultados en CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar en CSV\n",
    "if not df_resultados.empty:\n",
    "    df_resultados.to_csv('resultados_wikipedia.csv', index=False, encoding='utf-8-sig')\n",
    "    print(\"✅ Datos guardados en 'resultados_wikipedia.csv'\")\n",
    "    \n",
    "    # Mostrar información del DataFrame\n",
    "    print(\"\\n📈 Información del dataset:\")\n",
    "    print(df_resultados.info())\n",
    "else:\n",
    "    print(\"❌ No hay datos para guardar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Mejores Prácticas <a name=\"mejores-practicas\"></a>\n",
    "\n",
    "### 9.1 Consejos importantes\n",
    "\n",
    "1. **Siempre usa esperas explícitas** en lugar de `time.sleep()`\n",
    "2. **Cierra el navegador** al terminar con `driver.quit()`\n",
    "3. **Usa try-except** para manejar errores\n",
    "4. **Respeta los robots.txt** de los sitios web\n",
    "5. **No sobrecargues los servidores** - añade pausas razonables\n",
    "6. **Usa headless mode** para mejor rendimiento en producción\n",
    "\n",
    "### 9.2 Función completa con mejores prácticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# MEJORES PRÁCTICAS: CONTEXT MANAGER\n",
    "# ========================================\n",
    "\n",
    "# PROBLEMA COMÚN:\n",
    "# Si olvidas llamar driver.quit(), el navegador queda abierto consumiendo memoria\n",
    "# Si hay un error en el código, driver.quit() puede no ejecutarse\n",
    "\n",
    "# SOLUCIÓN PROFESIONAL: Context Manager (with statement)\n",
    "\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def selenium_driver(headless=False):\n",
    "    \"\"\"\n",
    "    Context Manager para gestionar automáticamente el ciclo de vida del driver.\n",
    "    \n",
    "    ¿QUÉ ES UN CONTEXT MANAGER?\n",
    "    Es un patrón de diseño que garantiza:\n",
    "    - Inicialización: Se ejecuta al entrar en el bloque 'with'\n",
    "    - Limpieza: Se ejecuta SIEMPRE al salir, incluso si hay errores\n",
    "    \n",
    "    VENTAJAS:\n",
    "    - No puedes olvidar cerrar el navegador\n",
    "    - El navegador se cierra automáticamente, incluso con errores\n",
    "    - Código más limpio y profesional\n",
    "    - Previene fugas de memoria\n",
    "    \n",
    "    Args:\n",
    "        headless (bool): Si True, ejecuta Chrome sin interfaz gráfica (más rápido)\n",
    "    \n",
    "    Yields:\n",
    "        webdriver: Instancia del driver de Chrome lista para usar\n",
    "    \"\"\"\n",
    "    \n",
    "    # CONFIGURACIÓN DE OPCIONES\n",
    "    options = webdriver.ChromeOptions()\n",
    "    \n",
    "    # Si headless=True, el navegador se ejecuta en segundo plano (sin ventana)\n",
    "    if headless:\n",
    "        options.add_argument('--headless')\n",
    "        # VENTAJA: Más rápido, ideal para producción o servidores\n",
    "        # DESVENTAJA: No puedes ver qué está haciendo\n",
    "    \n",
    "    # Opciones adicionales para mayor estabilidad\n",
    "    options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "    options.add_argument('--start-maximized')\n",
    "    options.add_argument('--disable-gpu')  # Desactivar GPU (útil en servidores)\n",
    "    options.add_argument('--no-sandbox')   # Mayor compatibilidad en Linux\n",
    "    \n",
    "    # INICIALIZAR EL DRIVER\n",
    "    driver = webdriver.Chrome(\n",
    "        service=Service(ChromeDriverManager().install()),\n",
    "        options=options\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # YIELD: Devuelve el driver al bloque 'with'\n",
    "        # El código dentro del 'with' se ejecuta aquí\n",
    "        yield driver\n",
    "        \n",
    "    finally:\n",
    "        # LIMPIEZA: Se ejecuta SIEMPRE al salir del bloque 'with'\n",
    "        # Incluso si hubo una excepción en el código\n",
    "        driver.quit()\n",
    "        print(\"✅ Navegador cerrado correctamente\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# EJEMPLO DE USO\n",
    "# ==========================================\n",
    "\n",
    "# USO TRADICIONAL (menos seguro):\n",
    "# driver = webdriver.Chrome(...)\n",
    "# driver.get(\"https://...\")\n",
    "# # ... hacer cosas ...\n",
    "# driver.quit()  # ¿Y si hay un error antes de esto?\n",
    "\n",
    "# USO CON CONTEXT MANAGER (recomendado):\n",
    "with selenium_driver(headless=False) as driver:\n",
    "    driver.get(\"https://www.wikipedia.org\")\n",
    "    print(f\"Título: {driver.title}\")\n",
    "    # Al salir del bloque 'with', driver.quit() se llama automáticamente\n",
    "\n",
    "# FLUJO DE EJECUCIÓN:\n",
    "# 1. Se ejecuta el código antes de 'yield' (inicialización)\n",
    "# 2. Se ejecuta el código dentro del bloque 'with'\n",
    "# 3. Se ejecuta el código en 'finally' (limpieza)\n",
    "# 4. El navegador SIEMPRE se cierra, no importa qué pase\n",
    "\n",
    "# ANALOGÍA PEDAGÓGICA:\n",
    "# Es como abrir un archivo:\n",
    "# with open('archivo.txt', 'r') as f:\n",
    "#     contenido = f.read()\n",
    "# # El archivo se cierra automáticamente\n",
    "\n",
    "# APLICACIÓN EN CIENCIA DE DATOS:\n",
    "# - Ejecutar múltiples scrapers sin preocuparte por la limpieza\n",
    "# - Automatizar procesos en servidores (headless=True)\n",
    "# - Código más robusto y mantenible\n",
    "# - Prevenir errores de recursos no liberados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Manejo robusto de errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# MANEJO ROBUSTO DE ERRORES\n",
    "# ========================================\n",
    "\n",
    "# En web scraping, MUCHAS cosas pueden salir mal:\n",
    "# - El elemento no existe\n",
    "# - La página tarda en cargar\n",
    "# - El sitio cambió su estructura\n",
    "# - Problemas de conexión\n",
    "\n",
    "# Es CRUCIAL manejar estos errores correctamente\n",
    "\n",
    "from selenium.common.exceptions import (\n",
    "    NoSuchElementException,      # Elemento no encontrado\n",
    "    TimeoutException,             # Tiempo de espera agotado\n",
    "    ElementNotInteractableException  # Elemento no interactuable\n",
    ")\n",
    "\n",
    "def extraer_elemento_seguro(driver, by, value, timeout=10):\n",
    "    \"\"\"\n",
    "    Función ROBUSTA para extraer elementos con manejo profesional de errores.\n",
    "    \n",
    "    FILOSOFÍA:\n",
    "    - \"Espera lo mejor, prepárate para lo peor\"\n",
    "    - Nunca asumas que un elemento existirá\n",
    "    - Siempre ten un plan B (valor por defecto)\n",
    "    \n",
    "    Args:\n",
    "        driver: WebDriver de Selenium\n",
    "        by: Método de localización (By.ID, By.CSS_SELECTOR, etc.)\n",
    "        value: Valor del localizador (el selector específico)\n",
    "        timeout: Tiempo máximo de espera en segundos (default: 10)\n",
    "    \n",
    "    Returns:\n",
    "        str: Texto del elemento o mensaje de error descriptivo\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # INTENTO 1: Esperar hasta que el elemento esté presente\n",
    "        # WebDriverWait es más inteligente que time.sleep()\n",
    "        elemento = WebDriverWait(driver, timeout).until(\n",
    "            EC.presence_of_element_located((by, value))\n",
    "        )\n",
    "        return elemento.text\n",
    "        \n",
    "    except TimeoutException:\n",
    "        # ERROR 1: El elemento no apareció en el tiempo límite\n",
    "        # Posibles causas:\n",
    "        # - Selector incorrecto\n",
    "        # - Página muy lenta\n",
    "        # - Elemento cargado con JavaScript que tardó más de lo esperado\n",
    "        return f\"⏱️ Timeout: Elemento no encontrado en {timeout} segundos\"\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        # ERROR 2: El elemento definitivamente no existe\n",
    "        # Posibles causas:\n",
    "        # - Selector erróneo\n",
    "        # - Estructura del sitio cambió\n",
    "        # - Estamos en la página equivocada\n",
    "        return \"❌ Elemento no existe en la página\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        # ERROR 3: Cualquier otro error inesperado\n",
    "        # Siempre es buena práctica tener un catch-all\n",
    "        return f\"❌ Error inesperado: {str(e)}\"\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# DEMOSTRACIÓN DE USO\n",
    "# ==========================================\n",
    "\n",
    "with selenium_driver() as driver:\n",
    "    driver.get(\"https://es.wikipedia.org\")\n",
    "    \n",
    "    # --- CASO 1: Elemento que SÍ existe ---\n",
    "    resultado1 = extraer_elemento_seguro(driver, By.ID, \"searchInput\")\n",
    "    print(f\"Resultado 1 (existe): {resultado1[:50] if len(resultado1) > 50 else resultado1}\")\n",
    "    \n",
    "    # --- CASO 2: Elemento que NO existe ---\n",
    "    resultado2 = extraer_elemento_seguro(driver, By.ID, \"elemento_inexistente\", timeout=3)\n",
    "    print(f\"Resultado 2 (no existe): {resultado2}\")\n",
    "\n",
    "# ==========================================\n",
    "# PATRÓN TRY-EXCEPT EN WEB SCRAPING\n",
    "# ==========================================\n",
    "\n",
    "# PATRÓN RECOMENDADO para extracción de datos:\n",
    "\n",
    "# datos = []\n",
    "# for item in items:\n",
    "#     try:\n",
    "#         titulo = item.find_element(By.CSS_SELECTOR, \"h2\").text\n",
    "#     except:\n",
    "#         titulo = \"No disponible\"\n",
    "#     \n",
    "#     try:\n",
    "#         precio = item.find_element(By.CSS_SELECTOR, \".precio\").text\n",
    "#     except:\n",
    "#         precio = \"No disponible\"\n",
    "#     \n",
    "#     datos.append({\n",
    "#         'titulo': titulo,\n",
    "#         'precio': precio\n",
    "#     })\n",
    "\n",
    "# VENTAJAS DE ESTE ENFOQUE:\n",
    "# 1. El scraper NO se detiene si falta un elemento\n",
    "# 2. Recopilas TODOS los datos disponibles, aunque algunos falten\n",
    "# 3. Puedes identificar patrones en los datos faltantes\n",
    "# 4. En ciencia de datos, datos parciales > sin datos\n",
    "\n",
    "# PRINCIPIOS CLAVE:\n",
    "# ✅ Siempre usa try-except para extracciones\n",
    "# ✅ Proporciona valores por defecto sensatos\n",
    "# ✅ Registra los errores para debugging\n",
    "# ✅ No dejes que un error detenga toda la recopilación\n",
    "# ✅ Valida los datos después de extraerlos\n",
    "\n",
    "# COMPARACIÓN:\n",
    "# Código SIN manejo de errores:\n",
    "#   precio = elemento.find_element(By.CLASS_NAME, \"precio\").text\n",
    "#   -> Se detiene si el elemento no existe\n",
    "#\n",
    "# Código CON manejo de errores:\n",
    "#   try:\n",
    "#       precio = elemento.find_element(By.CLASS_NAME, \"precio\").text\n",
    "#   except:\n",
    "#       precio = \"No disponible\"\n",
    "#   -> Continúa incluso si el elemento no existe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  Ejercicios Propuestos\n",
    "\n",
    "1. **Ejercicio 1:** Crea un scraper que extraiga los títulos de las noticias principales de un sitio de noticias\n",
    "\n",
    "2. **Ejercicio 2:** Extrae una tabla de datos de Wikipedia y realiza un análisis básico con pandas\n",
    "\n",
    "3. **Ejercicio 3:** Automatiza una búsqueda en Google y extrae los primeros 10 resultados\n",
    "\n",
    "4. **Ejercicio 4:** Crea un scraper que navegue por múltiples páginas y compile datos en un CSV\n",
    "\n",
    "---\n",
    "\n",
    "##  Recursos Adicionales\n",
    "\n",
    "- [Documentación oficial de Selenium](https://www.selenium.dev/documentation/)\n",
    "- [Selenium con Python](https://selenium-python.readthedocs.io/)\n",
    "- [XPath Cheat Sheet](https://devhints.io/xpath)\n",
    "- [CSS Selectors Reference](https://www.w3schools.com/cssref/css_selectors.asp)\n",
    "\n",
    "---\n",
    "\n",
    "##  Conclusión\n",
    "\n",
    "¡Felicidades! Has completado el tutorial de Selenium para Ciencia de Datos. Ahora conoces:\n",
    "\n",
    "- ✅ Configuración y uso básico de Selenium\n",
    "- ✅ Localización e interacción con elementos web\n",
    "- ✅ Extracción de datos para análisis\n",
    "- ✅ Técnicas avanzadas de web scraping\n",
    "- ✅ Mejores prácticas y manejo de errores\n",
    "\n",
    "### Próximos pasos:\n",
    "\n",
    "1. Practica con diferentes sitios web\n",
    "2. Combina Selenium con BeautifulSoup para parsing más eficiente\n",
    "3. Aprende sobre proxies y rotación de user agents\n",
    "4. Explora Scrapy para proyectos más grandes\n",
    "\n",
    "**¡Happy Scraping! **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ame",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
