{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "dM0AU5JmpZa3"
   },
   "source": [
    "# Textacy & Spacy\n",
    "Librerias de procesado de NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actualizamos pip a la última versión\n",
    "# pip es el gestor de paquetes de Python\n",
    "# Comando desactivado (comentado con #) - ejecutar solo si es necesario\n",
    "#!pip install --user  --upgrade pip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# INSTALACIÓN DE SPACY Y MODELOS DE LENGUAJE\n",
    "# ========================================\n",
    "\n",
    "# Instalamos la librería spacy\n",
    "# Comando desactivado - ejecutar solo en la primera instalación\n",
    "#!pip install -U spacy\n",
    "\n",
    "# Descargamos el modelo pequeño de inglés\n",
    "# 'sm' = small (modelo pequeño, más rápido pero menos preciso)\n",
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalamos textacy, una librería que complementa spacy con funcionalidades adicionales\n",
    "# Comando desactivado - ejecutar solo en la primera instalación\n",
    "#%pip install textacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargamos el modelo GRANDE de inglés\n",
    "# 'lg' = large (modelo grande con mejor precisión y vectores de palabras)\n",
    "# Este modelo es más pesado pero tiene mejor rendimiento\n",
    "#!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargamos el modelo GRANDE de español\n",
    "# Este modelo permite procesar textos en español con alta precisión\n",
    "#!python -m spacy download es_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Invalid requirement: '#': Expected package name at the start of dependency specifier\n",
      "    #\n",
      "    ^\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Invalid requirement: '#': Expected package name at the start of dependency specifier\n",
      "    #\n",
      "    ^\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# INSTRUCCIONES DE INSTALACIÓN\n",
    "# ========================================\n",
    "\n",
    "'''\n",
    "Versiones compatibles\n",
    "Despues hay que reiniciar el entorno de ejecución\n",
    "'''\n",
    "\n",
    "# Instalamos spacy y textacy\n",
    "# Estos comandos están desactivados - solo ejecutar una vez\n",
    "# !pip install spacy\n",
    "# !pip install textacy\n",
    "\n",
    "# Para siguientes ejecuciones, solo ejecutar estos comandos para descargar los modelos\n",
    "# Después de ejecutar, REINICIAR el entorno de ejecución (Runtime > Restart Runtime)\n",
    "!python -m spacy download en_core_web_lg  # Modelo grande de inglés\n",
    "!python -m spacy download es_core_news_lg  # Modelo grande de español"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "A5rKVBF0pKa6"
   },
   "source": [
    "# Spacy\n",
    "https://spacy.io/\n",
    "\n",
    "NOTA: Recuerda reiniciar el entorno de ejecucion despues de la instalacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "g5__omBtznMg"
   },
   "outputs": [],
   "source": [
    "# Importamos la librería spacy, que es una de las mejores herramientas de NLP\n",
    "import spacy\n",
    "\n",
    "# Cargamos el modelo pre-entrenado para inglés (large = modelo grande con mejor precisión)\n",
    "# 'en_core_web_lg' incluye vectores de palabras, reconocimiento de entidades, POS tagging, etc.\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "XvUcxUvRx3CT"
   },
   "source": [
    "## Text basics\n",
    "Veamos como trabajar cn estos primeros ejemplos con la libreria ´spacy´. Cosas que podemos hacer:\n",
    "1. Tokenizar en frases\n",
    "2. Tokenizar en palabras\n",
    "3. Acceder a los atributos de cada token\n",
    "4. Acceder a las entidades del texto\n",
    "5. Visualizar las entidades del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yx7f0Wv9ul01",
    "outputId": "da5d47cf-de20-4e1e-ebcc-d4ee4e09b77b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "London is the capital and most populous city of England and \n",
      "the United Kingdom.  Standing on the River Thames in the south east \n",
      "of the island of Great Britain, London has been a major settlement \n",
      "for two millennia. It was founded by the Romans, who named it Londinium.\n",
      "\n",
      "0 \n",
      "\n",
      "1 London is the capital and most populous city of England and \n",
      "the United Kingdom.  \n",
      "2 Standing on the River Thames in the south east \n",
      "of the island of Great Britain, London has been a major settlement \n",
      "for two millennia.\n",
      "3 It was founded by the Romans, who named it Londinium.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# EJEMPLO 1: TOKENIZACIÓN DE FRASES\n",
    "# ========================================\n",
    "\n",
    "# Definimos el texto que queremos analizar\n",
    "# Este texto habla sobre Londres y será nuestro ejemplo de entrada\n",
    "text = \"\"\"\n",
    "London is the capital and most populous city of England and \n",
    "the United Kingdom.  Standing on the River Thames in the south east \n",
    "of the island of Great Britain, London has been a major settlement \n",
    "for two millennia. It was founded by the Romans, who named it Londinium.\n",
    "\"\"\"\n",
    "\n",
    "# Procesamos el texto con spacy\n",
    "# Al aplicar nlp(text)(nuestro modelo), spacy realiza automáticamente:\n",
    "# - Tokenización (división en palabras)\n",
    "# - POS tagging (etiquetado gramatical)\n",
    "# - Reconocimiento de entidades\n",
    "# - Análisis de dependencias sintácticas\n",
    "doc = nlp(text)\n",
    "\n",
    "# Imprimimos el documento completo\n",
    "print(doc)\n",
    "\n",
    "# Iteramos sobre cada frase detectada automáticamente por spacy\n",
    "# spacy usa el modelo de lenguaje para identificar dónde termina cada frase\n",
    "for num, sentence in enumerate(doc.sents):\n",
    "  print(num, sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contamos cuántas frases tiene nuestro documento\n",
    "# doc.sents es un generador, por eso lo convertimos a lista\n",
    "# Resultado esperado: 4 frases\n",
    "len(list(doc.sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " SPACE False\n",
      "London London PROPN False\n",
      "is be AUX True\n",
      "the the DET True\n",
      "capital capital NOUN False\n",
      "and and CCONJ True\n",
      "most most ADV True\n",
      "populous populous ADJ False\n",
      "city city NOUN False\n",
      "of of ADP True\n",
      "England England PROPN False\n",
      "and and CCONJ True\n",
      "\n",
      " \n",
      " SPACE False\n",
      "the the DET True\n",
      "United United PROPN False\n",
      "Kingdom Kingdom PROPN False\n",
      ". . PUNCT False\n",
      "    SPACE False\n",
      "Standing stand VERB False\n",
      "on on ADP True\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# EJEMPLO 2: ANÁLISIS DE TOKENS (PALABRAS)\n",
    "# ========================================\n",
    "\n",
    "# Iteramos sobre las primeras 20 palabras del documento\n",
    "# Cada token (palabra) tiene múltiples atributos útiles:\n",
    "for word in doc[:20]:\n",
    "  # word.text = la palabra original tal como aparece en el texto\n",
    "  # word.lemma_ = forma base de la palabra (ej: \"running\" -> \"run\")\n",
    "  # word.pos_ = Part Of Speech, la categoría gramatical (NOUN, VERB, ADJ, etc.)\n",
    "  # word.is_stop = True si es una stopword (palabras comunes como \"the\", \"is\", \"a\")\n",
    "  print(word.text, word.lemma_, word.pos_, word.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JIe3TYa9RNfm",
    "outputId": "f90a4cd9-f411-41e5-a000-750fb5f88e7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificamos el tipo de objeto que devuelve spacy\n",
    "# Es un objeto de tipo Doc (documento procesado) que contiene toda la información lingüística\n",
    "type(doc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "UpBWJ2gby81T"
   },
   "source": [
    "## Syntactic analysis\n",
    "Doing the school homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "id": "9N42WYyyy86b",
    "outputId": "f2d56011-4783-4711-f8f7-445f2a46dfd2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"3f21ae8aceb84270b547bc769b531e7c-0\" class=\"displacy\" width=\"2500\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">London</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">capital</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">most</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">populous</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">city</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">England</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">United</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">Kingdom</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3f21ae8aceb84270b547bc769b531e7c-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3f21ae8aceb84270b547bc769b531e7c-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3f21ae8aceb84270b547bc769b531e7c-0-1\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3f21ae8aceb84270b547bc769b531e7c-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3f21ae8aceb84270b547bc769b531e7c-0-2\" stroke-width=\"2px\" d=\"M245,264.5 C245,89.5 570.0,89.5 570.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3f21ae8aceb84270b547bc769b531e7c-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M570.0,266.5 L578.0,254.5 562.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3f21ae8aceb84270b547bc769b531e7c-0-3\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3f21ae8aceb84270b547bc769b531e7c-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M740.0,266.5 L748.0,254.5 732.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3f21ae8aceb84270b547bc769b531e7c-0-4\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3f21ae8aceb84270b547bc769b531e7c-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,266.5 L937,254.5 953,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3f21ae8aceb84270b547bc769b531e7c-0-5\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3f21ae8aceb84270b547bc769b531e7c-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3f21ae8aceb84270b547bc769b531e7c-0-6\" stroke-width=\"2px\" d=\"M595,264.5 C595,89.5 1270.0,89.5 1270.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3f21ae8aceb84270b547bc769b531e7c-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1270.0,266.5 L1278.0,254.5 1262.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3f21ae8aceb84270b547bc769b531e7c-0-7\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,177.0 1440.0,177.0 1440.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3f21ae8aceb84270b547bc769b531e7c-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1440.0,266.5 L1448.0,254.5 1432.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3f21ae8aceb84270b547bc769b531e7c-0-8\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,177.0 1615.0,177.0 1615.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3f21ae8aceb84270b547bc769b531e7c-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1615.0,266.5 L1623.0,254.5 1607.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3f21ae8aceb84270b547bc769b531e7c-0-9\" stroke-width=\"2px\" d=\"M1645,264.5 C1645,177.0 1790.0,177.0 1790.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3f21ae8aceb84270b547bc769b531e7c-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1790.0,266.5 L1798.0,254.5 1782.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3f21ae8aceb84270b547bc769b531e7c-0-10\" stroke-width=\"2px\" d=\"M1995,264.5 C1995,89.5 2320.0,89.5 2320.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3f21ae8aceb84270b547bc769b531e7c-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1995,266.5 L1987,254.5 2003,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3f21ae8aceb84270b547bc769b531e7c-0-11\" stroke-width=\"2px\" d=\"M2170,264.5 C2170,177.0 2315.0,177.0 2315.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3f21ae8aceb84270b547bc769b531e7c-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2170,266.5 L2162,254.5 2178,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3f21ae8aceb84270b547bc769b531e7c-0-12\" stroke-width=\"2px\" d=\"M595,264.5 C595,2.0 2325.0,2.0 2325.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3f21ae8aceb84270b547bc769b531e7c-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2325.0,266.5 L2333.0,254.5 2317.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ========================================\n",
    "# EJEMPLO 3: ANÁLISIS SINTÁCTICO (DEPENDENCY PARSING)\n",
    "# ========================================\n",
    "\n",
    "# Importamos displacy para visualizaciones interactivas\n",
    "from spacy import displacy\n",
    "\n",
    "# Creamos un nuevo documento con una frase más simple para visualizar mejor\n",
    "doc2 = nlp(\"London is the capital and most populous city of England and the United Kingdom\")\n",
    "\n",
    "# Visualizamos el árbol de dependencias sintácticas\n",
    "# style=\"dep\" muestra las relaciones gramaticales entre palabras\n",
    "# (sujeto, verbo, objeto, modificadores, etc.)\n",
    "# jupyter=True permite que se muestre correctamente en Jupyter Notebook\n",
    "displacy.render(doc2, jupyter=True, style=\"dep\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "BhcKxFvisxNj"
   },
   "source": [
    "## Entities in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GoUNKXsSsxXy",
    "outputId": "522e7782-4aa7-45e1-ddcc-d1fdd9f6ff72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "London GPE Countries, cities, states\n",
      "England GPE Countries, cities, states\n",
      "the United Kingdom GPE Countries, cities, states\n",
      "south east LOC Non-GPE locations, mountain ranges, bodies of water\n",
      "Great Britain GPE Countries, cities, states\n",
      "London GPE Countries, cities, states\n",
      "two millennia DATE Absolute or relative dates or periods\n",
      "Romans NORP Nationalities or religious or political groups\n",
      "Londinium PERSON People, including fictional\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# EJEMPLO 4: RECONOCIMIENTO DE ENTIDADES (NER)\n",
    "# ========================================\n",
    "\n",
    "# Iteramos sobre todas las entidades nombradas que spacy ha detectado automáticamente\n",
    "# Las entidades son cosas como nombres de lugares, personas, fechas, organizaciones, etc.\n",
    "for entity in doc.ents:\n",
    "  # entity.text = el texto de la entidad\n",
    "  # entity.label_ = el tipo de entidad (GPE, PERSON, DATE, etc.)\n",
    "  # spacy.explain() nos da una descripción humana del tipo de entidad\n",
    "  print(entity.text, entity.label_, spacy.explain(entity.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "8o01ox8YylRj",
    "outputId": "ae38b8fb-6575-4009-96af-80fdb9ab0550"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Companies, agencies, institutions, etc.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Si tenemos dudas sobre qué significa alguna etiqueta, podemos usar explain()\n",
    "# Por ejemplo, ¿qué es 'ORG'?\n",
    "spacy.explain('ORG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "id": "UwfOcDgCtEue",
    "outputId": "eadd1e47-cebe-453a-808a-35d2904aec5b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"><br>\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    London\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " is the capital and most populous city of \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    England\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and <br>\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the United Kingdom\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ".  Standing on the River Thames in the \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    south east\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " <br>of the island of \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Great Britain\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    London\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " has been a major settlement <br>for \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    two millennia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". It was founded by the \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Romans\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       ", who named it \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Londinium\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ".<br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizamos las entidades de forma gráfica y coloreada\n",
    "# style='ent' muestra las entidades resaltadas con diferentes colores según su tipo\n",
    "# Esto es muy útil para presentaciones y para verificar visualmente el NER\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "k4J_qGHusl9H"
   },
   "source": [
    "## Replacing names\n",
    "Hide names for GDPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8zHtOLvSsmEp",
    "outputId": "99bd35f8-5eff-4622-f119-5b8bd6426e0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " In 1950 , GDPR published his famous article \"Computing Machinery and Intelligence \" . In 1957 , GDPR \n",
      " Syntactic Structures revolutionized Linguistics with ' universal grammar ' , a rule based system of syntactic structures . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# EJEMPLO 5: ANONIMIZACIÓN DE DATOS (GDPR COMPLIANCE)\n",
    "# ========================================\n",
    "\n",
    "# Esta función reemplaza un token individual si es un nombre de persona\n",
    "def replace_name_with_placeholder(token):\n",
    "    # token.ent_iob indica si el token es parte de una entidad (0 = no es parte)\n",
    "    # token.ent_type_ indica el tipo de entidad (PERSON, GPE, ORG, etc.)\n",
    "    if token.ent_iob != 0 and token.ent_type_ == \"PERSON\":\n",
    "        # Si es una persona, la reemplazamos por \"GDPR\" para proteger la privacidad\n",
    "        return \"GDPR\"\n",
    "    else:\n",
    "        # Si no es una persona, devolvemos el texto original\n",
    "        return token.text\n",
    "\n",
    "# Esta función procesa un texto completo y oculta todos los nombres de personas\n",
    "def scrub(text):\n",
    "    # Procesamos el texto con spacy\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Retokenizamos para fusionar las entidades multi-palabra en un solo token\n",
    "    # Por ejemplo: \"Alan Turing\" se convierte en un solo token en lugar de dos\n",
    "    with doc.retokenize() as retokenizer:\n",
    "        for ent in doc.ents:\n",
    "            retokenizer.merge(ent)\n",
    "    \n",
    "    # Aplicamos la función de reemplazo a cada token\n",
    "    tokens = map(replace_name_with_placeholder, doc)\n",
    "    \n",
    "    # Unimos todos los tokens de vuelta en un string\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Texto de prueba con nombres de personas famosas\n",
    "s = \"\"\"\n",
    "In 1950, Alan Turing published his famous article \"Computing Machinery and Intelligence\". In 1957, Noam Chomsky's \n",
    "Syntactic Structures revolutionized Linguistics with 'universal grammar', a rule based system of syntactic structures.\n",
    "\"\"\"\n",
    "\n",
    "# Aplicamos la anonimización y mostramos el resultado\n",
    "# Resultado esperado: \"Alan Turing\" y \"Noam Chomsky\" serán reemplazados por \"GDPR\"\n",
    "print(scrub(s))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "oGvpaIAqzwOH"
   },
   "source": [
    "## Lematize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iKra7djBzwXj",
    "outputId": "a1e019b7-3aad-40d1-e5b2-a4203c49f250"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " SPACE\n",
      "London London PROPN\n",
      "is be AUX\n",
      "the the DET\n",
      "capital capital NOUN\n",
      "and and CCONJ\n",
      "most most ADV\n",
      "populous populous ADJ\n",
      "city city NOUN\n",
      "of of ADP\n",
      "England England PROPN\n",
      "and and CCONJ\n",
      "\n",
      " \n",
      " SPACE\n",
      "the the DET\n",
      "United United PROPN\n",
      "Kingdom Kingdom PROPN\n",
      ". . PUNCT\n",
      "    SPACE\n",
      "Standing stand VERB\n",
      "on on ADP\n",
      "the the DET\n",
      "River River PROPN\n",
      "Thames Thames PROPN\n",
      "in in ADP\n",
      "the the DET\n",
      "south south PROPN\n",
      "east east PROPN\n",
      "\n",
      " \n",
      " SPACE\n",
      "of of ADP\n",
      "the the DET\n",
      "island island NOUN\n",
      "of of ADP\n",
      "Great Great PROPN\n",
      "Britain Britain PROPN\n",
      ", , PUNCT\n",
      "London London PROPN\n",
      "has have AUX\n",
      "been be AUX\n",
      "a a DET\n",
      "major major ADJ\n",
      "settlement settlement NOUN\n",
      "\n",
      " \n",
      " SPACE\n",
      "for for ADP\n",
      "two two NUM\n",
      "millennia millennium NOUN\n",
      ". . PUNCT\n",
      "It it PRON\n",
      "was be AUX\n",
      "founded found VERB\n",
      "by by ADP\n",
      "the the DET\n",
      "Romans Romans PROPN\n",
      ", , PUNCT\n",
      "who who PRON\n",
      "named name VERB\n",
      "it it PRON\n",
      "Londinium Londinium PROPN\n",
      ". . PUNCT\n",
      "\n",
      " \n",
      " SPACE\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# EJEMPLO 6: LEMATIZACIÓN\n",
    "# ========================================\n",
    "\n",
    "# La lematización convierte las palabras a su forma base/diccionario\n",
    "# Ejemplos:\n",
    "# - \"running\" -> \"run\"\n",
    "# - \"better\" -> \"good\"\n",
    "# - \"was\" -> \"be\"\n",
    "\n",
    "# Iteramos sobre cada palabra del documento\n",
    "for w in doc:\n",
    "  # w.text = palabra original\n",
    "  # w.lemma_ = forma base de la palabra (lema)\n",
    "  # w.pos_ = categoría gramatical\n",
    "  print(w.text, w.lemma_, w.pos_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "o_e1pnbgz_0X"
   },
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j_M6OKU3z__q",
    "outputId": "701e21b9-d50e-4903-ca0e-c73746e56180"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'your', 'thru', 'seeming', 'his', 'ourselves', 'only', 'yet', 'must', 'keep', 'anywhere', 'out', 'empty', '’ve', 'often', 'me', 'without', '’s', 'them', 'hundred']\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# EJEMPLO 7: STOPWORDS (PALABRAS VACÍAS)\n",
    "# ========================================\n",
    "\n",
    "# Las stopwords son palabras muy comunes que generalmente no aportan mucho significado\n",
    "# Ejemplos: \"the\", \"is\", \"a\", \"an\", \"in\", \"to\", \"for\", etc.\n",
    "\n",
    "# Importamos la lista de stopwords en inglés\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "# Mostramos las primeras 20 stopwords de la lista\n",
    "# Spacy tiene ~300+ stopwords en inglés\n",
    "print(list(STOP_WORDS)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RXNvYLeD0QJ0",
    "outputId": "48725150-7661-4395-a27c-2a4782b52da4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      ", London, capital, populous, city, England, \n",
      ", United, Kingdom,  , Standing, River, Thames, south, east, \n",
      ", island, Great, Britain, London, major, settlement, \n",
      ", millennia, founded, Romans, named, Londinium, \n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Creamos una lista limpia removiendo stopwords y puntuación\n",
    "# Esta es una técnica común en NLP para reducir el ruido en el análisis\n",
    "\n",
    "# List comprehension que filtra:\n",
    "# - not palabra.is_stop: elimina stopwords (the, is, a, etc.)\n",
    "# - not palabra.is_punct: elimina signos de puntuación (. , ! ?)\n",
    "lista_clean = [palabra for palabra in doc if not palabra.is_stop and not palabra.is_punct]\n",
    "\n",
    "# Resultado: solo palabras con significado relevante\n",
    "print(lista_clean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "_3oBFA3XacUf"
   },
   "source": [
    "# Spanish\n",
    "## Spacy  and entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WyDUzV-eax_7",
    "outputId": "e4575ab9-ce92-4d3c-a20d-a4b297eab994"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Londres (LOC)\n",
      "London (LOC)\n",
      "Inglaterra (LOC)\n",
      "Reino Unido.2​3​ Situada (LOC)\n",
      "Támesis (LOC)\n",
      "Londres (LOC)\n",
      "Londinium (LOC)\n",
      "El núcleo antiguo de la urbe (MISC)\n",
      "City de Londres (LOC)\n",
      "Londres (LOC)\n",
      "Londres (LOC)\n",
      "Gran Londres,6​ (LOC)\n",
      "Londres.7​\n",
      "Londres (LOC)\n",
      "Londres (LOC)\n",
      "Londres (LOC)\n",
      "Juegos Olímpicos de Verano.21​\n",
      "En esta ciudad multirracial convive gente de un gran número de culturas (MISC)\n",
      "La Autoridad del Gran Londres (MISC)\n",
      "Reino Unido.24​ El área urbana del (LOC)\n",
      "Gran Londres (LOC)\n",
      "Europa (LOC)\n",
      "Londres (LOC)\n",
      "Imperio británico (LOC)\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# EJEMPLO 8: PROCESAMIENTO EN ESPAÑOL\n",
    "# ========================================\n",
    "\n",
    "# Cargamos el modelo pre-entrenado para español (large)\n",
    "nlp_es = spacy.load('es_core_news_lg')\n",
    "\n",
    "# Texto de ejemplo en español (artículo sobre Londres de Wikipedia)\n",
    "text = '''Londres (en inglés, London, pronunciado /ˈlʌndən/ ( escuchar)) es la capital y mayor ciudad de Inglaterra y del Reino Unido.2​3​ Situada a orillas del río Támesis, Londres es un importante asentamiento humano desde que fue fundada por los romanos con el nombre de Londinium hace casi dos milenios.4​ El núcleo antiguo de la urbe, la City de Londres, conserva básicamente su perímetro medieval de una milla cuadrada. Desde el siglo XIX el nombre «Londres» también hace referencia a toda la metrópolis desarrollada alrededor de este núcleo.5​ El grueso de esta conurbación forma la región de Londres y el área administrativa del Gran Londres,6​ gobernado por el alcalde y la asamblea de Londres.7​\n",
    "Londres es una ciudad global, uno de los centros neurálgicos en el ámbito de las artes, el comercio, la educación, el entretenimiento, la moda, las finanzas, los medios de comunicación, la investigación, el turismo o el transporte.8​ Es el principal centro financiero del mundo9​10​11​ y una de las áreas metropolitanas con mayor PIB.12​13​ Londres es también una capital cultural mundial,14​15​16​17​ la ciudad más visitada considerando el número de visitas internacionales18​ y tiene el mayor sistema aeroportuario del mundo según el tráfico de pasajeros.19​ Asimismo, las 43 universidades de la ciudad conforman la mayor concentración de centros de estudios superiores de toda Europa.20​ En el año 2012 Londres se convirtió en la única ciudad en albergar la celebración de tres Juegos Olímpicos de Verano.21​\n",
    "En esta ciudad multirracial convive gente de un gran número de culturas que hablan más de trescientos idiomas distintos.22​ La Autoridad del Gran Londres estima que en 2015 la ciudad tiene 8,63 millones de habitantes,23​ que supone el 12,5 % del total de habitantes del Reino Unido.24​ El área urbana del Gran Londres, con 10 470 00025​ habitantes, es la segunda más grande de Europa, pero su área metropolitana, con una población estimada de entre 12 y 14 millones,26​27​ es la mayor del continente. Desde 1831 a 1925 Londres, como capital del Imperio británico, fue la ciudad más poblada del mundo.'''\n",
    "\n",
    "# Procesamos el texto en español\n",
    "doc = nlp_es(text)\n",
    "\n",
    "# Extraemos y mostramos todas las entidades nombradas detectadas\n",
    "# En español, las etiquetas pueden ser: LOC (lugar), PER (persona), ORG (organización), MISC (misceláneo)\n",
    "for entity in doc.ents:\n",
    "    print(f\"{entity.text} ({entity.label_})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Miscellaneous entities, e.g. events, nationalities, products or works of art'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificamos qué significa la etiqueta 'MISC' en el modelo de español\n",
    "# MISC = Miscellaneous (eventos, nacionalidades, productos, obras de arte, etc.)\n",
    "spacy.explain('MISC')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "5GwuAvRS1TLb"
   },
   "source": [
    "## Most frequent words\n",
    "In a Wikipedia page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalamos la librería wikipedia para obtener contenido de artículos\n",
    "# Comando desactivado - ejecutar solo si no está instalada\n",
    "#%pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las stopwords en español\n",
    "# Similar al inglés, pero adaptadas al español\n",
    "from spacy.lang.es.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cuanta',\n",
       " 'fui',\n",
       " 'suyas',\n",
       " 'comentó',\n",
       " 'quiere',\n",
       " 'cuánto',\n",
       " 'vuestra',\n",
       " 'solamente',\n",
       " 'pocos',\n",
       " 'podriamos',\n",
       " 'siempre',\n",
       " 'unos',\n",
       " 'aun',\n",
       " 'nuestras',\n",
       " 'haceis',\n",
       " 'porque',\n",
       " 'tuyas',\n",
       " 'podrán',\n",
       " 'tu',\n",
       " 'vosotros']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos las primeras 20 stopwords en español\n",
    "# Ejemplos: \"el\", \"la\", \"de\", \"que\", \"en\", \"y\", etc.\n",
    "list(STOP_WORDS)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "id": "zmuqxci01TTh",
    "outputId": "8f5d5796-9ab8-4b8b-d89c-2c6f17e89442"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data science is an interdisciplinary academic field that uses statistics, scientific computing, scientific methods, processing, scientific visualization, algorithms and systems to extract or extrapolate knowledge from potentially noisy, structured, or unstructured data. \\nData science also integrates domain knowledge from the underlying application domain (e.g., natural sciences, information technology, and medicine). Data science is multifaceted and can be described as a science, a research paradigm, a research method, a discipline, a workflow, and a profession.\\nData science is \"a concept to unify statistics, data analysis, informatics, and their related methods\" to \"understand and analyze actual phenomena\" with data. It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge. However, data science is different from computer science and information science. Turing Award winner Jim Gra'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ========================================\n",
    "# EJEMPLO 9: ANÁLISIS DE PALABRAS FRECUENTES CON WIKIPEDIA\n",
    "# ========================================\n",
    "\n",
    "# Importamos la librería wikipedia para obtener contenido de artículos\n",
    "import wikipedia\n",
    "\n",
    "# Configuramos el idioma a inglés\n",
    "wikipedia.set_lang(\"en\")\n",
    "\n",
    "# Obtenemos el artículo completo sobre \"Data Science\"\n",
    "wiki = wikipedia.page(title=\"Data Science\")\n",
    "\n",
    "# Extraemos el contenido del artículo\n",
    "text = wiki.content\n",
    "\n",
    "# Mostramos los primeros 1000 caracteres como muestra\n",
    "text[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w8s0R3vU3NAZ",
    "outputId": "3c71df2d-5abe-488f-fb50-fbe8b242e97a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data',\n",
       " 'science',\n",
       " 'field',\n",
       " 'statistics',\n",
       " 'computing',\n",
       " 'methods',\n",
       " 'processing',\n",
       " 'visualization',\n",
       " 'algorithms',\n",
       " 'systems']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraemos solo los SUSTANTIVOS del texto\n",
    "# Filtramos:\n",
    "# - Que NO sean stopwords\n",
    "# - Que NO sean signos de puntuación\n",
    "# - Que SÍ sean sustantivos (NOUN)\n",
    "\n",
    "# List comprehension con múltiples condiciones\n",
    "nombres = [w.text.lower() for w in nlp(text) if ((not w.is_stop) and (not w.is_punct) and (w.pos_ == 'NOUN'))]\n",
    "\n",
    "# Mostramos los primeros 10 sustantivos encontrados\n",
    "nombres[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('science', 43),\n",
       " ('statistics', 15),\n",
       " ('=', 14),\n",
       " ('analysis', 11),\n",
       " ('information', 8),\n",
       " ('computing', 6),\n",
       " ('knowledge', 6),\n",
       " ('field', 5),\n",
       " ('computer', 5)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contamos la frecuencia de cada palabra usando Counter\n",
    "# Counter es una estructura de datos que cuenta automáticamente elementos\n",
    "from collections import Counter\n",
    "\n",
    "# Creamos un contador con todas las palabras\n",
    "word_freq = Counter(nombres)\n",
    "\n",
    "# Mostramos las 10 palabras más comunes (excluyendo la primera con [1:])\n",
    "# most_common(10) devuelve una lista de tuplas (palabra, frecuencia)\n",
    "word_freq.most_common(10)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'En estadística, la regresión lineal o ajuste lineal es un modelo matemático usado para aproximar la relación de dependencia entre una variable dependiente \\n  \\n    \\n      \\n        Y\\n      \\n    \\n    {\\\\displaystyle Y}\\n  \\n, \\n  \\n    \\n      \\n        m\\n      \\n    \\n    {\\\\displaystyle m}\\n  \\n variables independientes \\n  \\n    \\n      \\n        \\n          X\\n          \\n            i\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle X_{i}}\\n  \\n con \\n  \\n    \\n      \\n        m\\n        ∈\\n        \\n          \\n            Z\\n          \\n          \\n            +\\n          \\n        \\n      \\n    \\n    {\\\\displaystyle m\\\\in \\\\mathbb {Z} ^{+}}\\n  \\n y un término aleatorio \\n  \\n    \\n      \\n        ε\\n      \\n    \\n    {\\\\displaystyle \\\\varepsilon }\\n  \\n. Este método es aplicable en muchas situaciones en las que se estudia la relación entre dos o más variables o predecir un comportamiento, algunas incluso sin relación con la tecnología. En caso de que no se pueda aplicar un modelo de regresión a un estudio, se dice que no hay corr'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ========================================\n",
    "# EJEMPLO 10: ANÁLISIS DE ADJETIVOS EN ESPAÑOL\n",
    "# ========================================\n",
    "\n",
    "# Cambiamos el idioma de wikipedia a español\n",
    "wikipedia.set_lang(\"es\")\n",
    "\n",
    "# Obtenemos el artículo sobre \"Regresión Lineal\" en español\n",
    "wiki = wikipedia.page(title=\"Regresión Lineal\")\n",
    "\n",
    "# Extraemos el contenido\n",
    "text = wiki.content\n",
    "\n",
    "# Mostramos los primeros 1000 caracteres\n",
    "text[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lineal',\n",
       " 'lineal',\n",
       " 'matemático',\n",
       " 'usado',\n",
       " 'dependiente',\n",
       " 'independiente',\n",
       " '\\\\displaystyle',\n",
       " '\\\\displaystyle',\n",
       " 'aleatorio',\n",
       " 'aplicable']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ahora extraemos ADJETIVOS en lugar de sustantivos\n",
    "# Usamos el lema (lemma_) en lugar del texto para normalizar las palabras\n",
    "# Por ejemplo: \"lineal\", \"lineales\", \"linealmente\" -> todos se convierten a \"lineal\"\n",
    "\n",
    "# Filtramos por:\n",
    "# - NO stopwords\n",
    "# - NO puntuación  \n",
    "# - SÍ adjetivos (ADJ)\n",
    "nombres = [w.lemma_ for w in nlp_es(text) if ((not w.is_stop) and (not w.is_punct) and (w.pos_ == 'ADJ'))]\n",
    "\n",
    "# Mostramos los primeros 10 adjetivos\n",
    "nombres[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C0D-pRly22_H",
    "outputId": "5bc9c178-6438-40ac-b2a6-ece714865a69"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('obtenido', 11),\n",
       " ('\\\\displaystyle', 8),\n",
       " ('múltiple', 8),\n",
       " ('independiente', 7),\n",
       " ('cuadrado', 7),\n",
       " ('simple', 7),\n",
       " ('dependiente', 6),\n",
       " ('aleatorio', 6),\n",
       " ('llamado', 6)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contamos la frecuencia de los adjetivos\n",
    "from collections import Counter\n",
    "\n",
    "# Creamos el contador\n",
    "word_freq = Counter(nombres)\n",
    "\n",
    "# Mostramos los 10 adjetivos más frecuentes (excluyendo el primero)\n",
    "# Esto nos ayuda a entender qué características se mencionan más en el artículo\n",
    "word_freq.most_common(10)[1:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "xWDuikM7VJtc"
   },
   "source": [
    "## Textacy London text\n",
    "Now we want to know things about London, from our previous text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalamos una versión específica de numpy compatible con textacy\n",
    "# numpy 1.26.4 es necesario para evitar conflictos de versiones\n",
    "# Después de instalar, REINICIAR el entorno de ejecución\n",
    "#%pip install numpy==1.26.4\n",
    "# then restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textacy==0.12.0 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.12.0)\n",
      "Requirement already satisfied: cachetools>=4.0.0 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from textacy==0.12.0) (6.2.1)\n",
      "Requirement already satisfied: catalogue~=2.0 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from textacy==0.12.0) (2.0.10)\n",
      "Requirement already satisfied: cytoolz>=0.10.1 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from textacy==0.12.0) (1.1.0)\n",
      "Requirement already satisfied: jellyfish>=0.8.0 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from textacy==0.12.0) (1.2.1)\n",
      "Requirement already satisfied: joblib>=0.13.0 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from textacy==0.12.0) (1.5.2)\n",
      "Requirement already satisfied: networkx>=2.0 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from textacy==0.12.0) (3.5)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from textacy==0.12.0) (2.2.6)\n",
      "Requirement already satisfied: pyphen>=0.10.0 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from textacy==0.12.0) (0.17.2)\n",
      "Requirement already satisfied: requests>=2.10.0 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from textacy==0.12.0) (2.32.5)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from textacy==0.12.0) (1.16.1)\n",
      "Requirement already satisfied: scikit-learn>=0.19.0 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from textacy==0.12.0) (1.7.2)\n",
      "Requirement already satisfied: spacy>=3.0.0 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from textacy==0.12.0) (3.8.9)\n",
      "Requirement already satisfied: tqdm>=4.19.6 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from textacy==0.12.0) (4.67.1)\n",
      "Requirement already satisfied: toolz>=0.8.0 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cytoolz>=0.10.1->textacy==0.12.0) (1.1.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.10.0->textacy==0.12.0) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.10.0->textacy==0.12.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.10.0->textacy==0.12.0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.10.0->textacy==0.12.0) (2025.8.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=0.19.0->textacy==0.12.0) (3.6.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy>=3.0.0->textacy==0.12.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy>=3.0.0->textacy==0.12.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy>=3.0.0->textacy==0.12.0) (1.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy>=3.0.0->textacy==0.12.0) (2.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy>=3.0.0->textacy==0.12.0) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy>=3.0.0->textacy==0.12.0) (8.3.9)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy>=3.0.0->textacy==0.12.0) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy>=3.0.0->textacy==0.12.0) (2.5.2)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy>=3.0.0->textacy==0.12.0) (0.4.3)\n",
      "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy>=3.0.0->textacy==0.12.0) (0.20.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy>=3.0.0->textacy==0.12.0) (2.12.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy>=3.0.0->textacy==0.12.0) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy>=3.0.0->textacy==0.12.0) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy>=3.0.0->textacy==0.12.0) (25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.0->textacy==0.12.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.0->textacy==0.12.0) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.0->textacy==0.12.0) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.0->textacy==0.12.0) (0.4.2)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy>=3.0.0->textacy==0.12.0) (1.3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy>=3.0.0->textacy==0.12.0) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.19.6->textacy==0.12.0) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer-slim<1.0.0,>=0.3.0->spacy>=3.0.0->textacy==0.12.0) (8.3.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from weasel<0.5.0,>=0.4.2->spacy>=3.0.0->textacy==0.12.0) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from weasel<0.5.0,>=0.4.2->spacy>=3.0.0->textacy==0.12.0) (7.5.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy>=3.0.0->textacy==0.12.0) (1.17.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\borja\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->spacy>=3.0.0->textacy==0.12.0) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Instalamos textacy versión 0.12.0 específicamente\n",
    "# Esta versión es compatible con las versiones actuales de spacy y numpy\n",
    "!pip install textacy==0.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si hay problemas de compatibilidad, instalar numpy 1.26.4\n",
    "# Comando desactivado - ejecutar solo si es necesario\n",
    "#%pip install numpy==1.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qOiN7HAmvNV2",
    "outputId": "cc8d904b-3cc0-4588-f6d5-95ce6ad6fe7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the things I know about London:\n",
      " - [the, capital, and, most, populous, city, of, England, and, the, United, Kingdom]\n",
      " - [a, major, settlement, for, two, millennia]\n",
      " - [a, huge, city]\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# EJEMPLO 11: EXTRACCIÓN DE INFORMACIÓN CON TEXTACY\n",
    "# ========================================\n",
    "\n",
    "# Textacy es una capa sobre spacy que facilita tareas más avanzadas\n",
    "import textacy.extract\n",
    "\n",
    "# Definimos un texto con múltiples afirmaciones sobre Londres\n",
    "text = \"\"\"London is the capital and most populous city of England and the United Kingdom. Standing on the River Thames in the south east of the island of Great Britain, London has been a major settlement for two millennia. London was founded by the Romans, \n",
    "who named it Londinium. London is a huge city. London has a lot of cute restaurants. Jaimito is my best friend.\n",
    "\"\"\"\n",
    "\n",
    "# Procesamos el texto con spacy\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extraemos AFIRMACIONES SEMIESTRUCTURADAS sobre \"London\"\n",
    "# Buscamos frases donde \"London\" es el sujeto y el verbo es \"be\" (ser/estar)\n",
    "# Esto nos permite extraer hechos específicos sobre Londres\n",
    "statements = textacy.extract.semistructured_statements(doc, entity=\"London\", cue='be')\n",
    "\n",
    "# Mostramos los resultados\n",
    "print(\"Here are the things I know about London:\")\n",
    "\n",
    "# Cada statement es una tupla de (sujeto, verbo, hecho)\n",
    "for statement in statements:\n",
    "    subject, verb, fact = statement\n",
    "    # Imprimimos solo el hecho extraído\n",
    "    print(f\" - {fact}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "hFwnqZzIaSNQ"
   },
   "source": [
    "## Textacy with Wikipedia API\n",
    "We don't want the most frequent words, we want sentences about London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "za6v7SL_2Ywo"
   },
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# EJEMPLO 12: EXTRACCIÓN DE INFORMACIÓN DE WIKIPEDIA\n",
    "# ========================================\n",
    "\n",
    "# Configuramos el idioma a inglés\n",
    "wikipedia.set_lang(\"en\")\n",
    "\n",
    "# Obtenemos el artículo completo de Londres\n",
    "london = wikipedia.page(\"London\")\n",
    "\n",
    "# Extraemos el contenido del artículo\n",
    "text = london.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NwOqJO902pO6",
    "outputId": "9d856c03-1993-4c18-976a-39a58d7680a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the things I know about London:\n",
      " - [the, world, 's, oldest, rapid, transit, system]\n"
     ]
    }
   ],
   "source": [
    "# Procesamos el artículo de Wikipedia sobre Londres\n",
    "doc = nlp(text)\n",
    "\n",
    "# Ahora buscamos información específica sobre \"London Underground\" (el metro de Londres)\n",
    "# Extraemos afirmaciones donde \"London Underground\" es el sujeto y \"be\" es el verbo\n",
    "statements = textacy.extract.semistructured_statements(doc, entity=\"London Underground\", cue='be')\n",
    "\n",
    "# Mostramos los resultados\n",
    "print(\"Here are the things I know about London:\")\n",
    "\n",
    "# Iteramos sobre cada afirmación encontrada\n",
    "for statement in statements:\n",
    "    subject, verb, fact = statement\n",
    "    # Imprimimos solo el hecho extraído\n",
    "    # Por ejemplo: \"London Underground is the world's oldest rapid transit system\"\n",
    "    print(f\" - {fact}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Textacy_y_spacy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
