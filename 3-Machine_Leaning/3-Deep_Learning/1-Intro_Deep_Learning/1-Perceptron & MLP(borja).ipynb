{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Perceptron\n",
    "\n",
    "<img src=\"./img/perceptron-6168423.jpg\" alt=\"drawing\" width=\"650\"/>\n",
    "\n",
    "Empezamos cargando librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# IMPORTACIÓN DE LIBRERÍAS\n# =============================================================================\n# NumPy: Librería fundamental para cálculos numéricos y operaciones con arrays\nimport numpy as np\n\n# Pandas: Herramienta para manipulación y análisis de datos estructurados\nimport pandas as pd\n\n# Seaborn: Librería de visualización de datos basada en matplotlib\n# También incluye datasets de ejemplo como el de pingüinos que usaremos\nimport seaborn as sns"
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos datos. Utilizaremos el dataset de pinguinos de seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# CARGA DEL DATASET DE PINGÜINOS\n# =============================================================================\n# Cargamos el dataset de pingüinos de Palmer, que incluye mediciones\n# de 3 especies diferentes de pingüinos (Adelie, Chinstrap, Gentoo)\ndf = sns.load_dataset(\"penguins\")\n\n# Visualizamos las primeras 5 filas para entender la estructura de los datos\ndf.head()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# INFORMACIÓN DEL DATASET\n# =============================================================================\n# Usamos .info() para ver:\n# - El número total de registros (344 pingüinos)\n# - Los tipos de datos de cada columna\n# - Valores nulos (importante: hay algunos NaN en las columnas numéricas y en 'sex')\ndf.info()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# LIMPIEZA Y PREPROCESAMIENTO DE DATOS\n# =============================================================================\n# Volvemos a cargar el dataset\ndf = sns.load_dataset(\"penguins\")\n\n# PASO 1: Eliminar filas con valores nulos\n# inplace=True modifica el DataFrame directamente sin crear una copia\ndf.dropna(inplace=True)\n\n# PASO 2: Codificación de variables categóricas a numéricas\n# Las redes neuronales necesitan datos numéricos, no texto\ncleanup_nums = {\"species\": {\"Adelie\": 0,      # Especie Adelie -> 0\n                            \"Chinstrap\": 1,   # Especie Chinstrap -> 1\n                            \"Gentoo\": 2},     # Especie Gentoo -> 2\n               \"sex\": {\"Male\": 0,             # Macho -> 0\n                       \"Female\": 1}}          # Hembra -> 1\n\n# Aplicamos el mapeo de valores categóricos a numéricos\ndf.replace(cleanup_nums, inplace=True)\n\n# PASO 3: One-Hot Encoding para la variable 'island'\n# get_dummies() convierte variables categóricas en columnas binarias (0 o 1)\n# Por ejemplo: 'island' se convierte en 'island_Biscoe', 'island_Dream', 'island_Torgersen'\ndf = pd.get_dummies(df)\n\n# Mostramos el resultado del preprocesamiento\ndf.head()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# VERIFICACIÓN DESPUÉS DEL PREPROCESAMIENTO\n# =============================================================================\n# Comprobamos que:\n# - Ahora tenemos 333 registros (eliminamos los que tenían NaN)\n# - Todas las columnas son numéricas\n# - Las islas se han convertido en 3 columnas binarias (one-hot encoding)\ndf.info()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# ESTADÍSTICAS DESCRIPTIVAS\n# =============================================================================\n# describe() nos muestra estadísticas como media, desviación estándar, \n# mínimo, máximo y cuartiles de cada variable numérica\n# Esto es importante para entender la escala de nuestras variables\ndf.describe()"
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos en train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# DIVISIÓN EN TRAIN Y TEST\n# =============================================================================\nfrom sklearn.model_selection import train_test_split\n\n# Separamos las características (X) de la variable objetivo (y)\n# iloc[:, 1:] selecciona todas las filas y desde la columna 1 en adelante (features)\nX = df.iloc[:, 1:]  # Características: todas las columnas excepto 'species'\n\n# iloc[:, 0] selecciona la primera columna (species), nuestra variable objetivo\ny = df.iloc[:, 0]   # Variable objetivo: especie del pingüino (0, 1 o 2)\n\n# Dividimos los datos en conjuntos de entrenamiento (80%) y prueba (20%)\n# test_size=0.2 significa que el 20% de los datos se usarán para test\n# random_state=42 asegura que la división sea reproducible\nX_train, X_test, y_train, y_test = train_test_split(X,\n                                                    y,\n                                                    test_size=0.2,\n                                                    random_state=42)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# VERIFICACIÓN DE LAS DIMENSIONES\n# =============================================================================\n# Imprimimos las dimensiones de cada conjunto para confirmar la división\nprint(X_train.shape)  # (266, 8) -> 266 muestras de entrenamiento, 8 características\nprint(X_test.shape)   # (67, 8) -> 67 muestras de test, 8 características\nprint(y_train.shape)  # (266,) -> 266 etiquetas de entrenamiento\nprint(y_test.shape)   # (67,) -> 67 etiquetas de test"
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a probar un Perceptrón"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# PRIMER MODELO: PERCEPTRÓN SIMPLE SIN ESTANDARIZAR\n# =============================================================================\nfrom sklearn.linear_model import Perceptron\n\n# Creamos un Perceptrón (red neuronal de una sola capa)\n# El perceptrón es el modelo más simple de red neuronal\nper_clf = Perceptron(random_state=1)\n\n# Entrenamos el modelo con los datos de entrenamiento\nper_clf.fit(X_train, y_train)\n\n# Evaluamos el modelo en el conjunto de test\n# score() devuelve la precisión (accuracy): % de predicciones correctas\n# RESULTADO: ~19% de precisión - ¡MUY MALO! Peor que adivinar al azar\nper_clf.score(X_test, y_test)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# COMPARACIÓN: REGRESIÓN LOGÍSTICA SIN ESTANDARIZAR\n# =============================================================================\nfrom sklearn.linear_model import LogisticRegression\n\n# Probamos con Regresión Logística para comparar\n# max_iter=10000 establece el número máximo de iteraciones para convergencia\nlog_reg = LogisticRegression(max_iter=10000)\n\n# Entrenamos el modelo\nlog_reg.fit(X_train, y_train)\n\n# Evaluamos en el conjunto de test\n# RESULTADO: ~98.5% de precisión - ¡EXCELENTE!\n# Esto demuestra que el Perceptrón simple tiene problemas con estos datos\nlog_reg.score(X_test, y_test)"
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos a estandarizar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que el perceptrón por si solo es bastante inútil, habrá que probar configuraciones más complejas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# MULTI LAYER PERCEPTRON (MLP) - CONFIGURACIÓN POR DEFECTO\n# =============================================================================\nfrom sklearn.neural_network import MLPClassifier\n# También existe MLPRegressor para problemas de regresión\n\n# Creamos un MLP con configuración por defecto\n# Por defecto tiene una capa oculta con 100 neuronas\nmlp = MLPClassifier(random_state=42)\n\n# Entrenamos el modelo\nmlp.fit(X_train, y_train)\n\n# Evaluamos en el conjunto de test\n# RESULTADO: ~43% de precisión - Mejor que el Perceptrón simple, pero aún malo\n# El MLP no está funcionando bien sin estandarización\nmlp.score(X_test, y_test)"
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos otra configuración. Es posible crear una red neuronal desde la propia función de MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# MLP CON CONFIGURACIÓN PERSONALIZADA (SIN ESTANDARIZAR)\n# =============================================================================\n# Intentamos mejorar el MLP con una arquitectura más compleja\nmlp = MLPClassifier(max_iter=500,                      # Aumentamos iteraciones\n                   activation='relu',                  # Función de activación ReLU\n                   hidden_layer_sizes = (150, 150, 150),  # 3 capas ocultas con 150 neuronas cada una\n                   random_state=42)\n\n# Entrenamos el modelo con la nueva arquitectura\nmlp.fit(X_train, y_train)\n\n# Evaluamos en el conjunto de test\n# RESULTADO: ~46% de precisión - Apenas mejoró\n# CONCLUSIÓN: El problema NO es la arquitectura, es la FALTA DE ESTANDARIZACIÓN\nmlp.score(X_test, y_test)"
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizan descenso del gradiente, y por tanto son muy sensibles al escalado. Estandarizamos para el siguiente ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# ESTANDARIZACIÓN DE DATOS + PERCEPTRÓN\n# =============================================================================\n# Las redes neuronales utilizan descenso del gradiente para optimización\n# Este algoritmo es MUY SENSIBLE a la escala de las características\n# Por ejemplo: body_mass_g está en miles, pero sex está entre 0 y 1\n\nfrom sklearn.preprocessing import StandardScaler\n\n# PASO 1: Crear el escalador\n# StandardScaler transforma los datos para que tengan media=0 y desviación estándar=1\nsc = StandardScaler()\n\n# PASO 2: Ajustar el escalador SOLO con los datos de entrenamiento\n# fit() calcula la media y desviación estándar de X_train\nsc.fit(X_train)\n\n# PASO 3: Transformar tanto train como test usando las estadísticas de train\n# ¡IMPORTANTE! Usamos las mismas estadísticas para evitar data leakage\nX_train_s = sc.transform(X_train)  # Estandarizamos el conjunto de entrenamiento\nX_test_s = sc.transform(X_test)    # Estandarizamos el conjunto de test\n\n# PASO 4: Entrenar Perceptrón con datos estandarizados\nper_clf = Perceptron()\nper_clf.fit(X_train_s, y_train)\n\n# PASO 5: Evaluar el modelo\nprint(per_clf.score(X_train_s, y_train))  # RESULTADO: 100% en train\nprint(per_clf.score(X_test_s, y_test))    # RESULTADO: 100% en test\n# ¡INCREÍBLE MEJORA! De 19% a 100% solo con estandarización"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# REGRESIÓN LOGÍSTICA CON DATOS ESTANDARIZADOS\n# =============================================================================\n# Probamos también la Regresión Logística con datos estandarizados\nlog_reg = LogisticRegression(max_iter=500)\n\n# Entrenamos con los datos estandarizados\nlog_reg.fit(X_train_s, y_train)\n\n# Evaluamos en ambos conjuntos\nprint(log_reg.score(X_train_s, y_train))  # 100% en train\nprint(log_reg.score(X_test_s, y_test))    # 100% en test\n# La Regresión Logística ya funcionaba bien, pero la estandarización la hace perfecta"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# MLP CON ESTANDARIZACIÓN - SOLUCIÓN DEFINITIVA\n# =============================================================================\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.preprocessing import StandardScaler\n\n# PASO 1: Crear y ajustar el escalador\nscaler = StandardScaler()\nscaler.fit(X_train)\n\n# PASO 2: Transformar los datos\nX_train_scal = scaler.transform(X_train)\nX_test_scal = scaler.transform(X_test)\n\n# PASO 3: Crear y entrenar el MLP (con configuración por defecto)\nmlp = MLPClassifier(max_iter=500)\nmlp.fit(X_train_scal, y_train)\n\n# PASO 4: Evaluar el modelo\nprint(mlp.score(X_train_scal, y_train))  # RESULTADO: 100% en train\nprint(mlp.score(X_test_scal, y_test))    # RESULTADO: 100% en test\n\n# LECCIÓN CLAVE: La estandarización es CRÍTICA para redes neuronales\n# Sin ella: 43% de precisión\n# Con ella: 100% de precisión"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# MATRIZ DE CONFUSIÓN - ANÁLISIS DETALLADO DE RESULTADOS\n# =============================================================================\nfrom sklearn.metrics import confusion_matrix\n\n# La matriz de confusión muestra cómo se distribuyen las predicciones\n# Filas: clases reales | Columnas: clases predichas\n# Diagonal principal: predicciones correctas\nconfusion_matrix(y_test, mlp.predict(X_test_scal))\n\n# INTERPRETACIÓN DEL RESULTADO:\n# [[31  0  0]   <- 31 Adelie correctamente clasificados, 0 errores\n#  [ 0 13  0]   <- 13 Chinstrap correctamente clasificados, 0 errores\n#  [ 0  0 23]]  <- 23 Gentoo correctamente clasificados, 0 errores\n# ¡PERFECTO! No hay errores de clasificación"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}