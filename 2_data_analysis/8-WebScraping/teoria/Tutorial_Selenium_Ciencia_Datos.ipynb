{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selenium para Ciencia de Datos\n",
    "\n",
    "#### Borja Barber Lead Instructor DS\n",
    "\n",
    "##  √çndice\n",
    "1. [Introducci√≥n](#introduccion)\n",
    "2. [Instalaci√≥n y Configuraci√≥n](#instalacion)\n",
    "3. [Conceptos B√°sicos](#conceptos-basicos)\n",
    "4. [Navegaci√≥n Web](#navegacion)\n",
    "5. [Localizaci√≥n de Elementos](#localizacion)\n",
    "6. [Extracci√≥n de Datos](#extraccion)\n",
    "7. [Web Scraping Avanzado](#scraping-avanzado)\n",
    "8. [Caso Pr√°ctico Completo](#caso-practico)\n",
    "9. [Mejores Pr√°cticas](#mejores-practicas)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducci√≥n <a name=\"introduccion\"></a>\n",
    "\n",
    "### ¬øQu√© es Selenium?\n",
    "\n",
    "Selenium es una herramienta de automatizaci√≥n de navegadores web que permite:\n",
    "- **Automatizar** interacciones con p√°ginas web\n",
    "- **Extraer datos** de sitios web din√°micos (JavaScript)\n",
    "- **Simular** comportamiento humano (clicks, scroll, formularios)\n",
    "- **Recopilar datos** para an√°lisis y ciencia de datos\n",
    "\n",
    "### ¬øPor qu√© usar Selenium en Ciencia de Datos?\n",
    "\n",
    "- Muchas p√°ginas web modernas cargan datos con JavaScript (AJAX)\n",
    "- BeautifulSoup y requests no pueden ejecutar JavaScript\n",
    "- Selenium permite acceder a datos que se cargan din√°micamente\n",
    "- Ideal para crear datasets personalizados mediante web scraping\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Instalaci√≥n y Configuraci√≥n <a name=\"instalacion\"></a>\n",
    "\n",
    "### Paso 1: Instalar Selenium\n",
    "\n",
    "Ejecuta el siguiente comando para instalar Selenium:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELDA 1: INSTALACI√ìN DE SELENIUM\n",
    "# ========================================\n",
    "\n",
    "# El s√≠mbolo ! ejecuta comandos del sistema operativo desde Jupyter\n",
    "# pip es el gestor de paquetes de Python que instala librer√≠as\n",
    "\n",
    "# Instalar Selenium - La librer√≠a principal para automatizar navegadores\n",
    "# Selenium permite controlar Chrome, Firefox, Safari, etc. mediante c√≥digo Python\n",
    "!pip install selenium\n",
    "\n",
    "# Instalar Pandas - Para manipular y analizar datos en formato tabular (DataFrames)\n",
    "# Pandas es esencial en ciencia de datos para trabajar con datos estructurados\n",
    "!pip install pandas\n",
    "\n",
    "# Instalar NumPy - Para operaciones num√©ricas y arrays\n",
    "# NumPy es la base del ecosistema cient√≠fico de Python\n",
    "!pip install numpy\n",
    "\n",
    "# NOTA PEDAG√ìGICA:\n",
    "# Estas instalaciones solo necesitan ejecutarse UNA VEZ en tu entorno.\n",
    "# Si ya las tienes instaladas, ver√°s un mensaje indicando que ya existen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 2: Instalar WebDriver Manager\n",
    "\n",
    "WebDriver Manager descarga autom√°ticamente el driver del navegador:\n",
    "\n",
    "**‚ö†Ô∏è NOTA IMPORTANTE SOBRE SELECTORES:**\n",
    "Los sitios web cambian frecuentemente su estructura HTML. Si encuentras errores como `NoSuchElementException`, significa que el selector CSS o XPath ya no es v√°lido. En el tutorial aprender√°s c√≥mo:\n",
    "- Usar try-except para manejar estos casos\n",
    "- Tener selectores alternativos como plan B\n",
    "- Verificar selectores usando las DevTools del navegador (F12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELDA 2: INSTALACI√ìN DE WEBDRIVER MANAGER\n",
    "# ========================================\n",
    "\n",
    "# WebDriver Manager es una herramienta que SIMPLIFICA enormemente trabajar con Selenium\n",
    "# \n",
    "# ¬øQU√â PROBLEMA RESUELVE?\n",
    "# Antes, ten√≠as que:\n",
    "# 1. Descargar manualmente el driver del navegador (chromedriver.exe)\n",
    "# 2. Colocarlo en una ruta espec√≠fica\n",
    "# 3. Actualizar manualmente cada vez que el navegador se actualiza\n",
    "#\n",
    "# WebDriver Manager hace todo esto AUTOM√ÅTICAMENTE por ti\n",
    "# Detecta tu navegador, descarga el driver correcto y lo gestiona\n",
    "\n",
    "!pip install webdriver-manager\n",
    "\n",
    "# VENTAJAS PARA CIENCIA DE DATOS:\n",
    "# - C√≥digo portable: funciona en cualquier m√°quina sin configuraci√≥n manual\n",
    "# - Siempre actualizado: descarga la versi√≥n compatible con tu navegador\n",
    "# - Menos errores: evita problemas de incompatibilidad de versiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 3: Importar librer√≠as necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELDA 3: IMPORTAR LIBRER√çAS NECESARIAS\n",
    "# ========================================\n",
    "\n",
    "# --- IMPORTACIONES DE SELENIUM ---\n",
    "\n",
    "# webdriver: El m√≥dulo principal que controla el navegador\n",
    "from selenium import webdriver\n",
    "\n",
    "# By: Clase que define C√ìMO buscar elementos en la p√°gina\n",
    "# Ejemplo: By.ID, By.CSS_SELECTOR, By.XPATH, etc.\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Keys: Simula teclas del teclado (Enter, Tab, flechas, etc.)\n",
    "# √ötil para enviar formularios o navegar con teclado\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "# WebDriverWait: Implementa ESPERAS INTELIGENTES\n",
    "# Espera hasta que se cumpla una condici√≥n (elemento visible, clickeable, etc.)\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "# expected_conditions (EC): Condiciones predefinidas para usar con WebDriverWait\n",
    "# Ejemplo: element_to_be_clickable, presence_of_element_located, etc.\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Service: Maneja el servicio del driver del navegador\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "# ChromeDriverManager: Descarga y configura autom√°ticamente el driver de Chrome\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# --- IMPORTACIONES PARA CIENCIA DE DATOS ---\n",
    "\n",
    "# pandas: Manipulaci√≥n de datos en formato tabular (DataFrames)\n",
    "# Lo usaremos para almacenar y procesar los datos scrapeados\n",
    "import pandas as pd\n",
    "\n",
    "# numpy: Operaciones num√©ricas y arrays\n",
    "# Complementa pandas para an√°lisis num√©rico\n",
    "import numpy as np\n",
    "\n",
    "# time: Control de tiempos y pausas\n",
    "# √ötil para dar tiempo a que las p√°ginas carguen completamente\n",
    "import time\n",
    "\n",
    "print(\"Todas las librer√≠as importadas correctamente\")\n",
    "\n",
    "# CONSEJO PEDAG√ìGICO:\n",
    "# Si alguna importaci√≥n falla, significa que la librer√≠a no est√° instalada.\n",
    "# Vuelve a las celdas anteriores y ejecuta los pip install correspondientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Conceptos B√°sicos <a name=\"conceptos-basicos\"></a>\n",
    "\n",
    "### 3.1 Inicializar el navegador\n",
    "\n",
    "El primer paso es crear una instancia del navegador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELDA 4: INICIALIZAR EL NAVEGADOR CHROME\n",
    "# ========================================\n",
    "\n",
    "# PASO 1: Configurar las opciones de Chrome\n",
    "# ChromeOptions() permite personalizar c√≥mo se ejecuta el navegador\n",
    "options = webdriver.ChromeOptions()\n",
    "\n",
    "# OPCI√ìN 1: Modo headless (sin interfaz gr√°fica)\n",
    "# Descomenta la siguiente l√≠nea si quieres que el navegador se ejecute en segundo plano\n",
    "# √ötil para servidores o cuando no necesitas ver el navegador\n",
    "# options.add_argument('--headless')\n",
    "\n",
    "# OPCI√ìN 2: Desactivar detecci√≥n de automatizaci√≥n\n",
    "# Algunos sitios detectan que Selenium est√° controlando el navegador\n",
    "# Esta opci√≥n ayuda a que el navegador parezca \"normal\"\n",
    "options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "\n",
    "# OPCI√ìN 3: Iniciar maximizado\n",
    "# Abre el navegador en pantalla completa\n",
    "# √ötil para asegurar que todos los elementos sean visibles\n",
    "options.add_argument('--start-maximized')\n",
    "\n",
    "# PASO 2: Inicializar el driver (el controlador del navegador)\n",
    "# Esto ABRE el navegador Chrome y te da control sobre √©l\n",
    "driver = webdriver.Chrome(\n",
    "    # Service: Configura el servicio del driver\n",
    "    # ChromeDriverManager().install(): Descarga autom√°ticamente el driver correcto\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    \n",
    "    # Aplica las opciones que configuramos arriba\n",
    "    options=options\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Navegador Chrome iniciado correctamente\")\n",
    "\n",
    "# QU√â EST√Å PASANDO EN SEGUNDO PLANO:\n",
    "# 1. ChromeDriverManager verifica tu versi√≥n de Chrome\n",
    "# 2. Descarga el chromedriver compatible (si no lo tiene)\n",
    "# 3. Chrome se abre y queda bajo control de Python\n",
    "# 4. Ahora puedes enviar comandos al navegador usando 'driver'\n",
    "\n",
    "# IMPORTANTE PARA LA CLASE:\n",
    "# - 'driver' es tu ROBOT que controla el navegador\n",
    "# - Todo lo que hagas con Selenium usa este objeto 'driver'\n",
    "# - Ejemplo: driver.get(), driver.find_element(), etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Abrir una p√°gina web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELDA 5: NAVEGAR A UNA P√ÅGINA WEB\n",
    "# ========================================\n",
    "\n",
    "# PASO 1: Definir la URL que queremos visitar\n",
    "# En este caso, vamos a Wikipedia (sitio perfecto para practicar web scraping)\n",
    "url = \"https://www.wikipedia.org\"\n",
    "\n",
    "# PASO 2: Usar driver.get() para navegar a la URL\n",
    "# Esto es equivalente a escribir la URL en la barra de direcciones y presionar Enter\n",
    "driver.get(url)\n",
    "\n",
    "# QU√â HACE driver.get():\n",
    "# 1. Navega a la URL especificada\n",
    "# 2. Espera a que la p√°gina cargue completamente (carga inicial del HTML)\n",
    "# 3. Devuelve el control una vez cargada\n",
    "\n",
    "# PASO 3: Obtener el t√≠tulo de la p√°gina\n",
    "# La propiedad driver.title devuelve el contenido de la etiqueta <title> del HTML\n",
    "# Esto es √∫til para verificar que estamos en la p√°gina correcta\n",
    "print(f\"T√≠tulo de la p√°gina: {driver.title}\")\n",
    "\n",
    "# PASO 4: Obtener la URL actual\n",
    "# driver.current_url devuelve la URL en la que estamos ahora\n",
    "# Puede ser diferente a la URL original si hubo redirecciones\n",
    "print(f\"URL actual: {driver.current_url}\")\n",
    "\n",
    "# APLICACI√ìN EN CIENCIA DE DATOS:\n",
    "# Verificar el t√≠tulo y URL nos ayuda a:\n",
    "# - Confirmar que la navegaci√≥n fue exitosa\n",
    "# - Detectar redirecciones inesperadas\n",
    "# - Validar que estamos en la p√°gina correcta antes de extraer datos\n",
    "# - Debugging: si algo falla, sabemos d√≥nde estamos realmente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Cerrar el navegador\n",
    "\n",
    "**Importante:** Siempre cierra el navegador al terminar para liberar recursos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cerrar la pesta√±a actual\n",
    "# driver.close()\n",
    "\n",
    "# Cerrar el navegador completamente\n",
    "# driver.quit()\n",
    "\n",
    "print(\"üí° No ejecutes esto a√∫n, lo usaremos al final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Navegaci√≥n Web <a name=\"navegacion\"></a>\n",
    "\n",
    "### 4.1 Operaciones b√°sicas de navegaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reiniciar el driver si es necesario\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=options\n",
    ")\n",
    "\n",
    "# Navegar a diferentes p√°ginas\n",
    "driver.get(\"https://www.wikipedia.org\")\n",
    "time.sleep(2)\n",
    "\n",
    "driver.get(\"https://www.python.org\")\n",
    "time.sleep(2)\n",
    "\n",
    "# Retroceder\n",
    "driver.back()\n",
    "time.sleep(1)\n",
    "print(f\"Despu√©s de retroceder: {driver.title}\")\n",
    "\n",
    "# Avanzar\n",
    "driver.forward()\n",
    "time.sleep(1)\n",
    "print(f\"Despu√©s de avanzar: {driver.title}\")\n",
    "\n",
    "# Refrescar la p√°gina\n",
    "driver.refresh()\n",
    "print(\"P√°gina refrescada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Capturas de pantalla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomar una captura de pantalla\n",
    "driver.get(\"https://www.wikipedia.org\")\n",
    "time.sleep(2)\n",
    "\n",
    "driver.save_screenshot(\"captura_wikipedia.png\")\n",
    "print(\"‚úÖ Captura de pantalla guardada como 'captura_wikipedia.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Localizaci√≥n de Elementos <a name=\"localizacion\"></a>\n",
    "\n",
    "### 5.1 M√©todos de localizaci√≥n\n",
    "\n",
    "Selenium ofrece varias formas de encontrar elementos en una p√°gina:\n",
    "\n",
    "| M√©todo | Descripci√≥n | Ejemplo |\n",
    "|--------|-------------|----------|\n",
    "| `By.ID` | Por el atributo id | `driver.find_element(By.ID, \"search\")` |\n",
    "| `By.NAME` | Por el atributo name | `driver.find_element(By.NAME, \"q\")` |\n",
    "| `By.CLASS_NAME` | Por la clase CSS | `driver.find_element(By.CLASS_NAME, \"btn\")` |\n",
    "| `By.TAG_NAME` | Por la etiqueta HTML | `driver.find_element(By.TAG_NAME, \"h1\")` |\n",
    "| `By.CSS_SELECTOR` | Por selector CSS | `driver.find_element(By.CSS_SELECTOR, \"div.container\")` |\n",
    "| `By.XPATH` | Por expresi√≥n XPath | `driver.find_element(By.XPATH, \"//div[@id='content']\")` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Ejemplos pr√°cticos de localizaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELDA 6: LOCALIZAR ELEMENTOS EN LA P√ÅGINA\n",
    "# ========================================\n",
    "\n",
    "# CONTEXTO: Estamos en la p√°gina principal de Wikipedia\n",
    "# Ahora vamos a aprender a ENCONTRAR elementos espec√≠ficos en la p√°gina\n",
    "\n",
    "# Navegar a Wikipedia\n",
    "driver.get(\"https://www.wikipedia.org\")\n",
    "time.sleep(2)  # Pausa de 2 segundos para asegurar que la p√°gina carg√≥\n",
    "\n",
    "# --- EJEMPLO 1: Localizar por ID ---\n",
    "# El ID es √∫nico en toda la p√°gina, es la forma M√ÅS R√ÅPIDA y CONFIABLE\n",
    "# Equivale a: document.getElementById(\"searchInput\") en JavaScript\n",
    "\n",
    "search_box = driver.find_element(By.ID, \"searchInput\")\n",
    "print(f\"‚úÖ Caja de b√∫squeda encontrada: {search_box.tag_name}\")\n",
    "\n",
    "# EXPLICACI√ìN:\n",
    "# - find_element() busca UN SOLO elemento (el primero que encuentre)\n",
    "# - By.ID indica que buscaremos por el atributo 'id' del HTML\n",
    "# - \"searchInput\" es el valor del id que buscamos: <input id=\"searchInput\">\n",
    "# - tag_name nos dice qu√© tipo de elemento HTML es (probablemente 'input')\n",
    "\n",
    "\n",
    "# --- EJEMPLO 2: Localizar por CSS Selector ---\n",
    "# Los selectores CSS son muy potentes y flexibles\n",
    "# Si conoces CSS, este m√©todo te resultar√° familiar\n",
    "\n",
    "try:\n",
    "    # Intentar varios selectores que Wikipedia usa\n",
    "    logo = driver.find_element(By.CSS_SELECTOR, \".central-featured\")\n",
    "    print(f\"‚úÖ Secci√≥n central encontrada\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è Selector espec√≠fico no encontrado (la estructura puede variar)\")\n",
    "\n",
    "# EXPLICACI√ìN:\n",
    "# - \".central-featured\" busca elementos con la clase CSS \"central-featured\"\n",
    "# - El punto (.) indica que es una clase\n",
    "# - CSS Selector puede ser muy espec√≠fico: \"div.clase #id > p\"\n",
    "# - IMPORTANTE: Los selectores pueden cambiar si el sitio actualiza su dise√±o\n",
    "\n",
    "\n",
    "# --- EJEMPLO 3: Localizar M√öLTIPLES elementos ---\n",
    "# find_elements() (plural) encuentra TODOS los elementos que coinciden\n",
    "\n",
    "# Buscar todos los enlaces en la p√°gina principal\n",
    "language_links = driver.find_elements(By.CSS_SELECTOR, \"a.link-box\")\n",
    "if len(language_links) > 0:\n",
    "    print(f\"‚úÖ Se encontraron {len(language_links)} enlaces de idiomas\")\n",
    "else:\n",
    "    # Plan B: buscar todos los enlaces en general\n",
    "    all_links = driver.find_elements(By.TAG_NAME, \"a\")\n",
    "    print(f\"‚úÖ Se encontraron {len(all_links)} enlaces en total en la p√°gina\")\n",
    "\n",
    "# DIFERENCIA CLAVE:\n",
    "# - find_element()  -> Devuelve 1 elemento (o error si no existe)\n",
    "# - find_elements() -> Devuelve una LISTA de elementos (puede ser vac√≠a)\n",
    "\n",
    "# APLICACI√ìN EN CIENCIA DE DATOS:\n",
    "# - Usar find_elements() para extraer m√∫ltiples productos, art√≠culos, precios, etc.\n",
    "# - Luego iterar sobre la lista para procesar cada elemento\n",
    "# - Ejemplo: extraer todos los t√≠tulos de noticias, todos los precios de productos\n",
    "\n",
    "# CONSEJO PEDAG√ìGICO:\n",
    "# Para encontrar el selector correcto:\n",
    "# 1. Abre las DevTools del navegador (F12)\n",
    "# 2. Click en el inspector de elementos (icono de flecha)\n",
    "# 3. Click en el elemento que quieres\n",
    "# 4. Click derecho en el HTML -> Copy -> Copy selector\n",
    "\n",
    "# IMPORTANTE: Siempre usa try-except cuando busques elementos espec√≠ficos\n",
    "# porque los sitios web cambian frecuentemente su estructura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Interactuar con elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELDA 7: INTERACTUAR CON ELEMENTOS (ESCRIBIR)\n",
    "# ========================================\n",
    "\n",
    "# Una vez que ENCONTRAMOS un elemento, podemos INTERACTUAR con √©l\n",
    "# Las interacciones m√°s comunes son: escribir texto, hacer click, enviar formularios\n",
    "\n",
    "# PASO 1: Localizar el campo de b√∫squeda\n",
    "search_box = driver.find_element(By.ID, \"searchInput\")\n",
    "\n",
    "# PASO 2: Limpiar el campo (por si tiene texto previo)\n",
    "search_box.clear()\n",
    "# clear() vac√≠a completamente el campo de texto\n",
    "# Buena pr√°ctica: siempre limpiar antes de escribir\n",
    "\n",
    "# PASO 3: Escribir texto en el campo\n",
    "search_box.send_keys(\"Python programming\")\n",
    "print(\"‚úÖ Texto ingresado en la b√∫squeda\")\n",
    "\n",
    "# EXPLICACI√ìN de send_keys():\n",
    "# - Simula que un usuario escribe en el teclado\n",
    "# - Escribe car√°cter por car√°cter (como un humano)\n",
    "# - Puede recibir texto normal o teclas especiales (Keys.ENTER, Keys.TAB, etc.)\n",
    "# - Es m√°s realista que simplemente cambiar el valor del campo\n",
    "\n",
    "\n",
    "# PASO 4: Enviar el formulario presionando Enter\n",
    "search_box.send_keys(Keys.RETURN)\n",
    "# Keys.RETURN simula presionar la tecla Enter\n",
    "# Esto env√≠a el formulario de b√∫squeda\n",
    "\n",
    "time.sleep(3)  # Esperar 3 segundos para que cargue la p√°gina de resultados\n",
    "\n",
    "print(f\"Navegado a: {driver.title}\")\n",
    "\n",
    "# ALTERNATIVAS para enviar formularios:\n",
    "# 1. send_keys(Keys.RETURN) - Presionar Enter (lo que usamos aqu√≠)\n",
    "# 2. elemento.submit() - Enviar el formulario directamente\n",
    "# 3. Hacer click en el bot√≥n de b√∫squeda\n",
    "\n",
    "# APLICACI√ìN EN CIENCIA DE DATOS:\n",
    "# - Automatizar b√∫squedas: buscar m√∫ltiples t√©rminos y recopilar resultados\n",
    "# - Rellenar formularios: extraer datos de sitios que requieren login\n",
    "# - Filtrar datos: seleccionar fechas, categor√≠as, etc. antes de extraer\n",
    "# \n",
    "# EJEMPLO DE USO REAL:\n",
    "# for termino in [\"Python\", \"Machine Learning\", \"Data Science\"]:\n",
    "#     search_box.clear()\n",
    "#     search_box.send_keys(termino)\n",
    "#     search_box.send_keys(Keys.RETURN)\n",
    "#     # ... extraer resultados ...\n",
    "#     # ... guardar en DataFrame ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Hacer click en elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresar a la p√°gina principal\n",
    "driver.get(\"https://www.wikipedia.org\")\n",
    "time.sleep(2)\n",
    "\n",
    "# Encontrar y hacer click en el enlace de espa√±ol\n",
    "try:\n",
    "    # M√©todo 1: Intentar por ID espec√≠fico\n",
    "    spanish_link = driver.find_element(By.XPATH, \"//a[@id='js-link-box-es']\")\n",
    "    spanish_link.click()\n",
    "    time.sleep(2)\n",
    "    print(f\"‚úÖ Click exitoso. Ahora en: {driver.title}\")\n",
    "except:\n",
    "    try:\n",
    "        # M√©todo 2: Buscar el enlace que contiene \"Espa√±ol\"\n",
    "        spanish_link = driver.find_element(By.XPATH, \"//a[contains(@href, 'es.wikipedia.org')]\")\n",
    "        spanish_link.click()\n",
    "        time.sleep(2)\n",
    "        print(f\"‚úÖ Click exitoso usando m√©todo alternativo. Ahora en: {driver.title}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è No se pudo hacer click en el enlace: {e}\")\n",
    "        print(\"Esto puede pasar si Wikipedia cambi√≥ su estructura HTML\")\n",
    "\n",
    "# EXPLICACI√ìN DE LOS M√âTODOS:\n",
    "# M√©todo 1: Busca por ID exacto (m√°s espec√≠fico pero puede cambiar)\n",
    "# M√©todo 2: Busca cualquier enlace que contenga 'es.wikipedia.org' (m√°s flexible)\n",
    "#\n",
    "# LECCI√ìN IMPORTANTE:\n",
    "# Siempre ten un Plan B cuando trabajes con selectores\n",
    "# Los sitios web actualizan su c√≥digo HTML frecuentemente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Extracci√≥n de Datos <a name=\"extraccion\"></a>\n",
    "\n",
    "### 6.1 Extraer texto de elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navegar a la Wikipedia en espa√±ol\n",
    "driver.get(\"https://es.wikipedia.org\")\n",
    "time.sleep(2)\n",
    "\n",
    "# Extraer el t√≠tulo principal\n",
    "try:\n",
    "    # Intentar m√©todo 1: por clase espec√≠fica\n",
    "    titulo = driver.find_element(By.CSS_SELECTOR, \"img.central-featured-logo\")\n",
    "    print(f\"T√≠tulo (alt text): {titulo.get_attribute('alt')}\")\n",
    "except:\n",
    "    try:\n",
    "        # M√©todo 2: por el t√≠tulo de la p√°gina\n",
    "        print(f\"T√≠tulo de la p√°gina: {driver.title}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error al extraer t√≠tulo: {e}\")\n",
    "\n",
    "# Extraer art√≠culos destacados\n",
    "# NOTA: La estructura de Wikipedia cambia, usaremos selectores m√°s gen√©ricos\n",
    "try:\n",
    "    # Buscar en la secci√≥n de art√≠culo destacado\n",
    "    featured_section = driver.find_element(By.ID, \"mp-tfa\")\n",
    "    # Buscar enlaces dentro de esa secci√≥n\n",
    "    featured_articles = featured_section.find_elements(By.TAG_NAME, \"a\")\n",
    "    \n",
    "    print(\"\\nüì∞ Enlaces en art√≠culo destacado:\")\n",
    "    for article in featured_articles[:3]:  # Primeros 3 enlaces\n",
    "        if article.text.strip():  # Solo mostrar si tiene texto\n",
    "            print(f\"  - {article.text}\")\n",
    "except:\n",
    "    print(\"\\n‚ö†Ô∏è No se encontr√≥ la secci√≥n de art√≠culos destacados\")\n",
    "    print(\"Esto es normal: Wikipedia cambia su estructura frecuentemente\")\n",
    "\n",
    "# LECCI√ìN IMPORTANTE PARA LA CLASE:\n",
    "# En web scraping real, SIEMPRE debes:\n",
    "# 1. Usar try-except para manejar cambios en la estructura\n",
    "# 2. Tener m√©todos alternativos de extracci√≥n\n",
    "# 3. Verificar peri√≥dicamente que tus scrapers sigan funcionando\n",
    "# 4. Usar selectores lo m√°s gen√©ricos posible (cuando sea apropiado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Extraer atributos de elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# EXTRAER ENLACES Y ATRIBUTOS\n",
    "# ========================================\n",
    "\n",
    "# Buscar enlaces en la secci√≥n principal de Wikipedia\n",
    "try:\n",
    "    # Buscar en la secci√≥n de art√≠culo destacado\n",
    "    tfa_section = driver.find_element(By.ID, \"mp-tfa\")\n",
    "    links = tfa_section.find_elements(By.TAG_NAME, \"a\")\n",
    "except:\n",
    "    # Si no encuentra esa secci√≥n, buscar en toda la p√°gina\n",
    "    links = driver.find_elements(By.CSS_SELECTOR, \"#content a\")\n",
    "\n",
    "print(\"üîó Enlaces encontrados:\")\n",
    "\n",
    "# Contador para limitar la salida\n",
    "count = 0\n",
    "for link in links:\n",
    "    texto = link.text.strip()\n",
    "    url = link.get_attribute(\"href\")\n",
    "    \n",
    "    # Solo mostrar enlaces con texto y URL v√°lida\n",
    "    if texto and url and count < 5:  # Limitar a 5 para no saturar la salida\n",
    "        print(f\"  Texto: {texto}\")\n",
    "        print(f\"  URL: {url}\\n\")\n",
    "        count += 1\n",
    "\n",
    "if count == 0:\n",
    "    print(\"  ‚ö†Ô∏è No se encontraron enlaces con texto en esta secci√≥n\")\n",
    "\n",
    "# CONCEPTOS CLAVE:\n",
    "# - .text -> Obtiene el TEXTO VISIBLE del elemento\n",
    "# - .get_attribute(\"href\") -> Obtiene el ATRIBUTO href (la URL del enlace)\n",
    "# - Otros atributos √∫tiles: \"class\", \"id\", \"src\" (para im√°genes), \"value\" (para inputs)\n",
    "\n",
    "# APLICACI√ìN EN CIENCIA DE DATOS:\n",
    "# Extraer:\n",
    "# - URLs de productos para visitar despu√©s\n",
    "# - Precios de elementos (get_attribute(\"data-price\"))\n",
    "# - IDs √∫nicos para seguimiento\n",
    "# - Clases CSS para categorizaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Esperas expl√≠citas (muy importante)\n",
    "\n",
    "Las esperas expl√≠citas son cruciales para trabajar con contenido din√°mico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELDA 8: ESPERAS EXPL√çCITAS (MUY IMPORTANTE)\n",
    "# ========================================\n",
    "\n",
    "# ‚ö†Ô∏è PROBLEMA CON time.sleep():\n",
    "# - time.sleep(5) siempre espera 5 segundos, aunque la p√°gina cargue en 1 segundo\n",
    "# - Si la p√°gina tarda m√°s de 5 segundos, el c√≥digo fallar√°\n",
    "# - Es INEFICIENTE y NO CONFIABLE\n",
    "\n",
    "# ‚úÖ SOLUCI√ìN: ESPERAS EXPL√çCITAS (WebDriverWait)\n",
    "# - Espera SOLO hasta que se cumpla una condici√≥n\n",
    "# - Si la condici√≥n se cumple antes, contin√∫a inmediatamente\n",
    "# - Si no se cumple en el tiempo l√≠mite, lanza una excepci√≥n\n",
    "# - Es EFICIENTE y CONFIABLE\n",
    "\n",
    "driver.get(\"https://es.wikipedia.org\")\n",
    "\n",
    "try:\n",
    "    # EJEMPLO 1: Esperar hasta que un elemento EXISTA en el DOM\n",
    "    # WebDriverWait(driver, 10) -> Espera M√ÅXIMO 10 segundos\n",
    "    # until() -> Espera hasta que la condici√≥n sea True\n",
    "    # presence_of_element_located -> El elemento existe en el HTML\n",
    "    \n",
    "    search_input = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.ID, \"searchInput\"))\n",
    "    )\n",
    "    print(\"‚úÖ Elemento de b√∫squeda encontrado con espera expl√≠cita\")\n",
    "    \n",
    "    # QU√â HACE ESTO:\n",
    "    # 1. Busca el elemento cada 0.5 segundos (por defecto)\n",
    "    # 2. Si lo encuentra, devuelve el elemento inmediatamente\n",
    "    # 3. Si pasan 10 segundos y no lo encuentra, lanza TimeoutException\n",
    "    \n",
    "    \n",
    "    # EJEMPLO 2: Esperar hasta que un elemento sea CLICKEABLE\n",
    "    # element_to_be_clickable verifica que:\n",
    "    # - El elemento existe\n",
    "    # - Es visible\n",
    "    # - Est√° habilitado (no disabled)\n",
    "    \n",
    "    search_button = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.CSS_SELECTOR, \"button[type='submit']\"))\n",
    "    )\n",
    "    print(\"‚úÖ Bot√≥n de b√∫squeda es clickeable\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error en espera: {e}\")\n",
    "\n",
    "# OTRAS CONDICIONES √öTILES:\n",
    "# - visibility_of_element_located: Elemento visible (no oculto con CSS)\n",
    "# - invisibility_of_element_located: Elemento NO visible\n",
    "# - text_to_be_present_in_element: Texto espec√≠fico presente\n",
    "# - element_to_be_selected: Checkbox/radio seleccionado\n",
    "# - staleness_of: Elemento ya no est√° en el DOM\n",
    "\n",
    "# POR QU√â ES CRUCIAL EN CIENCIA DE DATOS:\n",
    "# - Sitios modernos cargan datos con JavaScript (AJAX)\n",
    "# - Los datos pueden tardar tiempo en aparecer\n",
    "# - Sin esperas expl√≠citas, extraer√°s datos incompletos o vac√≠os\n",
    "# - Las esperas expl√≠citas garantizan que los datos est√©n listos\n",
    "\n",
    "# REGLA DE ORO:\n",
    "# ‚ùå NO uses time.sleep() para esperar elementos\n",
    "# ‚úÖ USA WebDriverWait con expected_conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Web Scraping Avanzado <a name=\"scraping-avanzado\"></a>\n",
    "\n",
    "### 7.1 Scroll en la p√°gina\n",
    "\n",
    "Muchas p√°ginas cargan contenido al hacer scroll:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navegar a una p√°gina\n",
    "# Abre la URL de Wikipedia sobre Python en el navegador controlado por Selenium\n",
    "driver.get(\"https://es.wikipedia.org/wiki/Python\")\n",
    "# Pausa la ejecuci√≥n durante 2 segundos para permitir que la p√°gina cargue completamente\n",
    "time.sleep(2)\n",
    "\n",
    "# Scroll hacia abajo\n",
    "# Ejecuta c√≥digo JavaScript que desplaza la ventana hasta el final de la p√°gina\n",
    "# scrollHeight obtiene la altura total del documento\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "# Espera 1 segundo despu√©s del desplazamiento\n",
    "time.sleep(1)\n",
    "print(\"‚úÖ Scroll hacia abajo completado\")\n",
    "\n",
    "# Scroll hacia arriba\n",
    "# Ejecuta JavaScript para volver al inicio de la p√°gina (posici√≥n 0,0)\n",
    "driver.execute_script(\"window.scrollTo(0, 0);\")\n",
    "# Pausa de 1 segundo para visualizar el movimiento\n",
    "time.sleep(1)\n",
    "print(\"‚úÖ Scroll hacia arriba completado\")\n",
    "\n",
    "# Scroll a un elemento espec√≠fico\n",
    "try:\n",
    "    # Intenta localizar un elemento HTML con el ID \"Historia\"\n",
    "    elemento = driver.find_element(By.ID, \"Historia\")\n",
    "    # Ejecuta JavaScript para hacer scroll hasta que el elemento sea visible\n",
    "    # scrollIntoView(true) alinea el elemento en la parte superior de la ventana\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView(true);\", elemento)\n",
    "    # Espera 1 segundo despu√©s del desplazamiento\n",
    "    time.sleep(1)\n",
    "    print(\"‚úÖ Scroll a elemento espec√≠fico completado\")\n",
    "except:\n",
    "    # Si el elemento no existe o hay alg√∫n error, muestra este mensaje\n",
    "    print(\"Elemento no encontrado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Manejar m√∫ltiples pesta√±as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrir una nueva pesta√±a\n",
    "driver.execute_script(\"window.open('https://www.python.org', '_blank');\")\n",
    "time.sleep(2)\n",
    "\n",
    "# Obtener todas las pesta√±as\n",
    "tabs = driver.window_handles\n",
    "print(f\"N√∫mero de pesta√±as abiertas: {len(tabs)}\")\n",
    "\n",
    "# Cambiar a la segunda pesta√±a\n",
    "driver.switch_to.window(tabs[1])\n",
    "print(f\"Pesta√±a activa: {driver.title}\")\n",
    "time.sleep(2)\n",
    "\n",
    "# Volver a la primera pesta√±a\n",
    "driver.switch_to.window(tabs[0])\n",
    "print(f\"Pesta√±a activa: {driver.title}\")\n",
    "\n",
    "# Cerrar la segunda pesta√±a\n",
    "driver.switch_to.window(tabs[1])\n",
    "driver.close()\n",
    "driver.switch_to.window(tabs[0])\n",
    "print(\"‚úÖ Segunda pesta√±a cerrada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Extraer tablas HTML a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELDA 9: EXTRAER TABLAS HTML A DATAFRAME\n",
    "# ========================================\n",
    "\n",
    "# üéØ OBJETIVO: Convertir una tabla HTML en un DataFrame de pandas\n",
    "# Esto es FUNDAMENTAL en ciencia de datos porque muchos datos est√°n en tablas web\n",
    "\n",
    "# PASO 1: Navegar a una p√°gina con tablas\n",
    "driver.get(\"https://es.wikipedia.org/wiki/Anexo:Pa%C3%ADses_por_poblaci%C3%B3n\")\n",
    "time.sleep(3)  # Dar tiempo a que cargue la tabla\n",
    "\n",
    "try:\n",
    "    # PASO 2: Localizar la tabla usando CSS Selector\n",
    "    # \"table.wikitable\" busca una tabla con la clase \"wikitable\"\n",
    "    tabla = driver.find_element(By.CSS_SELECTOR, \"table.wikitable\")\n",
    "    \n",
    "    # PASO 3: Extraer los ENCABEZADOS de la tabla\n",
    "    encabezados = []\n",
    "    # Las etiquetas <th> contienen los encabezados de las columnas\n",
    "    headers = tabla.find_elements(By.TAG_NAME, \"th\")\n",
    "    \n",
    "    for header in headers[:5]:  # Solo los primeros 5 encabezados\n",
    "        # .strip() elimina espacios en blanco al inicio y final\n",
    "        encabezados.append(header.text.strip())\n",
    "    \n",
    "    # QU√â HICIMOS:\n",
    "    # - Encontramos todos los <th> dentro de la tabla\n",
    "    # - Extraemos el texto de cada uno\n",
    "    # - Los guardamos en una lista que ser√° el header del DataFrame\n",
    "    \n",
    "    \n",
    "    # PASO 4: Extraer las FILAS de datos\n",
    "    filas = []\n",
    "    # Las etiquetas <tr> representan filas (table row)\n",
    "    rows = tabla.find_elements(By.TAG_NAME, \"tr\")\n",
    "    \n",
    "    # Iteramos sobre las filas (saltamos la primera que son encabezados)\n",
    "    for row in rows[1:11]:  # Filas 1 a 10 (primeros 10 pa√≠ses)\n",
    "        # Las etiquetas <td> son las celdas de datos (table data)\n",
    "        celdas = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        \n",
    "        # Verificar que la fila tiene suficientes celdas\n",
    "        if len(celdas) >= 3:\n",
    "            # Extraer el texto de cada celda (primeras 5 columnas)\n",
    "            fila_datos = [celda.text.strip() for celda in celdas[:5]]\n",
    "            # A√±adir la fila a nuestra lista\n",
    "            filas.append(fila_datos)\n",
    "    \n",
    "    # ESTRUCTURA HTML DE UNA TABLA:\n",
    "    # <table>\n",
    "    #   <tr>                    <- Fila\n",
    "    #     <th>Encabezado 1</th> <- Celda de encabezado\n",
    "    #     <th>Encabezado 2</th>\n",
    "    #   </tr>\n",
    "    #   <tr>\n",
    "    #     <td>Dato 1</td>        <- Celda de datos\n",
    "    #     <td>Dato 2</td>\n",
    "    #   </tr>\n",
    "    # </table>\n",
    "    \n",
    "    \n",
    "    # PASO 5: Crear el DataFrame de pandas\n",
    "    df = pd.DataFrame(filas, columns=encabezados if encabezados else None)\n",
    "    \n",
    "    print(\"‚úÖ Tabla extra√≠da exitosamente\\\\n\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # AHORA TIENES UN DATAFRAME CON LOS DATOS DE LA TABLA WEB!\n",
    "    # Puedes hacer an√°lisis, limpiar datos, exportar a CSV, etc.\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error al extraer tabla: {e}\")\n",
    "\n",
    "# APLICACIONES EN CIENCIA DE DATOS:\n",
    "# 1. Extraer tablas de estad√≠sticas deportivas\n",
    "# 2. Recopilar datos financieros de sitios de bolsa\n",
    "# 3. Obtener rankings de universidades, empresas, etc.\n",
    "# 4. Compilar datos demogr√°ficos de m√∫ltiples fuentes\n",
    "# 5. Crear datasets para Machine Learning\n",
    "\n",
    "# SIGUIENTE PASO T√çPICO:\n",
    "# df.to_csv('paises_poblacion.csv', index=False)  # Guardar a CSV\n",
    "# df.describe()  # An√°lisis estad√≠stico\n",
    "# df.plot()  # Visualizaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Caso Pr√°ctico Completo <a name=\"caso-practico\"></a>\n",
    "\n",
    "### Proyecto: Extraer datos de b√∫squeda de Wikipedia\n",
    "\n",
    "Vamos a crear un scraper que:\n",
    "1. Busca un t√©rmino en Wikipedia\n",
    "2. Extrae informaci√≥n de los resultados\n",
    "3. Guarda los datos en un DataFrame\n",
    "4. Exporta a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_wikipedia(termino_busqueda, num_resultados=5):\n",
    "    \"\"\"\n",
    "    ========================================\n",
    "    CASO PR√ÅCTICO COMPLETO: SCRAPER DE WIKIPEDIA\n",
    "    ========================================\n",
    "    \n",
    "    Esta funci√≥n demuestra un FLUJO COMPLETO de web scraping para ciencia de datos:\n",
    "    1. Configurar el navegador\n",
    "    2. Navegar a un sitio web\n",
    "    3. Realizar una b√∫squeda\n",
    "    4. Extraer datos estructurados\n",
    "    5. Limpiar y organizar los datos\n",
    "    6. Retornar un DataFrame listo para an√°lisis\n",
    "    \n",
    "    Args:\n",
    "        termino_busqueda (str): T√©rmino que queremos investigar\n",
    "        num_resultados (int): Cantidad de resultados a extraer (no usado en esta versi√≥n)\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame con informaci√≥n estructurada del art√≠culo\n",
    "    \"\"\"\n",
    "    \n",
    "    # ==========================================\n",
    "    # PASO 1: CONFIGURACI√ìN DEL NAVEGADOR\n",
    "    # ==========================================\n",
    "    \n",
    "    options = webdriver.ChromeOptions()\n",
    "    \n",
    "    # Opci√≥n anti-detecci√≥n: algunos sitios bloquean bots\n",
    "    options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "    \n",
    "    # Maximizar ventana para asegurar que todos los elementos sean visibles\n",
    "    options.add_argument('--start-maximized')\n",
    "    \n",
    "    # Inicializar el driver con configuraci√≥n autom√°tica\n",
    "    driver = webdriver.Chrome(\n",
    "        service=Service(ChromeDriverManager().install()),\n",
    "        options=options\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # ==========================================\n",
    "        # PASO 2: NAVEGACI√ìN Y B√öSQUEDA\n",
    "        # ==========================================\n",
    "        \n",
    "        # Navegar a Wikipedia en espa√±ol\n",
    "        driver.get(\"https://es.wikipedia.org\")\n",
    "        print(f\"üîç Buscando: {termino_busqueda}\")\n",
    "        \n",
    "        # ESPERA EXPL√çCITA: Asegurar que el campo de b√∫squeda existe\n",
    "        # Esto es M√ÅS CONFIABLE que time.sleep()\n",
    "        search_box = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.ID, \"searchInput\"))\n",
    "        )\n",
    "        \n",
    "        # Limpiar y escribir el t√©rmino de b√∫squeda\n",
    "        search_box.clear()\n",
    "        search_box.send_keys(termino_busqueda)\n",
    "        search_box.send_keys(Keys.RETURN)  # Enviar formulario\n",
    "        \n",
    "        # Esperar a que la p√°gina de resultados cargue\n",
    "        time.sleep(3)\n",
    "        \n",
    "        # ==========================================\n",
    "        # PASO 3: EXTRACCI√ìN DE DATOS\n",
    "        # ==========================================\n",
    "        \n",
    "        # Inicializar lista para almacenar los datos\n",
    "        datos = []\n",
    "        \n",
    "        # --- EXTRAER T√çTULO DEL ART√çCULO ---\n",
    "        try:\n",
    "            # El t√≠tulo principal est√° en un <h1> con id \"firstHeading\"\n",
    "            titulo = driver.find_element(By.ID, \"firstHeading\").text\n",
    "        except:\n",
    "            # Si no se encuentra, usar valor por defecto\n",
    "            titulo = \"No disponible\"\n",
    "        \n",
    "        \n",
    "        # --- EXTRAER PRIMER P√ÅRRAFO (RESUMEN) ---\n",
    "        try:\n",
    "            # Encontrar TODOS los p√°rrafos en el contenido principal\n",
    "            parrafos = driver.find_elements(By.CSS_SELECTOR, \"#mw-content-text p\")\n",
    "            primer_parrafo = \"\"\n",
    "            \n",
    "            # Buscar el primer p√°rrafo con contenido significativo\n",
    "            for p in parrafos:\n",
    "                texto = p.text.strip()\n",
    "                # Filtrar p√°rrafos vac√≠os o muy cortos\n",
    "                if len(texto) > 50:\n",
    "                    # Limitar a 200 caracteres para mantener el DataFrame manejable\n",
    "                    primer_parrafo = texto[:200] + \"...\"\n",
    "                    break\n",
    "        except:\n",
    "            primer_parrafo = \"No disponible\"\n",
    "        \n",
    "        \n",
    "        # --- EXTRAER N√öMERO DE SECCIONES ---\n",
    "        try:\n",
    "            # Los encabezados de secci√≥n tienen la clase \"mw-headline\"\n",
    "            secciones = driver.find_elements(By.CSS_SELECTOR, \".mw-headline\")\n",
    "            num_secciones = len(secciones)\n",
    "            # Este dato nos indica la \"profundidad\" del art√≠culo\n",
    "        except:\n",
    "            num_secciones = 0\n",
    "        \n",
    "        \n",
    "        # --- EXTRAER CATEGOR√çAS ---\n",
    "        try:\n",
    "            # Las categor√≠as est√°n en la parte inferior del art√≠culo\n",
    "            categorias = driver.find_elements(By.CSS_SELECTOR, \"#mw-normal-catlinks ul li\")\n",
    "            # Extraer solo las primeras 3 categor√≠as\n",
    "            lista_categorias = [cat.text for cat in categorias[:3]]\n",
    "            # Unirlas en un string separado por comas\n",
    "            categorias_texto = \", \".join(lista_categorias)\n",
    "        except:\n",
    "            categorias_texto = \"No disponible\"\n",
    "        \n",
    "        \n",
    "        # ==========================================\n",
    "        # PASO 4: ESTRUCTURAR LOS DATOS\n",
    "        # ==========================================\n",
    "        \n",
    "        # Crear un diccionario con los datos extra√≠dos\n",
    "        # Esto facilita la conversi√≥n a DataFrame\n",
    "        datos.append({\n",
    "            'T√≠tulo': titulo,\n",
    "            'Descripci√≥n': primer_parrafo,\n",
    "            'N√∫mero de secciones': num_secciones,\n",
    "            'Categor√≠as': categorias_texto,\n",
    "            'URL': driver.current_url  # URL final (puede haber habido redirecci√≥n)\n",
    "        })\n",
    "        \n",
    "        \n",
    "        # ==========================================\n",
    "        # PASO 5: CONVERTIR A DATAFRAME\n",
    "        # ==========================================\n",
    "        \n",
    "        # pandas.DataFrame convierte nuestra lista de diccionarios en una tabla\n",
    "        df = pd.DataFrame(datos)\n",
    "        \n",
    "        print(f\"‚úÖ Extracci√≥n completada: {len(datos)} resultados\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        # MANEJO DE ERRORES: Si algo falla, mostrar el error\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        # Retornar DataFrame vac√≠o para evitar que el programa se detenga\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    finally:\n",
    "        # ==========================================\n",
    "        # PASO 6: LIMPIEZA (SIEMPRE SE EJECUTA)\n",
    "        # ==========================================\n",
    "        \n",
    "        # IMPORTANTE: Siempre cerrar el navegador para liberar recursos\n",
    "        # finally: se ejecuta SIEMPRE, incluso si hubo un error\n",
    "        driver.quit()\n",
    "\n",
    "# ==========================================\n",
    "# EJECUTAR LA FUNCI√ìN\n",
    "# ==========================================\n",
    "\n",
    "# Buscar informaci√≥n sobre \"Inteligencia Artificial\"\n",
    "df_resultados = buscar_wikipedia(\"Inteligencia Artificial\")\n",
    "\n",
    "print(\"\\\\nüìä Resultados:\")\n",
    "print(df_resultados)\n",
    "\n",
    "# EXPLICACI√ìN PEDAG√ìGICA DEL FLUJO:\n",
    "# 1. Configuramos el navegador con opciones espec√≠ficas\n",
    "# 2. Navegamos a Wikipedia y realizamos una b√∫squeda\n",
    "# 3. Esperamos a que cargue la p√°gina (con esperas expl√≠citas)\n",
    "# 4. Extraemos m√∫ltiples tipos de datos del art√≠culo\n",
    "# 5. Estructuramos los datos en un diccionario\n",
    "# 6. Convertimos a DataFrame para an√°lisis\n",
    "# 7. Cerramos el navegador (limpieza de recursos)\n",
    "\n",
    "# PR√ìXIMOS PASOS:\n",
    "# - Guardar el DataFrame en CSV\n",
    "# - Analizar los datos con pandas\n",
    "# - Crear visualizaciones\n",
    "# - Escalar para buscar m√∫ltiples t√©rminos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar los resultados en CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar en CSV\n",
    "if not df_resultados.empty:\n",
    "    df_resultados.to_csv('resultados_wikipedia.csv', index=False, encoding='utf-8-sig')\n",
    "    print(\"‚úÖ Datos guardados en 'resultados_wikipedia.csv'\")\n",
    "    \n",
    "    # Mostrar informaci√≥n del DataFrame\n",
    "    print(\"\\nüìà Informaci√≥n del dataset:\")\n",
    "    print(df_resultados.info())\n",
    "else:\n",
    "    print(\"‚ùå No hay datos para guardar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Mejores Pr√°cticas <a name=\"mejores-practicas\"></a>\n",
    "\n",
    "### 9.1 Consejos importantes\n",
    "\n",
    "1. **Siempre usa esperas expl√≠citas** en lugar de `time.sleep()`\n",
    "2. **Cierra el navegador** al terminar con `driver.quit()`\n",
    "3. **Usa try-except** para manejar errores\n",
    "4. **Respeta los robots.txt** de los sitios web\n",
    "5. **No sobrecargues los servidores** - a√±ade pausas razonables\n",
    "6. **Usa headless mode** para mejor rendimiento en producci√≥n\n",
    "\n",
    "### 9.2 Funci√≥n completa con mejores pr√°cticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# MEJORES PR√ÅCTICAS: CONTEXT MANAGER\n",
    "# ========================================\n",
    "\n",
    "# PROBLEMA COM√öN:\n",
    "# Si olvidas llamar driver.quit(), el navegador queda abierto consumiendo memoria\n",
    "# Si hay un error en el c√≥digo, driver.quit() puede no ejecutarse\n",
    "\n",
    "# SOLUCI√ìN PROFESIONAL: Context Manager (with statement)\n",
    "\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def selenium_driver(headless=False):\n",
    "    \"\"\"\n",
    "    Context Manager para gestionar autom√°ticamente el ciclo de vida del driver.\n",
    "    \n",
    "    ¬øQU√â ES UN CONTEXT MANAGER?\n",
    "    Es un patr√≥n de dise√±o que garantiza:\n",
    "    - Inicializaci√≥n: Se ejecuta al entrar en el bloque 'with'\n",
    "    - Limpieza: Se ejecuta SIEMPRE al salir, incluso si hay errores\n",
    "    \n",
    "    VENTAJAS:\n",
    "    - No puedes olvidar cerrar el navegador\n",
    "    - El navegador se cierra autom√°ticamente, incluso con errores\n",
    "    - C√≥digo m√°s limpio y profesional\n",
    "    - Previene fugas de memoria\n",
    "    \n",
    "    Args:\n",
    "        headless (bool): Si True, ejecuta Chrome sin interfaz gr√°fica (m√°s r√°pido)\n",
    "    \n",
    "    Yields:\n",
    "        webdriver: Instancia del driver de Chrome lista para usar\n",
    "    \"\"\"\n",
    "    \n",
    "    # CONFIGURACI√ìN DE OPCIONES\n",
    "    options = webdriver.ChromeOptions()\n",
    "    \n",
    "    # Si headless=True, el navegador se ejecuta en segundo plano (sin ventana)\n",
    "    if headless:\n",
    "        options.add_argument('--headless')\n",
    "        # VENTAJA: M√°s r√°pido, ideal para producci√≥n o servidores\n",
    "        # DESVENTAJA: No puedes ver qu√© est√° haciendo\n",
    "    \n",
    "    # Opciones adicionales para mayor estabilidad\n",
    "    options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "    options.add_argument('--start-maximized')\n",
    "    options.add_argument('--disable-gpu')  # Desactivar GPU (√∫til en servidores)\n",
    "    options.add_argument('--no-sandbox')   # Mayor compatibilidad en Linux\n",
    "    \n",
    "    # INICIALIZAR EL DRIVER\n",
    "    driver = webdriver.Chrome(\n",
    "        service=Service(ChromeDriverManager().install()),\n",
    "        options=options\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # YIELD: Devuelve el driver al bloque 'with'\n",
    "        # El c√≥digo dentro del 'with' se ejecuta aqu√≠\n",
    "        yield driver\n",
    "        \n",
    "    finally:\n",
    "        # LIMPIEZA: Se ejecuta SIEMPRE al salir del bloque 'with'\n",
    "        # Incluso si hubo una excepci√≥n en el c√≥digo\n",
    "        driver.quit()\n",
    "        print(\"‚úÖ Navegador cerrado correctamente\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# EJEMPLO DE USO\n",
    "# ==========================================\n",
    "\n",
    "# USO TRADICIONAL (menos seguro):\n",
    "# driver = webdriver.Chrome(...)\n",
    "# driver.get(\"https://...\")\n",
    "# # ... hacer cosas ...\n",
    "# driver.quit()  # ¬øY si hay un error antes de esto?\n",
    "\n",
    "# USO CON CONTEXT MANAGER (recomendado):\n",
    "with selenium_driver(headless=False) as driver:\n",
    "    driver.get(\"https://www.wikipedia.org\")\n",
    "    print(f\"T√≠tulo: {driver.title}\")\n",
    "    # Al salir del bloque 'with', driver.quit() se llama autom√°ticamente\n",
    "\n",
    "# FLUJO DE EJECUCI√ìN:\n",
    "# 1. Se ejecuta el c√≥digo antes de 'yield' (inicializaci√≥n)\n",
    "# 2. Se ejecuta el c√≥digo dentro del bloque 'with'\n",
    "# 3. Se ejecuta el c√≥digo en 'finally' (limpieza)\n",
    "# 4. El navegador SIEMPRE se cierra, no importa qu√© pase\n",
    "\n",
    "# ANALOG√çA PEDAG√ìGICA:\n",
    "# Es como abrir un archivo:\n",
    "# with open('archivo.txt', 'r') as f:\n",
    "#     contenido = f.read()\n",
    "# # El archivo se cierra autom√°ticamente\n",
    "\n",
    "# APLICACI√ìN EN CIENCIA DE DATOS:\n",
    "# - Ejecutar m√∫ltiples scrapers sin preocuparte por la limpieza\n",
    "# - Automatizar procesos en servidores (headless=True)\n",
    "# - C√≥digo m√°s robusto y mantenible\n",
    "# - Prevenir errores de recursos no liberados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Manejo robusto de errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# MANEJO ROBUSTO DE ERRORES\n",
    "# ========================================\n",
    "\n",
    "# En web scraping, MUCHAS cosas pueden salir mal:\n",
    "# - El elemento no existe\n",
    "# - La p√°gina tarda en cargar\n",
    "# - El sitio cambi√≥ su estructura\n",
    "# - Problemas de conexi√≥n\n",
    "\n",
    "# Es CRUCIAL manejar estos errores correctamente\n",
    "\n",
    "from selenium.common.exceptions import (\n",
    "    NoSuchElementException,      # Elemento no encontrado\n",
    "    TimeoutException,             # Tiempo de espera agotado\n",
    "    ElementNotInteractableException  # Elemento no interactuable\n",
    ")\n",
    "\n",
    "def extraer_elemento_seguro(driver, by, value, timeout=10):\n",
    "    \"\"\"\n",
    "    Funci√≥n ROBUSTA para extraer elementos con manejo profesional de errores.\n",
    "    \n",
    "    FILOSOF√çA:\n",
    "    - \"Espera lo mejor, prep√°rate para lo peor\"\n",
    "    - Nunca asumas que un elemento existir√°\n",
    "    - Siempre ten un plan B (valor por defecto)\n",
    "    \n",
    "    Args:\n",
    "        driver: WebDriver de Selenium\n",
    "        by: M√©todo de localizaci√≥n (By.ID, By.CSS_SELECTOR, etc.)\n",
    "        value: Valor del localizador (el selector espec√≠fico)\n",
    "        timeout: Tiempo m√°ximo de espera en segundos (default: 10)\n",
    "    \n",
    "    Returns:\n",
    "        str: Texto del elemento o mensaje de error descriptivo\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # INTENTO 1: Esperar hasta que el elemento est√© presente\n",
    "        # WebDriverWait es m√°s inteligente que time.sleep()\n",
    "        elemento = WebDriverWait(driver, timeout).until(\n",
    "            EC.presence_of_element_located((by, value))\n",
    "        )\n",
    "        return elemento.text\n",
    "        \n",
    "    except TimeoutException:\n",
    "        # ERROR 1: El elemento no apareci√≥ en el tiempo l√≠mite\n",
    "        # Posibles causas:\n",
    "        # - Selector incorrecto\n",
    "        # - P√°gina muy lenta\n",
    "        # - Elemento cargado con JavaScript que tard√≥ m√°s de lo esperado\n",
    "        return f\"‚è±Ô∏è Timeout: Elemento no encontrado en {timeout} segundos\"\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        # ERROR 2: El elemento definitivamente no existe\n",
    "        # Posibles causas:\n",
    "        # - Selector err√≥neo\n",
    "        # - Estructura del sitio cambi√≥\n",
    "        # - Estamos en la p√°gina equivocada\n",
    "        return \"‚ùå Elemento no existe en la p√°gina\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        # ERROR 3: Cualquier otro error inesperado\n",
    "        # Siempre es buena pr√°ctica tener un catch-all\n",
    "        return f\"‚ùå Error inesperado: {str(e)}\"\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# DEMOSTRACI√ìN DE USO\n",
    "# ==========================================\n",
    "\n",
    "with selenium_driver() as driver:\n",
    "    driver.get(\"https://es.wikipedia.org\")\n",
    "    \n",
    "    # --- CASO 1: Elemento que S√ç existe ---\n",
    "    resultado1 = extraer_elemento_seguro(driver, By.ID, \"searchInput\")\n",
    "    print(f\"Resultado 1 (existe): {resultado1[:50] if len(resultado1) > 50 else resultado1}\")\n",
    "    \n",
    "    # --- CASO 2: Elemento que NO existe ---\n",
    "    resultado2 = extraer_elemento_seguro(driver, By.ID, \"elemento_inexistente\", timeout=3)\n",
    "    print(f\"Resultado 2 (no existe): {resultado2}\")\n",
    "\n",
    "# ==========================================\n",
    "# PATR√ìN TRY-EXCEPT EN WEB SCRAPING\n",
    "# ==========================================\n",
    "\n",
    "# PATR√ìN RECOMENDADO para extracci√≥n de datos:\n",
    "\n",
    "# datos = []\n",
    "# for item in items:\n",
    "#     try:\n",
    "#         titulo = item.find_element(By.CSS_SELECTOR, \"h2\").text\n",
    "#     except:\n",
    "#         titulo = \"No disponible\"\n",
    "#     \n",
    "#     try:\n",
    "#         precio = item.find_element(By.CSS_SELECTOR, \".precio\").text\n",
    "#     except:\n",
    "#         precio = \"No disponible\"\n",
    "#     \n",
    "#     datos.append({\n",
    "#         'titulo': titulo,\n",
    "#         'precio': precio\n",
    "#     })\n",
    "\n",
    "# VENTAJAS DE ESTE ENFOQUE:\n",
    "# 1. El scraper NO se detiene si falta un elemento\n",
    "# 2. Recopilas TODOS los datos disponibles, aunque algunos falten\n",
    "# 3. Puedes identificar patrones en los datos faltantes\n",
    "# 4. En ciencia de datos, datos parciales > sin datos\n",
    "\n",
    "# PRINCIPIOS CLAVE:\n",
    "# ‚úÖ Siempre usa try-except para extracciones\n",
    "# ‚úÖ Proporciona valores por defecto sensatos\n",
    "# ‚úÖ Registra los errores para debugging\n",
    "# ‚úÖ No dejes que un error detenga toda la recopilaci√≥n\n",
    "# ‚úÖ Valida los datos despu√©s de extraerlos\n",
    "\n",
    "# COMPARACI√ìN:\n",
    "# C√≥digo SIN manejo de errores:\n",
    "#   precio = elemento.find_element(By.CLASS_NAME, \"precio\").text\n",
    "#   -> Se detiene si el elemento no existe\n",
    "#\n",
    "# C√≥digo CON manejo de errores:\n",
    "#   try:\n",
    "#       precio = elemento.find_element(By.CLASS_NAME, \"precio\").text\n",
    "#   except:\n",
    "#       precio = \"No disponible\"\n",
    "#   -> Contin√∫a incluso si el elemento no existe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  Ejercicios Propuestos\n",
    "\n",
    "1. **Ejercicio 1:** Crea un scraper que extraiga los t√≠tulos de las noticias principales de un sitio de noticias\n",
    "\n",
    "2. **Ejercicio 2:** Extrae una tabla de datos de Wikipedia y realiza un an√°lisis b√°sico con pandas\n",
    "\n",
    "3. **Ejercicio 3:** Automatiza una b√∫squeda en Google y extrae los primeros 10 resultados\n",
    "\n",
    "4. **Ejercicio 4:** Crea un scraper que navegue por m√∫ltiples p√°ginas y compile datos en un CSV\n",
    "\n",
    "---\n",
    "\n",
    "##  Recursos Adicionales\n",
    "\n",
    "- [Documentaci√≥n oficial de Selenium](https://www.selenium.dev/documentation/)\n",
    "- [Selenium con Python](https://selenium-python.readthedocs.io/)\n",
    "- [XPath Cheat Sheet](https://devhints.io/xpath)\n",
    "- [CSS Selectors Reference](https://www.w3schools.com/cssref/css_selectors.asp)\n",
    "\n",
    "---\n",
    "\n",
    "##  Conclusi√≥n\n",
    "\n",
    "¬°Felicidades! Has completado el tutorial de Selenium para Ciencia de Datos. Ahora conoces:\n",
    "\n",
    "- ‚úÖ Configuraci√≥n y uso b√°sico de Selenium\n",
    "- ‚úÖ Localizaci√≥n e interacci√≥n con elementos web\n",
    "- ‚úÖ Extracci√≥n de datos para an√°lisis\n",
    "- ‚úÖ T√©cnicas avanzadas de web scraping\n",
    "- ‚úÖ Mejores pr√°cticas y manejo de errores\n",
    "\n",
    "### Pr√≥ximos pasos:\n",
    "\n",
    "1. Practica con diferentes sitios web\n",
    "2. Combina Selenium con BeautifulSoup para parsing m√°s eficiente\n",
    "3. Aprende sobre proxies y rotaci√≥n de user agents\n",
    "4. Explora Scrapy para proyectos m√°s grandes\n",
    "\n",
    "**¬°Happy Scraping! **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ame",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
